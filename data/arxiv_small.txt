In summary of the research findings presented in this paper, various brain regions are correlated with vocabulary and vocabulary acquisition. Semantic associations for vocabulary seem to be located near brain areas that vary according to the type of vocabulary, e.g. ventral temporal regions important for words for things that can be seen. Semantic processing is believed to be strongly associated with the ANG. Phonological ability has been closely related to the anterior surfaces of the SMG. Pathways through the posterior SMG are thought to link the anterior SMG and the ANG. In vocabulary tasks, mediotemporal structures may be related to long-term memory processing, with left hippocampal and parahippocampal regions related to long-term and working memory, respectively. Precentral structures are associated with phonological retrieval. Furthermore, many more regions of the brain are of interest in vocabulary tasks, particularly in areas important for visual and auditory processing. Furthermore, differences between brain anatomies can be attributed to vocabulary demands of different languages.

In this paper, structural controllability of a leader-follower multi-agent system with multiple leaders is studied from a graph-theoretic point of view. The problem of preservation of structural controllability under simultaneous failures in both the communication links and the agents is investigated. The effects of the loss of agents and communication links on the controllability of an information flow graph are previously studied. In this work, the corresponding results are exploited to introduce some useful indices and importance measures that help characterize and quantify the role of individual links and agents in the controllability of the overall network. Existing results are then extended by considering the effects of losses in both links and agents at the same time. To this end, the concepts of joint r,s-controllability and joint t-controllability are introduced as quantitative measures of reliability for a multi-agent system, and their important properties are investigated. Lastly, the class of jointly critical digraphs is introduced and it is stated that if a digraph is jointly critical, then joint t-controllability is a necessary and sufficient condition for remaining controllable following the failure of any set of links and agents, with cardinality less than t. Various examples are exploited throughout the paper to elaborate on the analytical findings.

We present a Deep Cuboid Detector which takes a consumer-quality RGB image of a cluttered scene and localizes all D cuboids box-like objects. Contrary to classical approaches which fit a D model from low-level cues like corners, edges, and vanishing points, we propose an end-to-end deep learning system to detect cuboids across many semantic categories e.g., ovens, shipping boxes, and furniture. We localize cuboids with a D bounding box, and simultaneously localize the cuboids corners, effectively producing a D interpretation of box-like objects. We refine keypoints by pooling convolutional features iteratively, improving the baseline method significantly. Our deep learning cuboid detector is trained in an end-to-end fashion and is suitable for real-time applications in augmented reality AR and robotics.

In this paper, we study the trade-off between accuracy and speed when building an object detection system based on convolutional neural networks. We consider three main families of detectors --- Faster R-CNN, R-FCN and SSD --- which we view as meta-architectures. Each of these can be combined with different kinds of feature extractors, such as VGG, Inception or ResNet. In addition, we can vary other parameters, such as the image resolution, and the number of box proposals. We develop a unified framework in Tensorflow that enables us to perform a fair comparison between all of these variants. We analyze the performance of many different previously published model combinations, as well as some novel ones, and thus identify a set of models which achieve different points on the speed-accuracy tradeoff curve, ranging from fast models, suitable for use on a mobile phone, to a much slower model that achieves a new state of the art on the COCO detection challenge.

In this paper, we propose a characterization of elementary trapping sets ETSs for irregular low-density parity-check LDPC codes. These sets are known to be the main culprits in the error floor region of such codes. The characterization of ETSs for irregular codes has been known to be a challenging problem due to the large variety of non-isomorphic ETS structures that can exist within the Tanner graph of these codes. This is a direct consequence of the variety of the degrees of the variable nodes that can participate in such structures. The proposed characterization is based on a hierarchical graphical representation of ETSs, starting from simple cycles of the graph, or from single variable nodes, and involves three simple expansion techniques degree-one tree dot, path and lollipop, thus, the terminology em dpl characterization. A similar dpl characterization was proposed in an earlier work by the authors for the leafless ETSs LETSs of variable-regular LDPC codes. The present paper generalizes the prior work to codes with a variety of variable node degrees and to ETSs that are not leafless. The proposed dpl characterization corresponds to an efficient search algorithm that, for a given irregular LDPC code, can find all the instances of a,b ETSs with size a and with the number of unsatisfied check nodes b within any range of interest a leq amax and b leq bmax, exhaustively. Although, brute force exhaustive search algorithms for ETSs of irregular LDPC codes exist, to the best of our knowledge, the proposed search algorithm is the first of its kind, in that, it is devised based on a characterization of ETSs that makes the search process efficient. Extensive simulation results are presented to show the versatility of the search algorithm, and to demonstrate that, compared to the literature, significant improvement in search speed can be obtained.

In this paper, we propose a learning-based supervised discrete hashing method. Binary hashing is widely used for large-scale image retrieval as well as video and document searches because the compact representation of binary code is essential for data storage and reasonable for query searches using bit-operations. The recently proposed Supervised Discrete Hashing SDH efficiently solves mixed-integer programming problems by alternating optimization and the Discrete Cyclic Coordinate descent DCC method. We show that the SDH model can be simplified without performance degradation based on some preliminary experiments we call the approximate model for this the Fast SDH FSDH model. We analyze the FSDH model and provide a mathematically exact solution for it. In contrast to SDH, our model does not require an alternating optimization algorithm and does not depend on initial values. FSDH is also easier to implement than Iterative Quantization ITQ. Experimental results involving a large-scale database showed that FSDH outperforms conventional SDH in terms of precision, recall, and computation time.

Requirements Engineering RE is a critical discipline mostly driven by uncertainty, since it is influenced by the customer domain or by the development process model used. We aim to investigate RE processes in successful project environments to discover characteristics and strategies that allow us to elaborate RE tailoring approaches in the future. We perform a field study on a set of projects at one company. First, we investigate by content analysis which RE artefacts were produced in each project and to what extent they were produced. Second, we perform qualitative analysis of semi-structured interviews to discover project parameters that relate to the produced artefacts. Third, we use cluster analysis to infer artefact patterns and probable RE execution strategies, which are the responses to specific project parameters. Fourth, we investigate by statistical tests the effort spent in each strategy in relation to the effort spent in change requests to evaluate the efficiency of execution strategies. Our results show no statistically significant difference between the efficiency of the strategies. In addition, it turned out that many parameters considered as the main causes for project failures can be successfully handled. Hence, practitioners can apply the artefact patterns and related project parameters to tailor the RE process according to individual project characteristics.

Most requirements engineering RE process improvement approaches are solution-driven and activity-based. They focus on the assessment of the RE of a company against an external norm of best practices. A consequence is that practitioners often have to rely on an improvement approach that skips a profound problem analysis and that results in an RE approach that might be alien to the organisational needs. In recent years, we have developed an RE improvement approach called emphArtREPI that guides a holistic RE improvement against individual goals of a company putting primary attention to the quality of the artefacts. In this paper, we aim at exploring ArtREPIs benefits and limitations. We contribute an industrial evaluation of ArtREPI by relying on a case study research. Our results suggest that ArtREPI is well-suited for the establishment of an RE that reflects a specific organisational culture but to some extent at the cost of efficiency resulting from intensive discussions on a terminology that suits all involved stakeholders. Our results reveal first benefits and limitations, but we can also conclude the need of longitudinal and independent investigations for which we herewith lay the foundation.

Defect models capture faults and methods to provoke failures. To integrate such defect models into existing quality assurance processes, we developed a defect model lifecycle framework, in which the elicitation and classification of context-specific defects forms a crucial step. Although we could gather first insights from its practical application, we still have little knowledge about its benefits and limitations. We aim at qualitatively analyzing the context-specific elicitation and classification of defects to explore the suitability of our approach for practical application. We apply case study research in multiple contexts and analyze  what kind of defects we can elicit and the degree to which the defects matter to a context only,  the extent to which it leads to results useful enough for describing and operationalizing defect models, and  if there is a perceived additional immediate benefit from a practitioners perspective. Our results strengthen our confidence on the suitability of our approach to elicit defects that are context-specific as well as context-independent. We conclude so far that our approach is suitable to provide a blueprint on how to elicit and classify defects for specific contexts to be used for the improvement of quality assurance techniques.

The various influences in the processes and application domains make Requirements Engineering RE inherently complex and difficult to implement. In general, we have two options for establishing an RE approach we can either establish an activity-based RE approach or we can establish an artefact-based one where project participants concentrate on the RE artefacts rather than on the way of creating them. While a number of activity-based RE approaches have been proposed in recent years, we have gained much empirical evidence and experiences about the advantages of the artefact-based paradigm for RE. However, artefact orientation is still a young paradigm with various interpretations and practical manifestations whereby we need a clear understanding of its basic concepts and a consolidated and evaluated view on the paradigm.   In this article, we contribute an artefact-based approach to RE AMDiRE that emerges from six years of experiences in fundamental and evidence-based research. To this end, we first discuss the basic notion of artefact orientation and its evolution in recent years. We briefly introduce a set of artefact-based RE models we developed in industrial research cooperations for different application domains, show their empirical evaluations, and their dissemination into academia and practice, eventually leading to the AMDiRE approach. We conclude with a discussion of experiences we made during the development and different industrial evaluations, and lessons learnt.

Active deep learning classification of hyperspectral images is considered in this paper. Deep learning has achieved success in many applications, but good-quality labeled samples are needed to construct a deep learning network. It is expensive getting good labeled samples in hyperspectral images for remote sensing applications. An active learning algorithm based on a weighted incremental dictionary learning is proposed for such applications. The proposed algorithm selects training samples that maximize two selection criteria, namely representative and uncertainty. This algorithm trains a deep network efficiently by actively selecting training samples at each iteration. The proposed algorithm is applied for the classification of hyperspectral images, and compared with other classification algorithms employing active learning. It is shown that the proposed algorithm is efficient and effective in classifying hyperspectral images.

A patent is a property right for an invention granted by the government to the inventor. An invention is a solution to a specific technological problem. So patents often have a high concentration of scientific and technical terms that are rare in everyday language. The Chinese word segmentation model trained on currently available everyday language data sets performs poorly because it cannot effectively recognize these scientific and technical terms. In this paper we describe a pragmatic approach to Chinese word segmentation on patents where we train a character-based semi-supervised sequence labeling model by extracting features from a manually segmented corpus of  patents, enhanced with information extracted from the Chinese TreeBank. Experiments show that the accuracy of our model reached . F score on a held-out test set and . on development set, compared with an F score of . on development set if the model is trained on the Chinese TreeBank. We also experimented with some existing domain adaptation techniques, the results show that the amount of target domain data and the selected features impact the performance of the domain adaptation techniques.

We present a matrix factorization algorithm that scales to input matrices that are large in both dimensions i.e., that contains morethan TB of data. The algorithm streams the matrix columns while subsampling them, resulting in low complexity per iteration andreasonable memory footprint. In contrast to previous online matrix factorization methods, our approach relies on low-dimensional statistics from past iterates to control the extra variance introduced by subsampling. We present a convergence analysis that guarantees us to reach a stationary point of the problem. Large speed-ups can be obtained compared to previous online algorithms that do not perform subsampling, thanks to the feature redundancy that often exists in high-dimensional settings.

Similarity search over chemical compound databases is a fundamental task in the discovery and design of novel drug-like molecules. Such databases often encode molecules as non-negative integer vectors, called molecular descriptors, which represent rich information on various molecular properties. While there exist efficient indexing structures for searching databases of binary vectors, solutions for more general integer vectors are in their infancy. In this paper we present a time- and space-efficient index for the problem that we call the succinct intervals-splitting tree algorithm for molecular descriptors SITAd. Our approach extends efficient methods for binary-vector databases, and uses ideas from succinct data structures. Our experiments, on a large database of over  million compounds, show SITAd significantly outperforms alternative approaches in practice.

In this viewpoint article, we discuss the electric properties of the medium around neurons, which are important to correctly interpret extracellular potentials or electric field effects in neural tissue. We focus on how these electric properties shape the frequency scaling of brain signals at different scales, such as intracellular recordings, the local field potential LFP, the electroencephalogram EEG or the magnetoencephalogram MEG. These signals display frequency-scaling properties which are not consistent with resistive media. The medium appears to exert a frequency filtering scaling as sqrtf, which is the typical frequency scaling of ionic diffusion. Such a scaling was also found recently by impedance measurements in physiological conditions. Ionic diffusion appears to be the only possible explanation to reconcile these measurements and the frequency-scaling properties found in different brain signals. However, other measurements suggest that the extracellular medium is essentially resistive. To resolve this discrepancy, we show new evidence that metal-electrode measurements can be perturbed by shunt currents going through the surface of the brain. Such a shunt may explain the contradictory measurements, and together with ionic diffusion, provides a framework where all observations can be reconciled. Finally, we propose a method to perform measurements avoiding shunting effects, thus enabling to test the predictions of this framework.

Hadoop MapReduce is a framework for distributed storage and processing of large datasets that is quite popular in big data analytics. It has various configuration parameters knobs which play an important role in deciding the performance i.e., the execution time of a given big data processing job. Default values of these parameters do not always result in good performance and hence it is important to tune them. However, there is inherent difficulty in tuning the parameters due to two important reasons - firstly, the parameter search space is large and secondly, there are cross-parameter interactions. Hence, there is a need for a dimensionality-free method which can automatically tune the configuration parameters by taking into account the cross-parameter dependencies. In this paper, we propose a novel Hadoop parameter tuning methodology, based on a noisy gradient algorithm known as the simultaneous perturbation stochastic approximation SPSA. The SPSA algorithm tunes the parameters by directly observing the performance of the Hadoop MapReduce system. The approach followed is independent of parameter dimensions and requires only  observations per iteration while tuning. We demonstrate the effectiveness of our methodology in achieving good performance on popular Hadoop benchmarks namely emphGrep, emphBigram, emphInverted Index, emphWord Co-occurrence and emphTerasort. Our method, when tested on a  node Hadoop cluster shows  decrease in execution time of Hadoop jobs on an average, when compared to the default configuration. Further, we also observe a reduction of  in execution times, when compared to prior methods.

Predictive models for software projects characteristics have been traditionally based on project-level metrics, employing only little developer-level information, or none at all. In this work we suggest novel metrics that capture temporal and semantic developer-level information collected on a per developer basis. To address the scalability challenges involved in computing these metrics for each and every developer for a large number of source code repositories, we have built a designated repository mining platform. This platform was used to create a metrics dataset based on processing nearly  highly popular open source GitHub repositories, consisting of  million LOC, and maintained by , developers. The computed metrics were then employed to predict the corrective, perfective, and adaptive maintenance activity profiles identified in previous works. Our results show both strong correlation and promising predictive power with R-squared values of ., ., and .. We also show how these results may help project managers to detect anomalies in the development process and to build better development teams. In addition, the platform we built has the potential to yield further predictive models leveraging developer-level metrics at scale.

An efficient algorithm to enumerate the vertices of a two-dimensional D projection of a polytope, is presented in this paper. The proposed algorithm uses the support function of the polytope to be projected and enumerated for vertices. The complexity of our algorithm is linear in the number of vertices of the projected polytope and we show empirically that the performance is significantly better in comparison to some known efficient algorithms of projection and enumeration.

As the world population gets older, the healthcare system must be adapted, among others by providing continuous health monitoring at home and in the city. The social activities have a significant role in everyone health status. Hence, this paper proposes a system to perform a data fusion of signals sampled on several subjects during social activities. This study implies the time synchronization of data coming from several sensors whether these are embedded on people or integrated in the environment. The data fusion is applied to several experiments including physical, cognitive and rest activities, with social aspects. The simultaneous and continuous analysis of four subjects cardiac activity and GPS coordinates provides a new way to distinguish different collaborative activities comparing the measurements between the subjects and along time.

We present and explore a model of stateless and self-stabilizing distributed computation, inspired by real-world applications such as routing on todays Internet. Processors in our model do not have an internal state, but rather interact by repeatedly mapping incoming messages labels to outgoing messages and output values. While seemingly too restrictive to be of interest, stateless computation encompasses both classical game-theoretic notions of strategic interaction and a broad range of practical applications e.g., Internet protocols, circuits, diffusion of technologies in social networks. We embark on a holistic exploration of stateless computation. We tackle two important questions  Under what conditions is self-stabilization, i.e., guaranteed convergence to a legitimate global configuration, achievable for stateless computation? and  What is the computational power of stateless computation? Our results for self-stabilization include a general necessary condition for self-stabilization and hardness results for verifying that a stateless protocol is self-stabilizing. Our main results for the power of stateless computation show that labels of logarithmic length in the number of processors yield substantial computational power even on ring topologies. We present a separation between unidirectional and bidirectional rings Lpoly vs. Ppoly, reflecting the sequential nature of computation on a unidirectional ring, as opposed to the parallelism afforded by the bidirectional ring. We leave the reader with many exciting directions for future research.

The construction of a complex-valued signal is an important step in many time series analysis techniques. In this paper, we model the observable real-valued signal as the real part of a latent complex-valued Gaussian process. To construct a meaningful imaginary part, we impose the constraint that, in expectation, the real and the imaginary part of the covariance function are in quadrature relation. Through an analysis of simulated chirplets and stochastic oscillations, we show that the Gaussian process complex-valued signal provides a much better estimate of the instantaneous amplitude and frequency than the established approaches. Furthermore, the complex-valued Gaussian process regression allows to incorporate prior information about the structure in signal and noise and thereby to tailor the analysis to the features of the signal. As a example, we analyze the non-stationary dynamics of brain oscillations in the alpha band, as measured using magneto-encephalography

With the digital breakthrough, smart phones have become very essential component. Mobile devices are very attractive attack surface for cyber thieves as they hold personal details accounts, locations, contacts, photos and have potential capabilities for eavesdropping with camerasmicrophone, wireless connections. Android, being the most popular, is the target of malicious hackers who are trying to use Android app as a tool to break into and control device. Android malware authors use many anti-analysis techniques to hide from analysis tools. Academic researchers and commercial anti-malware companies are putting great effort to detect such malicious apps. They are making use of the combinations of static, dynamic and behavior based analysis techniques. Despite of all the security mechanisms provided by Android, apps can carry out malicious actions through collusion. In collusion malicious functionality is divided across multiple apps. Each participating app accomplish its part and communicate information to another app through Inter Component Communication ICC. ICC do not require any special permissions. Also, there is no compulsion to inform user about the communication. Each participating app needs to request a minimal set of privileges, which may make it appear benign to current state-of-the-art techniques that analyze one app at a time. There are many surveys on app analysis techniques in Android however they focus on single-app analysis. This survey augments this through focusing only on collusion among multiple-apps. In this paper, we present Android vulnerabilities that may be exploited for a possible collusion attack. We cover the existing threat analysis, scenarios, and a detailed comparison of tools for intra and inter-app analysis. To the best of our knowledge this is the first survey on app collusion and state-of-the-art detection tools in Android.

Context-free and context-sensitive formal grammars are often regarded as more appropriate to model proteins than regular level models such as finite state automata and Hidden Markov Models. In theory, the claim is well founded in the fact that many biologically relevant interactions between residues of protein sequences have a character of nested or crossed dependencies. In practice, there is hardly any evidence that grammars of higher expressiveness have an edge over old good HMMs in typical applications including recognition and classification of protein sequences. This is in contrast to RNA modeling, where CFG power some of the most successful tools. There have been proposed several explanations of this phenomenon. On the biology side, one difficulty is that interactions in proteins are often less specific and more collective in comparison to RNA. On the modeling side, a difficulty is the larger alphabet which combined with high complexity of CF and CS grammars imposes considerable trade-offs consisting on information reduction or learning sub-optimal solutions. Indeed, some studies hinted that CF level of expressiveness brought an added value in protein modeling when CF and regular grammars where implemented in the same framework. However, there have been no systematic study of explanatory power provided by various grammatical models. The first step to this goal is define objective criteria of such evaluation. Intuitively, a decent explanatory grammar should generate topology, or the parse tree, consistent with topology of the protein, or its secondary andor tertiary structure. In this piece of research we build on this intuition and propose a set of measures to compare topology of the parse tree of a grammar with topology of the protein structure.

The trend towards increasingly deep neural networks has been driven by a general observation that increasing depth increases the performance of a network. Recently, however, evidence has been amassing that simply increasing depth may not be the best way to increase performance, particularly given other limitations. Investigations into deep residual networks have also suggested that they may not in fact be operating as a single deep network, but rather as an ensemble of many relatively shallow networks. We examine these issues, and in doing so arrive at a new interpretation of the unravelled view of deep residual networks which explains some of the behaviours that have been observed experimentally. As a result, we are able to derive a new, shallower, architecture of residual networks which significantly outperforms much deeper models such as ResNet- on the ImageNet classification dataset. We also show that this performance is transferable to other problem domains by developing a semantic segmentation approach which outperforms the state-of-the-art by a remarkable margin on datasets including PASCAL VOC, PASCAL Context, and Cityscapes. The architecture that we propose thus outperforms its comparators, including very deep ResNets, and yet is more efficient in memory use and sometimes also in training time. The code and models are available at httpsgithub.comitijyouademxapp

Oblivious transfer OT is an important tool in cryptography. It serves as a subroutine to other complex procedures of both theoretical and practical significance. Common attribute of OT protocols is that one party Alice has to send a message to another party Bob and has to stay oblivious on whether Bob did receive the message. Specific OT protocols vary by exact definition of the task - in the all-or-nothing protocol Alice sends a single bit-string message, which Bob is able to read only with  probability, whereas in -out-of- OT protocol Bob reads one out of two messages sent by Alice. These two flavours of protocol are known to be equivalent. Recently a computationally secure all-or-nothing OT protocol based on quantum states was developed in A. Souto et. al., PRA , , which however cannot be reduced to -out-of- OT protocol by standard means. Here we present an elaborated reduction of this protocol which retains the security of the original.

We propose a construction of de Bruijn sequences by the cycle joining method from linear feedback shift registers LFSRs with arbitrary characteristic polynomial fx. We study in detail the cycle structure of the set Omegafx that contains all sequences produced by a specific LFSR on distinct inputs and provide an efficient way to find a state of each cycle. Our structural results lead to an efficient algorithm to find all conjugate pairs between any two cycles, yielding the adjacency graph. The approach provides a practical method to generate a large class of de Bruijn sequences. Many recently-proposed constructions of de Bruijn sequences are shown to be special cases of our construction.

The right performance of a supply chain depends on the pattern of relationships among firms. Although there is not a general consensus among researchers yet, many studies point that scale-free topologies, where few highly related firms are combined with many low-related firms, assure the highest efficiency of a supply chain. This paper studies the network topology that leads to the highest agility of the supply chain when sudden demand changes occur. To do this, an agent-based model of a supply chain with restricted relationship between agents is built. The model includes three tiers, where the flow of material is distributed from the bottom supplier to the final customer passing necessarily through firms in every tier. Agility is measured in the model simulations through the order fulfillment rate. Unlike to previous theoretical and lab results, the simulation of the model shows that the highest levels of agility are not obtained with a scale-free topology. Instead, homogeneous distribution of links, such as those induced by regular or Poisson probability laws, shows higher agility values than heterogeneous distributions. Other previous recommendations, such as redundancy or having multiple suppliers, are confirmed by the simulations. The general conclusion is that the most suitable network topology in terms of agility depends on the specific conditions of the supply chain and the aspects of the performance to be analyzed.

We present an online deliberation system using mutual evaluation in order to collaboratively develop solutions. Participants submit their proposals and evaluate each others proposals some of them may then be invited by the system to rewrite problematic proposals. Two cases are discussed a proposal supported by many, but not by a given person, who is then invited to rewrite it for making yet more acceptable and a poorly presented but presumably interesting proposal. The first of these cases has been successfully implemented. Proposals are evaluated along two axes-understandability or clarity, or, more generally, quality, and agreement. The latter is used by the system to cluster proposals according to their ideas, while the former is used both to present the best proposals on top of their clusters, and to find poorly written proposals candidates for rewriting. These functionalities may be considered as important components of a large scale online deliberation system.

Privacy has been frequently identified as a main concern for system developers while dealing withmanaging personal information. Despite this, most existing work on privacy requirements deals with them as a special case of security requirements. Therefore, key aspects of privacy are, usually, overlooked. In this context, wrong design decisions might be made due to insufficient understanding of privacy concerns. In this paper, we address this problem with a systematic literature review whose main purpose is to identify the main conceptsrelations for capturing privacy requirements. In addition, the identified conceptsrelations are further analyzed to propose a novel privacy ontology to be used by software engineers when dealing with privacy requirements.

The interest in the properties of edge states in Chern insulators and in mathbbZ topological insulator has increased rapidly in recent years. We present calculations on how to influence the transport properties of chiral and helical edge states by modifications of the edges in the Haldane and in the Kane-Mele model. The Fermi velocity of the chiral edge states becomes direction-dependent as does the spin-dependent Fermi velocity of the helical edge states. Moreover, it is possible to tune the Fermi velocity by orders of magnitude. Additionally, we explicitly investigate the robustness of edge states against local disorder. The edge states can be reconstructed in the Brillouin zone in presence of disorder. The influence of the width and of the length of the system is studied as well as the dependence on the strength of the disorder.

In this paper, we propose a novel approach for verification of on-line signatures based on user dependent feature selection and symbolic representation. Unlike other signature verification methods, which work with same features for all users, the proposed approach introduces the concept of user dependent features. It exploits the typicality of each and every user to select different features for different users. Initially all possible features are extracted for all users and a method of feature selection is employed for selecting user dependent features. The selected features are clustered using Fuzzy C means algorithm. In order to preserve the intra-class variation within each user, we recommend to represent each cluster in the form of an interval valued symbolic feature vector. A method of signature verification based on the proposed cluster based symbolic representation is also presented. Extensive experimentations are conducted on MCYT- User DB and MCYT- User DB online signature data sets to demonstrate the effectiveness of the proposed novel approach.

Quantum technologies hold the promise of not only faster algorithmic processing of data, via quantum computation, but also of more secure communications, in the form of quantum cryptography. In recent years, a number of protocols have emerged which seek to marry these concepts for the purpose of securing computation rather than communication. These protocols address the task of securely delegating quantum computation to an untrusted device while maintaining the privacy, and in some instances the integrity, of the computation. We present a review of the progress to date in this emerging area.

Emotion estimation in music listening is confronting challenges to capture the emotion variation of listeners. Recent years have witnessed attempts to exploit multimodality fusing information from musical contents and physiological signals captured from listeners to improve the performance of emotion recognition. In this paper, we present a study of fusion of signals of electroencephalogram EEG, a tool to capture brainwaves at a high-temporal resolution, and musical features at decision level in recognizing the time-varying binary classes of arousal and valence. Our empirical results showed that the fusion could outperform the performance of emotion recognition using only EEG modality that was suffered from inter-subject variability, and this suggested the promise of multimodal fusion in improving the accuracy of music-emotion recognition.

This paper aims to provide a comprehensive modeling and representation of etymological data in digital dictionaries. The purpose is to integrate in one coherent framework both digital representations of legacy dictionaries, and also born-digital lexical databases that are constructed manually or semi-automatically. We want to propose a systematic and coherent set of modeling principles for a variety of etymological phenomena that may contribute to the creation of a continuum between existing and future lexical constructs, where anyone interested in tracing the history of words and their meanings will be able to seamlessly query lexical resources.Instead of designing an ad hoc model and representation language for digital etymological data, we will focus on identifying all the possibilities offered by the TEI guidelines for the representation of lexical information.

Multi-group multicast beamforming in wireless systems with large antenna arrays and massive audience is investigated in this paper. Multicast beamforming design is a well-known non-convex quadratically constrained quadratic programming QCQP problem. A conventional method to tackle this problem is to approximate it as a semi-definite programming problem via semi-definite relaxation, whose performance, however, deteriorates considerably as the number of per-group users goes large. A recent attempt is to apply convex-concave procedure CCP to find a stationary solution by treating it as a difference of convex programming problem, whose complexity, however, increases dramatically as the problem size increases. In this paper, we propose a low-complexity high-performance algorithm for multi-group multicast beamforming design in large-scale wireless systems by leveraging the alternating direction method of multipliers ADMM together with CCP. In specific, the original non-convex QCQP problem is first approximated as a sequence of convex subproblems via CCP. Each convex subproblem is then reformulated as a novel ADMM form. Our ADMM reformulation enables that each updating step is performed by solving multiple small-size subproblems with closed-form solutions in parallel. Numerical results show that our fast algorithm maintains the same favorable performance as state-of-the-art algorithms but reduces the complexity by orders of magnitude.

We consider the following combinatorial search problem we are given some excellent elements of n and we should find at least one, asking questions of the following type Is there an excellent element in A subset n?. G.O.H. Katona proved sharp results for the number of questions needed to ask in the adaptive, non-adaptive and two-round versions of this problem.   We verify a conjecture of Katona by proving that in the r-round version we need to ask rnrO queries for fixed r and this is sharp.   We also prove bounds for the queries needed to ask if we want to find at least d excellent elements.

This letter considers the problem of sparse signal reconstruction from the timing of its Level Crossings LCs. We formulate the sparse Zero Crossing ZC reconstruction problem in terms of a single -bit Compressive Sensing CS model. We also extend the Smoothed L SL sparse reconstruction algorithm to the -bit CS framework and propose the Binary SL BSL algorithm for iterative reconstruction of the sparse signal from ZCs in cases where the number of sparse coefficients is not known to the reconstruction algorithm a priori. Similar to the ZC case, we propose a system of simultaneously constrained signed-CS problems to reconstruct a sparse signal from its Level Crossings LCs and modify both the Binary Iterative Hard Thresholding BIHT and BSL algorithms to solve this problem. Simulation results demonstrate superior performance of the proposed LC reconstruction techniques in comparison with the literature.

Bit-vector formulas arising from hardware verification problems often contain word-level arithmetic operations. Empirical evidence shows that state-of-the-art SMT solvers are not very efficient at reasoning about bit-vector formulas with multiplication. This is particularly true when multiplication operators are decomposed and represented in alternative ways in the formula.We present a pre-processing heuristic that identifies certain types of decomposed multipliers, and adds special assertions to the input formula encoding the equivalence of sub-terms to word-level multiplication. The pre-processed formulas are then solved using an SMT solver. Our experiments with three SMT solvers show that our heuristic allows several formulas to be solved quickly, while the same formulas time out without the pre-processing step.

Facial landmark detection is an important but challenging task for real-world computer vision applications. This paper proposes an accurate and robust approach for facial landmark detection by combining data-driven and model-driven methods. Firstly, a fully convolutional network FCN is trained to generate response maps of all facial landmark points. Such a data-driven method can make full use of holistic information in a facial image for global estimation of facial landmarks. Secondly, the maximum points in the response maps are fitted with a pre-trained point distribution model PDM to generate initial facial landmark shape. Such a model-driven method can correct the location errors of outliers by considering shape prior information. Thirdly, a weighted version of Regularized Landmark Mean-Shift RLMS is proposed to fine-tune facial landmark shapes iteratively. The weighting strategy is based on the confidence of convolutional response maps so that FCN is integrated into the framework of Constrained Local Model CLM. Such an Estimation-Correction-Tuning process perfectly combines the global robustness advantage of data-driven method FCN, outlier correction advantage of model-driven method PDM and non-parametric optimization advantage of RLMS. The experimental results demonstrate that the proposed approach outperforms state-of-the-art solutions on the -W dataset. Our approach is well-suited for face images with large poses, exaggerated expression, and occlusions.

We present an alternative voting system that aims at bridging the gap between proportional representative systems and majoritarian, single winner election systems. The system lets people vote for multiple parties, but then assigns each ballot to a single party. This opens a whole range of possible systems, all representative. We show theoretically that this space is convex. Then among the possible parliaments we present an algorithm to produce the most majoritarian result. We then test the system and compare the results with a pure proportional and a majoritarian voting system showing how the results are comparable with the majoritarian system. Then we simulate the system and show how it tends to produce parties of exponentially decreasing size with always a first, major party. Finally we describe how the system can be used in a context of a parliament made up of two separate houses.

A bridge in a graph is an edge whose removal disconnects the graph and increases the number of connected components. We calculate the fraction of bridges in a wide range of real-world networks and their randomized counterparts. We find that real networks typically have more bridges than their completely randomized counterparts, but very similar fraction of bridges as their degree-preserving randomizations. We define a new edge centrality measure, called bridgeness, to quantify the importance of a bridge in damaging a network. We find that certain real networks have very large average and variance of bridgeness compared to their degree-preserving randomizations and other real networks. Finally, we offer an analytical framework to calculate the bridge fraction , the average and variance of bridgeness for uncorrelated random networks with arbitrary degree distributions.

There are repetitive patterns in strategies of manipulating source code. For example, modifying source code before acquiring knowledge of how a code works is a depth-first style and reading and understanding before modifying source code is a breadth-first style. To the extent we know there is no study on the influence of personality on them. The objective of this study is to understand the influence of personality on programming styles. We did a correlational study with  programmers at the University of Stuttgart. Academic achievement, programming experience, attitude towards programming and five personality factors were measured via self-assessed survey. The programming styles were asked in the survey or mined from the software repositories. Performance in programming was composed of bug-proneness of programmers which was mined from software repositories, the grades they got in a software project course and their estimate of their own programming ability. We did statistical analysis and found that Openness to Experience has a positive association with breadth-first style and Conscientiousness has a positive association with depth-first style. We also found that in addition to having more programming experience and better academic achievement, the styles of working depth-first and saving coarse-grained revisions improve performance in programming.

We present a new algorithm for boosting generalized additive models for location, scale and shape GAMLSS that allows to incorporate stability selection, an increasingly popular way to obtain stable sets of covariates while controlling the per-family error rate PFER. The model is fitted repeatedly to subsampled data and variables with high selection frequencies are extracted. To apply stability selection to boosted GAMLSS, we develop a new noncyclical fitting algorithm that incorporates an additional selection step of the best-fitting distribution parameter in each iteration. This new algorithms has the additional advantage that optimizing the tuning parameters of boosting is reduced from a multi-dimensional to a one-dimensional problem with vastly decreased complexity. The performance of the novel algorithm is evaluated in an extensive simulation study. We apply this new algorithm to a study to estimate abundance of common eider in Massachusetts, USA, featuring excess zeros, overdispersion, non-linearity and spatio-temporal structures. Eider abundance is estimated via boosted GAMLSS, allowing both mean and overdispersion to be regressed on covariates. Stability selection is used to obtain a sparse set of stable predictors.

Reducing bit-widths of weights, activations, and gradients of a Neural Network can shrink its storage size and memory usage, and also allow for faster training and inference by exploiting bitwise operations. However, previous attempts for quantization of RNNs show considerable performance degradation when using low bit-width weights and activations. In this paper, we propose methods to quantize the structure of gates and interlinks in LSTM and GRU cells. In addition, we propose balanced quantization methods for weights to further reduce performance degradation. Experiments on PTB and IMDB datasets confirm effectiveness of our methods as performances of our models match or surpass the previous state-of-the-art of quantized RNN.

Context Software quality is a complex concept. Therefore, assessing and predicting it is still challenging in practice as well as in research. Activity-based quality models break down this complex concept into concrete definitions, more precisely facts about the system, process, and environment as well as their impact on activities performed on and with the system. However, these models lack an operationalisation that would allow them to be used in assessment and prediction of quality. Bayesian networks have been shown to be a viable means for this task incorporating variables with uncertainty. Objective The qualitative knowledge contained in activity-based quality models are an abundant basis for building Bayesian networks for quality assessment. This paper describes a four-step approach for deriving systematically a Bayesian network from an assessment goal and a quality model. Method The four steps of the approach are explained in detail and with running examples. Furthermore, an initial evaluation is performed, in which data from NASA projects and an open source system is obtained. The approach is applied to this data and its applicability is analysed. Results The approach is applicable to the data from the NASA projects and the open source system. However, the predictive results vary depending on the availability and quality of the data, especially the underlying general distributions. Conclusion The approach is viable in a realistic context but needs further investigation in case studies in order to analyse its predictive validity.

Assessing and predicting the complex concept of software quality is still challenging in practice as well as research. Activity-based quality models break down this complex con- cept into more concrete definitions, more precisely facts about the system, process and environment and their impact on ac- tivities performed on and with the system. However, these models lack an operationalisation that allows to use them in assessment and prediction of quality. Bayesian Networks BN have been shown to be a viable means for assessment and prediction incorporating variables with uncertainty. This paper describes how activity-based quality models can be used to derive BN models for quality assessment and pre- diction. The proposed approach is demonstrated in a proof of concept using publicly available data.

We consider a system in which there exists two ISPs, one big Content Provider CP, and a continuum of End-Users EUs. One of the ISPs is neutral and the other is non-neutral. We consider that the CP can differentiate between ISPs by controlling the quality of the content she is offering on each one. We also consider that EUs have different levels of innate preferences for ISPs. We formulate a sequential game, and explicitly characterize all the possible Sub-game Perfect Nash Equilibria SPNE of the game. We prove that if an SPNE exists, it would be one of the five possible strategies each of which we explicitly characterize. We prove that when EUs have sufficiently low innate preferences for ISPs, a unique SPNE exists in which the neutral ISP would be driven out of the market. We also prove that when these preferences are sufficiently high, there exists a unique SPNE with a non-neutral outcome in which both ISPs are active. Numerical results reveal that the neutral ISP receives a lower payoff and the non-neutral ISP receives a higher payoff most of the time in a non-neutral scenario. However, we identify scenarios in which the non-neutral ISP loses payoff by adopting non-neutrality. We also show that a non-neutral regime yields a higher welfare for EUs in comparison to a neutral one if the market power of the non-neutral ISP is small, the sensitivity of EUs respectively, the CP to the quality is low respectively, high, or a combinations of these factors.

Fast and accurate upper-body and head pose estimation is a key task for automatic monitoring of driver attention, a challenging context characterized by severe illumination changes, occlusions and extreme poses. In this work, we present a new deep learning framework for head localization and pose estimation on depth images. The core of the proposal is a regression neural network, called POSEidon, which is composed of three independent convolutional nets followed by a fusion layer, specially conceived for understanding the pose by depth. In addition, to recover the intrinsic value of face appearance for understanding head position and orientation, we propose a new Face-from-Depth approach for learning image faces from depth. Results in face reconstruction are qualitatively impressive. We test the proposed framework on two public datasets, namely Biwi Kinect Head Pose and ICT-DHP, and on Pandora, a new challenging dataset mainly inspired by the automotive setup. Results show that our method overcomes all recent state-of-art works, running in real time at more than  frames per second.

We initiate the study of a new problem on em searching and fetching in a distributed environment concerning emphtreasure-evacuation from a unit disk. A treasure and an exit are located at unknown positions on the perimeter of a disk and at known arc distance. A team of two robots start from the center of the disk, and their goal is to fetch the treasure to the exit. At any time the robots can move anywhere they choose on the disk, independently of each other, with the same speed. A robot detects an interesting point treasure or exit only if it passes over the exact location of that point. We are interested in designing distributed algorithms that minimize the worst-case treasure-evacuation time, i.e. the time it takes for the treasure to be discovered and brought fetched to the exit by any of the robots.   The communication protocol between the robots is either em wireless, where information is shared at any time, or em face-to-face i.e. non-wireless, where information can be shared only if the robots meet. For both models we obtain upper bounds for fetching the treasure to the exit. Our main technical contribution pertains to the face-to-face model. More specifically, we demonstrate how robots can exchange information without meeting, effectively achieving a highly efficient treasure-evacuation protocol which is minimally affected by the lack of distant communication. Finally, we complement our positive results above by providing a lower bound in the face-to-face model.

We study the sampling of spatial fields using sensors that are location-unaware but deployed according to a known statistical distribution. It has been shown that uniformly distributed location-unaware sensors cannot infer bandlimited fields due to the symmetry and shift-invariance of the field.   This work studies asymmetric nonuniform distributions on location-unaware sensors that will enable bandlimited field inference. For the sake of analytical tractability, location-unaware sensors are restricted to a discrete grid. Oversampling followed by clustering of the samples using the probability distribution that governs sensor placement on the grid is used to infer the field . Based on this clustering algorithm, the main result of this work is to find the optimal probability distribution on sensor locations that minimizes the detection error-probability of the underlying spatial field. The proposed clustering algorithm is also extended to include the case of signal reconstruction in the presence of sensor noise by treating the distribution of the noisy samples as a mixture model and using clustering to estimate the mixture model parameters.

We examine the determinization of monitors for HML with recursion. We demonstrate that every monitor is equivalent to a deterministic one, which is at most doubly exponential in size with respect to the original monitor. When monitors are described as CCS-like processes, this doubly exponential bound is optimal. When deterministic monitors are described as finite automata as their LTS, then they can be exponentially more succinct than their CCS process form.

We devise the Unit Commitment Nearest Neighbor UCNN algorithm to be used as a proxy for quickly approximating outcomes of short-term decisions, to make tractable hierarchical long-term assessment and planning for large power systems. Experimental results on an updated version of IEEE-RTS show high accuracy measured on operational cost, achieved in run-times that are lower in several orders of magnitude than the traditional approach.

A large body of work in behavioral fields attempts to develop models that describe the way people, as opposed to rational agents, make decisions. A recent Choice Prediction Competition  challenged researchers to suggest a model that captures  classic choice biases and can predict human decisions under risk and ambiguity. The competition focused on simple decision problems, in which human subjects were asked to repeatedly choose between two gamble options.   In this paper we present our approach for predicting human decision behavior we suggest to use machine learning algorithms with features that are based on well-established behavioral theories. The basic idea is that these psychological features are essential for the representation of the data and are important for the success of the learning process. We implement a vanilla model in which we train SVM models using behavioral features that rely on the psychological properties underlying the competition baseline model. We show that this basic model captures the  choice biases and outperforms all the other learning-based models in the competition. The preliminary results suggest that such hybrid models can significantly improve the prediction of human decision making, and are a promising direction for future research.

We propose a novel method for stereo estimation, combining advantages of convolutional neural networks CNNs and optimization-based approaches. The optimization, posed as a conditional random field CRF, takes local matching costs and consistency-enforcing smoothness costs as inputs, both estimated by CNN blocks. To perform the inference in the CRF we use an approach based on linear programming relaxation with a fixed number of iterations. We address the challenging problem of training this hybrid model end-to-end. We show that in the discriminative formulation structured support vector machine the training is practically feasible. The trained hybrid model with shallow CNNs is comparable to state-of-the-art deep models in both time and performance. The optimization part efficiently replaces sophisticated and not jointly trainable but commonly applied post-processing steps by a trainable, well-understood model.

Mobile devices have become ubiquitous due to centralization of private user information, contacts, messages and multiple sensors. Google Android, an open-source mobile Operating System OS, is currently the market leader. Android popularity has motivated the malware authors to employ set of cyber attacks leveraging code obfuscation techniques. Obfuscation is an action that modifies an application app code, preserving the original semantics and functionality to evade anti-malware. Code obfuscation is a contentious issue. Theoretical code analysis techniques indicate that, attaining a verifiable and secure obfuscation is impossible. However, obfuscation tools and techniques are popular both among malware developers to evade anti-malware and commercial software developers protect intellectual rights. We conducted a survey to uncover answers to concrete and relevant questions concerning Android code obfuscation and protection techniques. The purpose of this paper is to review code obfuscation and code protection practices, and evaluate efficacy of existing code de-obfuscation tools. In particular, we discuss Android code obfuscation methods, custom app protection techniques, and various de-obfuscation methods. Furthermore, we review and analyse the obfuscation techniques used by malware authors to evade analysis efforts. We believe that, there is a need to investigate efficiency of the defense techniques used for code protection. This survey would be beneficial to the researchers and practitioners, to understand obfuscation and de-obfuscation techniques to propose novel solutions on Android.

We consider the problem of parametric statistical inference when likelihood computations are prohibitively expensive but sampling from the model is possible. Several so-called likelihood-free methods have been developed to perform inference in the absence of a likelihood function. The popular synthetic likelihood approach infers the parameters by modelling summary statistics of the data by a Gaussian probability distribution. In another popular approach called approximate Bayesian computation, the inference is performed by identifying parameter values for which the summary statistics of the simulated data are close to those of the observed data. Synthetic likelihood is easier to use as no measure of closeness is required but the Gaussianity assumption is often limiting. Moreover, both approaches require judiciously chosen summary statistics. We here present an alternative inference approach that is as easy to use as synthetic likelihood but not as restricted in its assumptions, and that, in a natural way, enables automatic selection of relevant summary statistic from a large set of candidates. The basic idea is to frame the problem of estimating the posterior as a problem of estimating the ratio between the data generating distribution and the marginal distribution. This problem can be solved by logistic regression, and including regularising penalty terms enables automatic selection of the summary statistics relevant to the inference task. We illustrate the general theory on toy problems and use it to perform inference for stochastic nonlinear dynamical systems.

In the data deluge context, pattern recognition or labeling in streams is becoming quite an essential and pressing task as data flows inside always bigger streams. The assessment of such tasks is not so easy when dealing with temporal data, namely patterns that have a duration a beginning and an end time-stamp. This paper details an approach based on an editing distance to first align a sequence of labeled temporal segments with a ground truth sequence, and then, by back-tracing an optimal alignment path, to provide a confusion matrix at the label level. From this confusion matrix, standard evaluation measures can easily be derived as well as other measures such as the latency that can be quite important in early pattern detection applications.

With the fifth generation G of mobile broadband systems, Radio Resources Management RRM will reach unprecedented levels of complexity. To cope with the higher complexity of RRM functionalities, while retaining the fast execution required in G, this manuscript presents a lean G RRM architecture that capitalizes on the most recent advances in the field of machine learning in combination with the large amount of data readily available in the network from measurements and system observations. The result is a general-purpose learning framework capable of generating algorithms specialized to RRM functionalities directly from data gathered in the network. The potential of this approach is verified in three study cases and future directions on applications of machine learning to RRM are discussed.

We give the first dimension-efficient algorithms for learning Rectified Linear Units ReLUs, which are functions of the form mathbfx mapsto max, mathbfw cdot mathbfx with mathbfw in mathbbSn-. Our algorithm works in the challenging Reliable Agnostic learning model of Kalai, Kanade, and Mansour  where the learner is given access to a distribution calD on labeled examples but the labeling may be arbitrary. We construct a hypothesis that simultaneously minimizes the false-positive rate and the loss on inputs given positive labels by calD, for any convex, bounded, and Lipschitz loss function.   The algorithm runs in polynomial-time in n with respect to any distribution on mathbbSn- the unit sphere in n dimensions and for any error parameter epsilon  Omegalog n this yields a PTAS for a question raised by F. Bach on the complexity of maximizing ReLUs. These results are in contrast to known efficient algorithms for reliably learning linear threshold functions, where epsilon must be Omega and strong assumptions are required on the marginal distribution. We can compose our results to obtain the first set of efficient algorithms for learning constant-depth networks of ReLUs.   Our techniques combine kernel methods and polynomial approximations with a dual-loss approach to convex programming. As a byproduct we obtain a number of applications including the first set of efficient algorithms for convex piecewise-linear fitting and the first efficient algorithms for noisy polynomial reconstruction of low-weight polynomials on the unit sphere.

In this paper we study oriented bipartite graphs. In particular, several characterizations of bitournaments are obtained. We introduce the concept of odd-even graphs and show that any oriented bipartite graph can be represented by some oriented odd-even graph. We show that the famous Goldbachs conjecture is equivalent to the connectedness of certain odd-even graphs.

This work concerns with the n-fold binary asymmetric channels mboxBACn. An equivalence relation between two channels can be characterized by both having the same decision criterion when maximum likelihood is considered. We introduce here a function mathcalS the BAC-function such that the parameters p,q of the binary channel which determine equivalent channels belong to certain region delimited by its level curves. Explicit equations determining these regions are given and the number of different mboxBACn classes is determined. A discusion on the size of these regions is also presented.

In this paper we consider the class of lambda-nondeterministic linear automata as a model of the class of linear languages. As usual in other automata models, lambda-moves do not increase the acceptance power. The main contribution of this paper is to introduce the deterministic linear automata and even linear automata, i.e. the natural restriction of nondeterministic linear automata for the deterministic and even linear language classes, respectively. In particular, there are different, but not equivalents, proposals for the class of deterministic linear languages. We proved here that the class of languages accepted by the deterministic linear automata are not contained in any of the these classes and in fact they properly contain these classes. Another, contribution is the generation of an infinite hierarchy of formal languages, going from the class of languages accepted by deterministic linear automata and achieved, in the limit, the class of linear languages.

Popular approaches to topic modeling often invoke the use of probabilistic generative models, such as Latent Dirichlet Allocation LDA. While such models have enjoyed widespread use and proven fruitful, these models or generalizing them to incorporate human input requires detailed and often unrealistic assumptions about the data generating process. We introduce a new approach to topic modeling via Correlation Explanation CorEx, which leverages an information-theoretic framework to bypass typical topic modeling assumptions. Using two challenging, real-world datasets, we demonstrate that CorEx yields results that are comparable to LDA in terms of semantic coherence and document classification. We then devise a flexible methodology for incorporating word-level domain knowledge into CorEx by introducing anchor words in a manner reminiscent of the information bottleneck. Augmenting CorEx with anchor words allows the topic model to be guided with minimal human intervention towards topics that do not naturally emerge. Furthermore, we show that these new topics are often highly coherent and act as better predictors in document classification.

Motivated by models of human decision making proposed to explain commonly observed deviations from conventional expected value preferences, we formulate two stochastic multi-armed bandit problems with distorted probabilities on the cost distributions the classic K-armed bandit and the linearly parameterized bandit. In both settings, we propose algorithms that are inspired by Upper Confidence Bound UCB, incorporate cost distortions, and exhibit sublinear regret assuming holder continuous weight distortion functions. For the K-armed setting, we show that the algorithm, called W-UCB, achieves problem-dependent regret OL M log n Deltafracalpha-, where n is the number of plays, Delta is the gap in distorted expected value between the best and next best arm, L and alpha are the Holder constants for the distortion function, and M is an upper bound on costs, and a problem-independent regret bound of OKLMalphan-alpha. We also present a matching lower bound on the regret, showing that the regret of W-UCB is essentially unimprovable over the class of Holder-continuous weight distortions. For the linearly parameterized setting, we develop a new algorithm, a variant of the Optimism in the Face of Uncertainty Linear bandit OFUL algorithm called WOFUL Weight-distorted OFUL, and show that it has regret Odsqrtn  mboxpolylogn with high probability, for sub-Gaussian cost distributions. Finally, numerical examples demonstrate the advantages resulting from using distortion-aware learning algorithms.

In this paper queue stability in a single-hop wireless multicast networks over erasure channels is analyzed. First, a queuing model consisting of several sub-queues is introduced. Under the queueing stability constraint, we adopt Lyapunov optimization model and define decision variables to derive a network coding based packet scheduling algorithm, which has significantly less complexity and shorter queue size compared with the existing solutions. Further, the proposed algorithm is modified to meet the requirements of time-critical data. Finally, the simulation results verify the effectiveness of our proposed algorithm.

Influential node detection is a central research topic in social network analysis. Many existing methods rely on the assumption that the network structure is completely known textita priori. However, in many applications, network structure is unavailable to explain the underlying information diffusion phenomenon. To address the challenge of information diffusion analysis with incomplete knowledge of network structure, we develop a multi-task low rank linear influence model. By exploiting the relationships between contagions, our approach can simultaneously predict the volume i.e. time series prediction for each contagion or topic and automatically identify the most influential nodes for each contagion. The proposed model is validated using synthetic data and an ISIS twitter dataset. In addition to improving the volume prediction performance significantly, we show that the proposed approach can reliably infer the most influential users for specific contagions.

Faster-than-Nyquist FTN signal can achieve higher spectral efficiency and capacity than Nyquist signal. For Nyquist signal, the capacity limit was shown in the pioneering work of Shannon. However, different from Nyquist signal, FTN signal has a smaller pulse interval or narrower subcarrier spacing. What is the capacity limit of FTN signal? In this paper, to the best of our knowledge, we first give the mathematical expression for the capacity limit of FTN non-orthogonal frequency-division multiplexing NOFDM signal, which can be also applied to FTN non-orthogonal time-division multiplexing signal. The mathematical expression shows that the capacity limit for FTN signal is higher than Shannon limit for Nyquist signal. Meanwhile, we demonstrate the principle of FTN NOFDM by taking fractional cosine transform-based NOFDM FrCT-NOFDM for instance. As far as we know, FrCT-NOFDM is first proposed in this paper. The simulations and experiments have been demonstrated to verify the feasibility of FrCT-NOFDM. When the bandwidth compression factor alpha is set to ., the subcarrier spacing is equal to  of the symbol rate per subcarrier. The transmission rate is about  faster than Nyquist rate and the capacity limit is  higher than Shannon limit.

The outcome of many social and economic interactions, such as stock-market transactions, is strongly determined by the predictions that agents make about the behavior of other individuals. Cognitive Hierarchy Theory provides a framework to model the consequences of forecasting accuracy that has proven to fit data from certain types of game theory experiments, such as Keynesian Beauty Contests and Entry Games. Here, we focus on symmetric two-players-two-actions games and establish an algorithm to find the players strategies according to the Cognitive Hierarchy Approach. We show that the Snowdrift Game exhibits a pattern of behavior whose complexity grows as the cognitive levels of players increases. In addition to finding the solutions up to the third cognitive level, we demonstrate, in this theoretical frame, two new properties of snowdrift games i any snowdrift game can be characterized by only a parameter -- its class, ii they are anti-symmetric with respect to the diagonal of the pay-offs space. Finally, we propose a model based on an evolutionary dynamics that captures the main features of the Cognitive Hierarchy Theory.

This paper introduces a novel approach for generating GIFs called Synchronized Deep Recurrent Attentive Writer Sync-DRAW. Sync-DRAW employs a Recurrent Variational Autoencoder R-VAE and an attention mechanism in a hierarchical manner to create a temporally dependent sequence of frames that are gradually formed over time. The attention mechanism in Sync-DRAW attends to each individual frame of the GIF in sychronization, while the R-VAE learns a latent distribution for the entire GIF at the global level. We studied the performance of our Sync-DRAW network on the Bouncing MNIST GIFs Dataset and also, the newly available TGIF dataset. Experiments have suggested that Sync-DRAW is efficient in learning the spatial and temporal information of the GIFs and generates frames where objects have high structural integrity. Moreover, we also demonstrate that Sync-DRAW can be extended to even generate GIFs automatically given just text captions.

This work studies the behavior of state-of-the-art memory controller designs when executing scale-out workloads. It considers memory scheduling techniques, memory page management policies, the number of memory channels, and the address mapping scheme used. Experimental measurements demonstrate Several recently proposed memory scheduling policies are not a good match for these scale-out workloads. The relatively simple First-Ready-First-Come-First-Served FR-FCFS policy performs consistently better, and for most of the studied workloads, the even simpler First-Come-First-Served scheduling policy is within  of FR-FCFS. Increasing the number of memory channels offers negligible performance benefits, e.g., performance improves by . on average for -channels vs. -channel. - of DRAM rows activations are accessed only once before closure. These observation can guide future development and optimization of memory controllers for scale-out workloads.

We classify the computational complexity of the popular video games Portal and Portal . We isolate individual mechanics of the game and prove NP-hardness, PSPACE-completeness, or pseudopolynomiality depending on the specific game mechanics allowed. One of our proofs generalizes to prove NP-hardness of many other video games such as Half-Life , Halo, Doom, Elder Scrolls, Fallout, Grand Theft Auto, Left  Dead, Mass Effect, Deus Ex, Metal Gear Solid, and Resident Evil.   These results build on the established literature on the complexity of video games.

This paper presents a concept of a novel method for adjusting hyper-parameters in Deep Learning DL algorithms. An external agent-observer monitors a performance of a selected Deep Learning algorithm. The observer learns to model the DL algorithm using a series of random experiments. Consequently, it may be used for predicting a response of the DL algorithm in terms of a selected quality measurement to a set of hyper-parameters. This allows to construct an ensemble composed of a series of evaluators which constitute an observer-assisted architecture. The architecture may be used to gradually iterate towards to the best achievable quality score in tiny steps governed by a unit of progress. The algorithm is stopped when the maximum number of steps is reached or no further progress is made.

We show how the classic Cramer-Rao bound limits how accurately one can simultaneously estimate values of a large number of Google Ad campaigns or similarly limit the measurement rate of many confounding AB tests.

Constructor rewriting systems are said to be cons-free if, roughly, constructor terms in the right-hand sides of rules are subterms of the left-hand sides the computational intuition is that rules cannot build new data structures. In programming language research, cons-free languages have been used to characterize hierarchies of computational complexity classes in term rewriting, cons-free first-order TRSs have been used to characterize the class PTIME. We investigate cons-free higher-order term rewriting systems, the complexity classes they characterize, and how these depend on the type order of the systems. We prove that, for every K geq , left-linear cons-free systems with type order K characterize EKTIME if unrestricted evaluation is used i.e., the system does not have a fixed reduction strategy. The main difference with prior work in implicit complexity is that i our results hold for non-orthogonal term rewriting systems with no assumptions on reduction strategy, and ii results for cons-free term rewriting systems have previously only been obtained for K  , and with additional syntactic restrictions besides cons-freeness and left-linearity. Our results are among the first implicit characterizations of the hierarchy E  ETIME subsetneq ETIME subsetneq ... Our work confirms prior results that having full non-determinism via overlapping rules does not directly allow characterization of non-deterministic complexity classes like NE. We also show that non-determinism makes the classes characterized highly sensitive to minor syntactic changes like admitting product types or non-left-linear rules.

-D image registration, which involves aligning two or more images, is a critical step in a variety of medical applications from diagnosis to therapy. Image registration is commonly performed by optimizing an image matching metric as a cost function. However, this task is challenging due to the non-convex nature of the matching metric over the plausible registration parameter space and insufficient approaches for a robust optimization. As a result, current approaches are often customized to a specific problem and sensitive to image quality and artifacts. In this paper, we propose a completely different approach to image registration, inspired by how experts perform the task. We first cast the image registration problem as a strategy learning process, where the goal is to find the best sequence of motion actions e.g. up, down, etc. that yields image alignment. Within this approach, an artificial agent is learned, modeled using deep convolutional neural networks, with D raw image data as the input, and the next optimal action as the output. To cope with the dimensionality of the problem, we propose a greedy supervised approach for an end-to-end training, coupled with attention-driven hierarchical strategy. The resulting registration approach inherently encodes both a data-driven matching metric and an optimal registration strategy policy. We demonstrate, on two -D-D medical image registration examples with drastically different nature of challenges, that the artificial agent outperforms several state-of-art registration methods by a large margin in terms of both accuracy and robustness.

Service level agreement SLA is an essential part of cloud systems to ensure maximum availability of services for customers. With a violation of SLA, the provider has to pay penalties. In this paper, we explore two machine learning models Naive Bayes and Random Forest Classifiers to predict SLA violations. Since SLA violations are a rare event in the real world . , the classification task becomes more challenging. In order to overcome these challenges, we use several re-sampling methods. We find that random forests with SMOTE-ENN re-sampling have the best performance among other methods with the accuracy of .  and F score of ..

This paper presents a novel filter with low computational demand to address the problem of orientation estimation of a robotic platform. This is conventionally addressed by extended Kalman filtering of measurements from a sensor suit which mainly includes accelerometers, gyroscopes, and a digital compass. Low cost robotic platforms demand simpler and computationally more efficient methods to address this filtering problem. Hence nonlinear observers with constant gains have emerged to assume this role. The nonlinear complementary filter is a popular choice in this domain which does not require covariance matrix propagation and associated computational overhead in its filtering algorithm. However, the gain tuning procedure of the complementary filter is not optimal, where it is often hand picked by trial and error. This process is counter intuitive to system noise based tuning capability offered by a stochastic filter like the Kalman filter. This paper proposes the right invariant formulation of the complementary filter, which preserves Kalman like system noise based gain tuning capability for the filter. The resulting filter exhibits efficient operation in elementary embedded hardware, intuitive system noise based gain tuning capability and accurate attitude estimation. The performance of the filter is validated using numerical simulations and by experimentally implementing the filter on an ARDrone . micro aerial vehicle platform.

In this paper, we consider the problem of learning high-dimensional tensor regression problems with low-rank structure. One of the core challenges associated with learning high-dimensional models is computation since the underlying optimization problems are often non-convex. While convex relaxations could lead to polynomial-time algorithms they are often slow in practice. On the other hand, limited theoretical guarantees exist for non-convex methods. In this paper we provide a general framework that provides theoretical guarantees for learning high-dimensional tensor regression models under different low-rank structural assumptions using the projected gradient descent algorithm applied to a potentially non-convex constraint set Theta in terms of its emphlocalized Gaussian width. We juxtapose our theoretical results for non-convex projected gradient descent algorithms with previous results on regularized convex approaches. The two main differences between the convex and non-convex approach are i from a computational perspective whether the non-convex projection operator is computable and whether the projection has desirable contraction properties and ii from a statistical upper bound perspective, the non-convex approach has a superior rate for a number of examples. We provide three concrete examples of low-dimensional structure which address these issues and explain the pros and cons for the non-convex and convex approaches. We supplement our theoretical results with simulations which show that, under several common settings of generalized low rank tensor regression, the projected gradient descent approach is superior both in terms of statistical error and run-time provided the step-sizes of the projected descent algorithm are suitably chosen.

We introduce Joint Causal Inference JCI, a powerful formulation of causal discovery from multiple datasets that allows to jointly learn both the causal structure and targets of interventions from statistical independences in pooled data. Compared with existing constraint-based approaches for causal discovery from multiple data sets, JCI offers several advantages it allows for several different types of interventions in a unified fashion, it can learn intervention targets, it systematically pools data across different datasets which improves the statistical power of independence tests, and most importantly, it improves on the accuracy and identifiability of the predicted causal relations. A technical complication that arises in JCI is the occurrence of faithfulness violations due to deterministic relations. We propose a simple but effective strategy for dealing with this type of faithfulness violations. We implement it in ACID, a determinism-tolerant extension of Ancestral Causal Inference ACI Magliacane et al., , a recently proposed logic-based causal discovery method that improves reliability of the output by exploiting redundant information in the data. We illustrate the benefits of JCI with ACID with an evaluation on a simulated dataset.

This paper intends at contributing to a better explanation of the totality of physics journals. The main assumption is that the Journal Impact Factor of a scientific journal has practical significance in citation field only in reference to the Journal Impact Factors of other journals. Instead of constructing new scientometric indicators, we identify a physics journal with corresponding empirical distribution function of citations. Using data from Web of Science Core Collection we consider the space of physics journals and the space of scientific publishers. The first provides a topology structure for the bibliometric grouping of physics journals. The second reveals the competitors triangle of regional publishers, transnational publishers and professional physical societies. These findings have prompted us to advance the hypothesis that the structure of the space of physics journals is determined by a system of relations between publishers.

The log Gaussian Cox process is a flexible class of point pattern models for capturing spatial and spatio-temporal dependence for point patterns. Model fitting requires approximation of stochastic integrals which is implemented through discretization of the domain of interest. With fine scale discretization, inference based on Markov chain Monte Carlo is computationally heavy because of the cost of repeated iteration or inversion or Cholesky decomposition cubic order of high dimensional covariance matrices associated with latent Gaussian variables. Furthermore, hyperparameters for latent Gaussian variables have strong dependence with sampled latent Gaussian variables. Altogether, standard Markov chain Monte Carlo strategies are inefficient and not well behaved.   In this paper, we propose an efficient computational strategy for fitting and inferring with spatial log Gaussian Cox processes. The proposed algorithm is based on a pseudo-marginal Markov chain Monte Carlo approach. We estimate an approximate marginal posterior for parameters of log Gaussian Cox processes and propose comprehensive model inference strategy. We provide details for all of the above along with some simulation investigation for the univariate and multivariate settings. As an example, we present an analysis of a point pattern of locations of three tree species, exhibiting positive and negative interaction between different species.

Generating high-resolution, photo-realistic images has been a long-standing goal in machine learning. Recently, Nguyen et al.  showed one interesting way to synthesize novel images by performing gradient ascent in the latent space of a generator network to maximize the activations of one or multiple neurons in a separate classifier network. In this paper we extend this method by introducing an additional prior on the latent code, improving both sample quality and sample diversity, leading to a state-of-the-art generative model that produces high quality images at higher resolutions x than previous generative models, and does so for all  ImageNet categories. In addition, we provide a unified probabilistic interpretation of related activation maximization methods and call the general class of models Plug and Play Generative Networks. PPGNs are composed of  a generator network G that is capable of drawing a wide range of image types and  a replaceable condition network C that tells the generator what to draw. We demonstrate the generation of images conditioned on a class when C is an ImageNet or MIT Places classification network and also conditioned on a caption when C is an image captioning network. Our method also improves the state of the art of Multifaceted Feature Visualization, which generates the set of synthetic inputs that activate a neuron in order to better understand how deep neural networks operate. Finally, we show that our model performs reasonably well at the task of image inpainting. While image models are used in this paper, the approach is modality-agnostic and can be applied to many types of data.

The Doob graph Dm,n is a distance-regular graph with the same parameters as the Hamming graph Hmn,. The maximum independent sets in the Doob graphs are analogs of the distance- MDS codes in the Hamming graphs. We prove that the logarithm of the number of the maximum independent sets in Dm,n grows as mn-o. The main tool for the upper estimation is constructing an injective map from the class of maximum independent sets in Dm,n to the class of distance- MDS codes in Hmn,.

We propose an oscillatory neural network implemented with two-dimensional tantalum disulfide devices operating in the change density wave regime at room temperature. An elementary cell of the network consists of two T-TaS devices connected in series. Such a cell has constant output and oscillatory states. All cells have the same bias voltage. There is constant current flowing through the cell in the constant output mode. The oscillations occur at a certain bias voltage due to the electrical-field driven metal-to-insulator transition owing to the changes in the charge density wave phase in the T-TaS channel. Two T-TaS devices oscillate out-of-phase where one of the devices is in the insulator phase while the other one is in the metallic state. The nearest-neighbor cells are coupled via graphene transistors. The cells are resistively coupled if the graphene transistor is in the On state while they are capacitively coupled if the transistor is in the Off state. The operation of the oscillatory neural network is simulated numerically for the x node network. The results of our numerical modeling show the formation of artificial vortexes and cellular-automata type data processing. The two-dimensional T-TaS devices, utilized in the network, offer a unique combination of properties such as scalability, high operational frequency, fast synchronization speed, and radiation hardness, which makes them promising for both consumer electronic and defense applications.

Following OW, we continue our analysis of  Quantum tomography, i.e., learning a quantum state, i.e., the quantum generalization of learning a discrete probability distribution  The distribution of Young diagrams output by the RSK algorithm on random words. Regarding , we introduce two powerful new tools i A precise upper bound on the expected length of the longest union of k disjoint increasing subsequences in a random length-n word with letter distribution alpha geq alpha geq cdots geq alphad ii A new majorization property of the RSK algorithm that allows one to analyze the Young diagram formed by the lower rows lambdak, lambdak, dots of its output.   These tools allow us to prove several new theorems concerning the distribution of random Young diagrams in the nonasymptotic regime, giving concrete error bounds that are optimal, or nearly so, in all parameters. As one example, we give a fundamentally new proof of the fact that the expected length of the longest increasing sequence in a random length-n permutation is bounded by sqrtn. This is the k  , alphai equiv fracd, d to infty special case of a much more general result we prove the expected length of the kth Young diagram row produced by an alpha-random word is alphak n pm sqrtalphakd n.   From our new analyses of random Young diagrams we derive several new results in quantum tomography, including i Learning the eigenvalues of an unknown state to epsilon-accuracy in Hellinger-squared, chi-squared, or KL distance, using n  Odepsilon copies ii Learning the optimal rank-k approximation of an unknown state to epsilon-fidelity Hellinger-squared distance using n  widetildeOkdepsilon copies.

This paper presents aims at mobility improvement of flexible underwater robots. For this purpose, a novel propulsion method using planar structural vibration pattern is proposed, and tested on two kinds of prototypes. The result of experiments showed the possibility of the movements for multiple directions forward, backward, turn, rotation, drift, and their combination. These movements are achieved by only one structure with two actuators. The results also indicated the possibility of driving using eigenmodes since movements were concentrated on low driving frequency area. To investigate the relation between movement and structural vibration pattern, we established a simulation model.

An essential task of groups is to provide efficient solutions for the complex problems they face. Indeed, considerable efforts have been devoted to the question of collective decision-making related to problems involving a single dominant feature. Here we introduce a quantitative formalism for finding the optimal distribution of the group members competences in the more typical case when the underlying problem is complex, i.e., multidimensional. Thus, we consider teams that are aiming at obtaining the best possible answer to a problem having a number of independent sub-problems. Our approach is based on a generic scheme for the process of evaluating the proposed solutions i.e., negotiation. We demonstrate that the best performing groups have at least one specialist for each sub-problem -- but a far less intuitive result is that finding the optimal solution by the interacting group members requires that the specialists also have some insight into the sub-problems beyond their unique fields. We present empirical results obtained by using a large-scale database of citations being in good agreement with the above theory. The framework we have developed can easily be adapted to a variety of realistic situations since taking into account the weights of the sub-problems, the opinions or the relations of the group is straightforward. Consequently, our method can be used in several contexts, especially when the optimal composition of a group of decision-makers is designed.

Variational inference provides a powerful tool for approximate probabilistic in- ference on complex, structured models. Typical variational inference methods, however, require to use inference networks with computationally tractable proba- bility density functions. This largely limits the design and implementation of vari- ational inference methods. We consider wild variational inference methods that do not require tractable density functions on the inference networks, and hence can be applied in more challenging cases. As an example of application, we treat stochastic gradient Langevin dynamics SGLD as an inference network, and use our methods to automatically adjust the step sizes of SGLD, yielding significant improvement over the hand-designed step size schemes

The Ministry of Social Development in Mexico is in charge of creating and assigning social programmes targeting specific needs in the population for the improvement of quality of life. To better target the social programmes, the Ministry is aimed to find clusters of households with the same needs based on demographic characteristics as well as poverty conditions of the household. Available data consists of continuous, ordinal, and nominal variables and the observations are not iid but come from a survey sample based on a complex design. We propose a Bayesian nonparametric mixture model that jointly models this mixed scale data and accommodates for the different sampling probabilities. The performance of the model is assessed via simulated data. A full analysis of socio-economic conditions in households in the State of Mexico is presented.

Recently, various deep-neural-network DNN-based approaches have been proposed for single-image super-resolution SISR. Despite their promising results on major structure regions such as edges and lines, they still suffer from limited performance on texture regions that consist of very complex and fine patterns. This is because, during the acquisition of a low-resolution LR image via down-sampling, these regions lose most of the high frequency information necessary to represent the texture details. In this paper, we present a novel texture enhancement framework for SISR to effectively improve the spatial resolution in the texture regions as well as edges and lines. We call our method, high-resolution HR style transfer algorithm. Our framework consists of three steps i generate an initial HR image from an interpolated LR image via an SISR algorithm, ii generate an HR style image from the initial HR image via down-scaling and tiling, and iii combine the HR style image with the initial HR image via a customized style transfer algorithm. Here, the HR style image is obtained by down-scaling the initial HR image and then repetitively tiling it into an image of the same size as the HR image. This down-scaling and tiling process comes from the idea that texture regions are often composed of small regions that similar in appearance albeit sometimes different in scale. This process creates an HR style image that is rich in details, which can be used to restore high-frequency texture details back into the initial HR image via the style transfer algorithm. Experimental results on a number of texture datasets show that our proposed HR style transfer algorithm provides more visually pleasing results compared with competitive methods.

We consider the problem of metric learning subject to a set of constraints on relative-distance comparisons between the data items. Such constraints are meant to reflect side-information that is not expressed directly in the feature vectors of the data items. The relative-distance constraints used in this work are particularly effective in expressing structures at finer level of detail than must-link ML and cannot-link CL constraints, which are most commonly used for semi-supervised clustering. Relative-distance constraints are thus useful in settings where providing an ML or a CL constraint is difficult because the granularity of the true clustering is unknown.   Our main contribution is an efficient algorithm for learning a kernel matrix using the log determinant divergence --- a variant of the Bregman divergence --- subject to a set of relative-distance constraints. The learned kernel matrix can then be employed by many different kernel methods in a wide range of applications. In our experimental evaluations, we consider a semi-supervised clustering setting and show empirically that kernels found by our algorithm yield clusterings of higher quality than existing approaches that either use MLCL constraints or a different means to implement the supervision using relative comparisons.

Object-to-camera motion produces a variety of apparent motion patterns that significantly affect performance of short-term visual trackers. Despite being crucial for designing robust trackers, their influence is poorly explored in standard benchmarks due to weakly defined, biased and overlapping attribute annotations. In this paper we propose to go beyond pre-recorded benchmarks with post-hoc annotations by presenting an approach that utilizes omnidirectional videos to generate realistic, consistently annotated, short-term tracking scenarios with exactly parameterized motion patterns. We have created an evaluation system, constructed a fully annotated dataset of omnidirectional videos and the generators for typical motion patterns. We provide an in-depth analysis of major tracking paradigms which is complementary to the standard benchmarks and confirms the expressiveness of our evaluation approach.

Sequence modeling with neural networks has lead to powerful models of symbolic music data. We address the problem of exploiting these models to reach creative musical goals. To this end we generalise previous work, which sampled Markovian sequence models under the constraint that the sequence belong to the language of a given finite state machine. We consider more expressive non-Markov models, thereby requiring approximate sampling which we provide in the form of an efficient sequential Monte Carlo method. In addition we provide and compare with a beam search strategy for conditional probability maximisation. Our algorithms are capable of convincingly re-harmonising famous musical works. To demonstrate this we provide visualisations, quantitative experiments, a human listening test and illustrative audio examples. We find both the sampling and optimisation procedures to be effective, yet complementary in character. For the case of highly permissive constraint sets, we find that sampling is to be preferred due to the overly regular nature of the optimisation based results.

In the Markov decision process model, policies are usually evaluated by expected cumulative rewards. As this decision criterion is not always suitable, we propose in this paper an algorithm for computing a policy optimal for the quantile criterion. Both finite and infinite horizons are considered. Finally we experimentally evaluate our approach on random MDPs and on a data center control problem.

Causal graphs, such as directed acyclic graphs DAGs and partial ancestral graphs PAGs, represent causal relationships among variables in a model. Methods exist for learning DAGs and PAGs from data and for converting DAGs to PAGs. However, these methods only output a single causal graph consistent with the independenciesdependencies the Markov equivalence class M estimated from the data. However, many distinct graphs may be consistent with M, and a data modeler may wish to select among these using domain knowledge. In this paper, we present a method that makes this possible. We introduce PAGADMG, the first method for enumerating all causal graphs consistent with M, under certain assumptions. PAGADMG converts a given PAG into a set of acyclic directed mixed graphs ADMGs. We prove the correctness of the approach and demonstrate its efficiency relative to brute-force enumeration.

We study the problem of recovering an incomplete mtimes n matrix of rank r with columns arriving online over time. This is known as the problem of life-long matrix completion, and is widely applied to recommendation system, computer vision, system identification, etc. The challenge is to design provable algorithms tolerant to a large amount of noises, with small sample complexity. In this work, we give algorithms achieving strong guarantee under two realistic noise models. In bounded deterministic noise, an adversary can add any bounded yet unstructured noise to each column. For this problem, we present an algorithm that returns a matrix of a small error, with sample complexity almost as small as the best prior results in the noiseless case. For sparse random noise, where the corrupted columns are sparse and drawn randomly, we give an algorithm that exactly recovers an mu-incoherent matrix by probability at least -delta with sample complexity as small as Oleftmurnlog rdeltaright. This result advances the state-of-the-art work and matches the lower bound in a worst case. We also study the scenario where the hidden matrix lies on a mixture of subspaces and show that the sample complexity can be even smaller. Our proposed algorithms perform well experimentally in both synthetic and real-world datasets.

We introduce a data-driven approach to complete partial D shapes through a combination of volumetric deep neural networks and D shape synthesis. From a partially-scanned input shape, our method first infers a low-resolution -- but complete -- output. To this end, we introduce a D-Encoder-Predictor Network D-EPN which is composed of D convolutional layers. The network is trained to predict and fill in missing data, and operates on an implicit surface representation that encodes both known and unknown space. This allows us to predict global structure in unknown areas at high accuracy. We then correlate these intermediary results with D geometry from a shape database at test time. In a final pass, we propose a patch-based D shape synthesis method that imposes the D geometry from these retrieved shapes as constraints on the coarsely-completed mesh. This synthesis process enables us to reconstruct fine-scale detail and generate high-resolution output while respecting the global mesh structure obtained by the D-EPN. Although our D-EPN outperforms state-of-the-art completion method, the main contribution in our work lies in the combination of a data-driven shape predictor and analytic D shape synthesis. In our results, we show extensive evaluations on a newly-introduced shape completion benchmark for both real-world and synthetic data.

Stochastic network design is a general framework for optimizing network connectivity. It has several applications in computational sustainability including spatial conservation planning, pre-disaster network preparation, and river network optimization. A common assumption in previous work has been made that network parameters e.g., probability of species colonization are precisely known, which is unrealistic in real- world settings. We therefore address the robust river network design problem where the goal is to optimize river connectivity for fish movement by removing barriers. We assume that fish passability probabilities are known only imprecisely, but are within some interval bounds. We then develop a planning approach that computes the policies with either high robust ratio or low regret. Empirically, our approach scales well to large river networks. We also provide insights into the solutions generated by our robust approach, which has significantly higher robust ratio than the baseline solution with mean parameter estimates.

The paper considers a bidirectional power flow model of the electric vehicles EVs in a charging station. The EVs can inject energies by discharging via a Vehicle-to-Grid VG service which can enhance the profits of the charging station. However, frequent charging and discharging degrade battery life. A proper compensation needs to be paid to the users to participate in the VG service. We propose a menu-based pricing scheme, where the charging station selects a price for each arriving user for the amount of battery utilization, the total energy, and the time deadline that the EV will stay. The user can accept one of the contracts or rejects all depending on their utilities. The charging station can serve users using a combination of the renewable energy and the conventional energy bought from the grid. We show that though there exists a profit maximizing price which maximizes the social welfare, it provides no surplus to the users if the charging station is aware of the utilities of the users. If the charging station is not aware of the exact utilities, the social welfare maximizing price may not maximize the expected profit. In fact, it can give a zero profit. We propose a pricing strategy which provides a guaranteed fixed profit to the charging station and it also maximizes the expected profit for a wide range of utility functions. Our analysis shows that when the harvested renewable energy is small the users have higher incentives for the VG service. We, numerically, show that the charging stations profit and the users surplus both increase as VG service is efficiently utilized by the pricing mechanism.

Cybersecurity is increasingly threatened by advanced and persistent attacks. As these attacks are often designed to disable a system or a critical resource, e.g., a user account repeatedly, it is crucial for the defender to keep updating its security measures to strike a balance between the risk of being compromised and the cost of security updates. Moreover, these decisions often need to be made with limited and delayed feedback due to the stealthy nature of advanced attacks. In addition to targeted attacks, such an optimal timing policy under incomplete information has broad applications in cybersecurity. Examples include key rotation, password change, application of patches, and virtual machine refreshing. However, rigorous studies of optimal timing are rare. Further, existing solutions typically rely on a pre-defined attack model that is known to the defender, which is often not the case in practice. In this work, we make an initial effort towards achieving optimal timing of security updates in the face of unknown stealthy attacks. We consider a variant of the influential FlipIt game model with asymmetric feedback and unknown attack time distribution, which provides a general model to consecutive security updates. The defenders problem is then modeled as a time associative bandit problem with dependent arms. We derive upper confidence bound based learning policies that achieve low regret compared with optimal periodic defense strategies that can only be derived when attack time distributions are known.

We construct an infinite family of two-Lee-weight and three-Lee-weight codes over the non-chain ring mathbbFpumathbbFpvmathbbFpuvmathbbFp, where u,v,uvvu. These codes are defined as trace codes. They have the algebraic structure of abelian codes. Their Lee weight distribution is computed by using Gauss sums. With a linear Gray map, we obtain a class of abelian three-weight codes and two-weight codes over mathbbFp. In particular, the two-weight codes we describe are shown to be optimal by application of the Griesmer bound. We also discuss their dual Lee distance. Finally, an application to secret sharing schemes is given.

In this work, we address the challenging video scene parsing problem by developing effective representation learning methods given limited parsing annotations. In particular, we contribute two novel methods that constitute a unified parsing framework.  textbfPredictive feature learning from nearly unlimited unlabeled video data. Different from existing methods learning features from single frame parsing, we learn spatiotemporal discriminative features by enforcing a parsing network to predict future frames and their parsing maps if available given only historical frames. In this way, the network can effectively learn to capture video dynamics and temporal context, which are critical clues for video scene parsing, without requiring extra manual annotations.  textbfPrediction steering parsing architecture that effectively adapts the learned spatiotemporal features to scene parsing tasks and provides strong guidance for any off-the-shelf parsing model to achieve better video scene parsing performance. Extensive experiments over two challenging datasets, Cityscapes and Camvid, have demonstrated the effectiveness of our methods by showing significant improvement over well-established baselines.

The multi-tiered concept of Internet of Things IoT devices, cloudlets and clouds is facilitating a user-centric IoT. However, in such three tier network, it is still desirable to investigate efficient strategies to offer the computing, storage and communications resources to the users. To this end, this paper proposes a new hierarchical model by introducing the concept of field, shallow, and deep cloudlets where the cloudlet tier itself is designed in three hierarchical levels based on the principle of LTE-Advanced backhaul network. Accordingly, we explore a two time scale approach in which the computing resources are offered in an auction-based profit maximization manner and then the communications resources are allocated to satisfy the users QoS.

In this paper, we construct an infinite family of three-weight binary codes from linear codes over the ring RmathbbFvmathbbFvmathbbF, where v. These codes are defined as trace codes. They have the algebraic structure of abelian codes. Their Lee weight distributions are computed by employing character sums. The three-weight binary linear codes which we construct are shown to be optimal when m is odd and m. They are cubic, that is to say quasi-cyclic of co-index three. An application to secret sharing schemes is given.

Image pattern recognition is an important area in digital image processing. An efficient pattern recognition algorithm should be able to provide correct recognition at a reduced computational time. Off late amongst the machine learning pattern recognition algorithms, Artificial fish swarm algorithm is one of the swarm intelligence optimization algorithms that works based on population and stochastic search. In order to achieve acceptable result, there are many parameters needs to be adjusted in AFSA. Among these parameters, visual and step are very significant in view of the fact that artificial fish basically move based on these parameters. In standard AFSA, these two parameters remain constant until the algorithm termination. Large values of these parameters increase the capability of algorithm in global search, while small values improve the local search ability of the algorithm. In this paper, we empirically study the performance of the AFSA and different approaches to balance between local and global exploration have been tested based on the adaptive modification of visual and step during algorithm execution. The proposed approaches have been evaluated based on the four well-known benchmark functions. Experimental results show considerable positive impact on the performance of AFSA. A Convex optimization has been integrated into the proposed work to have an ideal segmentation of the input image which is a MR brain image.

We construct a class of three-Lee-weight and two infinite families of five-Lee-weight codes over the ring RmathbbF vmathbbF vmathbbF vmathbbF vmathbbF, where v. The same ring occurs in the quintic construction of binary quasi-cyclic codes. The length of these codes depends on the degree m of ring extension. They have the algebraic structure of abelian codes. Their Lee weight distribution is computed by using character sums. Given a linear Gray map, we obtain three families of binary abelian codes with few weights. In particular, we obtain a class of three-weight codes which are optimal. Finally, an application to secret sharing schemes is given.

We construct an infinite family of two-Lee-weight and three-Lee-weight codes over the chain ring mathbbFpumathbbFp. They have the algebraic structure of abelian codes. Their Lee weight distribution is computed by using Gauss sums. Then by using a linear Gray map, we obtain an infinite family of abelian codes with few weights over mathbbFp. In particular, we obtain an infinite family of two-weight codes which meets the Griesmer bound with equality. Finally, an application to secret sharing schemes is given.

This paper studies polar coding for secure communications over the general two-way wiretap channel, where two legitimate users communicate with each other simultaneously while a passive eavesdropper overhears a combination of their exchanged signals. The legitimate users wish to design a coding scheme such that the interference between their codewords can be leveraged to jam the eavesdropper. This security method is called coded cooperative jamming. In this model, the eavesdropper observes a two-user multiple access channel MAC. Inspired by recent studies on polar coding for asymmetric channels, Slepian-Wolf coding, MACs and general wiretap channels, we design a polar code-based cooperative jamming code that achieves the whole secrecy rate region of the general two-way wiretap channel under the strong secrecy criterion. To make proper alignment of polar indices, a multi-block strategy is used. For the special case when the eavesdropper channel is degraded with respect to both legitimate channels, a simplified scheme is proposed which can simultaneously ensure reliability and weak secrecy within a single transmission block. An example of the binary erasure channel case is given to demonstrate the performance of our scheme.

We provide a maximum likelihood formulation for the blind estimation of massive mmWave MIMO channels while taking into account their underlying sparse structure. The main advantage of this approach is the fact that the overhead due to pilot sequences can be reduced dramatically especially when operating at low SNR per antenna. Thereby, the sparsity in the angular domain is exploited as a key property to enable the unambiguous blind separation between users channels. On the other hand, as only the sparsity is assumed, the proposed method is robust with respect to the statistical properties of the channel and data and allows the estimation in rapidly time-varying scenarios and eventually the separation of interfering users from adjacent base stations. Additionally, a performance limit is derived based on the clairvoyant Cramer Rao lower bound. Simulation results demonstrate that this maximum likelihood formulation yields superior estimation accuracy with reasonable computational complexity and limited model assumptions.

Problems such as predicting a new shading field Y for an image X are ambiguous many very distinct solutions are good. Representing this ambiguity requires building a conditional model PYX of the prediction, conditioned on the image. Such a model is difficult to train, because we do not usually have training data containing many different shadings for the same image. As a result, we need different training examples to share data to produce good models. This presents a danger we call code space collapse - the training procedure produces a model that has a very good loss score, but which represents the conditional distribution poorly. We demonstrate an improved method for building conditional models by exploiting a metric constraint on training data that prevents code space collapse. We demonstrate our model on two example tasks using real data image saturation adjustment, image relighting. We describe quantitative metrics to evaluate ambiguous generation results. Our results quantitatively and qualitatively outperform different strong baselines.

Multi-person pose estimation in wild images is a challenging problem, where human detector inevitably suffers from errors both in localization and recognition. These undesirable errors would ultimately result in failures of most CNN-based single-person pose estimators. In this paper, a novel regional multi-person pose estimation RMPE framework is proposed to facilitate single-person pose estimator in presence of the inaccurate human detector. In particular, our framework consists of three novel techniques, namely, symmetric spatial transformer network SSTN, deep proposals generator DPG and parametric pose non-maximum suppression NMS. Extensive experimental results have demonstrated the validity and effectiveness of the proposed approach. In comparison to the state-of-the-art approach, the proposed approach significantly achieves  increase in mAP on MPII multi person dataset. Our model and source codes are publicly available.

Machine learning models, including state-of-the-art deep neural networks, are vulnerable to small perturbations that cause unexpected classification errors. This unexpected lack of robustness raises fundamental questions about their generalization properties and poses a serious concern for practical deployments. As such perturbations can remain imperceptible - commonly called adversarial examples that demonstrate an inherent inconsistency between vulnerable machine learning models and human perception - some prior work casts this problem as a security issue as well. Despite the significance of the discovered instabilities and ensuing research, their cause is not well understood, and no effective method has been developed to address the problem highlighted by adversarial examples. In this paper, we present a novel theory to explain why this unpleasant phenomenon exists in deep neural networks. Based on that theory, we introduce a simple, efficient and effective training approach, Batch Adjusted Network Gradients BANG, which significantly improves the robustness of machine learning models. While the BANG technique does not rely on any form of data augmentation or the application of adversarial images for training, the resultant classifiers are more resistant to adversarial perturbations while maintaining or even enhancing classification performance overall.

We use Kolmogorov complexity methods to give a lower bound on the effective Hausdorff dimension of the point x, axb, given real numbers a, b, and x. We apply our main theorem to a problem in fractal geometry, giving an improved lower bound on the classical Hausdorff dimension of generalized sets of Furstenberg type.

Deep learning based landcover classification algorithms have recently been proposed in literature. In hyperspectral images HSI they face the challenges of large dimensionality, spatial variability of spectral signatures and scarcity of labeled data. In this article we propose an end-to-end deep learning architecture that extracts band specific spectral-spatial features and performs landcover classification. The architecture has fewer independent connection weights and thus requires lesser number of training data. The method is found to outperform the highest reported accuracies on popular hyperspectral image data sets.

With the development of state-of-art deep reinforcement learning, we can efficiently tackle continuous control problems. But the deep reinforcement learning method for continuous control is based on historical data, which would make unpredicted decisions in unfamiliar scenarios. Combining deep reinforcement learning and safety based control can get good performance for self-driving and collision avoidance. In this passage, we use the Deep Deterministic Policy Gradient algorithm to implement autonomous driving without vehicles around. The vehicle can learn the driving policy in a stable and familiar environment, which is efficient and reliable. Then we use the artificial potential field to design collision avoidance algorithm with vehicles around. The path tracking method is also taken into consideration. The combination of deep reinforcement learning and safety based control performs well in most scenarios.

Content on the Internet is heterogeneous and arises from various domains like News, Entertainment, Finance and Technology. Understanding such content requires identifying named entities persons, places and organizations as one of the key steps. Traditionally Named Entity Recognition NER systems have been built using available annotated datasets like CoNLL, MUC and demonstrate excellent performance. However, these models fail to generalize onto other domains like Sports and Finance where conventions and language use can differ significantly. Furthermore, several domains do not have large amounts of annotated labeled data for training robust Named Entity Recognition models. A key step towards this challenge is to adapt models learned on domains where large amounts of annotated training data are available to domains with scarce annotated data.   In this paper, we propose methods to effectively adapt models learned on one domain onto other domains using distributed word representations. First we analyze the linguistic variation present across domains to identify key linguistic insights that can boost performance across domains. We propose methods to capture domain specific semantics of word usage in addition to global semantics. We then demonstrate how to effectively use such domain specific knowledge to learn NER models that outperform previous baselines in the domain adaptation setting.

We propose an asynchronous, decentralized algorithm for consensus optimization. The algorithm runs over a network in which the agents communicate with their neighbors and perform local computation. In the proposed algorithm, each agent can compute and communicate independently at different times, for different durations, with the information it has even if the latest information from its neighbors is not yet available. Such an asynchronous algorithm reduces the time that agents would otherwise waste idle because of communication delays or because their neighbors are slower. It also eliminates the need for a global clock for synchronization. Mathematically, the algorithm involves both primal and dual variables, uses fixed step-size parameters, and provably converges to the exact solution under a bounded delay assumption and a random agent assumption. When running synchronously, the algorithm performs just as well as existing competitive synchronous algorithms such as PG-EXTRA, which diverges without synchronization. Numerical experiments confirm the theoretical findings and illustrate the performance of the proposed algorithm.

Decision tree is an important method for both induction research and data mining, which is mainly used for model classification and prediction. ID algorithm is the most widely used algorithm in the decision tree so far. In this paper, the shortcoming of IDs inclining to choose attributes with many values is discussed, and then a new decision tree algorithm which is improved version of ID. In our proposed algorithm attributes are divided into groups and then we apply the selection measure  for these groups. If information gain is not good then again divide attributes values into groups. These steps are done until we get good classificationmisclassification ratio. The proposed algorithms classify the data sets more accurately and efficiently.

We investigate adversarial attacks for autoencoders. We propose a procedure that distorts the input image to mislead the autoencoder in reconstructing a completely different target image. We attack the internal latent representations, attempting to make the adversarial input produce an internal representation as similar as possible as the targets. We find that autoencoders are much more robust to the attack than classifiers while some examples have tolerably small input distortion, and reasonable similarity to the target image, there is a quasi-linear trade-off between those aims. We report results on MNIST and SVHN datasets, and also test regular deterministic autoencoders, reaching similar conclusions in all cases. Finally, we show that the usual adversarial attack for classifiers, while being much easier, also presents a direct proportion between distortion on the input, and misdirection on the output. That proportionality however is hidden by the normalization of the output, which maps a linear layer into non-linear probabilities.

The computational complexity of multicut-like problems may vary significantly depending on whether the terminals are fixed or not. In this work we present a comprehensive study of this phenomenon in two types of cut problems in directed graphs double cut and bicut.   . The fixed-terminal edge-weighted double cut is known to be solvable efficiently. We show a tight approximability factor of  for the fixed-terminal node-weighted double cut. We show that the global node-weighted double cut cannot be approximated to a factor smaller than  under the Unique Games Conjecture UGC.   . The fixed-terminal edge-weighted bicut is known to have a tight approximability factor of . We show that the global edge-weighted bicut is approximable to a factor strictly better than , and that the global node-weighted bicut cannot be approximated to a factor smaller than  under UGC.   . In relation to these investigations, we also prove two results on undirected graphs which are of independent interest. First, we show NP-completeness and a tight inapproximability bound of  for the node-weighted -cut problem. Second, we show that for constant k, there exists an efficient algorithm to solve the minimum s,t-separating k-cut problem.   Our techniques for the algorithms are combinatorial, based on LPs and based on enumeration of approximate min-cuts. Our hardness results are based on combinatorial reductions and integrality gap instances.

Many software projects fail due to problems in requirements engineering RE. The goal of this paper is analyzing a specific and relevant RE problem in detail incompletehidden requirements. We replicated a global family of RE surveys with representatives of software organizations in Austria and Brazil. We used the data to a characterize the criticality of the selected RE problem, and to b analyze the reported main causes and mitigation actions. Based on the analysis, we discuss how to prevent the problem. The survey includes  different organizations in Austria and  in Brazil, including small, medium and large sized companies, conducting both, plan-driven and agile development processes. Respondents from both countries cited the incompletehidden requirements problem as one of the most critical RE problems. We identified and graphically represented the main causes and documented solution options to address these causes. Further, we compiled a list of reported mitigation actions. From a practical point of view, this paper provides further insights into common causes of incompletehidden requirements and on how to prevent this problem.

Most of the data produced in software projects is of textual nature source code, specifications, or documentations. The advances in quantitative analysis methods drove a lot of data analytics in software engineering. This has overshadowed to some degree the importance of texts and their qualitative analysis. Such analysis has, however, merits for researchers and practitioners as well.   In this chapter, we describe the basics of analysing text in software projects. We first describe how to manually analyse and code textual data. Next, we give an overview of mixed methods to automatic text analysis including N-Grams and clone detection as well as more sophisticated natural language processing identifying syntax and contexts of words. Those methods and tools are of critical importance to aid in the challenges in todays huge amounts of textual data.   We illustrate the introduced methods via a running example and conclude by presenting two industrial studies.

The works of Rabindranath Tagore have been sung by various artistes over generations spanning over almost  years. there are few songs which were popular in the early years and have been able to retain their popularity over the years while some others have faded away. In this study we look to find cues for the singing style of these songs which have kept them alive for all these years. For this we took  min clip of four Tagore songs which have been sung by five generation of artistes over  years and analyze them with the help of latest nonlinear techniques Multifractal Detrended Fluctuation Analysis MFDFA. The multifractal spectral width is a manifestation of the inherent complexity of the signal and may prove to be an important parameter to identify the singing style of particular generation of singers and how this style varies over different generations. The results are discussed in detail.

In North Indian Classical Music, raga forms the basic structure over which individual improvisations is performed by an artist based on hisher creativity. The Alap is the opening section of a typical Hindustani Music HM performance, where the raga is introduced and the paths of its development are revealed using all the notes used in that particular raga and allowed transitions between them with proper distribution over time. In India, corresponding to each raga, several emotional flavors are listed, namely erotic love, pathetic, devotional, comic, horrific, repugnant, heroic, fantastic, furious, peaceful. The detection of emotional cues from Hindustani Classical music is a demanding task due to the inherent ambiguity present in the different ragas, which makes it difficult to identify any particular emotion from a certain raga. In this study we took the help of a high resolution mathematical microscope MFDFA or Multifractal Detrended Fluctuation Analysis to procure information about the inherent complexities and time series fluctuations that constitute an acoustic signal. With the help of this technique,  min alap portion of six conventional ragas of Hindustani classical music namely, Darbari Kanada, Yaman, Mian ki Malhar, Durga, Jay Jayanti and Hamswadhani played in three different musical instruments were analyzed. The results are discussed in detail.

A promising approach to hedge against the inherent uncertainty of renewable generation is to equip the renewable plants with energy storage systems. This paper focuses on designing profit maximization offering strategies, i.e., the strategies that determine the offering price and volume, for a storage-assisted renewable power producer that participates in hour-ahead electricity market. Designing the strategies is challenging since i the underlying problem is coupled across time due to the evolution of the storage level, and ii inputs to the problem including the renewable output and market clearing price are unknown when submitting offers. Following the competitive online algorithm design approach, we first study a basic setting where the renewable output and the clearing price are known for the next hour. We propose sOffer, a simple online offering strategy that achieves the best possible competitive ratio of Olog theta, where theta is the ratio between the maximum and the minimum clearing prices. Then, we consider the case where the clearing price is unknown. By exploiting the idea of submitting multiple offers to combat price uncertainty, we propose mOffer, and demonstrate that the competitive ratio of mOffer converges to that of sOffer as the number of offers grows. Finally, we extend our approach to the scenario where the renewable output has forecasting error. We propose gOffer as the generalized offering strategy and characterize its competitive ratio as a function of the forecasting error. Our trace-driven experiments demonstrate that our algorithms achieve performance close to the offline optimal and outperform a baseline alternative significantly.

This paper focuses on a similarity measure, known as the Wasserstein distance, with which to compare images. The Wasserstein distance results from a partial differential equation PDE formulation of Monges optimal transport problem. We present an efficient numerical solution method for solving Monges problem. To demonstrate the measures discriminatory power when comparing images, we use it within the architecture of the k-Nearest Neighbour k-NN machine learning algorithm to illustrate the measures potential benefits over other more traditional distance metrics and also the state-of-the-art Tangent Space distance on the well-known MNIST dataset. To our knowledge, the PDE formulation of the Wasserstein metric has not been presented for dealing with image comparison, nor has the Wasserstein distance been used within the k-nearest neighbour architecture.

The health status of elderly subjects is highly correlated to their activities together with their social interactions. Thus, the long term monitoring in home of their health status, shall also address the analysis of collaborative activities. This paper proposes a preliminary approach of such a system which can detect the simultaneous presence of several subjects in a common area using Kinect depth cameras. Most areas in home being dedicated to specific tasks, the localization enables the classification of tasks, whether collaborative or not. A scenario of a  hours day shrunk into  minutes was used to validate our approach. It pointed out the need of artifacts removal to reach high specificity and good sensitivity.

In several decision-making problems, alternatives should be ranked on the basis of paired comparisons between them. We present an axiomatic approach for the universal ranking problem with arbitrary preference intensities, incomplete and multiple comparisons. In particular, two basic properties - independence of irrelevant matches and self-consistency - are considered. It is revealed that there exists no ranking method satisfying both requirements at the same time. The impossibility result holds under various restrictions on the set of ranking problems, however, it does not emerge in the case of round-robin tournaments. An interesting and more general possibility result is obtained by restricting the domain of independence of irrelevant matches through the concept of macrovertex.

Recurrent Neural Networks RNNs have been successfully used in many applications. However, the problem of learning long-term dependencies in sequences using these networks is still a major challenge. Recent methods have been suggested to solve this problem by constraining the transition matrix to be unitary during training, which ensures that its norm is exactly equal to one. These methods either have limited expressiveness or scale poorly with the size of the network when compared with the simple RNN case, especially when using stochastic gradient descent SGD with a small mini-batch size. Our contributions are as follows. We first show that constraining the transition matrix to be unitary is a special case of an orthogonal constraint. Therefore, it may not be necessary to work with complex-valued matrices. Then we present a new parametrisation of the transition matrix which allows efficient training of an RNN while ensuring that the matrix is always orthogonal. Using our approach, one SGD step can, in the worst case, be performed in time complexity mathcalOT n, where T and n are the length of the input sequence and the size of the hidden layer respectively. This time complexity is the same as that of the simple RNN. Finally, we test our new parametrisation on problems with long-term dependencies. Our results show that the orthogonal constraint on the transition matrix applied through our parametrisation gives similar benefits to the unitary constraint, without the time complexity limitations.

We devise the first polynomial time algorithm computing a pure Nash equilibrium for atomic splittable congestion games with singleton strategies and player-specific affine cost functions. Our algorithm is purely combinatorial and computes the exact equilibrium assuming rational input. The idea is to reduce equilibrium computation to the problem of computing an equilibrium for an associated integrally-splittable singleton congestion game in which the players can only split their demands in integral multiples of a common packet size. While these integral games have been considered in the literature before, no polynomial time algorithm computing an equilibrium was known. Also for this class, we devise the first polynomial time algorithm and use it as a building block for our main algorithm.

We propose a new method to estimate the -dof trajectory of a flying object such as a quadrotor UAV within a D airspace monitored using multiple fixed ground cameras. It is based on a new structure from motion formulation for the D reconstruction of a single moving point with known motion dynamics. Our main contribution is a new bundle adjustment procedure which in addition to optimizing the camera poses, regularizes the point trajectory using a prior based on motion dynamics or specifically flight dynamics. Furthermore, we can infer the underlying control input sent to the UAVs autopilot that determined its flight trajectory.   Our method requires neither perfect single-view tracking nor appearance matching across views. For robustness, we allow the tracker to generate multiple detections per frame in each video. The true detections and the data association across videos is estimated using robust multi-view triangulation and subsequently refined during our bundle adjustment procedure. Quantitative evaluation on simulated data and experiments on real videos from indoor and outdoor scenes demonstrates the effectiveness of our method.

Recent machine learning methods make it possible to model potential energy of atomic configurations with chemical-level accuracy as calculated from ab-initio calculations and at speeds suitable for molecular dynamics simulation. Best performance is achieved when the known physical constraints are encoded in the machine learning models. For example, the atomic energy is invariant under global translations and rotations it is also invariant to permutations of same-species atoms. Although simple to state, these symmetries are complicated to encode into machine learning algorithms. In this paper, we present a machine learning approach based on graph theory that naturally incorporates translation, rotation, and permutation symmetries. Specifically, we use a random walk graph kernel to measure the similarity of two adjacency matrices, each of which represents a local atomic environment. We show on a standard benchmark that our Graph Approximated Energy GRAPE method is competitive with state of the art kernel methods. Furthermore, the GRAPE framework is flexible and admits many possible extensions.

Many prediction tasks contain uncertainty. In some cases, uncertainty is inherent in the task itself. In next-frame or future prediction, for example, many distinct outcomes are equally valid. In other cases, uncertainty arises from the way data is labeled. For example, in object detection, many objects of interest often go unlabeled, and in human pose estimation, occluded joints are often labeled with ambiguous values. In this work we focus on a principled approach for handling such scenarios. In particular, we propose a framework for reformulating existing single-prediction models as multiple hypothesis prediction MHP models, and we propose an associated meta loss and optimization procedure to train them. To demonstrate our approach, we consider three diverse applications human pose estimation, future prediction and image classification. We find that MHP models outperform their single-hypothesis counterparts in all cases, and that MHP models simultaneously expose valuable insights into the variability of predictions.

The paper analyzes the interaction between humans and computers in terms of response time in solving the image-based CAPTCHA. In particular, the analysis focuses on the attitude of the different Internet users in easily solving four different types of image-based CAPTCHAs which include facial expressions like animated character, old woman, surprised face, worried face. To pursue this goal, an experiment is realized involving  Internet users in solving the four types of CAPTCHAs, differentiated by age, Internet experience, and education level. The response times are collected for each user. Then, association rules are extracted from user data, for evaluating the dependence of the response time in solving the CAPTCHA from age, education level and experience in internet usage by statistical analysis. The results implicitly capture the users psychological states showing in what states the users are more sensible. It reveals to be a novelty and a meaningful analysis in the state-of-the-art.

The advent of the Internet has significantly transformed the daily activities of millions of people, with one of them being the way people communicate where Instant Messaging IM and Voice over IP VoIP communications have become prevalent. Although IM applications are ubiquitous communication tools nowadays, it was observed that the relevant research on the topic of evidence collection from IM services was limited. The reason is an IM can serve as a very useful yet very dangerous platform for the victim and the suspect to communicate. Indeed, the increased use of Instant Messengers on smart phones has turned to be the goldmine for mobile and computer forensic experts. Traces and Evidence left by applications can be held on smart phones and retrieving those potential evidences with right forensic technique is strongly required. Recently, most research on IM forensics focus on applications such as WhatsApp, Viber and Skype. However, in the literature, there are very few forensic analysis and comparison related to IM applications such as WhatsApp, Viber and Skype and Tango on both iOS and Android platforms, even though the total users of this application already exceeded  billion. Therefore, in this paper we present forensic acquisition and analysis of these four IMs and VoIPs for both iOS and Android platforms. We try to answer on how evidence can be collected when IM communications are used. We also define taxonomy of target artefacts in order to guide and structure the subsequent forensic analysis. Finally, a review of the information that can become available via the IM vendor was conducted. The achieved results of this research provided elaborative answers on the types of artifacts that can be identified by these IM and VoIP applications. We compare moreover the forensics analysis of these popular applications WhatApp, Skype, Viber and Tango.

This paper studies channel coding for the discrete memoryless multiple-access channel with a given possibly suboptimal decoding rule. A multi-letter successive decoding rule depending on an arbitrary non-negative decoding metric is considered, and achievable rate regions and error exponents are derived both for the standard MAC independent codebooks, and for the cognitive MAC one user knows both messages with superposition coding. In the cognitive case, the rate region and error exponent are shown to be tight with respect to the ensemble average. The rate regions are compared with those of the maximum-metric decoder, and numerical examples are given for which successive decoding yields a strictly higher sum rate for a given pair of input distributions.

Fully convolutional neural networks give accurate, per-pixel prediction for input images and have applications like semantic segmentation. However, a typical FCN usually requires lots of floating point computation and large run-time memory, which effectively limits its usability. We propose a method to train Bit Fully Convolution Network BFCN, a fully convolutional neural network that has low bit-width weights and activations. Because most of its computation-intensive convolutions are accomplished between low bit-width numbers, a BFCN can be accelerated by an efficient bit-convolution implementation. On CPU, the dot product operation between two bit vectors can be reduced to bitwise operations and popcounts, which can offer much higher throughput than -bit multiplications and additions.   To validate the effectiveness of BFCN, we conduct experiments on the PASCAL VOC  semantic segmentation task and Cityscapes. Our BFCN with -bit weights and -bit activations, which runs .x faster on CPU or requires less than  resources on FPGA, can achieve comparable performance as the -bit counterpart.

Automatic image synthesis research has been rapidly growing with deep networks getting more and more expressive. In the last couple of years, we have observed images of digits, indoor scenes, birds, chairs, etc. being automatically generated. The expressive power of image generators have also been enhanced by introducing several forms of conditioning variables such as object names, sentences, bounding box and key-point locations. In this work, we propose a novel deep conditional generative adversarial network architecture that takes its strength from the semantic layout and scene attributes integrated as conditioning variables. We show that our architecture is able to generate realistic outdoor scene images under different conditions, e.g. day-night, sunny-foggy, with clear object boundaries.

In this paper we advance the state-of-the-art for crowd counting in high density scenes by further exploring the idea of a fully convolutional crowd counting model introduced by Zhang et al., . Producing an accurate and robust crowd count estimator using computer vision techniques has attracted significant research interest in recent years. Applications for crowd counting systems exist in many diverse areas including city planning, retail, and of course general public safety. Developing a highly generalised counting model that can be deployed in any surveillance scenario with any camera perspective is the key objective for research in this area. Techniques developed in the past have generally performed poorly in highly congested scenes with several thousands of people in frame Rodriguez et al., . Our approach, influenced by the work of Zhang et al., , consists of the following contributions  A training set augmentation scheme that minimises redundancy among training samples to improve model generalisation and overall counting performance  a deep, single column, fully convolutional network FCN architecture  a multi-scale averaging step during inference. The developed technique can analyse images of any resolution or aspect ratio and achieves state-of-the-art counting performance on the Shanghaitech Part B and UCF CC  datasets as well as competitive performance on Shanghaitech Part A.

In this paper, we develop an agent-based version of the Diamond search equilibrium model - also called Coconut Model. In this model, agents are faced with production decisions that have to be evaluated based on their expectations about the future utility of the produced entity which in turn depends on the global production level via a trading mechanism. While the original dynamical systems formulation assumes an infinite number of homogeneously adapting agents obeying strong rationality conditions, the agent-based setting allows to discuss the effects of heterogeneous and adaptive expectations and enables the analysis of non-equilibrium trajectories. Starting from a baseline implementation that matches the asymptotic behavior of the original model, we show how agent heterogeneity can be accounted for in the aggregate dynamical equations. We then show that when agents adapt their strategies by a simple temporal difference learning scheme, the system converges to one of the fixed points of the original system. Systematic simulations reveal that this is the only stable equilibrium solution.

Reasoning about objects, relations, and physics is central to human intelligence, and a key goal of artificial intelligence. Here we introduce the interaction network, a model which can reason about how objects in complex systems interact, supporting dynamical predictions, as well as inferences about the abstract properties of the system. Our model takes graphs as input, performs object- and relation-centric reasoning in a way that is analogous to a simulation, and is implemented using deep neural networks. We evaluate its ability to reason about several challenging physical domains n-body problems, rigid-body collision, and non-rigid dynamics. Our results show it can be trained to accurately simulate the physical trajectories of dozens of objects over thousands of time steps, estimate abstract quantities such as energy, and generalize automatically to systems with different numbers and configurations of objects and relations. Our interaction network implementation is the first general-purpose, learnable physics engine, and a powerful general framework for reasoning about object and relations in a wide variety of complex real-world domains.

Systems for automatic extraction of semantic information about events from large textual resources are now available these tools are capable to generate RDF datasets about text extracted events and this knowledge can be used to reason over the recognized events. On the other hand, text based tasks for event recognition, as for example event coreference i.e. recognizing whether two textual descriptions refer to the same event, do not take into account ontological information of the extracted events in their process. In this paper, we propose a method to derive event coreference on text extracted event data using semantic based rule reasoning. We demonstrate our method considering a limited yet representative set of event types we introduce a formal analysis on their ontological properties and, on the base of this, we define a set of coreference criteria. We then implement these criteria as RDF-based reasoning rules to be applied on text extracted event data. We evaluate the effectiveness of our approach over a standard coreference benchmark dataset.

Recently, video captioning has been attracting an increasing amount of interest, due to its potential for improving accessibility and information retrieval. While existing methods rely on different kinds of visual features and model structures, they do not fully exploit relevant semantic information. We present an extensible approach to jointly leverage several sorts of visual features and semantic attributes. Our novel architecture builds on LSTMs for sentence generation, with several attention layers and two multimodal layers. The attention mechanism learns to automatically select the most salient visual features or semantic attributes, and the multimodal layer yields overall representations for the input and outputs of the sentence generation component. Experimental results on the challenging MSVD and MSR-VTT datasets show that our framework outperforms the state-of-the-art approaches, while ground truth based semantic attributes are able to further elevate the output quality to a near-human level.

Time-efficient link discovery is of central importance to implement the vision of the Semantic Web. Some of the most rapid Link Discovery approaches rely internally on planning to execute link specifications. In newer works, linear models have been used to estimate the runtime the fastest planners. However, no other category of models has been studied for this purpose so far. In this paper, we study non-linear runtime estimation functions for runtime estimation. In particular, we study exponential and mixed models for the estimation of the runtimes of planners. To this end, we evaluate three different models for runtime on six datasets using  link specifications. We show that exponential and mixed models achieve better fits when trained but are only to be preferred in some cases. Our evaluation also shows that the use of better runtime approximation models has a positive impact on the overall execution of link specifications.

This is a Commentary in PhysicsToday on the novel review process developed by the biology journal eLife, with the suggestion that it be adopted by physics journals.

The project aims to provide a semi-supervised approach to identify Multiword Expressions in a multilingual context consisting of English and most of the major Indian languages. Multiword expressions are a group of words which refers to some conventional or regional way of saying things. If they are literally translated from one language to another the expression will lose its inherent meaning.   To automatically extract multiword expressions from a corpus, an extraction pipeline have been constructed which consist of a combination of rule based and statistical approaches. There are several types of multiword expressions which differ from each other widely by construction. We employ different methods to detect different types of multiword expressions. Given a POS tagged corpus in English or any Indian language the system initially applies some regular expression filters to narrow down the search space to certain patterns like, reduplication, partial reduplication, compound nouns, compound verbs, conjunct verbs etc.. The word sequences matching the required pattern are subjected to a series of linguistic tests which include verb filtering, named entity filtering and hyphenation filtering test to exclude false positives. The candidates are then checked for semantic relationships among themselves using Wordnet. In order to detect partial reduplication we make use of Wordnet as a lexical database as well as a tool for lemmatising. We detect complex predicates by investigating the features of the constituent words. Statistical methods are applied to detect collocations. Finally, lexicographers examine the list of automatically extracted candidates to validate whether they are true multiword expressions or not and add them to the multiword dictionary accordingly.

Disjoint union is a partial binary operation returning the union of two sets if they are disjoint and undefined otherwise. A disjoint-union partial algebra of sets is a collection of sets closed under disjoint unions, whenever they are defined. We provide a recursive first-order axiomatisation of the class of partial algebras isomorphic to a disjoint-union partial algebra of sets but prove that no finite axiomatisation exists. We do the same for other signatures including one or both of disjoint union and subset complement, another partial binary operation we define.   Domain-disjoint union is a partial binary operation on partial functions, returning the union if the arguments have disjoint domains and undefined otherwise. For each signature including one or both of domain-disjoint union and subset complement and optionally including composition, we consider the class of partial algebras isomorphic to a collection of partial functions closed under the operations. Again the classes prove to be axiomatisable, but not finitely axiomatisable, in first-order logic.   We define the notion of pairwise combinability. For each of the previously considered signatures, we examine the class isomorphic to a partial algebra of setspartial functions under an isomorphism mapping arbitrary suprema of pairwise combinable sets to the corresponding disjoint unions. We prove that for each case the class is not closed under elementary equivalence.   However, when intersection is added to any of the signatures considered, the isomorphism class of the partial algebras of sets is finitely axiomatisable and in each case we give such an axiomatisation.

textttrCOSA is a software package interfaced to the R language. It implements statistical techniques for clustering objects on subsets of attributes in multivariate data. The main output of COSA is a dissimilarity matrix that one can subsequently analyze with a variety of proximity analysis methods. Our package extends the original COSA software Friedman and Meulman,  by adding functions for hierarchical clustering methods, least squares multidimensional scaling, partitional clustering, and data visualization. In the many publications that cite the COSA paper by Friedman and Meulman , the COSA program is actually used only a small number of times. This can be attributed to the fact that thse original implementation is not very easy to install and use. Moreover, the available software is out-of-date. Here, we introduce an up-to-date software package and a clear guidance for this advanced technique. The software package and related links are available for free at urlhttpsgithub.commkampertrCOSA

The ubiquitous nature of modern Information Retrieval and Virtual World give rise to new realities. To what extent are these realities real? Which physics should be applied to quantitatively describe them? In this essay I dwell on few examples. The first is Adaptive neural networks, which are not networks and not neural, but still provide service similar to classical ANNs in extended fashion. The second is the emergence of objects looking like Einsteinian spacetime, which describe the behavior of an Internet surfer like geodesic motion. The third is the demonstration of nonclassical and even stronger-than-quantum probabilities in Information Retrieval, their use.   Immense operable datasets provide new operationalistic environments, which become to greater and greater extent realities. In this essay, I consider the overall Information Retrieval process as an objective physical process, representing it according to Melucci metaphor in terms of physical-like experiments. Various semantic environments are treated as analogs of various realities. The readers attention is drawn to topos approach to physical theories, which provides a natural conceptual and technical framework to cope with the new emerging realities.

The Hat Game Eberts Hat Problem got much attention in the beginning of this century not in the last place by its connections to coding theory and computer science. There were publications in The New York Times, Die Zeit and abcNews. Exact solutions with two colors are only known in the symmetric case equal probabilities for the two players when Nk- using Hamming codes, Nk extended Hamming codes and up to N using bounds on covering codes of radius , where N is the number of players. How the probabilities and strategies behave when the two colors are not equally likely asymmetric case, is an open problem. Where the symmetric case is hard, both mathematically and from the point of view of computational complexity, we may expect the asymmetric case to be harder and perhaps beyond the capabilities of contemporary mathematics and computer science. However there is a surprising answer to the open problem elementary mathematics in combination with adequate computer programs suffices to do the job and the new approach gives also new insights in the classical symmetric case. Where the standard theory in the symmetric case works with Hamming codes and covering sets of radius , the new approach deals with adequate sets of radius N-. Our main results in this paper are a simple and effective way to analyze N-person two color hat problems, and a dramatically decrease of computational complexity.

Known algorithms for manipulating octagons do not preserve their sparsity, leading typically to quadratic or cubic time and space complexities even if no relation among variables is known when they are all bounded. In this paper, we present new algorithms, which use and return octagons represented as weakly closed difference bound matrices, preserve the sparsity of their input and have better performance in the case their inputs are sparse. We prove that these algorithms are as precise as the known ones.

We address one of the main challenges towards autonomous quadrotor flight in complex environments, which is flight through narrow gaps. While previous works relied on off-board localization systems or on accurate prior knowledge of the gap position and orientation, we rely solely on onboard sensing and computing and estimate the full state by fusing gap detection from a single onboard camera with an IMU. This problem is challenging for two reasons i the quadrotor pose uncertainty with respect to the gap increases quadratically with the distance from the gap ii the quadrotor has to actively control its orientation towards the gap to enable state estimation i.e., active vision. We solve this problem by generating a trajectory that considers geometric, dynamic, and perception constraints during the approach maneuver, the quadrotor always faces the gap to allow state estimation, while respecting the vehicle dynamics during the traverse through the gap, the distance of the quadrotor to the edges of the gap is maximized. Furthermore, we replan the trajectory during its execution to cope with the varying uncertainty of the state estimate. We successfully evaluate and demonstrate the proposed approach in many real experiments. To the best of our knowledge, this is the first work that addresses and achieves autonomous, aggressive flight through narrow gaps using only onboard sensing and computing and without prior knowledge of the pose of the gap.

This paper describes a computational model, called the Dirichlet process Gaussian mixture model with latent joints DPGMM-LJ, that can find latent tree structure embedded in data distribution in an unsupervised manner. By combining DPGMM-LJ and a pre-existing body map formation method, we propose a method that enables an agent having multi-link body structure to discover its kinematic structure, i.e., body schema, from tactile information alone. The DPGMM-LJ is a probabilistic model based on Bayesian nonparametrics and an extension of Dirichlet process Gaussian mixture model DPGMM. In a simulation experiment, we used a simple fetus model that had five body parts and performed structured random movements in a womb-like environment. It was shown that the method could estimate the number of body parts and kinematic structures without any pre-existing knowledge in many cases. Another experiment showed that the degree of motor coordination in random movements affects the result of body schema formation strongly. It is confirmed that the accuracy rate for body schema estimation had the highest value . when the ratio of motor coordination was . in our setting. These results suggest that kinematic structure can be estimated from tactile information obtained by a fetus moving randomly in a womb without any visual information even though its accuracy was not so high. They also suggest that a certain degree of motor coordination in random movements and the sufficient dimension of state space that represents the body map are important to estimate body schema correctly.

The IPv addresses exhaustion demands a protocol transition from IPv to IPv. The original transition technique, the dual stack, is not widely deployed yet and it demanded the creation of new transition techniques to extend the transition period. This work makes an experimental comparison of techniques that use dual stack with a limited IPv address. This limited address might be a RFC  address with a NAT at the Internet Service Provider ISP gateway, also known as Carrier Grade NAT CGN, or an Address Plus Port AP shared IPv address. The chosen techniques also consider an IPv only ISP network. The transport of the IPv packets through the IPv only networks may use IPv packets encapsulated on IPv packets or a double translation, by making one IPv to IPv translation to enter the IPv only network and one IPv to IPv translation to return to the IPv network. The chosen techniques were DS-Lite, XLAT, MAP-E and MAP-T. The first part of the test is to check some of the most common usages of the Internet by a home user and the impacts of the transition techniques on the user experience. The second part is a measured comparison considering bandwidth, jitter and latency introduced by the techniques and processor usage on the network equipment.

Centrality, as a geometrical property of the collision, is crucial for the physical interpretation of nucleus-nucleus and proton-nucleus experimental data. However, it cannot be directly accessed in event-by-event data analysis. Common methods for centrality estimation in A-A and p-A collisions usually rely on a single detector either on the signal in zero-degree calorimeters or on the multiplicity in some semi-central rapidity range. In the present work, we made an attempt to develop an approach for centrality determination that is based on machine-learning techniques and utilizes information from several detector subsystems simultaneously. Different event classifiers are suggested and evaluated for their selectivity power in terms of the number of nucleons-participants and the impact parameter of the collision. Finer centrality resolution may allow to reduce impact from so-called volume fluctuations on physical observables being studied in heavy-ion experiments like ALICE at the LHC and fixed target experiment NASHINE on SPS.

The unprecedented availability of large-scale human behavioral data is profoundly changing the world we live in. Researchers, companies, governments, financial institutions, non-governmental organizations and also citizen groups are actively experimenting, innovating and adapting algorithmic decision-making tools to understand global patterns of human behavior and provide decision support to tackle problems of societal importance. In this chapter, we focus our attention on social good decision-making algorithms, that is algorithms strongly influencing decision-making and resource optimization of public goods, such as public health, safety, access to finance and fair employment. Through an analysis of specific use cases and approaches, we highlight both the positive opportunities that are created through data-driven algorithmic decision-making, and the potential negative consequences that practitioners should be aware of and address in order to truly realize the potential of this emergent field. We elaborate on the need for these algorithms to provide transparency and accountability, preserve privacy and be tested and evaluated in context, by means of living lab approaches involving citizens. Finally, we turn to the requirements which would make it possible to leverage the predictive power of data-driven human behavior analysis while ensuring transparency, accountability, and civic participation.

Context Todays safety critical systems are increasingly reliant on software. Software becomes responsible for most of the critical functions of systems. Many different safety analysis techniques have been developed to identify hazards of systems. FTA and FMEA are most commonly used by safety analysts. Recently, STPA has been proposed with the goal to better cope with complex systems including software. Objective This research aimed at comparing quantitatively these three safety analysis techniques with regard to their effectiveness, applicability, understandability, ease of use and efficiency in identifying software safety requirements at the system level. Method We conducted a controlled experiment with  master and bachelor students applying these three techniques to three safety-critical systems train door control, anti-lock braking and traffic collision and avoidance. Results The results showed that there is no statistically significant difference between these techniques in terms of applicability, understandability and ease of use, but a significant difference in terms of effectiveness and efficiency is obtained. Conclusion We conclude that STPA seems to be an effective method to identify software safety requirements at the system level. In particular, STPA addresses more different software safety requirements than the traditional techniques FTA and FMEA, but STPA needs more time to carry out by safety analysts with little or no prior experience.

Most machine learning classifiers, including deep neural networks, are vulnerable to adversarial examples. Such inputs are typically generated by adding small but purposeful modifications that lead to incorrect outputs while imperceptible to human eyes. The goal of this paper is not to introduce a single method, but to make theoretical steps towards fully understanding adversarial examples. By using concepts from topology, our theoretical analysis brings forth the key reasons why an adversarial example can fool a classifier f and adds its oracle f, like human eyes in such analysis. By investigating the topological relationship between two pseudometric spaces corresponding to predictor f and oracle f, we develop necessary and sufficient conditions that can determine if f is always robust strong-robust against adversarial examples according to f. Interestingly our theorems indicate that just one unnecessary feature can make f not strong-robust, and the right feature representation learning is the key to getting a classifier that is both accurate and strong robust.

Most of the temporal lobe epilepsy detection approaches are based on hippocampus deformation and use complicated features, resulting, detection is done with complicated features extraction and pre-processing task. In this paper, a new detection method based on shape-based features and spherical harmonics is proposed which can analysis the hippocampus shape anomaly and detection asymmetry. This method consisted of two main parts  shape feature extraction, and  image classification. For evaluation, HFH database is used which is publicly available in this field. Nine different geometry and  spherical harmonic features are introduced then selected Eighteen of them that detect the asymmetry in hippocampus significantly in a randomly selected subset of the dataset. Then a support vector machine SVM classifier was employed to classify the remaining images of the dataset to normal and epileptic images using our selected features. On a dataset of  images,  images were used for feature extraction and the rest  for classification. The results show that the proposed method has accuracy, specificity and sensitivity of, respectively, , , and . Therefore, the proposed approach shows acceptable result and is straightforward also complicated pre-processing steps were omitted compared to other methods.

We present the Neural Physics Engine NPE, a framework for learning simulators of intuitive physics that naturally generalize across variable object count and different scene configurations. We propose a factorization of a physical scene into composable object-based representations and a neural network architecture whose compositional structure factorizes object dynamics into pairwise interactions. Like a symbolic physics engine, the NPE is endowed with generic notions of objects and their interactions realized as a neural network, it can be trained via stochastic gradient descent to adapt to specific object properties and dynamics of different worlds. We evaluate the efficacy of our approach on simple rigid body dynamics in two-dimensional worlds. By comparing to less structured architectures, we show that the NPEs compositional representation of the structure in physical interactions improves its ability to predict movement, generalize across variable object count and different scene configurations, and infer latent properties of objects such as mass.

In this paper, we propose a novel curvature-penalized minimal path model via an orientation-lifted Finsler metric and the Euler elastica curve. The original minimal path model computes the globally minimal geodesic by solving an Eikonal partial differential equation PDE. Essentially, this first-order model is unable to penalize curvature which is related to the path rigidity property in the classical active contour models. To solve this problem, we present an Eikonal PDE-based Finsler elastica minimal path approach to address the curvature-penalized geodesic energy minimization problem. We were successful at adding the curvature penalization to the classical geodesic energy. The basic idea of this work is to interpret the Euler elastica bending energy via a novel Finsler elastica metric that embeds a curvature penalty. This metric is non-Riemannian, anisotropic and asymmetric, and is defined over an orientation-lifted space by adding to the image domain the orientation as an extra space dimension. Based on this orientation lifting, the proposed minimal path model can benefit from both the curvature and orientation of the paths. Thanks to the fast marching method, the global minimum of the curvature-penalized geodesic energy can be computed efficiently. We introduce two anisotropic image data-driven speed functions that are computed by steerable filters. Based on these orientation-dependent speed functions, we can apply the proposed Finsler elastica minimal path model to the applications of closed contour detection, perceptual grouping and tubular structure extraction. Numerical experiments on both synthetic and real images show that these applications of the proposed model indeed obtain promising results.

We present a method for inducing new dialogue systems from very small amounts of unannotated dialogue data, showing how word-level exploration using Reinforcement Learning RL, combined with an incremental and semantic grammar - Dynamic Syntax DS - allows systems to discover, generate, and understand many new dialogue variants. The method avoids the use of expensive and time-consuming dialogue act annotations, and supports more natural incremental dialogues than turn-based systems. Here, language generation and dialogue management are treated as a joint decisionoptimisation problem, and the MDP model for RL is constructed automatically. With an implemented system, we show that this method enables a wide range of dialogue variations to be automatically captured, even when the system is trained from only a single dialogue. The variants include question-answer pairs, over- and under-answering, self- and other-corrections, clarification interaction, split-utterances, and ellipsis. This generalisation property results from the structural knowledge and constraints present within the DS grammar, and highlights some limitations of recent systems built using machine learning techniques only.

Information Centric Networking ICN advocates the philosophy of accessing the content independent of its location. Owing to this location independence in ICN, the routers en-route can be enabled to cache the content to serve the future requests for the same content locally. Several ICN architectures have been proposed in the literature along with various caching algorithms for caching and cache replacement at the routers en-route. The aim of this paper is to critically evaluate various caching policies using Named Data Networking NDN, an ICN architecture proposed in literature. We have presented the performance comparison of different caching policies naming First In First Out FIFO, Least Recently Used LRU, and Universal Caching UC in two network models Watts-Strogatz WS model suitable for dense short link networks such as sensor networks and Sprint topology better suited for large Internet Service Provider ISP networks using ndnSIM, an ns based discrete event simulator for NDN architecture. Our results indicate that UC outperforms other caching policies such as LRU and FIFO and makes UC a better alternative for both sensor networks and ISP networks.

Large Deformation Diffeomorphic Metric Mapping LDDMM is a widely used deformable registration algorithm for computing smooth invertible maps between various types of anatomical shapes such as landmarks, curves, surfaces or images. In this work, we specifically focus on the case of images and adopt an optimal control point of view so as to extend the original LDDMM with Sum of Squared Differences SSD matching term to a framework more robust to intensity variations, which is critical for cross-modality registration. We implement a mutual information based LDDMM MI-LDDMM algorithm and demonstrate its superiority to SSD-LDDMM in aligning D phantoms with differing intensity profiles. This algorithm is then used to register CLARITY mouse brain images to a standard mouse atlas despite their differences in grayscale values. We complement the approach by showing how a cascaded multi-scale method improves the optimization while reducing the run time of the algorithm.

The ability to perform effective off-policy learning would revolutionize the process of building better interactive systems, such as search engines and recommendation systems for e-commerce, computational advertising and news. Recent approaches for off-policy evaluation and learning in these settings appear promising. With this paper, we provide real-world data and a standardized test-bed to systematically investigate these algorithms using data from display advertising. In particular, we consider the problem of filling a banner ad with an aggregate of multiple products the user may want to purchase. This paper presents our test-bed, the sanity checks we ran to ensure its validity, and shows results comparing state-of-the-art off-policy learning methods like doubly robust optimization, POEM, and reductions to supervised learning using regression baselines. Our results show experimental evidence that recent off-policy learning methods can improve upon state-of-the-art supervised learning techniques on a large-scale real-world data set.

Current image captioning methods are usually trained via penalized maximum likelihood estimation. However, the log-likelihood score of a caption does not correlate well with human assessments of quality. Standard syntactic evaluation metrics, such as BLEU, METEOR and ROUGE, are also not well correlated. The newer SPICE and CIDEr metrics are better correlated, but have traditionally been hard to optimize for. In this paper, we show how to use a policy gradient PG method to directly optimize a linear combination of SPICE and CIDEr a combination we call SPIDEr the SPICE score ensures our captions are semantically faithful to the image, while CIDEr score ensures our captions are syntactically fluent. The PG method we propose improves on the prior MIXER approach, by using Monte Carlo rollouts instead of mixing MLE training with PG. We show empirically that our algorithm leads to easier optimization and improved results compared to MIXER. Finally, we show that using our PG method we can optimize any of the metrics, including the proposed SPIDEr metric which results in image captions that are strongly preferred by human raters compared to captions generated by the same model but trained to optimize MLE or the COCO metrics.

Although support vector machines SVMs are theoretically well understood, their underlying optimization problem becomes very expensive if, for example, hundreds of thousands of samples and a non-linear kernel are considered. Several approaches have been proposed in the past to address this serious limitation. In this work we investigate a decomposition strategy that learns on small, spatially defined data chunks. Our contributions are two fold On the theoretical side we establish an oracle inequality for the overall learning method using the hinge loss, and show that the resulting rates match those known for SVMs solving the complete optimization problem with Gaussian kernels. On the practical side we compare our approach to learning SVMs on small, randomly chosen chunks. Here it turns out that for comparable training times our approach is significantly faster during testing and also reduces the test error in most cases significantly. Furthermore, we show that our approach easily scales up to  million training samples including hyper-parameter selection using cross validation, the entire training only takes a few hours on a single machine. Finally, we report an experiment on  million training samples.

Recent advances in neural variational inference have facilitated efficient training of powerful directed graphical models with continuous latent variables, such as variational autoencoders. However, these models usually assume simple, uni-modal priors - such as the multivariate Gaussian distribution - yet many real-world data distributions are highly complex and multi-modal. Examples of complex and multi-modal distributions range from topics in newswire text to conversational dialogue responses. When such latent variable models are applied to these domains, the restriction of the simple, uni-modal prior hinders the overall expressivity of the learned model as it cannot possibly capture more complex aspects of the data distribution. To overcome this critical restriction, we propose a flexible, simple prior distribution which can be learned efficiently and potentially capture an exponential number of modes of a target distribution. We develop the multi-modal variational encoder-decoder framework and investigate the effectiveness of the proposed prior in several natural language processing modeling tasks, including document modeling and dialogue modeling.

A number of recent approaches to policy learning in D game domains have been successful going directly from raw input images to actions. However when employed in complex D environments, they typically suffer from challenges related to partial observability, combinatorial exploration spaces, path planning, and a scarcity of rewarding scenarios. Inspired from prior work in human cognition that indicates how humans employ a variety of semantic concepts and abstractions object categories, localisation, etc. to reason about the world, we build an agent-model that incorporates such abstractions into its policy-learning framework. We augment the raw image input to a Deep Q-Learning Network DQN, by adding details of objects and structural elements encountered, along with the agents localisation. The different components are automatically extracted and composed into a topological representation using on-the-fly object detection and D-scene reconstruction.We evaluate the efficacy of our approach in Doom, a D first-person combat game that exhibits a number of challenges discussed, and show that our augmented framework consistently learns better, more effective policies.

Disordered quantum antiferromagnets in two-dimensional compounds have been a focus of interest in the last years due to their exotic properties. However, with very few exceptions, the ground states of the corresponding Hamiltonians are notoriously difficult to simulate making their characterization and detection very elusive, both, theoretically and experimentally. Here we propose a method to signal quantum disordered antiferromagnets by doing exact diagonalization in small lattices using random boundary conditions and averaging the observables of interest over the different disorder realizations. We apply our method to study a Heisenberg spin- model in an anisotropic triangular lattice. In this model, the competition between frustration and quantum fluctuations might lead to some spin liquid phases as predicted from different methods ranging from spin wave mean field theory to D-DMRG or PEPS. Our method accurately reproduces the ordered phases expected of the model and signals disordered phases by the presence of a large number of quasi degenerate ground states together with the absence of a local order parameter. The method presents a weak dependence on finite size effects.

We present an optimizer which uses Bayesian optimization to tune the system parameters of distributed stochastic gradient descent SGD. Given a specific context, our goal is to quickly find efficient configurations which appropriately balance the load between the available machines to minimize the average SGD iteration time. Our experiments consider setups with over thirty parameters. Traditional Bayesian optimization, which uses a Gaussian process as its model, is not well suited to such high dimensional domains. To reduce convergence time, we exploit the available structure. We design a probabilistic model which simulates the behavior of distributed SGD and use it within Bayesian optimization. Our model can exploit many runtime measurements for inference per evaluation of the objective function. Our experiments show that our resulting optimizer converges to efficient configurations within ten iterations, the optimized configurations outperform those found by generic optimizer in thirty iterations by up to X.

Typical techniques for sequence classification are designed for well-segmented sequences which has been edited to remove noisy or irrelevant parts. Therefore, such methods cannot be easily applied on noisy sequences which are expected in real-world applications. We present the Temporal Attention-Gated Model TAGM which is able to deal with noisy sequences. Our model assimilates ideas from attention models and gated recurrent networks. Specifically, we employ an attention model to measure the relevance of each time step of a sequence to the final decision. We then use the relevant segments based on their attention scores in a novel gated recurrent network to learn the hidden representation for the classification. More importantly, our attention weights provide a physically meaningful interpretation for the salience of each time step in the sequence. We demonstrate the merits of our model in both interpretability and classification performance on a variety of tasks, including speech recognition, textual sentiment analysis and event recognition.

Smart phone apps that enable users to easily track their diets have become widespread in the last decade. This has created an opportunity to discover new insights into obesity and weight loss by analyzing the eating habits of the users of such apps. In this paper, we present dietvec an approach to modeling latent structure in a massive database of electronic diet journals. Through an iterative contract-and-expand process, our model learns real-valued embeddings of users diets, as well as embeddings for individual foods and meals. We demonstrate the effectiveness of our approach on a real dataset of K users of the popular diet-tracking app LoseItfootnotehttpwww.loseit.com. To the best of our knowledge, this is the largest fine-grained diet tracking study in the history of nutrition and obesity research. Our results suggest that dietvec finds interpretable results at all levels, discovering intuitive representations of foods, meals, and diets.

Automating the detection of anomalous events within long video sequences is challenging due to the ambiguity of how such events are defined. We approach the problem by learning generative models that can identify anomalies in videos using limited supervision. We propose end-to-end trainable composite Convolutional Long Short-Term Memory Conv-LSTM networks that are able to predict the evolution of a video sequence from a small number of input frames. Regularity scores are derived from the reconstruction errors of a set of predictions with abnormal video sequences yielding lower regularity scores as they diverge further from the actual sequence over time. The models utilize a composite structure and examine the effects of conditioning in learning more meaningful representations. The best model is chosen based on the reconstruction and prediction accuracy. The Conv-LSTM models are evaluated both qualitatively and quantitatively, demonstrating competitive results on anomaly detection datasets. Conv-LSTM units are shown to be an effective tool for modeling and predicting video sequences.

Student-t processes have recently been proposed as an appealing alternative non-parameteric function prior. They feature enhanced flexibility and predictive variance. In this work the use of Student-t processes are explored for multi-objective Bayesian optimization. In particular, an analytical expression for the hypervolume-based probability of improvement is developed for independent Student-t process priors of the objectives. Its effectiveness is shown on a multi-objective optimization problem which is known to be difficult with traditional Gaussian processes.

Distributed representations of words have been shown to capture lexical semantics, as demonstrated by their effectiveness in word similarity and analogical relation tasks. But, these tasks only evaluate lexical semantics indirectly. In this paper, we study whether it is possible to utilize distributed representations to generate dictionary definitions of words, as a more direct and transparent representation of the embeddings semantics. We introduce definition modeling, the task of generating a definition for a given word and its embedding. We present several definition model architectures based on recurrent neural networks, and experiment with the models over multiple data sets. Our results show that a model that controls dependencies between the word being defined and the definition words performs significantly better, and that a character-level convolution layer designed to leverage morphology can complement word-level embeddings. Finally, an error analysis suggests that the errors made by a definition model may provide insight into the shortcomings of word embeddings.

We employ techniques from topological data analysis to model sensor networks. Our approach to sensor integration uses the topological method of sheaves over cell complexes. The internal consistency of data from individual sensors is determined by a set of consistency functions assigned to elements of the complex. Using these functions we determine, for any collection of data, the unique set of maximal sections of consistent data received from the sensors. We offer a proof for the existence and uniqueness of these sections and illustrate the ideas with examples.

European options can be priced by solving parabolic partial-integro differential equations under stochastic volatility and jump-diffusion models like Heston, Merton, and Bates models. American option prices can be obtained by solving linear complementary problems LCPs with the same operators. A finite difference discretization leads to a so-called full order model FOM. Reduced order models ROMs are derived employing proper orthogonal decomposition POD. The early exercise constraint of American options is enforced by a penalty on subset of grid points. The presented numerical experiments demonstrate that pricing with ROMs can be orders of magnitude faster within a given model parameter variation range.

We present a learning framework for abstracting complex shapes by learning to assemble objects using D volumetric primitives. In addition to generating simple and geometrically interpretable explanations of D objects, our framework also allows us to automatically discover and exploit consistent structure in the data. We demonstrate that using our method allows predicting shape representations which can be leveraged for obtaining a consistent parsing across the instances of a shape collection and constructing an interpretable shape similarity measure. We also examine applications for image-based prediction as well as shape manipulation.

We propose the formal study of governed blockchains that are owned and controlled by organizations and that neither create cryptocurrencies nor provide any incentives to solvers of cryptographic puzzles. We view such approaches as frameworks in which system parts, such as the cryptographic puzzle, may be instantiated with different technology. Owners of such a blockchain procure puzzle solvers as resources they control, and use a mathematical model to compute optimal parameters for the cryptographic puzzle mechanism or other parts of the blockchain. We illustrate this approach with a use case in which blockchains record hashes of financial process transactions to increase their trustworthiness and that of their audits. For Proof of Work as cryptographic puzzle, we develop a detailed mathematical model to derive MINLP optimization problems for computing optimal Proof of Work configuration parameters that trade off potentially conflicting aspects such as availability, resiliency, security, and cost in this governed setting. We demonstrate the utility of such a mining calculus by solving some instances of this problem. This experimental validation is strengthened by statistical experiments that confirm the validity of random variables used in formulating our mathematical model. We hope that our work may facilitate the creation of domain-specific blockchains for a wide range of applications such as trustworthy information in Internet of Things systems and bespoke improvements of legacy financial services.

We propose an automated method for detecting aggressive prostate cancerCaP Gleason score  based on a comprehensive analysis of the lesion and the surrounding normal prostate tissue which has been simultaneously captured in T-weighted MR images, diffusion-weighted images DWI and apparent diffusion coefficient maps ADC. The proposed methodology was tested on a dataset of  patients  aggressive,  non-aggressive. We evaluated the performance of a wide range of popular quantitative imaging features on the characterization of aggressive versus non-aggressive CaP. We found that a group of  discriminative predictors among  quantitative imaging features can be used to produce an area under the ROC curve of ..

We present a variational approximation to the information bottleneck of Tishby et al. . This variational approach allows us to parameterize the information bottleneck model using a neural network and leverage the reparameterization trick for efficient training. We call this method Deep Variational Information Bottleneck, or Deep VIB. We show that models trained with the VIB objective outperform those that are trained with other forms of regularization, in terms of generalization performance and robustness to adversarial attack.

In this paper, the problem of finding a Nash equilibrium of a multi-player game is considered. The players are only aware of their own cost functions as well as the action space of all players. We develop a relatively fast algorithm within the framework of inexact-ADMM. It requires a communication graph for the information exchange between the players as well as a few mild assumptions on cost functions. The convergence proof of the algorithm to a Nash equilibrium of the game is then provided. Moreover, the convergence rate is investigated via simulations.

In this paper we introduce the TorontoCity benchmark, which covers the full greater Toronto area GTA with . km of land,  km of road and around , buildings. Our benchmark provides different perspectives of the world captured from airplanes, drones and cars driving around the city. Manually labeling such a large scale dataset is infeasible. Instead, we propose to utilize different sources of high-precision maps to create our ground truth. Towards this goal, we develop algorithms that allow us to align all data sources with the maps while requiring minimal human supervision. We have designed a wide variety of tasks including building height estimation reconstruction, road centerline and curb extraction, building instance segmentation, building contour extraction reorganization, semantic labeling and scene type classification recognition. Our pilot study shows that most of these tasks are still difficult for modern convolutional neural networks.

Deep reinforcement learning RL can acquire complex behaviors from low-level inputs, such as images. However, real-world applications of such methods require generalizing to the vast variability of the real world. Deep networks are known to achieve remarkable generalization when provided with massive amounts of labeled data, but can we provide this breadth of experience to an RL agent, such as a robot? The robot might continuously learn as it explores the world around it, even while deployed. However, this learning requires access to a reward function, which is often hard to measure in real-world domains, where the reward could depend on, for example, unknown positions of objects or the emotional state of the user. Conversely, it is often quite practical to provide the agent with reward functions in a limited set of situations, such as when a human supervisor is present or in a controlled setting. Can we make use of this limited supervision, and still benefit from the breadth of experience an agent might collect on its own? In this paper, we formalize this problem as semisupervised reinforcement learning, where the reward function can only be evaluated in a set of labeled MDPs, and the agent must generalize its behavior to the wide range of states it might encounter in a set of unlabeled MDPs, by using experience from both settings. Our proposed method infers the task objective in the unlabeled MDPs through an algorithm that resembles inverse RL, using the agents own prior experience in the labeled MDPs as a kind of demonstration of optimal behavior. We evaluate our method on challenging tasks that require control directly from images, and show that our approach can improve the generalization of a learned deep neural network policy by using experience for which no reward function is available. We also show that our method outperforms direct supervised learning of the reward.

We study the problems of multi-person pose segmentation in natural images and instance segmentation in biological images with crowded cells. We formulate these distinct tasks as integer programs where variables correspond to posescells. To optimize, we propose a generic relaxation scheme for solving these combinatorial problems using a column generation formulation where the program for generating a column is solved via exact optimization of very small scale integer programs. This results in efficient exploration of the spaces of poses and cells.

The paper considers the problem of the extremely low frequency magnetic field radiation generated by the tablet computers. Accordingly, the measurement of the magnetic field radiation from a set of tablets is carried out. Furthermore, the measurement results are analyzed and clustered according to the K-Medians algorithm to obtain different magnetic field ranges. The obtained cluster ranges are evaluated according to the reference level proposed by the TCO standard in order to define dangerous areas in the neighborhood of tablet, which are established during the typical work with tablet computers. Analysis shows that dangerous areas correspond to specific inner components of tablet, and gives suggestions to users for a safe usage of tablet and to companies producing tablet components for limiting the risk of magnetic field exposure.

Memory and logic integration on the same chip is becoming increasingly cost effective, creating the opportunity to offload data-intensive functionality to processing units placed inside memory chips. The introduction of memory-side processing units MPUs into conventional systems faces virtual memory as the first big showstopper without efficient hardware support for address translation MPUs have highly limited applicability. Unfortunately, conventional translation hardware i.e., TLBs, MMU caches, and page table walkers incurs dramatic overheads due to the limited reach, increasingly high miss penalty, and high translation coherence cost incurred with rapidly growing aggregate memory size.   In this paper, we are the first to show that the historically important flexibility to map any virtual page to any page frame is unnecessary in todays servers. We find that while limiting the associativity of the virtual-to-physical mapping incurs no penalty, it can break the translate-then-fetch serialization if combined with careful data placement in the MPUs memory, allowing for translation and data fetch to proceed independently and in parallel. We propose the Distributed Inverted Page Table DIPTA, a near-memory structure in which the smallest memory partition keeps the translation information for its data share, ensuring that the translation completes together with the data fetch. DIPTA completely eliminates the conventional translation hardware, as well as the performance overhead of translation, achieving speedups of up to .x and .x over conventional translation using KB and GB pages respectively, and obviating the need for translation-related broadcasts.

We present a modular framework, the Workload Characterisation Framework WCF, that is developed to reproducibly obtain, store and compare key characteristics of radio astronomy processing software. As a demonstration, we discuss the experiences using the framework to characterise a LOFAR calibration and imaging pipeline.

We present an automatic mortality prediction scheme based on the unstructured textual content of clinical notes. Proposing a convolutional document embedding approach, our empirical investigation using the MIMIC-III intensive care database shows significant performance gains compared to previously employed methods such as latent topic distributions or generic docvec embeddings. These improvements are especially pronounced for the difficult problem of post-discharge mortality prediction.

We propose a new method for learning a representation of image motion in an unsupervised fashion. We do so by learning an image sequence embedding that respects associativity and invertibility properties of composed sequences with known temporal order. This procedure makes minimal assumptions about scene content, and the resulting networks learn to exploit rigid and non-rigid motion cues. We show that a deep neural network trained to respect these constraints implicitly identifies the characteristic motion patterns of many different sequence types.   Our network architecture consists of a CNN followed by an LSTM and is structured to learn motion representations over sequences of arbitrary length. We demonstrate that a network trained using our unsupervised procedure on real-world sequences of human actions and vehicle motion can capture semantic regions corresponding to the motion in the scene, and not merely image-level differences, without requiring any motion labels. Furthermore, we present results that suggest our method can be used to extract information useful for independent motion tracking, localization, and nearest neighbor identification. Our results suggest that this representation may be useful for motion-related tasks where explicit labels are often very difficult to obtain.

Due to physiological variation, patients diagnosed with the same condition may exhibit divergent, but related, responses to the same treatments. Hidden Parameter Markov Decision Processes HiP-MDPs tackle this transfer-learning problem by embedding these tasks into a low-dimensional space. However, the original formulation of HiP-MDP had a critical flaw the embedding uncertainty was modeled independently of the agents state uncertainty, requiring an unnatural training procedure in which all tasks visited every part of the state space---possible for robots that can be moved to a particular location, impossible for human patients. We update the HiP-MDP framework and extend it to more robustly develop personalized medicine strategies for HIV treatment.

The problem of distinct value estimation has many applications. Being a critical component of query optimizers in databases, it also has high commercial impact. Many distinct value estimators have been proposed, using various statistical approaches. However, characterizing the errors incurred by these estimators is an open problem existing analytical approaches are not powerful enough, and extensive empirical studies at large scale do not exist. We conduct an extensive large-scale empirical study of  distinct value estimators from four different approaches to the problem over families of Zipfian distributions whose parameters model real-world applications. Our study is the first that emphscales to the size of a billion-rows that todays large commercial databases have to operate in. This allows us to characterize the error that is encountered in real-world applications of distinct value estimation. By mining the generated data, we show that estimator error depends on a key latent parameter --- the average uniform class size --- that has not been studied previously. This parameter also allows us to unearth error patterns that were previously unknown. Importantly, ours is the first approach that provides a framework for emphvisualizing the error patterns in distinct value estimation, facilitating discussion of this problem in enterprise settings. Our characterization of errors can be used for several problems in distinct value estimation, such as the design of hybrid estimators. This work aims at the practitioner and the researcher alike, and addresses questions frequently asked by both audiences.

Deep convolutional neural networks continue to advance the state-of-the-art in many domains as they grow bigger and more complex. It has been observed that many of the parameters of a large network are redundant, allowing for the possibility of learning a smaller network that mimics the outputs of the large network through a process called Knowledge Distillation. We show, however, that standard Knowledge Distillation is not effective for learning small models for the task of pedestrian detection. To improve this process, we introduce a higher-dimensional hint layer to increase information flow. We also estimate the variance in the outputs of the large network and propose a loss function to incorporate this uncertainty. Finally, we attempt to boost the complexity of the small network without increasing its size by using as input hand-designed features that have been demonstrated to be effective for pedestrian detection. We succeed in training a model that contains times fewer parameters than the large network while outperforming AlexNet on the Caltech Pedestrian Dataset.

Individual robots are not effective at exploring large unmapped areas. An alternate approach is to use a swarm of simple robots that work together, rather than a single highly capable robot. The central-place foraging algorithm CPFA is effective for coordinating robot swarm search and collection tasks. Robots start at a centrally placed location nest, explore potential targets in the area without global localization or central control, and return the targets to the nest. The scalability of the CPFA is limited because large numbers of robots produce more inter-robot collisions and large search areas result in substantial travel costs. We address these problems with the multiple-place foraging algorithm MPFA, which uses multiple nests distributed throughout the search area. Robots start from a randomly assigned home nest but return to the closest nest with found targets. We simulate the foraging behavior of robot swarms in the robot simulator ARGoS and employ a genetic algorithm to discover different optimized foraging strategies as swarm sizes and the number of targets are scaled up. In our experiments, the MPFA always produces higher foraging rates, fewer collisions, and lower travel and search time compared to the CPFA for the partially clustered targets distribution. The main contribution of this paper is that we systematically quantify the advantages of the MPFA reduced travel time and collisions, the potential disadvantages less communication among robots, and the ability of a genetic algorithm to tune MPFA parameters to mitigate search inefficiency due to less communication.

We propose a hybrid process calculus for modelling and reasoning on cyber-physical systems CPSs. The dynamics of the calculus is expressed in terms of a labelled transition system in the SOS style of Plotkin. This is used to define a bisimulation-based behavioural semantics which support compositional reasonings. Finally, we prove run-time properties and system equalities for a non-trivial case study.

This paper introduces AcCoRD Actor-based Communication via Reaction-Diffusion version .. AcCoRD is a sandbox reaction-diffusion solver designed for the study of molecular communication systems. It uses a hybrid of microscopic and mesoscopic simulation models that enables scalability via user control of local accuracy. AcCoRD is developed in C as an open source command line tool and includes utilities to process simulation output in MATLAB. The latest code and links to user documentation can be found at httpsgithub.comadamjgnoelAcCoRD. This paper provides an overview of AcCoRDs design, including the motivation for developing a specialized reaction-diffusion solver. The corresponding algorithms are presented in detail, including the computational complexity of the microscopic and mesoscopic models. Other novel derivations include the transition rates between adjacent mesoscopic subvolumes of different sizes. Simulation results demonstrate the use of AcCoRD as both an accurate reaction-diffusion solver and one that is catered to the analysis of molecular communication systems. A link is included to videos that demonstrate many of the simulated scenarios. Additional insights from the simulation results include the selection of suitable hybrid model parameters, the impact of reactive surfaces that are in the proximity of a hybrid interface, and the size of a bounded environment that is necessary to assume that it is unbounded. The development of AcCoRD is ongoing, so its future direction is also discussed in order to highlight improvements that will expand its potential areas of application. New features that are being planned at the time of writing include a fluid flow model and more complex actor behavior.

We present a method for D object detection and pose estimation from a single image. In contrast to current techniques that only regress the D orientation of an object, our method first regresses relatively stable D object properties using a deep convolutional neural network and then combines these estimates with geometric constraints provided by a D object bounding box to produce a complete D bounding box. The first network output estimates the D object orientation using a novel hybrid discrete-continuous loss, which significantly outperforms the L loss. The second output regresses the D object dimensions, which have relatively little variance compared to alternatives and can often be predicted for many object types. These estimates, combined with the geometric constraints on translation imposed by the D bounding box, enable us to recover a stable and accurate D object pose. We evaluate our method on the challenging KITTI object detection benchmark both on the official metric of D orientation estimation and also on the accuracy of the obtained D bounding boxes. Although conceptually simple, our method outperforms more complex and computationally expensive approaches that leverage semantic segmentation, instance level segmentation and flat ground priors and sub-category detection. Our discrete-continuous loss also produces state of the art results for D viewpoint estimation on the Pascal D dataset.

Supervised pre-training currently yields state-of-the-art performance for representation learning for visual recognition, yet it comes at the cost of  intensive manual annotations and  an inherent restriction in the scope of data relevant for learning. In this work, we explore unsupervised feature learning from unlabeled video. We introduce a novel object-centric approach to temporal coherence that encourages similar representations to be learned for object-like regions segmented from nearby frames. Our framework relies on a Siamese-triplet network to train a deep convolutional neural network CNN representation. Compared to existing temporal coherence methods, our idea has the advantage of lightweight preprocessing of the unlabeled video no tracking required while still being able to extract object-level regions from which to learn invariances. Furthermore, as we show in results on several standard datasets, our method typically achieves substantial accuracy gains over competing unsupervised methods for image classification and retrieval tasks.

We propose using canonical correlation analysis CCA to generate features from sequences of medical billing codes. Applying this novel use of CCA to a database of medical billing codes for patients with diverticulitis, we first demonstrate that the CCA embeddings capture meaningful relationships among the codes. We then generate features from these embeddings and establish their usefulness in predicting future elective surgery for diverticulitis, an important marker in efforts for reducing costs in healthcare.

During the past decade, machine learning has become extremely popular and can be found in many aspects of our every day life. Nowayadays with explosion of data while rapid growth of computation capacity, Distributed Deep Neural Networks DDNNs which can improve their performance linearly with more computation resources, have become hot and trending. However, there has not been an in depth study of the performance of these systems, and how well they scale.   In this paper we analyze CNTK, one of the most commonly used DDNNs, by first building a performance model and then evaluating the system two settings a small cluster with all nodes in a single rack connected to a top of rack switch, and in large scale using Blue Waters with arbitary placement of nodes. Our main focus was the scalability of the system with respect to adding more nodes. Based on our results, this system has an excessive initialization overhead because of poor IO utilization which dominates the whole execution time. Because of this, the system does not scale beyond a few nodes  in Blue Waters. Additionally, due to a single server-multiple worker design the server becomes a bottleneck after  nodes limiting the scalability of the CNTK.

We propose a new approach for editing face images, which enables numerous exciting applications including face relighting, makeup transfer and face detail editing. Our face edits are based on a visual representation, which includes geometry, face segmentation, albedo, illumination and detail map. To recover our visual representation, we start by estimating geometry using a morphable face model, then decompose the face image to recover the albedo, and then shade the geometry with the albedo and illumination. The residual between our shaded geometry and the input image produces our detail map, which carries high frequency information that is either insufficiently or incorrectly captured by our shading process. By manipulating the detail map, we can edit face images with reality and identity preserved. Our representation allows various applications. First, it allows a user to directly manipulate various illumination. Second, it allows non-parametric makeup transfer with input faces distinctive identity features preserved. Third, it allows non-parametric modifications to the face appearance by transferring details. For face relighting and detail editing, we evaluate via a user study and our method outperforms other methods. For makeup transfer, we evaluate via an online attractiveness evaluation system, and can reliably make people look younger and more attractive. We also show extensive qualitative comparisons to existing methods, and have significant improvements over previous techniques.

We present a data-driven inference method that can synthesize a photorealistic texture map of a complete D face model given a partial D view of a person in the wild. After an initial estimation of shape and low-frequency albedo, we compute a high-frequency partial texture map, without the shading component, of the visible face area. To extract the fine appearance details from this incomplete input, we introduce a multi-scale detail analysis technique based on mid-layer feature correlations extracted from a deep convolutional neural network. We demonstrate that fitting a convex combination of feature correlations from a high-resolution face database can yield a semantically plausible facial detail description of the entire face. A complete and photorealistic texture map can then be synthesized by iteratively optimizing for the reconstructed feature correlations. Using these high-resolution textures and a commercial rendering framework, we can produce high-fidelity D renderings that are visually comparable to those obtained with state-of-the-art multi-view face capture systems. We demonstrate successful face reconstructions from a wide range of low resolution input images, including those of historical figures. In addition to extensive evaluations, we validate the realism of our results using a crowdsourced user study.

Accurately predicting drug responses to cancer is an important problem hindering oncologists efforts to find the most effective drugs to treat cancer, which is a core goal in precision medicine. The scientific community has focused on improving this prediction based on genomic, epigenomic, and proteomic datasets measured in human cancer cell lines. Real-world cancer cell lines contain noise, which degrades the performance of machine learning algorithms. This problem is rarely addressed in the existing approaches. In this paper, we present a noise-filtering approach that integrates techniques from numerical linear algebra and information retrieval targeted at filtering out noisy cancer cell lines. By filtering out noisy cancer cell lines, we can train machine learning algorithms on better quality cancer cell lines. We evaluate the performance of our approach and compare it with an existing approach using the Area Under the ROC Curve AUC on clinical trial data. The experimental results show that our proposed approach is stable and also yields the highest AUC at a statistically significant level.

Iterative methods on irregular grids have been used widely in all areas of comptational science and engineering for solving partial differential equations with complex geometry. They provide the flexibility to express complex shapes with relatively low computational cost. However, the direction of the evolution of high-performance processors in the last two decades have caused serious degradation of the computational efficiency of iterative methods on irregular grids, because of relatively low memory bandwidth. Data compression can in principle reduce the necessary memory memory bandwidth of iterative methods and thus improve the efficiency. We have implemented several data compression algorithms on the PEZY-SC processor, using the matrix generated for the HPCG benchmark as an example. For the SpMV Sparse Matrix-Vector multiplication part of the HPCG benchmark, the best implementation without data compression achieved .Gflopschip, close to the theoretical limit due to the memory bandwidth. Our implementation with data compression has achieved .Gflops. This is of course rather extreme case, since the grid used in HPCG is geometrically regular and thus its compression efficiency is very high. However, in real applications, it is in many cases possible to make a large part of the grid to have regular geometry, in particular when the resolution is high. Note that we do not need to change the structure of the program, except for the addition of the data compressiondecompression subroutines. Thus, we believe the data compression will be very useful way to improve the performance of many applications which rely on the use of irregular grids.

Incentivized social advertising, an emerging marketing model, provides monetization opportunities not only to the owners of the social networking platforms but also to their influential users by offering a cut on the advertising revenue. We consider a social network the host that sells ad-engagements to advertisers by inserting their ads, in the form of promoted posts, into the feeds of carefully selected initial endorsers or seed users these users receive monetary incentives in exchange for their endorsements. The endorsements help propagate the ads to the feeds of their followers. In this context, the problem for the host is is to allocate ads to influential users, taking into account the propensity of ads for viral propagation, and carefully apportioning the monetary budget of each of the advertisers between incentives to influential users and ad-engagement costs, with the rational goal of maximizing its own revenue. We consider a monetary incentive for the influential users, which is proportional to their influence potential. We show that revenue maximization in incentivized social advertising corresponds to the problem of monotone submodular function maximization, subject to a partition matroid constraint on the ads-to-seeds allocation, and submodular knapsack constraints on the advertisers budgets. This problem is NP-hard and we devise  greedy algorithms with provable approximation guarantees, which differ in their sensitivity to seed user incentive costs. Our approximation algorithms require repeatedly estimating the expected marginal gain in revenue as well as in advertiser payment. By exploiting a connection to the recent advances made in scalable estimation of expected influence spread, we devise efficient and scalable versions of the greedy algorithms.

Jointly integrating aspect ratio and context has been extensively studied and shown performance improvement in traditional object detection systems such as the DPMs. It, however, has been largely ignored in deep neural network based detection systems. This paper presents a method of integrating a mixture of object models and region-based convolutional networks for accurate object detection. Each mixture component accounts for both object aspect ratio and multi-scale contextual information explicitly i it exploits a mixture of tiling configurations in the RoI pooling to remedy the warping artifacts caused by a single type RoI pooling e.g., with equally-sized  x  cells, and to respect the underlying object shapes more ii it looks from both the inside and the outside of a RoI by incorporating contextual information at two scales global context pooled from the whole image and local context pooled from the surrounding of a RoI. To facilitate accurate detection, this paper proposes a multi-stage detection scheme for integrating the mixture of object models, which utilizes the detection results of the model at the previous stage as the proposals for the current in both training and testing. The proposed method is called the aspect ratio and context aware region-based convolutional network ARC-R-CNN. In experiments, ARC-R-CNN shows very competitive results with Faster R-CNN  and R-FCN  on two datasets the PASCAL VOC and the Microsoft COCO. It obtains significantly better mAP performance using high IoU thresholds on both datasets.

Mammography is the most widely used method to screen breast cancer. Because of its mostly manual nature, variability in mass appearance, and low signal-to-noise ratio, a significant number of breast masses are missed or misdiagnosed. In this work, we present how Convolutional Neural Networks can be used to directly classify pre-segmented breast masses in mammograms as benign or malignant, using a combination of transfer learning, careful pre-processing and data augmentation to overcome limited training data. We achieve state-of-the-art results on the DDSM dataset, surpassing human performance, and show interpretability of our model.

We consider the minimization of non-convex quadratic forms regularized by a cubic term, which exhibit multiple saddle points and poor local minima. Nonetheless, we prove that, under mild assumptions, gradient descent approximates the textitglobal minimum to within varepsilon accuracy in Ovarepsilon-logvarepsilon steps for large varepsilon and Ologvarepsilon steps for small varepsilon compared to a condition number we define, with at most logarithmic dependence on the problem dimension. When we use gradient descent to approximate the Nesterov-Polyak cubic-regularized Newton step, our result implies a rate of convergence to second-order stationary points of general smooth non-convex functions.

The Internet of Things IoT promises ubiquitous connectivity of everything everywhere, which represents the biggest technology trend in the years to come. It is expected that by  over  billion devices will be connected to cellular networks far beyond the number of devices in current wireless networks. Machine-to-Machine MM communications aims at providing the communication infrastructure for enabling IoT by facilitating the billions of multi-role devices to communicate with each other and with the underlying data transport infrastructure without, or with little, human intervention. Providing this infrastructure will require a dramatic shift from the current protocols mostly designed for human-to-human HH applications. This article reviews recent GPP solutions for enabling massive cellular IoT and investigates the random access strategies for MM communications, which shows that cellular networks must evolve to handle the new ways in which devices will connect and communicate with the system. A massive non-orthogonal multiple access NOMA technique is then presented as a promising solution to support a massive number of IoT devices in cellular networks, where we also identify its practical challenges and future research directions.

Feature selection is a process of choosing a subset of relevant features so that the quality of prediction models can be improved. An extensive body of work exists on information-theoretic feature selection, based on maximizing Mutual Information MI between subsets of features and class labels. The prior methods use a lower order approximation, by treating the joint entropy as a summation of several single variable entropies. This leads to locally optimal selections and misses multi-way feature combinations. We present a higher order MI based approximation technique called Higher Order Feature Selection HOFS. Instead of producing a single list of features, our method produces a ranked collection of feature subsets that maximizes MI, giving better comprehension feature ranking as to which features work best together when selected, due to their underlying interdependent structure. Our experiments demonstrate that the proposed method performs better than existing feature selection approaches while keeping similar running times and computational complexity.

We aim to create a framework for transfer learning using latent factor models to learn the dependence structure between a larger source dataset and a target dataset. The methodology is motivated by our goal of building a risk-assessment model for surgery patients, using both institutional and national surgical outcomes data. The national surgical outcomes data is collected through NSQIP National Surgery Quality Improvement Program, a database housing almost  million patients from over  different hospitals. We build a latent factor model with a hierarchical prior on the loadings matrix to appropriately account for the different covariance structure in our data. We extend this model to handle more complex relationships between the populations by deriving a scale mixture formulation using stick-breaking properties. Our model provides a transfer learning framework that utilizes all information from both the source and target data, while modeling the underlying inherent differences between them.

We propose a new task of unsupervised action detection by action matching. Given two long videos, the objective is to temporally detect all pairs of matching video segments. A pair of video segments are matched if they share the same human action. The task is category independent---it does not matter what action is being performed---and no supervision is used to discover such video segments. Unsupervised action detection by action matching allows us to align videos in a meaningful manner. As such, it can be used to discover new action categories or as an action proposal technique within, say, an action detection pipeline. Moreover, it is a useful pre-processing step for generating video highlights, e.g., from sports videos.   We present an effective and efficient method for unsupervised action detection. We use an unsupervised temporal encoding method and exploit the temporal consistency in human actions to obtain candidate action segments. We evaluate our method on this challenging task using three activity recognition benchmarks, namely, the MPII Cooking activities dataset, the THUMOS action detection benchmark and a new dataset called the IKEA dataset. On the MPII Cooking dataset we detect action segments with a precision of . and recall of . over  long video pairs and over  ground truth action segments. Similarly, on THUMOS dataset we obtain . precision and . recall over  ground truth action segment pairs.

This paper presents a method of zero-shot learning ZSL which poses ZSL as the missing data problem, rather than the missing label problem. Specifically, most existing ZSL methods focus on learning mapping functions from the image feature space to the label embedding space. Whereas, the proposed method explores a simple yet effective transductive framework in the reverse way --- our method estimates data distribution of unseen classes in the image feature space by transferring knowledge from the label embedding space. In experiments, our method outperforms the state-of-the-art on two popular datasets.

Recently it has been shown that policy-gradient methods for reinforcement learning can be utilized to train deep end-to-end systems directly on non-differentiable metrics for the task at hand. In this paper we consider the problem of optimizing image captioning systems using reinforcement learning, and show that by carefully optimizing our systems using the test metrics of the MSCOCO task, significant gains in performance can be realized. Our systems are built using a new optimization approach that we call self-critical sequence training SCST. SCST is a form of the popular REINFORCE algorithm that, rather than estimating a baseline to normalize the rewards and reduce variance, utilizes the output of its own test-time inference algorithm to normalize the rewards it experiences. Using this approach, estimating the reward signal as actor-critic methods must do and estimating normalization as REINFORCE algorithms typically do is avoided, while at the same time harmonizing the model with respect to its test-time inference procedure. Empirically we find that directly optimizing the CIDEr metric with SCST and greedy decoding at test-time is highly effective. Our results on the MSCOCO evaluation sever establish a new state-of-the-art on the task, improving the best result in terms of CIDEr from . to ..

This paper studies state estimation over noisy channels for stochastic non-linear systems. We consider three estimation objectives, a strong and a weak form of almost sure stability of the estimation error as well as quadratic stability in expectation. For all three objectives, we derive lower bounds on the smallest channel capacity C above which the objective can be achieved with an arbitrarily small error. Lower bounds are obtained via a dynamical systems through a novel construction of a dynamical system, an information-theoretic and a random dynamical systems approach. The first two approaches show that for a large class of systems, such as additive noise systems, C  infty, i.e., the estimation objectives cannot be achieved via channels of finite capacity. The random dynamical systems approach is shown to be operationally non-adequate for the problem, since it yields finite lower bounds C under mild assumptions. Finally, we prove that a memoryless noisy channel in general constitutes no obstruction to asymptotic almost sure state estimation with arbitrarily small errors, when there is no noise in the system.

Programming by demonstration PbD is an effective technique for developing complex robot manipulation tasks, such as opening bottles or using human tools. In order for such tasks to generalize to new scenes, the robot needs to be able to perceive objects, object parts, or other task-relevant parts of the scene. Previous work has relied on rigid, task-specific perception systems for this purpose. This paper presents a flexible and open-ended perception system that lets users specify perceptual landmarks during the demonstration, by capturing parts of the point cloud from the demonstration scene. We present a method for localizing landmarks in new scenes and experimentally evaluate this method in a variety of settings. Then, we provide examples where user-specified landmarks are used together with PbD on a PR robot to perform several complex manipulation tasks. Finally, we present findings from a user evaluation of our landmark specification interface demonstrating its feasibility as an end-user tool.

Transition-based models can be fast and accurate for constituent parsing. Compared with chart-based models, they leverage richer features by extracting history information from a parser stack, which spans over non-local constituents. On the other hand, during incremental parsing, constituent information on the right hand side of the current word is not utilized, which is a relative weakness of shift-reduce parsing. To address this limitation, we leverage a fast neural model to extract lookahead features. In particular, we build a bidirectional LSTM model, which leverages the full sentence information to predict the hierarchy of constituents that each word starts and ends. The results are then passed to a strong transition-based constituent parser as lookahead features. The resulting parser gives . absolute improvement in WSJ and . in CTB compared to the baseline, given the highest reported accuracies for fully-supervised parsing.

Distributed renewable energy resources have attracted significant attention in recent years due to the falling cost of the renewable energy technology, extensive federal and state incentives, and the application in improving load-point reliability. This growing proliferation, however, is changing the traditional consumption load curves by adding considerable levels of variability and further challenging the electricity supply-demand balance. In this paper, the application of microgrids in effectively capturing the distribution network net load variability, caused primarily by the prosumers, is investigated. Microgrids provide a viable and localized solution to this challenge while removing the need for costly investments by the electric utility on reinforcing the existing electricity infrastructure. A flexibility-oriented microgrid optimal scheduling model is proposed and developed to coordinate the microgrid net load with the aggregated consumersprosumers net load in the distribution network with a focus on ramping issues. The proposed coordination is performed to capture both inter-hour and intra-hour net load variabilities. Numerical simulations on a test distribution feeder with one microgrid and several consumers and prosumers exhibit the effectiveness of the proposed model.

In conventional cellular networks, for base stations BSs that are deployed far away from each other, it is general to assume them to be mutually independent. Nevertheless, after long-term evolution of cellular networks in various generations, this assumption no longer holds. Instead, the BSs, which seem to be gradually deployed by operators in a service-oriented manner, have embedded many fundamentally distinctive features in their locations, coverage and traffic loading. These features can be leveraged to analyze the intrinsic pattern in BSs and even human community. In this paper, according to large-scale measurement datasets, we build up a correlation model of BSs by utilizing one of the most important features, ie., spatial traffic. Coupling with the theory of complex networks, we make further analysis on the structure and characteristics of this traffic load correlation model. Numerical results show that the degree distribution follows scale-free property. Also the datasets unveil the characteristics of fractality and small-world. Furthermore, we apply collective influence CI algorithm to localize the influential base stations and demonstrate that some low-degree BSs may outrank BSs with larger degree.

Existing image captioning models do not generalize well to out-of-domain images containing novel scenes or objects. This limitation severely hinders the use of these models in real world applications dealing with images in the wild. We address this problem using a flexible approach that enables existing deep captioning architectures to take advantage of image taggers at test time, without re-training. Our method uses constrained beam search to force the inclusion of selected tag words in the output, and fixed, pretrained word embeddings to facilitate vocabulary expansion to previously unseen tag words. Using this approach we achieve state of the art results for out-of-domain captioning on MS COCO and improved results for in-domain captioning. In order to demonstrate the scalability of our approach, we generate and publicly release captions for the complete ImageNet classification dataset containing .M images. Each ImageNet caption includes the ground-truth image label. Human evaluations indicate that  of the resulting captions are likely to meet or exceed human quality increasing to  for certain categories such as birds.

Knowledge of patients affective state could prove to be crucial for health-care professionals in both diagnosis and treatment, however, this requires patients to report how they feel. In practice the sampling rate of affective states needs to be kept low, in order to ensure that the patients can rest. Furthermore using traditional methods of measuring affective states, is not always possible, e.g. patients can be incapable of verbal communications. In this study we explore the prediction of peoples self-reported affective state by measuring multiple physiological signals. We use different Neural networks NN setups and compare with different multiple linear regression MLR setups for prediction of changes in affective states. The results showed that NN and MLR predicted the change in affective states with accuracies of . and ., respectively.

Autonomous systems can be used to search for sparse signals in a large space e.g., aerial robots can be deployed to localize threats, detect gas leaks, or respond to distress calls. Intuitively, search algorithms may increase efficiency by collecting aggregate measurements summarizing large contiguous regions. However, most existing search methods either ignore the possibility of such region observations e.g., Bayesian optimization and multi-armed bandits or make strong assumptions about the sensing mechanism that allow each measurement to arbitrarily encode all signals in the entire environment e.g., compressive sensing. We propose an algorithm that actively collects data to search for sparse signals using only noisy measurements of the average values on rectangular regions including single points, based on the greedy maximization of information gain. We analyze our algorithm in d and show that it requires tildeOfracnmuk measurements to recover all of k signal locations with small Bayes error, where mu and n are the signal strength and the size of the search space, respectively. We also show that active designs can be fundamentally more efficient than passive designs with region sensing, contrasting with the results of Arias-Castro, Candes, and Davenport . We demonstrate the empirical performance of our algorithm on a search problem using satellite image data and in high dimensions.

Though there are some works on improving distributed word representations using lexicons, the improper overfitting of the words that have multiple meanings is a remaining issue deteriorating the learning when lexicons are used, which needs to be solved. An alternative method is to allocate a vector per sense instead of a vector per word. However, the word representations estimated in the former way are not as easy to use as the latter one. Our previous work uses a probabilistic method to alleviate the overfitting, but it is not robust with a small corpus. In this paper, we propose a new neural network to estimate distributed word representations using a lexicon and a corpus. We add a lexicon layer in the continuous bag-of-words model and a threshold node after the output of the lexicon layer. The threshold rejects the unreliable outputs of the lexicon layer that are less likely to be the same with their inputs. In this way, it alleviates the overfitting of the polysemous words. The proposed neural network can be trained using negative sampling, which maximizing the log probabilities of target words given the context words, by distinguishing the target words from random noises. We compare the proposed neural network with the continuous bag-of-words model, the other works improving it, and the previous works estimating distributed word representations using both a lexicon and a corpus. The experimental results show that the proposed neural network is more efficient and balanced for both semantic tasks and syntactic tasks than the previous works, and robust to the size of the corpus.

This paper presents the development of a hybrid learning system based on Support Vector Machines SVM, Adaptive Neuro-Fuzzy Inference System ANFIS and domain knowledge to solve prediction problem. The proposed two-stage Domain Knowledge based Fuzzy Information System DKFIS improves the prediction accuracy attained by ANFIS alone. The proposed framework has been implemented on a noisy and incomplete dataset acquired from a hydrocarbon field located at western part of India. Here, oil saturation has been predicted from four different well logs i.e. gamma ray, resistivity, density, and clay volume. In the first stage, depending on zero or near zero and non-zero oil saturation levels the input vector is classified into two classes Class  and Class  using SVM. The classification results have been further fine-tuned applying expert knowledge based on the relationship among predictor variables i.e. well logs and target variable - oil saturation. Second, an ANFIS is designed to predict non-zero Class  oil saturation values from predictor logs. The predicted output has been further refined based on expert knowledge. It is apparent from the experimental results that the expert intervention with qualitative judgment at each stage has rendered the prediction into the feasible and realistic ranges. The performance analysis of the prediction in terms of four performance metrics such as correlation coefficient CC, root mean square error RMSE, and absolute error mean AEM, scatter index SI has established DKFIS as a useful tool for reservoir characterization.

Point cloud is an important type of geometric data structure. Due to its irregular format, most researchers transform such data to regular D voxel grids or collections of images. This, however, renders data unnecessarily voluminous and causes issues. In this paper, we design a novel type of neural network that directly consumes point clouds and well respects the permutation invariance of points in the input. Our network, named PointNet, provides a unified architecture for applications ranging from object classification, part segmentation, to scene semantic parsing. Though simple, PointNet is highly efficient and effective. Empirically, it shows strong performance on par or even better than state of the art. Theoretically, we provide analysis towards understanding of what the network has learnt and why the network is robust with respect to input perturbation and corruption.

We introduce a novel approach for parallelizing MCMC inference in models with spatially determined conditional independence relationships, for which existing techniques exploiting graphical model structure are not applicable. Our approach is motivated by a model of seismic events and signals, where events detected in distant regions are approximately independent given those in intermediate regions. We perform parallel inference by coloring a factor graph defined over regions of latent space, rather than individual model variables. Evaluating on a model of seismic event detection, we achieve significant speedups over serial MCMC with no degradation in inference quality.

This paper focuses on the challenging problem of D pose estimation of a diverse spectrum of articulated objects from single depth images. A novel structured prediction approach is considered, where D poses are represented as skeletal models that naturally operate on manifolds. Given an input depth image, the problem of predicting the most proper articulation of underlying skeletal model is thus formulated as sequentially searching for the optimal skeletal configuration. This is subsequently addressed by convolutional neural nets trained end-to-end to render sequential prediction of the joint locations as regressing a set of tangent vectors of the underlying manifolds. Our approach is examined on various articulated objects including human hand, mouse, and fish benchmark datasets. Empirically it is shown to deliver highly competitive performance with respect to the state-of-the-arts, while operating in real-time over  FPS.

Recently, there has been an increasing interest in designing distributed convex optimization algorithms under the setting where the data matrix is partitioned on features. Algorithms under this setting sometimes have many advantages over those under the setting where data is partitioned on samples, especially when the number of features is huge. Therefore, it is important to understand the inherent limitations of these optimization problems. In this paper, with certain restrictions on the communication allowed in the procedures, we develop tight lower bounds on communication rounds for a broad class of non-incremental algorithms under this setting. We also provide a lower bound on communication rounds for a class of randomized incremental algorithms.

Generation of D data by deep neural network has been attracting increasing attention in the research community. The majority of extant works resort to regular representations such as volumetric grids or collection of images however, these representations obscure the natural invariance of D shapes under geometric transformations and also suffer from a number of other issues. In this paper we address the problem of D reconstruction from a single image, generating a straight-forward form of output -- point cloud coordinates. Along with this problem arises a unique and interesting issue, that the groundtruth shape for an input image may be ambiguous. Driven by this unorthodox output form and the inherent ambiguity in groundtruth, we design architecture, loss function and learning paradigm that are novel and effective. Our final solution is a conditional shape sampler, capable of predicting multiple plausible D point clouds from an input image. In experiments not only can our system outperform state-of-the-art methods on single image based d reconstruction benchmarks but it also shows a strong performance for d shape completion and promising ability in making multiple plausible predictions.

Many state-of-the-art approaches to people tracking rely on detecting them in each frame independently, grouping detections into short but reliable trajectory segments, and then further grouping them into full trajectories. This grouping typically relies on imposing local smoothness constraints but almost never on enforcing more global constraints on the trajectories. In this paper, we propose an approach to imposing global consistency by first inferring behavioral patterns from the ground truth and then using them to guide the tracking algorithm. When used in conjunction with several state-of-the-art algorithms, this further increases their already good performance. Furthermore, we propose an unsupervised scheme that yields almost similar improvements without the need for ground truth.

In this paper, we study the problem of semantic annotation on D models that are represented as shape graphs. A functional view is taken to represent localized information on graphs, so that annotations such as part segment or keypoint are nothing but - indicator vertex functions. Compared with images that are D grids, shape graphs are irregular and non-isomorphic data structures. To enable the prediction of vertex functions on them by convolutional neural networks, we resort to spectral CNN method that enables weight sharing by parameterizing kernels in the spectral domain spanned by graph laplacian eigenbases. Under this setting, our network, named SyncSpecCNN, strive to overcome two key challenges how to share coefficients and conduct multi-scale analysis in different parts of the graph for a single shape, and how to share information across related but different shapes that may be represented by very different graphs. Towards these goals, we introduce a spectral parameterization of dilated convolutional kernels and a spectral transformer network. Experimentally we tested our SyncSpecCNN on various tasks, including D shape part segmentation and D keypoint prediction. State-of-the-art performance has been achieved on all benchmark datasets.

With the introduction of the Electric Health Records, large amounts of digital data become available for analysis and decision support. When physicians are prescribing treatments to a patient, they need to consider a large range of data variety and volume, making decisions increasingly complex. Machine learning based Clinical Decision Support systems can be a solution to the data challenges. In this work we focus on a class of decision support in which the physicians decision is directly predicted. Concretely, the model would assign higher probabilities to decisions that it presumes the physician are more likely to make. Thus the CDS system can provide physicians with rational recommendations. We also address the problem of correlation in target features Often a physician is required to make multiple sub-decisions in a block, and that these decisions are mutually dependent. We propose a solution to the target correlation problem using a tensor factorization model. In order to handle the patients historical information as sequential data, we apply the so-called Encoder-Decoder-Framework which is based on Recurrent Neural Networks RNN as encoders and a tensor factorization model as a decoder, a combination which is novel in machine learning. With experiments with real-world datasets we show that the proposed model does achieve better prediction performances.

Multiple Sclerosis is a degenerative condition of the central nervous system that affects nearly . million of individuals in terms of their physical, cognitive, psychological and social capabilities. Researchers are currently investigating on the use of patient reported outcome measures for the assessment of impact and evolution of the disease on the life of the patients. To date, a clear understanding on the use of such measures to predict the evolution of the disease is still lacking. In this work we resort to regularized machine learning methods for binary classification and multiple output regression. We propose a pipeline that can be used to predict the disease progression from patient reported measures. The obtained model is tested on a data set collected from an ongoing clinical research project.

The traditional algorithms do not meet the latest multiple requirements simultaneously for objects. Density-based method is one of the methodologies, which can detect arbitrary shaped clusters where clusters are defined as dense regions separated by low density regions. In this paper, we present a new clustering algorithm to enhance the density-based algorithm DBSCAN. This enables an automatic parameter generation strategy to create clusters with different densities and enables noises recognition, and generates arbitrary shaped clusters. The kdtree is used for increasing the memory efficiency. Experimental result shows that proposed algorithm is capable of handling complex objects with good memory efficiency and accuracy.

The biggest challenge in the field of image processing is to recognize documents both in printed and handwritten format. Optical Character Recognition OCR is a type of document image analysis where scanned digital image that contains either machine printed or handwritten script input into an OCR software engine and translating it into an editable machine readable digital text format. A Neural network is designed to model the way in which the brain performs a particular task or function of interest The neural network is simulated in software on a digital computer. Character Recognition refers to the process of converting printed Text documents into translated Unicode Text. The printed documents available in the form of books, papers, magazines, etc. are scanned using standard scanners which produce an image of the scanned document. Lines are identifying by an algorithm where we identify top and bottom of line. Then in each line character boundaries are calculated by an algorithm then using these calculation, characters is isolated from the image and then we classify each character by basic back propagation. Each image character is comprised of  pixels. We have used the Back propagation Neural Network for efficient recognition where the errors were corrected through back propagation and rectified neuron values were transmitted by feed-forward method in the neural network of multiple layers.

A required feature for the next generation of wireless communication networks will be the capability to serve simultaneously a large number of devices with heterogeneous CSIT qualities and demands. In this paper, we consider the overloaded MISO BC with two groups of CSIT qualities. We propose a transmission scheme where degraded symbols are superimposed on top of spatially-multiplexed symbols. The developed strategy allows to serve all users in a non-orthogonal manner and the analysis shows an enhanced perfomance compared to existing schemes. Moreover, optimality in a DoF sense is shown.

A major hurdle to the deployment of quantum linear systems algorithms and recent quantum simulation algorithms lies in the difficulty to find inexpensive reversible circuits for arithmetic using existing hand coded methods. Motivated by recent advances in reversible logic synthesis, we synthesize arithmetic circuits using classical design automation flows and tools. The combination of classical and reversible logic synthesis enables the automatic design of large components in reversible logic starting from well-known hardware description languages such as Verilog. As a prototype example for our approach we automatically generate high quality networks for the reciprocal x, which is necessary for quantum linear systems algorithms.

Time Series Clustering is an important subroutine in many higher-level data mining analyses, including data editing for classifiers, summarization, and outlier detection. It is well known that for similarity search the superiority of Dynamic Time Warping DTW over Euclidean distance gradually diminishes as we consider ever larger datasets. However, as we shall show, the same is not true for clustering. Clustering time series under DTW remains a computationally expensive operation. In this work, we address this issue in two ways. We propose a novel pruning strategy that exploits both the upper and lower bounds to prune off a very large fraction of the expensive distance calculations. This pruning strategy is admissible and gives us provably identical results to the brute force algorithm, but is at least an order of magnitude faster. For datasets where even this level of speedup is inadequate, we show that we can use a simple heuristic to order the unavoidable calculations in a most-useful-first ordering, thus casting the clustering into an anytime framework. We demonstrate the utility of our ideas with both single and multidimensional case studies in the domains of astronomy, speech physiology, medicine and entomology. In addition, we show the generality of our clustering framework to other domains by efficiently obtaining semantically significant clusters in protein sequences using the Edit Distance, the discrete data analogue of DTW.

We introduce a probabilistic Bayesian framework and associated software toolbox for mapping population receptive fields pRFs based on fMRI data. This generic approach is intended to work with stimuli of any dimension and is demonstrated and validated in the context of D retinotopic mapping. The framework enables the experimenter to specify generative encoding models of fMRI timeseries, in which experimental manipulations enter a pRF model of neural activity, which in turns drives a nonlinear model of neurovascular coupling and Blood Oxygenation Level Dependent BOLD response. The neuronal and haemodynamic parameters are estimated together on a voxel-by-voxel or region-of-interest basis using a Bayesian estimation algorithm variational Laplace. This offers several novel contributions to receptive field modelling. The variance  covariance of parameters are estimated, enabling receptive fields to be plotted while properly representing uncertainty about pRF size and location. Variability in the haemodynamic response across the brain is accounted for. Furthermore, the framework introduces formal hypothesis testing to pRF analysis, enabling competing models to be evaluated based on their model evidence approximated by the variational free energy, which represents the optimal tradeoff between accuracy and complexity. Using simulations and empirical data, we found that parameters typically used to represent pRF size and neuronal scaling are strongly correlated, which should be taken into account when making inferences. We used the framework to compare the evidence for six variants of pRF model using T functional MRI data and we found a circular Difference of Gaussians DoG model to be the best explanation for our data overall. We hope this framework will prove useful for mapping stimulus spaces with any number of dimensions onto the anatomy of the brain.

This work proposes a feature-based technique to recognize vehicle types within day and night times. Support vector machine SVM classifier is applied on image histogram and CENsus Transformed histogRam Oriented Gradient CENTROG features in order to classify vehicle types during the day and night. Thermal images were used for the night time experiments. Although thermal images suffer from low image resolution, lack of colour and poor texture information, they offer the advantage of being unaffected by high intensity light sources such as vehicle headlights which tend to render normal images unsuitable for night time image capturing and subsequent analysis. Since contour is useful in shape based categorisation and the most distinctive feature within thermal images, CENTROG is used to capture this feature information and is used within the experiments. The experimental results so obtained were compared with those obtained by employing the CENsus TRansformed hISTogram CENTRIST. Experimental results revealed that CENTROG offers better recognition accuracies for both day and night times vehicle types recognition.

This letter introduces a method to manage energy storage in electricity grids. Starting from the stochastic characterization of electricity generation and demand, we propose an equation that relates the storage level for every time-step as a function of its previous state and the realized surplusdeficit of electricity. Therefrom, we can obtain the probability that, in the next time-step i there is a generation surplus that cannot be stored, or ii there is a demand need that cannot be supplied by the available storage. We expect this simple procedure can be used as the basis of electricity self-management algorithms in micro-level e.g. individual households or in meso-level e.g. groups of houses.

We study nonuniform sampling in shift-invariant spaces and the construction of Gabor frames with respect to the class of totally positive functions whose Fourier transform factors as  hat gxi prodjn pi ideltajxi- , e-c xi for delta,ldots,deltanin mathbbR, c  in which case g is called totally positive of Gaussian type.   In analogy to Beurlings sampling theorem for the Paley-Wiener space of entire functions, we prove that every separated set with lower Beurling density  is a sampling set for the shift-invariant space generated by such a g. In view of the known necessary density conditions, this result is optimal and validates the heuristic reasonings in the engineering literature.   Using a subtle connection between sampling in shift-invariant spaces and the theory of Gabor frames, we show that the set of phase-space shifts of g with respect to a rectangular lattice alpha mathbbZ times beta mathbbZ forms a frame, if and only if alpha beta . This solves an open problem going back to Daubechies in  for the class of totally positive functions of Gaussian type.   The proof strategy involves the connection between sampling in shift-invariant spaces and Gabor frames, a new characterization of sampling sets without inequalities in the style of Beurling, new properties of totally positive functions, and the interplay between zero sets of functions in a shift-invariant space and functions in the Bargmann-Fock space.

An important problem for HCI researchers is to estimate the parameter values of a cognitive model from behavioral data. This is a difficult problem, because of the substantial complexity and variety in human behavioral strategies. We report an investigation into a new approach using approximate Bayesian computation ABC to condition model parameters to data and prior knowledge. As the case study we examine menu interaction, where we have click time data only to infer a cognitive model that implements a search behaviour with parameters such as fixation duration and recall probability. Our results demonstrate that ABC i improves estimates of model parameter values, ii enables meaningful comparisons between model variants, and iii supports fitting models to individual users. ABC provides ample opportunities for theoretical HCI research by allowing principled inference of model parameter values and their uncertainty.

Bedside monitors in Intensive Care Units ICUs frequently sound incorrectly, slowing response times and desensitising nurses to alarms Chambrin, , causing true alarms to be missed Hug et al., . We compare sliding window predictors with recurrent predictors to classify patient state-of-health from ICU multivariate time series we report slightly improved performance for the RNN for three out of four targets.

We introduce Dynamic SOS as a framework for describing semantics of programming languages that include dynamic software upgrades. Dynamic SOS DSOS is built on top of the Modular SOS of P. Mosses, with an underlying category theory formalization. The idea of Dynamic SOS is to bring out the essential differences between dynamic upgrade constructs and program execution constructs. The important feature of Modular SOS MSOS that we exploit in DSOS is the sharp separation of the program execution code from the additional data structures needed at run-time. In DSOS we aim to achieve the same modularity and decoupling for dynamic software upgrades. This is partly motivated by the long term goal of having machine-checkable proofs for general results like type safety. We exemplify Dynamic SOS on two languages supporting dynamic software upgrades, namely the C-like PROTEUS, which supports updating of variables, functions, records, or types at specific program points, and CREOL, which supports dynamic class upgrades in the setting of concurrent objects. Existing type analyses for software upgrades can be done on top of DSOS too, as we illustrate for PROTEUS. A second contribution is the definition of a general encapsulating construction on Modular SOS useful in situations where a form of encapsulation of the execution is needed. We show how to apply this in the setting of concurrent object-oriented programming with active objects and asynchronous method calls.

This paper describes a new neuroimaging analysis toolbox that allows for the modeling of nonlinear effects at the voxel level, overcoming limitations of methods based on linear models like the GLM. We illustrate its features using a relevant example in which distinct nonlinear trajectories of Alzheimers disease related brain atrophy patterns were found across the full biological spectrum of the disease.

After the Estonian Parliamentary Elections held in , an additional verification mechanism was integrated into the i-voting system in order to resist corrupted voting devices, including the so called Students Attack where a student practically showed that the voting system is indeed not verifiable by developing several versions of malware capable of blocking or even changing the vote. This mechanism gives voters the opportunity to verify whether the vote they cast is stored in the central system correctly. However, the verification phase ends by displaying the cast vote in plain form on the verification device. In other words, the device on which the verification is done learns the voters choice. In this work, our aim is to investigate this verification phase in detail and to point out that leaking the voters choice to the verification application may harm the voter privacy. Additionally, when applied in a wide range, this would even compromise the fairness and the overall secrecy of the elections. In this respect, we propose an alternative verification mechanism for the Estonian i-voting system to overcome this vulnerability. Not only is the proposed mechanism secure and resistant against corrupted verification devices, so does it successfully verify whether the vote is correctly stored in the system. We also highlight that our proposed mechanism brings only symmetric encryptions and hash functions on the verification device, thereby mitigating these weaknesses in an efficient way with a negligible cost. More concretely, it brings only m additional symmetric key decryptions to the verification device, where m denoting the number of candidates. Finally, we prove the security of the proposed verification mechanism and compare the cost complexity of the proposed method with that of the current mechanism.

Todays JavaScript applications are composed of scripts from different origins that are loaded at run time. As not all of these origins are equally trusted, the execution of these scripts should be isolated from one another. However, some scripts must access the application state and some may be allowed to change it, while preserving the confidentiality and integrity constraints of the application.   This paper presents design and implementation of DecentJS, a language-embedded sandbox for full JavaScript. It enables scripts to run in a configurable degree of isolation with fine-grained access control. It provides a transactional scope in which effects are logged for review by the access control policy. After inspection of the log, effects can be committed to the application state or rolled back.   The implementation relies on JavaScript proxies to guarantee full interposition for the full language and for all code, including dynamically loaded scripts and code injected via eval. Its only restriction is that scripts must be compliant with JavaScripts strict mode.

Functional languages with strong static type systems have beneficial properties to help ensure program correctness and reliability. Surprisingly, their practical significance in applications is low relative to other languages lacking in those dimensions. In this paper, the programs-as-proofs analogy is taken seriously to gain speculative insights by analysis of creation habits in the proof-centric discipline of mathematics. Viewed in light of this analogy, a sampling of mathematicians attitudes towards formal proof suggests that the crucial role of intuition and experimentation in programming tasks may be under appreciated, hinting at a possible explanation of the challenges rigorously disciplined languages face in practical applications.

This paper presents a systematic evaluation of Neural Network NN for classification of real-world data. In the field of machine learning, it is often seen that a single parameter that is predictive accuracy is being used for evaluating the performance of a classifier model. However, this parameter might not be considered reliable given a dataset with very high level of skewness. To demonstrate such behavior, seven different types of datasets have been used to evaluate a Multilayer Perceptron MLP using twelve different parameters which include micro- and macro-level estimation. In the present study, the most common problem of prediction called multiclass classification has been considered. The results that are obtained for different parameters for each of the dataset could demonstrate interesting findings to support the usability of these set of performance evaluation parameters.

In our setting enumeration amounts to generate all solutions of a problem instance without duplicates. We address the problem of enumerating the models of B-formulae. A B-formula is a propositional formula whose connectives are taken from a fixed set B of Boolean connectives. Without imposing any specific order to output the solutions, this task is solved. We completely classify the complexity of this enumeration task for all possible sets of connectives B imposing the orders of  non-decreasing weight,  non-increasing weight the weight of a model being the number of variables assigned to . We consider also the weighted variants where a non-negative integer weight is assigned to each variable and show that this add-on leads to more sophisticated enumeration algorithms and even renders previously tractable cases intractable, contrarily to the constraint setting. As a by-product we obtain complete complexity classifications for the optimization problems known as Min-Ones and Max-Ones which are in the B-formula setting two different tasks.

The identification and quantification of markers in medical images is critical for diagnosis, prognosis and management of patients in clinical practice. Supervised- or weakly supervised training enables the detection of findings that are known a priori. It does not scale well, and a priori definition limits the vocabulary of markers to known entities reducing the accuracy of diagnosis and prognosis. Here, we propose the identification of anomalies in large-scale medical imaging data using healthy examples as a reference. We detect and categorize candidates for anomaly findings untypical for the observed data. A deep convolutional autoencoder is trained on healthy retinal images. The learned model generates a new feature representation, and the distribution of healthy retinal patches is estimated by a one-class support vector machine. Results demonstrate that we can identify pathologic regions in images without using expert annotations. A subsequent clustering categorizes findings into clinically meaningful classes. In addition the learned features outperform standard embedding approaches in a classification task.

We introduce a common generalization of the strong Hanani-Tutte theorem and the weak Hanani-Tutte theorem if a graph G has a drawing D in the plane where every pair of independent edges crosses an even number of times, then G has a planar drawing preserving the rotation of each vertex that was incident only to even edges in D. The theorem is implicit in the proof of the strong Hanani-Tutte theorem by Pelsmajer, Schaefer and vStefankovivc. We give a new, somewhat simpler proof.

The term UniMath refers both to a formal system for mathematics, as well as a computer-checked library of mathematics formalized in that system. The UniMath system is a core dependent type theory, augmented by the univalence axiom. The system is kept as small as possible in order to ease verification of it - in particular, general inductive types are not part of the system.   In this work, we partially remedy the lack of inductive types by constructing some datatypes and their associated induction principles from other type constructors. This involves a formalization of a category-theoretic result on the construction of initial algebras, as well as a mechanism to conveniently use the datatypes obtained. We also connect this construction to a previous formalization of substitution for languages with variable binding. Altogether, we construct a framework that allows us to concisely specify, via a simple notion of binding signature, a language with variable binding. From such a specification we obtain the datatype of terms of that language, equipped with a certified monadic substitution operation and a suitable recursion scheme. Using this we formalize the untyped lambda calculus and the raw syntax of Martin-Lof type theory.

Long Short-Term Memory LSTM is widely used in speech recognition. In order to achieve higher prediction accuracy, machine learning scientists have built larger and larger models. Such large model is both computation intensive and memory intensive. Deploying such bulky model results in high power consumption and leads to high total cost of ownership TCO of a data center. In order to speedup the prediction and make it energy efficient, we first propose a load-balance-aware pruning method that can compress the LSTM model size by x x from pruning and x from quantization with negligible loss of the prediction accuracy. The pruned model is friendly for parallel processing. Next, we propose scheduler that encodes and partitions the compressed model to each PE for parallelism, and schedule the complicated LSTM data flow. Finally, we design the hardware architecture, named Efficient Speech Recognition Engine ESE that works directly on the compressed model. Implemented on Xilinx XCKU FPGA running at MHz, ESE has a performance of  GOPS working directly on the compressed LSTM network, corresponding to . TOPS on the uncompressed one, and processes a full LSTM for speech recognition with a power dissipation of  Watts. Evaluated on the LSTM for speech recognition benchmark, ESE is x and x faster than Core i k CPU and Pascal Titan X GPU implementations. It achieves x and .x higher energy efficiency compared with the CPU and GPU respectively.

We present probabilistic neural programs, a framework for program induction that permits flexible specification of both a computational model and inference algorithm while simultaneously enabling the use of deep neural networks. Probabilistic neural programs combine a computation graph for specifying a neural network with an operator for weighted nondeterministic choice. Thus, a program describes both a collection of decisions as well as the neural network architecture used to make each one. We evaluate our approach on a challenging diagram question answering task where probabilistic neural programs correctly execute nearly twice as many programs as a baseline model.

Introducing more Distributed Generation DG into power grid infrastructure drives more attention to understand how large scale DG affects grid operation. Islanding is an important concern in this area. Islanding refers to the condition that DGs within a microgrid continue energizing while the microgrid has been disconnected from the main grid. Considering the adverse effects of Islanding, it should be detected and managed in a proper way. After Islanding has been detected, even though the first option is tripping all inverterbased DG unit in the system, the system has this option to work as a stand-alone microgrid. For achieving this goal, the frequency of microgrid should be regulated. This paper proposes an islanding detection method based on current detection in a parallel arm with the fuse arm of the microgrid. After islanding detection, this paper presents an effective implementation Demand Response DR to regulate the frequency in islanded microgrid as an Ancillary Service AS considering the transient constraints of frequency in inverterbased generations.

This work is concerned with the application of game theoretic principles to model competition between demand response aggregators for selling excess energy stored in electrochemical storage devices directly to other aggregators in a power market. This market framework is presented as an alternative to the traditional vertically integrated market structure, which may be better suited for developing demand response and smart grid technologies, in addition to increasing penetration of independent renewable energy generation devices. Demand for power generated by the utility through combustion of fuel could be replaced, lowering emission of pollutants, when the energy used to charge the batteries is produced sustainably and traded on smaller scales. The four variants of game are considered both non-cooperative unregulated competition and Stackelberg regulations on transaction price and size, each with and without DR scheduling. The Nash equilibrium is derived for each game variant in order to serve as a bid-price decision making criteria which determines the optimal bidding strategy for an aggregator to sell in the market. The model is applied to a case study involving completion for selling between two aggregators. Bidding strategy is dependent on parameters inherent to an aggregators energy storage hardware, and the strategy selected by each aggregator does not vary with the variations in the game conditions considered. Demand response scheduling offers greater payoff for aggregators who implement it, compared with those who do not. Addition of transaction price and volume regulations to the market do not affect the participants optimal bidding strategies the Nash equilibrium, but lowers payoffs for all aggregators participating in the market relative to unregulated competition.

Automatic essay scoring AES refers to the process of scoring free text responses to given prompts, considering human grader scores as the gold standard. Writing such essays is an essential component of many language and aptitude exams. Hence, AES became an active and established area of research, and there are many proprietary systems used in real life applications today. However, not much is known about which specific linguistic features are useful for prediction and how much of this is consistent across datasets. This article addresses that by exploring the role of various linguistic features in automatic essay scoring using two publicly available datasets of non-native English essays written in test taking scenarios. The linguistic properties are modeled by encoding lexical, syntactic, discourse and error types of learner language in the feature set. Predictive models are then developed using these features on both datasets and the most predictive features are compared. While the results show that the feature set used results in good predictive models with both datasets, the question what are the most predictive features? has a different answer for each dataset.

Context A case study is a powerful research strategy for investigating complex social-technical and managerial phenomena in real life settings. However, when the phenomenon has not been fully discovered or understood, pilot case studies are important to refine the research problem, the research variables, and the case study design before launching a full-scale investigation. The role of pilot case studies has not been fully addressed in empirical software engineering research literature. Objective To explore the use of pilot case studies in the design of full-scale case studies, and to report the main lessons learned from an industrial pilot study. Method We designed and conducted an exploratory case study to identify new relevant research variables that influence the innovative behaviour of software engineers in the industrial setting and to refine the full-scale case study design for the next phase of our research. Results The use of a pilot case study identified several important research variables that were missing in the initial framework. The pilot study also supported a more sophisticated case study design, which was used to guide a full-scale study. Conclusions When a research topic has not been fully discovered or understood, it is difficult to create a case study design that covers the relevant research variables and their potential relationships. Conducting a full-scale case study using an untested case design can lead to waste of resources and time if the design has to be reworked during the study. In these situations, the use of pilot case studies can significantly improve the case study design.

Trends in media usage by students can affect the way they learn. Students demand the use of technology, thus institutions and instructors should meet students requests. This paper describes the results of a survey where drivers in the use of media show continuously increasing or decreasing values from the first to the fourth year of study experience at the Western University, Canada, highlighting trends in the usage of new and traditional media in higher education by students. The survey was used to gather data on students media usage habits and user satisfaction from first to fourth year of study and found that media usage increases over the years from first to fourth. The presentation of data using bar charts reveals a slight increase over the years in students owning notebooks or laptops off-campus and a significant increase from first to fourth year of students accessing online academic periodicals and journals. Another noteworthy finding relates to fourth year students being more conscious of the quality of information that they read on the Internet in comparison to students in first year, even though this is a slight year on year increase.

As software systems are becoming larger, more complex, and dependent on many third-party software components, the chances of their failure are increasing further. This calls for intense efforts to improve the quality of testing in the software development process.

As one of the crucial human aspects, individual decision-making behavior that may affect the quality of a software project is adaptive to the environment in which the individual is. However, no comprehensive reference framework of the environmental factors influencing individual decision-making behavior in software projects is presently available. This paper undertakes a systematic literature review SLR to gain insight into existing studies on this topic. After a careful SLR process,  studies were targeted to solve this question. Based on these extracted studies, we first provided a taxonomy of environmental factors comprising eight categories. Then a total of  factors are identified and classified using these eight categories, and some major environmental factors of each category are listed in the paper. The environmental factors listing and the taxonomy can help researchers and practitioners to better understand and predict the behavior of individuals during decision making and to design more effective solutions to improve people management in software projects.

We introduce the concept of dynamic image, a novel compact representation of videos useful for video analysis especially when convolutional neural networks CNNs are used. The dynamic image is based on the rank pooling concept and is obtained through the parameters of a ranking machine that encodes the temporal evolution of the frames of the video. Dynamic images are obtained by directly applying rank pooling on the raw image pixels of a video producing a single RGB image per video. This idea is simple but powerful as it enables the use of existing CNN models directly on video data with fine-tuning. We present an efficient and effective approximate rank pooling operator, speeding it up orders of magnitude compared to rank pooling. Our new approximate rank pooling CNN layer allows us to generalize dynamic images to dynamic feature maps and we demonstrate the power of our new representations on standard benchmarks in action recognition achieving state-of-the-art performance.

The Center of Gravity COG method is one of the most popular defuzzification techniques of fuzzy mathematics. In earlier works the COG technique was properly adapted to be used as an assessment model RFAMand several variations of it GRFAM, TFAM and TpFAMwere also constructed for the same purpose. In this paper the outcomes of all these models are compared to the corresponding outcomes of a traditional assessment method of the bi-valued logic, the Grade Point Average GPA Index. Examples are also presented illustrating our results.

Machine learning is making substantial progress in diverse applications. The success is mostly due to advances in deep learning. However, deep learning can make mistakes and its generalization abilities to new tasks are questionable. We ask when and how one can combine network outputs, when i details of the observations are evaluated by learned deep components and ii facts and confirmation rules are available in knowledge based systems. We show that in limited contexts the required number of training samples can be low and self-improvement of pre-trained networks in more general context is possible. We argue that the combination of sparse outlier detection with deep components that can support each other diminish the fragility of deep methods, an important requirement for engineering applications. We argue that supervised learning of labels may be fully eliminated under certain conditions a component based architecture together with a knowledge based system can train itself and provide high quality answers. We demonstrate these concepts on the State Farm Distracted Driver Detection benchmark. We argue that the view of the Study Panel  may overestimate the requirements on years of focused research and careful, unique construction for AI systems.

Networks have been a general tool for representing, analyzing, and modeling relational data arising in several domains. One of the most important aspect of network analysis is community detection or network clustering. Until recently, the major focus have been on discovering community structure in single i.e., monoplex networks. However, with the advent of relational data with multiple modalities, multiplex networks, i.e., networks composed of multiple layers representing different aspects of relations, have emerged. Consequently, community detection in multiplex network, i.e., detecting clusters of nodes shared by all layers, has become a new challenge. In this paper, we propose Network Fusion for Composite Community Extraction NF-CCE, a new class of algorithms, based on four different non-negative matrix factorization models, capable of extracting composite communities in multiplex networks. Each algorithm works in two steps first, it finds a non-negative, low-dimensional feature representation of each network layer then, it fuses the feature representation of layers into a common non-negative, low-dimensional feature representation via collective factorization. The composite clusters are extracted from the common feature representation. We demonstrate the superior performance of our algorithms over the state-of-the-art methods on various types of multiplex networks, including biological, social, economic, citation, phone communication, and brain multiplex networks.

A major challenge facing existing sequential Monte-Carlo methods for parameter estimation in physics stems from the inability of existing approaches to robustly deal with experiments that have different mechanisms that yield the results with equivalent probability. We address this problem here by proposing a form of particle filtering that clusters the particles that comprise the sequential Monte-Carlo approximation to the posterior before applying a resampler. Through a new graphical approach to thinking about such models, we are able to devise an artificial-intelligence based strategy that automatically learns the shape and number of the clusters in the support of the posterior. We demonstrate the power of our approach by applying it to randomized gap estimation and a form of low circuit-depth phase estimation where existing methods from the physics literature either exhibit much worse performance or even fail completely.

The conventional theory of burning works well in the case of uniform media where all system parameters are spatially independent. We develop a theory of burning in disordered media. In this case, rare regions hot spots where the burning process is more effective than on average may control the heat propagation in an explosive sample. We show that most predictions of the theory of burning are quite different from the conventional case. In particular, we show that a system of randomly distributed hot spots exhibits a dynamic phase transition, which is similar to the percolation transition. Depending on parameters of the system the phase transition can be either first or second order. These two regimes are separated by a tricritical point. The above results may be applicable to dynamics of any over-heated disordered system with a first order phase transition.

Several studies have been conducted on understanding third-party user tracking on the web. However, web trackers can only track users on sites where they are embedded by the publisher, thus obtaining a fragmented view of a users online footprint. In this work, we investigate a different form of user tracking, where extensions enabled on a browser can capture the complete browsing behavior of a user and communicate the collected sensitive information to a remote server untrusted by the user. We conduct the first large-scale empirical study of  spying browser extensions on the Chrome Web Store. We observe that these extensions steal a variety of sensitive user information, such as the complete browsing history of the users e.g., the sequence of web traversals, online social network OSN access tokens, and IP address and geolocation of users. We present an in-depth analysis of the spying behavior of these extensions. Finally, we investigate the potential for automatically detecting spying extensions by applying machine learning schemes using a comprehensive set of features capturing various client-side and network behavior. Our findings highlight the importance of detecting and limiting user behavior tracking by browser extensions.

We consider parallel asynchronous Markov Chain Monte Carlo MCMC sampling for problems where we can leverage stochastic gradients to define continuous dynamics which explore the target distribution. We outline a solution strategy for this setting based on stochastic gradient Hamiltonian Monte Carlo sampling SGHMC which we alter to include an elastic coupling term that ties together multiple MCMC instances. The proposed strategy turns inherently sequential HMC algorithms into asynchronous parallel versions. First experiments empirically show that the resulting parallel sampler significantly speeds up exploration of the target distribution, when compared to standard SGHMC, and is less prone to the harmful effects of stale gradients than a naive parallelization approach.

In this paper, we explore ordinal classification in the context of deep neural networks through a simple modification of the squared error loss which not only allows it to not only be sensitive to class ordering, but also allows the possibility of having a discrete probability distribution over the classes. Our formulation is based on the use of a softmax hidden layer, which has received relatively little attention in the literature. We empirically evaluate its performance on the Kaggle diabetic retinopathy dataset, an ordinal and high-resolution dataset and show that it outperforms all of the baselines employed.

The ability to learn tasks in a sequential fashion is crucial to the development of artificial intelligence. Neural networks are not, in general, capable of this and it has been widely thought that catastrophic forgetting is an inevitable feature of connectionist models. We show that it is possible to overcome this limitation and train networks that can maintain expertise on tasks which they have not experienced for a long time. Our approach remembers old tasks by selectively slowing down learning on the weights important for those tasks. We demonstrate our approach is scalable and effective by solving a set of classification tasks based on the MNIST hand written digit dataset and by learning several Atari  games sequentially.

Colorectal cancer CRC is the third cause of cancer death worldwide. Currently, the standard approach to reduce CRC-related mortality is to perform regular screening in search for polyps and colonoscopy is the screening tool of choice. The main limitations of this screening procedure are polyp miss-rate and inability to perform visual assessment of polyp malignancy. These drawbacks can be reduced by designing Decision Support Systems DSS aiming to help clinicians in the different stages of the procedure by providing endoluminal scene segmentation. Thus, in this paper, we introduce an extended benchmark of colonoscopy image, with the hope of establishing a new strong benchmark for colonoscopy image analysis research. We provide new baselines on this dataset by training standard fully convolutional networks FCN for semantic segmentation and significantly outperforming, without any further post-processing, prior results in endoluminal scene segmentation.

Proactive monitoring of ones health could avoid serious diseases as well as better maintain the individuals well-being. In todays IoT world, there has been numerous wearable technological devices to monitormeasure different health attributes. However, with that increasing number of attributes and wearables, it becomes unclear to the individual which ones they should be using. The aim of this paper is to provide a recommendation engine for personalized recommended wearables for any given individual. The way the engine works is through first identifying the diseases that this person is at risk of, given hisher attributes and medical history. We built a machine learning classification model for this task. Second, these diseases are mapped to the attributes that need to be measured in order to monitor such diseases. Third, we map these measurements to the appropriate wearable technologies. This is done via a textual analytics model that we developed that uses available information of different wearables to map the aforementioned measurements to these wearables. The output can be used to recommend the wearables to individuals as well as provide a feedback to wearable developers for common measurements that do not have corresponding wearables today.

We connect high-dimensional subset selection and submodular maximization. Our results extend the work of Das and Kempe  from the setting of linear regression to arbitrary objective functions. For greedy feature selection, this connection allows us to obtain strong multiplicative performance bounds on several methods without statistical modeling assumptions. We also derive recovery guarantees of this form under standard assumptions. Our work shows that greedy algorithms perform within a constant factor from the best possible subset-selection solution for a broad class of general objective functions. Our methods allow a direct control over the number of obtained features as opposed to regularization parameters that only implicitly control sparsity. Our proof technique uses the concept of weak submodularity initially defined by Das and Kempe. We draw a connection between convex analysis and submodular set function theory which may be of independent interest for other statistical learning applications that have combinatorial structure.

Due to its remarkable energy compaction properties, the discrete cosine transform DCT is employed in a multitude of compression standards, such as JPEG and H.HEVC. Several low-complexity integer approximations for the DCT have been proposed for both -D and -D signal analysis. The increasing demand for low-complexity, energy efficient methods require algorithms with even lower computational costs. In this paper, new -point DCT approximations with very low arithmetic complexity are presented. The new transforms are proposed based on pruning state-of-the-art DCT approximations. The proposed algorithms were assessed in terms of arithmetic complexity, energy retention capability, and image compression performance. In addition, a metric combining performance and computational complexity measures was proposed. Results showed good performance and extremely low computational complexity. Introduced algorithms were mapped into systolic-array digital architectures and physically realized as digital prototype circuits using FPGA technology and mapped to nm CMOS technology. All hardware-related metrics showed low resource consumption of the proposed pruned approximate transforms. The best proposed transform according to the introduced metric presents a reduction in power consumption of --.

Understanding the D world is a fundamental problem in computer vision. However, learning a good representation of D objects is still an open problem due to the high dimensionality of the data and many factors of variation involved. In this work, we investigate the task of single-view D object reconstruction from a learning agents perspective. We formulate the learning process as an interaction between D and D representations and propose an encoder-decoder network with a novel projection loss defined by the perspective transformation. More importantly, the projection loss enables the unsupervised learning using D observation without explicit D supervision. We demonstrate the ability of the model in generating D volume from a single D image with three sets of experiments  learning from single-class objects  learning from multi-class objects and  testing on novel object classes. Results show superior performance and better generalization ability for D object reconstruction when the projection loss is involved.

We study machine learning formulations of inductive program synthesis that is, given input-output examples, synthesize source code that maps inputs to corresponding outputs. Our key contribution is TerpreT, a domain-specific language for expressing program synthesis problems. A TerpreT model is composed of a specification of a program representation and an interpreter that describes how programs map inputs to outputs. The inference task is to observe a set of input-output examples and infer the underlying program. From a TerpreT model we automatically perform inference using four different back-ends gradient descent thus each TerpreT model can be seen as defining a differentiable interpreter, linear program LP relaxations for graphical models, discrete satisfiability solving, and the Sketch program synthesis system. TerpreT has two main benefits. First, it enables rapid exploration of a range of domains, program representations, and interpreter models. Second, it separates the model specification from the inference algorithm, allowing proper comparisons between different approaches to inference.   We illustrate the value of TerpreT by developing several interpreter models and performing an extensive empirical comparison between alternative inference algorithms on a variety of program models. To our knowledge, this is the first work to compare gradient-based search over program space to traditional search-based alternatives. Our key empirical finding is that constraint solvers dominate the gradient descent and LP-based formulations.   This is a workshop summary of a longer report at arXiv.

We investigate iterated compositions of weighted sums of Gaussian kernels and provide an interpretation of the construction that shows some similarities with the architectures of deep neural networks. On the theoretical side, we show that these kernels are universal and that SVMs using these kernels are universally consistent. We further describe a parameter optimization method for the kernel parameters and empirically compare this method to SVMs, random forests, a multiple kernel learning approach, and to some deep neural networks.

Multiple extensions of Recurrent Neural Networks RNNs have been proposed recently to address the difficulty of storing information over long time periods. In this paper, we experiment with the capacity of Neural Turing Machines NTMs to deal with these long-term dependencies on well-balanced strings of parentheses. We show that not only does the NTM emulate a stack with its heads and learn an algorithm to recognize such words, but it is also capable of strongly generalizing to much longer sequences.

Recently, there have been several promising methods to generate realistic imagery from deep convolutional networks. These methods sidestep the traditional computer graphics rendering pipeline and instead generate imagery at the pixel level by learning from large collections of photos e.g. faces or bedrooms. However, these methods are of limited utility because it is difficult for a user to control what the network produces. In this paper, we propose a deep adversarial image synthesis architecture that is conditioned on sketched boundaries and sparse color strokes to generate realistic cars, bedrooms, or faces. We demonstrate a sketch based image synthesis system which allows users to scribble over the sketch to indicate preferred color for objects. Our network can then generate convincing images that satisfy both the color and the sketch constraints of user. The network is feed-forward which allows users to see the effect of their edits in real time. We compare to recent work on sketch to image synthesis and show that our approach can generate more realistic, more diverse, and more controllable outputs. The architecture is also effective at user-guided colorization of grayscale images.

Problems at the intersection of vision and language are of significant importance both as challenging research questions and for the rich set of applications they enable. However, inherent structure in our world and bias in our language tend to be a simpler signal for learning than visual modalities, resulting in models that ignore visual information, leading to an inflated sense of their capability.   We propose to counter these language priors for the task of Visual Question Answering VQA and make vision the V in VQA matter! Specifically, we balance the popular VQA dataset Antol et al., ICCV  by collecting complementary images such that every question in our balanced dataset is associated with not just a single image, but rather a pair of similar images that result in two different answers to the question. Our dataset is by construction more balanced than the original VQA dataset and has approximately twice the number of image-question pairs. Our complete balanced dataset will be publicly released as part of the nd iteration of the Visual Question Answering Challenge VQA v..   We further benchmark a number of state-of-art VQA models on our balanced dataset. All models perform significantly worse on our balanced dataset, suggesting that these models have indeed learned to exploit language priors. This finding provides the first concrete empirical evidence for what seems to be a qualitative sense among practitioners.   Finally, our data collection protocol for identifying complementary images enables us to develop a novel interpretable model, which in addition to providing an answer to the given image, question pair also provides a counter-example based explanation - specifically, it identifies an image that is similar to the original image, but it believes has a different answer to the same question. This can help in building trust for machines among their users.

Support vector machines SVMs have been recognized as a potential tool for supervised classification analyses in different domains of research. In essence, SVM is a binary classifier. Therefore, in case of a multiclass problem, the problem is divided into a series of binary problems which are solved by binary classifiers, and finally the classification results are combined following either the one-against-one or one-against-all strategies. In this paper, an attempt has been made to classify lithology using a multiclass SVM based framework using well logs as predictor variables. Here, the lithology is classified into four classes such as sand, shaly sand, sandy shale and shale based on the relative values of sand and shale fractions as suggested by an expert geologist. The available dataset consisting well logs gamma ray, neutron porosity, density, and P-sonic and class information from four closely spaced wells from an onshore hydrocarbon field is divided into training and testing sets. We have used one-against-all strategy to combine the results of multiple binary classifiers. The reported results established the superiority of multiclass SVM compared to other classifiers in terms of classification accuracy. The selection of kernel function and associated parameters has also been investigated here. It can be envisaged from the results achieved in this study that the proposed framework based on multiclass SVM can further be used to solve classification problems. In future research endeavor, seismic attributes can be introduced in the framework to classify the lithology throughout a study area from seismic inputs.

Water saturation is an important property in reservoir engineering domain. Thus, satisfactory classification of water saturation from seismic attributes is beneficial for reservoir characterization. However, diverse and non-linear nature of subsurface attributes makes the classification task difficult. In this context, this paper proposes a generalized Support Vector Data Description SVDD based novel classification framework to classify water saturation into two classes Class high and Class low from three seismic attributes seismic impedance, amplitude envelop, and seismic sweetness. G-metric means and program execution time are used to quantify the performance of the proposed framework along with established supervised classifiers. The documented results imply that the proposed framework is superior to existing classifiers. The present study is envisioned to contribute in further reservoir modeling.

The generation of political event data has remained much the same since the mid-s, both in terms of data acquisition and the process of coding text into data. Since the s, however, there have been significant improvements in open-source natural language processing software and in the availability of digitized news content. This paper presents a new, next-generation event dataset, named Phoenix, that builds from these and other advances. This dataset includes improvements in the underlying news collection process and event coding software, along with the creation of a general processing pipeline necessary to produce daily-updated data. This paper provides a face validity checks by briefly examining the data for the conflict in Syria, and a comparison between Phoenix and the Integrated Crisis Early Warning System data.

Dynamic line rating DLR models the transmission capacity of overhead lines as a function of ambient conditions. It takes advantage of the physical thermal property of overhead line conductors, thus making DLR less conservative compared to the traditional worst-case oriented nominal line rating NLR. Employing DLR brings potential benefits for grid integration of variable Renewable Energy Sources RES, such as wind and solar energy. In this paper, we reproduce weather conditions from renewable feed-ins and local temperature records, and calculate DLR in accordance with the RES feed-in and load demand data step. Simulations with high time resolution, using a predictive dispatch optimization and the Power Node modeling framework, of a six-node benchmark power system loosely based on the German power system are performed for the current situation, using actual wind and PV feed-in data. The integration capability of DLR under high RES production shares is inspected through simulations with scaled-up RES profiles and reduced dispatchable generation capacity. The simulation result demonstrates a comparison between DLR and NLR in terms of reductions in RES generation curtailments and load shedding, while discussions on the practicality of adopting DLR in the current power system is given in the end.

In this paper we present FRIDA---an algorithm for estimating directions of arrival of multiple wideband sound sources. FRIDA combines multi-band information coherently and achieves state-of-the-art resolution at extremely low signal-to-noise ratios. It works for arbitrary array layouts, but unlike the various steered response power and subspace methods, it does not require a grid search. FRIDA leverages recent advances in sampling signals with a finite rate of innovation. It is based on the insight that for any array layout, the entries of the spatial covariance matrix can be linearly transformed into a uniformly sampled sum of sinusoids.

Many large-scale, complex systems consist of interactions between humans, human-made systems and the environment. The approach developed in this paper is to partition the problem space into two fundamental layers and identify, parameterize and model the main dimensions of each layer and interactions across and in between layers. One layer is the key actors or major organization or human decision makers who influence the state of the world. The other layer includes the domains or fields of knowledge relevant to the problem being addressed. These domains include elements such as the physical earth and its atmosphere, world demography, world economy, level of globalization, and politics. Key parameters for each of the actor types and domains will be extracted and assessed using existing data sources. Novel systems, uncertainty modeling and analysis techniques are combined with advanced computational technologies to determine a spectrum of likely future system states and conduct ifthen scenario analyses.

Deep learning for human action recognition in videos is making significant progress, but is slowed down by its dependency on expensive manual labeling of large video collections. In this work, we investigate the generation of synthetic training data for action recognition, as it has recently shown promising results for a variety of other computer vision tasks. We propose an interpretable parametric generative model of human action videos that relies on procedural generation and other computer graphics techniques of modern game engines.We generate a diverse, realistic, and physically plausible dataset of human action videos, called PHAV for Procedural Human Action Videos. It contains a total of , videos, more than , examples for each action of  categories. Our approach is not limited to existing motion capture sequences, and we procedurally define  synthetic actions. We introduce a deep multi-task representation learning architecture to mix synthetic and real videos, even if the action categories differ. Our experiments on the UCF and HMDB benchmarks suggest that combining our large set of synthetic videos with small real-world datasets can boost recognition performance, significantly outperforming fine-tuning state-of-the-art unsupervised generative models of videos.

Exploration has been a crucial part of reinforcement learning, yet several important questions concerning exploration efficiency are still not answered satisfactorily by existing analytical frameworks. These questions include exploration parameter setting, situation analysis, and hardness of MDPs, all of which are unavoidable for practitioners. To bridge the gap between the theory and practice, we propose a new analytical framework called the success probability of exploration. We show that those important questions of exploration above can all be answered under our framework, and the answers provided by our framework meet the needs of practitioners better than the existing ones. More importantly, we introduce a concrete and practical approach to evaluating the success probabilities in certain MDPs without the need of actually running the learning algorithm. We then provide empirical results to verify our approach, and demonstrate how the success probability of exploration can be used to analyse and predict the behaviours and possible outcomes of exploration, which are the keys to the answer of the important questions of exploration.

Geographical load balancing can optimize the utilization of green energy and the cost of electricity by taking the advantages of green and price diversities at geographical dispersed data centers. However, higher green energy utilization or lower electricity cost may actually increase the total energy consumption, and is not necessarily the best option. The achievable energy tradeoffs can be captured by taking into consideration of a defined service efficiency parameter for geo-dispersed data centers.

Let P be a set called points, Q be a set called queries and a function  fPtimes Qto ,infty called cost. For an error parameter epsilon, a set Ssubseteq P with a emphweight function wP rightarrow ,infty is an epsilon-coreset if sumsin Sws fs,q approximates sumpin P fp,q up to a multiplicative factor of pmepsilon for every given query qin Q.   We construct coresets for the k-means clustering of n input points, both in an arbitrary metric space and d-dimensional Euclidean space. For Euclidean space, we present the first coreset whose size is simultaneously independent of both d and n. In particular, this is the first coreset of size on for a stream of n sparse points in a d ge n dimensional space e.g. adjacency matrices of graphs. We also provide the first generalizations of such coresets for handling outliers. For arbitrary metric spaces, we improve the dependence on k to k log k and present a matching lower bound.   For M-estimator clustering special cases include the well-known k-median and k-means clustering, we introduce a new technique for converting an offline coreset construction to the streaming setting. Our method yields streaming coreset algorithms requiring the storage of OS  k log n points, where S is the size of the offline coreset. In comparison, the previous state-of-the-art was the merge-and-reduce technique that required OS loga n points, where a is the exponent in the offline constructions dependence on epsilon-. For example, combining our offline and streaming results, we produce a streaming metric k-means coreset algorithm using Oepsilon- k log k log n points of storage. The previous state-of-the-art required Oepsilon- k log k log n points.

The significant computational costs of deploying neural networks in large-scale or resource constrained environments, such as data centers and mobile devices, has spurred interest in model compression, which can achieve a reduction in both arithmetic operations and storage memory. Several techniques have been proposed for reducing or compressing the parameters for feed-forward and convolutional neural networks, but less is understood about the effect of parameter compression on recurrent neural networks RNN. In particular, the extent to which the recurrent parameters can be compressed and the impact on short-term memory performance, is not well understood. In this paper, we study the effect of complexity reduction, through singular value decomposition rank reduction, on RNN and minimal gated recurrent unit MGRU networks for several tasks. We show that considerable rank reduction is possible when compressing recurrent weights, even without fine tuning. Furthermore, we propose a perturbation model for the effect of general perturbations, such as a compression, on the recurrent parameters of RNNs. The model is tested against a noiseless memorization experiment that elucidates the short-term memory performance. In this way, we demonstrate that the effect of compression of recurrent parameters is dependent on the degree of temporal coherence present in the data and task. This work can guide on-the-fly RNN compression for novel environments or tasks, and provides insight for applying RNN compression in low-power devices, such as hearing aids.

Motivated by applications in social network community analysis, we introduce a new clustering paradigm termed motif clustering. Unlike classical clustering, motif clustering aims to minimize the number of clustering errors associated with both edges and certain higher order graph structures motifs that represent atomic units of social organizations. Our contributions are two-fold We first introduce motif correlation clustering, in which the goal is to agnostically partition the vertices of a weighted complete graph so that certain predetermined important social subgraphs mostly lie within the same cluster, while less relevant social subgraphs are allowed to lie across clusters. We then proceed to introduce the notion of motif covers, in which the goal is to cover the vertices of motifs via the smallest number of near cliques in the graph. Motif cover algorithms provide a natural solution for overlapping clustering and they also play an important role in latent feature inference of networks. For both motif correlation clustering and its extension introduced via the covering problem, we provide hardness results, algorithmic solutions and community detection results for two well-studied social networks.

Semantic sparsity is a common challenge in structured visual classification problems when the output space is complex, the vast majority of the possible predictions are rarely, if ever, seen in the training set. This paper studies semantic sparsity in situation recognition, the task of producing structured summaries of what is happening in images, including activities, objects and the roles objects play within the activity. For this problem, we find empirically that most object-role combinations are rare, and current state-of-the-art models significantly underperform in this sparse data regime. We avoid many such errors by  introducing a novel tensor composition function that learns to share examples across role-noun combinations and  semantically augmenting our training data with automatically gathered examples of rarely observed outputs using web data. When integrated within a complete CRF-based structured prediction model, the tensor-based approach outperforms existing state of the art by a relative improvement of . and . on top- verb and noun-role accuracy, respectively. Adding  million images with our semantic augmentation techniques gives further relative improvements of . and . on top- verb and noun-role accuracy.

In this paper, we discuss how to design the graph topology to reduce the communication complexity of certain algorithms for decentralized optimization. Our goal is to minimize the total communication needed to achieve a prescribed accuracy. We discover that the so-called expander graphs are near-optimal choices. We propose three approaches to construct expander graphs for different numbers of nodes and node degrees. Our numerical results show that the performance of decentralized optimization is significantly better on expander graphs than other regular graphs.

The linear subspace model is pervasive in science and engineering and particularly in large datasets which are often incomplete due to missing measurements and privacy issues. Therefore, a critical problem in modeling is to develop algorithms for estimating a low-dimensional subspace model from incomplete data efficiently in terms of both computational complexity and memory storage. In this paper we study an algorithm that processes blocks of incomplete data to estimate the underlying subspace model. Our algorithm has a simple interpretation as optimizing the subspace to fit the observed data block but remain close to the previous estimate. We prove a linear rate of convergence for the algorithm and our rate holds with high probability.

We establish a cutting lemma for definable families of sets in distal structures, as well as the optimality of the distal cell decomposition for definable families of sets on the plane in o-minimal expansions of fields. Using it, we generalize the results in J. Fox, J. Pach, A. Sheffer, A. Suk, and J. Zahl. A semi-algebraic version of Zarankiewiczs problem, Preprint, arXiv.  on the semialgebraic planar Zarankiewicz problem to arbitrary o-minimal structures, in particular obtaining an o-minimal generalization of the Szemeredi-Trotter theorem.

Natural language understanding and dialogue policy learning are both essential in conversational systems that predict the next system actions in response to a current user utterance. Conventional approaches aggregate separate models of natural language understanding NLU and system action prediction SAP as a pipeline that is sensitive to noisy outputs of error-prone NLU. To address the issues, we propose an end-to-end deep recurrent neural network with limited contextual dialogue memory by jointly training NLU and SAP on DSTC multi-domain human-human dialogues. Experiments show that our proposed model significantly outperforms the state-of-the-art pipeline models for both NLU and SAP, which indicates that our joint model is capable of mitigating the affects of noisy NLU outputs, and NLU model can be refined by error flows backpropagating from the extra supervised signals of system actions.

We study trace codes with defining set L, a subgroup of the multiplicative group of an extension of degree m of the alphabet ring mathbbFumathbbFumathbbF, with u. These codes are abelian, and their ternary images are quasi-cyclic of co-index three a.k.a. cubic codes. Their Lee weight distributions are computed by using Gauss sums. These codes have three nonzero weights when m is singly-even and Lfracm-m. When m is odd, and Lfracm-m, or Lm-m and m is a positive integer, we obtain two new infinite families of two-weight codes which are optimal. Applications of the image codes to secret sharing schemes are also given.

In this paper, several classes of three-weight codes and two-weight codes for the homogeneous metric over the chain ring RmathbbFpumathbbFpcdots uk-mathbbFp, with uk, are constructed, which generalises citeSL, the special case of pk. These codes are defined as trace codes. In some cases of their defining sets, they are abelian. Their homogeneous weight distributions are computed by using exponential sums. In particular, in the two-weight case, we give some conditions of optimality of their Gray images by using the Griesmer bound. Their dual homogeneous distance is also given. The codewords of these codes are shown to be minimal for inclusion of supports, a fact favorable to an application to secret sharing schemes.

We show that the Bellman operator underlying the options framework leads to a matrix splitting, an approach traditionally used to speed up convergence of iterative solvers for large linear systems of equations. Based on standard comparison theo- rems for matrix splittings, we then show how the asymptotic rate of convergence varies as a function of the inherent timescales of the options. This new perspective highlights a trade-off between asymptotic performance and the cost of computation associated with building a good set of options.

Peer prediction is a method to promote contributions of information by users in settings in which there is no way to verify the quality of responses. In multi-task peer prediction, the reports from users across multiple tasks are used to score contributions. This paper extends the em correlated agreement CA multi-task peer prediction mechanismciteshnayderinformed to allow the reports from users to be on heterogeneous tasks, each associated with different distributions on responses. The motivation comes from wanting to elicit user-generated content about places in a city, where tasks vary because places, and questions about places, vary. We prove that the generalized CA mechanism is em informed truthful under weak conditions, meaning that it is strictly beneficial for a user to invest effort and acquire information, and that truthful reporting is the best strategy when investing effort, as well as an equilibrium. We demonstrate that the mechanism has good incentive properties when tested in simulation on distributions derived from user reports on Google Local Guides.

A switched-capacitor matrix multiplier is presented for approximate computing and machine learning applications. The multiply-and-accumulate operations perform discrete-time charge-domain signal processing using passive switches and  aF unit capacitors. The computation is digitized with a  b asynchronous successive approximation register analog-to-digital converter. The analyses of incomplete charge accumulation and thermal noise are discussed. The design was fabricated in  nm CMOS, and experimental measurements of multiplication are illustrated using matched filtering and image convolutions to analyze noise and offset. Two applications are highlighted  energy-efficient feature extraction layer performing both compression and classification in a neural network for an analog front end and  analog acceleration for solving optimization problems that are traditionally performed in the digital domain. The chip obtains measured efficiencies of . TOPSW at  GHz for the first application and . TOPSW at . GHz for the second application.

Segmenting a structural magnetic resonance imaging MRI scan is an important pre-processing step for analytic procedures and subsequent inferences about longitudinal tissue changes. Manual segmentation defines the current gold standard in quality but is prohibitively expensive. Automatic approaches are computationally intensive, incredibly slow at scale, and error prone due to usually involving many potentially faulty intermediate steps. In order to streamline the segmentation, we introduce a deep learning model that is based on volumetric dilated convolutions, subsequently reducing both processing time and errors. Compared to its competitors, the model has a reduced set of parameters and thus is easier to train and much faster to execute. The contrast in performance between the dilated network and its competitors becomes obvious when both are tested on a large dataset of unprocessed human brain volumes. The dilated network consistently outperforms not only another state-of-the-art deep learning approach, the up convolutional network, but also the ground truth on which it was trained. Not only can the incredible speed of our model make large scale analyses much easier but we also believe it has great potential in a clinical setting where, with little to no substantial delay, a patient and provider can go over test results.

We tackle the prediction of instructor intervention in student posts from discussion forums in Massive Open Online Courses MOOCs. Our key finding is that using automatically obtained discourse relations improves the prediction of when instructors intervene in student discussions, when compared with a state-of-the-art, feature-rich baseline. Our supervised classifier makes use of an automatic discourse parser which outputs Penn Discourse Treebank PDTB tags that represent in-post discourse features. We show PDTB relation-based features increase the robustness of the classifier and complement baseline features in recalling more diverse instructor intervention patterns. In comprehensive experiments over  MOOC offerings from several disciplines, the PDTB discourse features improve performance on average. The resultant models are less dependent on domain-specific vocabulary, allowing them to better generalize to new courses.

We review disruptive innovations introduced in the RoboCup D Soccer Simulation League over the twenty years since its inception, and trace the progress of our champion team Gliders. We conjecture that the League has been developing as an ecosystem shaped by diverse approaches taken by participating teams, increasing in its overall complexity. A common feature is that different champion teams succeeded in finding a way to decompose the enormous search-space of possible single- and multi-agent behaviours, by automating the exploration of the problem space with various techniques which accelerated the software development efforts. These methods included interactive debugging, machine learning, automated planning, and opponent modelling. The winning approach developed by Gliders is centred on human-based evolutionary computation which optimised several components such as an action-dependent evaluation function, dynamic tactics with Voronoi diagrams, information dynamics, and bio-inspired collective behaviour.

There is an increasing interest in estimating expectations outside of the classical inference framework, such as for models expressed as probabilistic programs. Many of these contexts call for some form of nested inference to be applied. In this paper, we analyse the behaviour of nested Monte Carlo NMC schemes, for which classical convergence proofs are insufficient. We give conditions under which NMC will converge, establish a rate of convergence, and provide empirical data that suggests that this rate is observable in practice. Finally, we prove that general-purpose nested inference schemes are inherently biased. Our results serve to warn of the dangers associated with naive composition of inference and models.

For a matroid with an ordered or labelled basis, a basis exchange step removes one element with label l and replaces it by a new element that results in a new basis, and with the new element assigned label l. We prove that one labelled basis can be reconfigured to another if and only if for every label, the initial and final elements with that label lie in the same connected component of the matroid. Furthermore, we prove that when the reconfiguration is possible, the number of basis exchange steps required is Or. for a rank r matroid. For a graphic matroid we improve the bound to Or log r.

We present the Mim-Solutions approach to the RecSys Challenge , which ranked nd. The goal of the competition was to prepare job recommendations for the users of the website Xing.com.   Our two phase algorithm consists of candidate selection followed by the candidate ranking. We ranked the candidates by the predicted probability that the user will positively interact with the job offer. We have used Gradient Boosting Decision Trees as the regression tool.

We consider non-monotone DR-submodular function maximization, where DR-submodularity diminishing return submodularity is an extension of submodularity for functions over the integer lattice based on the concept of the diminishing return property. Maximizing non-monotone DR-submodular functions has many applications in machine learning that cannot be captured by submodular set functions. In this paper, we present a fracepsilon-approximation algorithm with a running time of roughly Ofracnepsilonlog B, where n is the size of the ground set, B is the maximum value of a coordinate, and epsilon   is a parameter. The approximation ratio is almost tight and the dependency of running time on B is exponentially smaller than the naive greedy algorithm. Experiments on synthetic and real-world datasets demonstrate that our algorithm outputs almost the best solution compared to other baseline algorithms, whereas its running time is several orders of magnitude faster.

The presence of bacteria or fungi in the bloodstream of patients is abnormal and can lead to life-threatening conditions. A computational model based on a bidirectional long short-term memory artificial neural network, is explored to assist doctors in the intensive care unit to predict whether examination of blood cultures of patients will return positive. As input it uses nine monitored clinical parameters, presented as time series data, collected from  ICU admissions at the Ghent University Hospital. Our main goal is to determine if general machine learning methods and more specific, temporal models, can be used to create an early detection system. This preliminary research obtains an area of . under the precision recall curve, proving the potential of temporal neural networks in this context.

In this paper, several classes of three-weight codes and two-weight codes for the homogeneous metric over the chain ring RmathbbFpumathbbFpcdots uk-mathbbFp, with uk, are constructed, which generalises citeSL, the special case of pk. These codes are defined as trace codes. In some cases of their defining sets, they are abelian. Their homogeneous weight distributions are computed by using exponential sums. In particular, in the two-weight case, we give some conditions of optimality of their Gray images by using the Griesmer bound. Their dual homogeneous distance is also given. The codewords of these codes are shown to be minimal for inclusion of supports, a fact favorable to an application to secret sharing schemes.

We construct two new infinite families of trace codes of dimension m, over the ring mathbbFpumathbbFp, when p is an odd prime. They have the algebraic structure of abelian codes. Their Lee weight distribution is computed by using Gauss sums. By Gray mapping, we obtain two infinite families of linear p-ary codes of respective lengths pm- and pm-. When m is singly-even, the first family gives five-weight codes. When m is odd, and pequiv  pmod, the first family yields p-ary two-weight codes, which are shown to be optimal by application of the Griesmer bound. The second family consists of two-weight codes that are shown to be optimal, by the Griesmer bound, whenever p and m ge , or pge  and mge . Applications to secret sharing schemes are given.

Math word problems provide a natural abstraction to a range of natural language understanding problems that involve reasoning about quantities, such as interpreting election results, news about casualties, and the financial section of a newspaper. Units associated with the quantities often provide information that is essential to support this reasoning. This paper proposes a principled way to capture and reason about units and shows how it can benefit an arithmetic word problem solver. This paper presents the concept of Unit Dependency Graphs UDGs, which provides a compact representation of the dependencies between units of numbers mentioned in a given problem. Inducing the UDG alleviates the brittleness of the unit extraction system and allows for a natural way to leverage domain knowledge about unit compatibility, for word problem solving. We introduce a decomposed model for inducing UDGs with minimal additional annotations, and use it to augment the expressions used in the arithmetic word problem solver of Roy and Roth  via a constrained inference framework. We show that introduction of UDGs reduces the error of the solver by over  , surpassing all existing systems for solving arithmetic word problems. In addition, it also makes the system more robust to adaptation to new vocabulary and equation forms .

Deep-learning metrics have recently demonstrated extremely good performance to match image patches for stereo reconstruction. However, training such metrics requires large amount of labeled stereo images, which can be difficult or costly to collect for certain applications. The main contribution of our work is a new semi-supervised method for learning deep metrics from unlabeled stereo images, given coarse information about the scenes and the optical system. Our method alternatively optimizes the metric with a standard stochastic gradient descent, and applies stereo constraints to regularize its prediction. Experiments on reference data-sets show that, for a given network architecture, training with this new method without ground-truth produces a metric with performance as good as state-of-the-art baselines trained with the said ground-truth. This work has three practical implications. Firstly, it helps to overcome limitations of training sets, in particular noisy ground truth. Secondly it allows to use much more training data during learning. Thirdly, it allows to tune deep metric for a particular stereo system, even if ground truth is not available.

Food image recognition is one of the promising applications of visual object recognition in computer vision. In this study, a small-scale dataset consisting of  images of ten categories and a five-layer CNN was constructed to recognize these images. The bag-of-features BoF model coupled with support vector machine was first tested as comparison, resulting in an overall accuracy of , while the CNN performed much better with an overall accuracy of . Data expansion techniques were applied to increase the size of training images, which achieved a significantly improved accuracy of more than  and prevent the overfitting issue that occurred to the CNN without using data expansion. Further improvement is within reach by collecting more images and optimizing the network architecture and relevant hyper-parameters.

Real-world complex networks describe connections between objects in reality, those objects are often endowed with some kind of features. How does the presence or absence of such features interplay with the network link structure? Although the situation here described is truly ubiquitous, there is a limited body of research dealing with large graphs of this kind. Many previous works considered homophily as the only possible transmission mechanism translating node features into links. Other authors, instead, developed more sophisticated models, that are able to handle complex feature interactions, but are unfit to scale to very large networks. We expand on the MGJ model, where interactions between pairs of features can foster or discourage link formation. In this work, we will investigate how to estimate the latent feature-feature interactions in this model. We shall propose two solutions the first one assumes feature independence and it is essentially based on Naive Bayes the second one, which relaxes the independence assumption assumption, is based on perceptrons. In fact, we show it is possible to cast the model equation in order to see it as the prediction rule of a perceptron. We analyze how classical results for the perceptrons can be interpreted in this context then, we define a fast and simple perceptron-like algorithm for this task, which can process  links in minutes. We then compare these two techniques, first with synthetic datasets that follows our model, gaining evidence that the Naive independence assumptions are detrimental in practice. Secondly, we consider a real, large-scale citation network where each node i.e., paper can be described by different types of characteristics there, our algorithm can assess how well each set of features can explain the links, and thus finding meaningful latent feature-feature interactions.

Wikipedia articles about the same topic in different language editions are built around different sources of information. For example, one can find very different news articles linked as references in the English Wikipedia article titled Annexation of Crimea by the Russian Federation than in its German counterpart determined via Wikipedias language links. Some of this difference can of course be attributed to the different language proficiencies of readers and editors in separate language editions, yet, although including English-language news sources seems to be no issue in the German edition, English references that are listed do not overlap highly with the ones in the articles English version. Such patterns could be an indicator of bias towards certain national contexts when referencing facts and statements in Wikipedia. However, determining for each reference which national context it can be traced back to, and comparing the link distributions to each other is infeasible for casual readers or scientists with non-technical backgrounds. Wikiwhere answers the question where Web references stem from by analyzing and visualizing the geographic location of external reference links that are included in a given Wikipedia article. Instead of relying solely on the IP location of a given URL our machine learning models consider several features.

Power consumption is a critical factor for the deployment of embedded computer vision systems. We explore the use of computational cameras that directly output binary gradient images to reduce the portion of the power consumption allocated to image sensing. We survey the accuracy of binary gradient cameras on a number of computer vision tasks using deep learning. These include object recognition, head pose regression, face detection, and gesture recognition. We show that, for certain applications, accuracy can be on par or even better than what can be achieved on traditional images. We are also the first to recover intensity information from binary spatial gradient images--useful for applications with a human observer in the loop, such as surveillance. Our results, which we validate with a prototype binary gradient camera, point to the potential of gradient-based computer vision systems.

This paper explores the problem of page migration in ring networks. A ring network is a connected graph, in which each node is connected with exactly two other nodes. In this problem, one of the nodes in a given network holds a page of size D. This node is called the server and the page is a non-duplicable data in the network. Requests are issued by nodes to access the page one after another. Every time a new request is issued, the server must serve the request and may migrate to another node before the next request arrives. A service costs the distance between the server and the requesting node, and the migration costs the distance of the migration multiplied by D. The problem is to minimize the total costs of services and migrations. We study this problem in uniform model, for which the page has a unit size, i.e. D. A .-competitive algorithm improving the current best upper bound is designed. We show that this ratio is tight for our algorithm.

Ensembles are a popular way to improve results of discriminative CNNs. The combination of several networks trained starting from different initializations improves results significantly. In this paper we investigate the usage of ensembles of GANs. The specific nature of GANs opens up several new ways to construct ensembles. The first one is based on the fact that in the minimax game which is played to optimize the GAN objective the generator network keeps on changing even after the network can be considered optimal. As such ensembles of GANs can be constructed based on the same network initialization but just taking models which have different amount of iterations. These so-called self ensembles are much faster to train than traditional ensembles. The second method, called cascade GANs, redirects part of the training data which is badly modeled by the first GAN to another GAN. In experiments on the CIFAR dataset we show that ensembles of GANs obtain model probability distributions which better model the data distribution. In addition, we show that these improved results can be obtained at little additional computational cost.

Despite the growing availability of big data in many fields, historical data on socioevironmental phenomena are often not available due to a lack of automated and scalable approaches for collecting, digitizing, and assembling them. We have developed a data-mining method for extracting tabulated, geocoded data from printed directories. While scanning and optical character recognition OCR can digitize printed text, these methods alone do not capture the structure of the underlying data. Our pipeline integrates both page layout analysis and OCR to extract tabular, geocoded data from structured text. We demonstrate the utility of this method by applying it to scanned manufacturing registries from Rhode Island that record  years of industrial land use. The resulting spatio-temporal data can be used for socioenvironmental analyses of industrialization at a resolution that was not previously possible. In particular, we find strong evidence for the dispersion of manufacturing from the urban core of Providence, the states capital, along the Interstate  corridor to the north and south.

In our modern society comfort became a standard. This comfort, especially in cars can only be achieved by equipping the car with more electronic devices. Some of the electronic devices must cooperate with each other and thus they require a communication channel, which can be wired or wireless. In these days, it would be hard to sell a new car operating with traditional keys. Almost all modern cars can be locked or unlocked with a Remote Keyless System. A Remote Keyless System consists of a key fob that communicates wirelessly with the car transceiver that is responsible for locking and unlocking the car. However there are several threats for wireless communication channels.   This paper describes the possible attacks against a Remote Keyless System and introduces a secure protocol as well as a lightweight Symmetric Encryption Algorithm for a Remote Keyless Entry System applicable in vehicles.

Stream Control Transmission Protocol SCTP was introduced in  as a multipath variant to traditional transport protocols, i.e. Transmission Control Protocol TCP and User Datagram Protocol UDP. Concurrent Multipath Transfer CMT has been proposed as an extension for SCTP to support concurrent usage of available multiple paths. In this paper, we propose a new congestion control algorithm for CMT-SCTP based on the principle of resource pooling. We use the connection bandwidth estimates to obtain the collection of the network resources being used by different flows on multiple paths. Based on these bandwidth estimates, we have used the bandwidth estimation based resource pooling approach to adjust the congestion window of the respective paths. We compare our proposed scheme with CMT-SCTP through ns- based simulations.

We consider mixed powerdomains combining ordinary nondeterminism and probabilistic nondeterminism. We characterise them as free algebras for suitable inequation-al theories we establish functional representation theorems and we show equivalencies between state transformers and appropriately healthy predicate transformers. The extended nonnegative reals serve as truth-values. As usual with powerdomains, everything comes in three flavours lower, upper, and order-convex. The powerdomains are suitable convex sets of subprobability valuations, corresponding to resolving nondeterministic choice before probabilistic choice. Algebraically this corresponds to the probabilistic choice operator distributing over the nondeterministic choice operator. An alternative approach to combining the two forms of nondeterminism would be to resolve probabilistic choice first, arriving at a domain-theoretic version of random sets. However, as we also show, the algebraic approach then runs into difficulties.   Rather than working directly with valuations, we take a domain-theoretic functional-analytic approach, employing domain-theoretic abstract convex sets called Kegelspitzen these are equivalent to the abstract probabilistic algebras of Graham and Jones, but are more convenient to work with. So we define power Kegelspitzen, and consider free algebras, functional representations, and predicate transformers. To do so we make use of previous work on domain-theoretic cones d-cones, with the bridge between the two of them being provided by a free d-cone construction on Kegelspitzen.

Gaussian noise removal is an interesting area in digital image processing not only to improve the visual quality, but for its impact on other post-processing algorithms like image registration or segmentation. Many presented state-of-the-art denoising methods are based on the self-similarity or patch-based image processing. Specifically, Non-Local Means NLM as a patch-based filter has gained increasing attention in recent years. Essentially, this filter tends to obtain the noise-less signal value by computing the Gaussian-weighted Euclidean distance between the patch under-processing and other patches inside the image. However, the NLM filter is sensitive to the outliers pixels that their intensity values are far away from other pixels inside the patch, meaning that the pixels with the symmetric locations in the patch are assigned the same weight. This can lead to sub-optimal denoising performance when the destructive nature of noise generates some outliers inside patches. In this paper, we propose a new weighting approach to modify the Gaussian kernel of the NLM filter. Our approach employs the geometric distance between image intensities to come up with new weights for each pixel of a patch, lowering the impact of outliers on the denoising performance. Experiments on a set of standard images and different noise levels show that our proposed method outperforms the other compared denoising filters.

The composition of polyphonic chorale music in the style of J.S Bach has represented a major challenge in automatic music composition over the last decades. The art of Bach chorales composition involves combining four-part harmony with characteristic rhythmic patterns and typical melodic movements to produce musical phrases which begin, evolve and end cadences in a harmonious way. To our knowledge, no model so far was able to solve all these problems simultaneously using an agnostic machine-learning approach. This paper introduces DeepBach, a statistical model aimed at modeling polyphonic music and specifically four parts, hymn-like pieces. We claim that, after being trained on the chorale harmonizations by Johann Sebastian Bach, our model is capable of generating highly convincing chorales in the style of Bach. We evaluate how indistinguishable our generated chorales are from existing Bach chorales with a listening test. The results corroborate our claim. A key strength of DeepBach is that it is agnostic and flexible. Users can constrain the generation by imposing some notes, rhythms or cadences in the generated score. This allows users to reharmonize user-defined melodies. DeepBachs generation is fast, making it usable for interactive music composition applications. Several generation examples are provided and discussed from a musical point of view.

We consider the Hypothesis Transfer Learning HTL problem where one incorporates a hypothesis trained on the source domain into the learning procedure of the target domain. Existing theoretical analysis either only studies specific algorithms or only presents upper bounds on the generalization error but not on the excess risk. In this paper, we propose a unified algorithm-dependent framework for HTL through a novel notion of transformation functions, which characterizes the relation between the source and the target domains. We conduct a general risk analysis of this framework and in particular, we show for the first time, if two domains are related, HTL enjoys faster convergence rates of excess risks for Kernel Smoothing and Kernel Ridge Regression than those of the classical non-transfer learning settings. We accompany this framework with an analysis of cross-validation for HTL to search for the best transfer technique and gracefully reduce to non-transfer learning when HTL is not helpful. Experiments on robotics and neural imaging data demonstrate the effectiveness of our framework.

Deep learning approaches have reached a celebrity status in artificial intelligence field, its success have mostly relied on Convolutional Networks CNN and Recurrent Networks. By exploiting fundamental spatial properties of images and videos, the CNN always achieves dominant performance on visual tasks. And the Recurrent Networks RNN especially long short-term memory methods LSTM can successfully characterize the temporal correlation, thus exhibits superior capability for time series tasks. Traffic flow data have plentiful characteristics on both time and space domain. However, applications of CNN and LSTM approaches on traffic flow are limited. In this paper, we propose a novel deep architecture combined CNN and LSTM to forecast future traffic flow CLTFP. An -dimension CNN is exploited to capture spatial features of traffic flow, and two LSTMs are utilized to mine the short-term variability and periodicities of traffic flow. Given those meaningful features, the feature-level fusion is performed to achieve short-term forecasting. The proposed CLTFP is compared with other popular forecasting methods on an open datasets. Experimental results indicate that the CLTFP has considerable advantages in traffic flow forecasting. in additional, the proposed CLTFP is analyzed from the view of Granger Causality, and several interesting properties of CLTFP are discovered and discussed .

Antimicrobial resistance is an important public health concern that has implications in the practice of medicine worldwide. Accurately predicting resistance phenotypes from genome sequences shows great promise in promoting better use of antimicrobial agents, by determining which antibiotics are likely to be effective in specific clinical cases. In healthcare, this would allow for the design of treatment plans tailored for specific individuals, likely resulting in better clinical outcomes for patients with bacterial infections. In this work, we present the recent work of Drouin et al.  on using Set Covering Machines to learn highly interpretable models of antibiotic resistance and complement it by providing a large scale application of their method to the entire PATRIC database. We report prediction results for  new datasets and present the Kover AMR platform, a new web-based tool allowing the visualization and interpretation of the generated models.

We propose Areas of Attention, a novel attention-based model for automatic image caption generation. Our approach models the interplay between the state of the RNN, image region descriptors and word embedding vectors by three pairwise interactions. It allows association of caption words with local visual appearances rather than with descriptors of the entire scene. This enables better generalization to complex scenes not seen during training. Our model is agnostic to the type of attention areas, and we instantiate it using regions based on CNN activation grids, object proposals, and spatial transformer networks. Our results show that all components of our model contribute to obtain state-of-the-art performance on the MSCOCO dataset. In addition, our results indicate that attention areas are correctly associated to meaningful latent semantic structure in the generated captions.

This paper deals with the localization problem of mobile robot subject to communication delay and packet loss. The delay and loss may appear in a random fashion in both control inputs and observation measurements. A unified state-space representation is constructed to describe these mixed uncertainties. Based on it, the optimal linear estimator is developed. The main idea is the derivation of a relevance factor to incorporate delayed measurements to the being estimate. The estimator is then extended for nonlinear systems. The performance of this method is tested within the simulations in MATLAB and the experiments in a real robot system. The good localization results prove the efficiency of the method for the purpose of localization of networked mobile robot.

We propose a framework for semi-automated annotation of video frames where the video is of an object that at any point in time can be labeled as being in one of a finite number of discrete states. A Hidden Markov Model HMM is used to model  the behavior of the underlying object and  the noisy observation of its state through an image processing algorithm. The key insight of this approach is that the annotation of frame-by-frame video can be reduced from a problem of labeling every single image to a problem of detecting a transition between states of the underlying objected being recording on video. The performance of the framework is evaluated on a driver gaze classification dataset composed of ,, images that were fully annotated over , hours of direct manual annotation labor. On this dataset, we achieve a x reduction in manual annotation for an average accuracy of . and a x reduction for an average accuracy of ..

In this paper, we study the Maximum Profit Pick-up Problem with Time Windows and Capacity Constraint MP-PPTWC. Our main results are  polynomial time algorithms, all having constant approximation factors. The first algorithm has an approximation ratio of      fracalphasqrtp epsilon log T, where i epsilon   and T are constants ii The maximum quantity supplied is qmax  Onp qmin, for some p  , where qmin is the minimum quantity supplied iii alpha   is a constant such that the optimal number of vehicles is always at least sqrt  p  alpha. The second algorithm has an approximation ratio of simeq    epsilon  frac  alpha epsilonsqrt  p log T. Finally, the third algorithm has an approximation ratio of simeq     epsilon log T. While our algorithms may seem to have quite high approximation ratios, in practice they work well and, in the majority of cases, the profit obtained is at least  of the optimum.

Product reviews contain a lot of useful information about product features and customer opinions. One important product feature is the complementary entity products that may potentially work together with the reviewed product. Knowing complementary entities of the reviewed product is very important because customers want to buy compatible products and avoid incompatible ones. In this paper, we address the problem of Complementary Entity Recognition CER. Since no existing method can solve this problem, we first propose a novel unsupervised method to utilize syntactic dependency paths to recognize complementary entities. Then we expand category-level domain knowledge about complementary entities using only a few general seed verbs on a large amount of unlabeled reviews. The domain knowledge helps the unsupervised method to adapt to different products and greatly improves the precision of the CER task. The advantage of the proposed method is that it does not require any labeled data for training. We conducted experiments on  popular products with about  reviews in total to demonstrate that the proposed approach is effective.

Recent tools for interactive data exploration significantly increase the chance that users make false discoveries. The crux is that these tools implicitly allow the user to test a large body of different hypotheses with just a few clicks thus incurring in the issue commonly known in statistics as the multiple hypothesis testing error. In this paper, we propose solutions to integrate multiple hypothesis testing control into interactive data exploration tools. A key insight is that existing methods for controlling the false discovery rate such as FDR are not directly applicable for interactive data exploration. We therefore discuss a set of new control procedures that are better suited and integrated them in our system called Aware. By means of extensive experiments using both real-world and synthetic data sets we demonstrate how Aware can help experts and novice users alike to efficiently control false discoveries.

In the correlated sampling problem, two players, say Alice and Bob, are given two distributions, say P and Q respectively, over the same universe and access to shared randomness. The two players are required to output two elements, without any interaction, sampled according to their respective distributions, while trying to minimize the probability that their outputs disagree. A well-known protocol due to Holenstein, with close variants for similar problems due to Broder, and to Kleinberg and Tardos, solves this task with disagreement probability at most  deltadelta, where delta is the total variation distance between P and Q. This protocol has been used in several different contexts including sketching algorithms, approximation algorithms based on rounding linear programming relaxations, the study of parallel repetition and cryptography.   In this note, we give a surprisingly simple proof that this protocol is in fact tight. Specifically, for every delta in ,, we show that any correlated sampling scheme should have disagreement probability at least deltadelta. This partially answers a recent question of Rivest.   Our proof is based on studying a new problem we call constrained agreement. Here, Alice is given a subset A subseteq n and is required to output an element i in A, Bob is given a subset B subseteq n and is required to output an element j in B, and the goal is to minimize the probability that i neq j. We prove tight bounds on this question, which turn out to imply tight bounds for correlated sampling. Though we settle basic questions about the two problems, our formulation also leads to several questions that remain open.

Magnetometer and inertial sensors are widely used for orientation estimation. Magnetometer usage is often troublesome, as it is prone to be interfered by onboard or ambient magnetic disturbance. The onboard soft-iron material distorts not only the magnetic field, but the magnetometer sensor frame coordinate and the cross-sensor misalignment relative to inertial sensors. It is desirable to conveniently put magnetic and inertial sensors information in a common frame. Existing methods either split the problem into successive intrinsic and cross-sensor calibrations, or rely on stationary accelerometer measurements which is infeasible in dynamic conditions. This paper formulates the magnetometer calibration and alignment to inertial sensors as a state estimation problem, and collectively solves the magnetometer intrinsic and cross-sensor calibrations, as well as the gyroscope bias estimation. Sufficient conditions are derived for the problem to be globally observable, even when no accelerometer information is used at all. An extended Kalman filter is designed to implement the state estimation and comprehensive test data results show the superior performance of the proposed approach. It is immune to acceleration disturbance and applicable potentially in any dynamic conditions.

In terrestrial communication networks without fixed infrastructure, unmanned aerial vehicle UAV-mounted mobile base stations MBSs provide an efficient solution to achieve wireless connectivity. This letter aims to minimize the number of MBSs needed to provide wireless coverage for a group of distributed ground terminals GTs, ensuring that each GT is within the communication range of at least one MBS. We propose a polynomial-time algorithm with successive MBS placement, where the MBSs are placed sequentially starting on the area perimeter of the uncovered GTs along a spiral path towards the center, until all GTs are covered. Each MBS is placed to cover as many uncovered GTs as possible, with higher priority given to the GTs on the boundary to reduce the occurrence of outlier GTs that each may require one dedicated MBS for its coverage. Numerical results show that the proposed algorithm performs favorably compared to other schemes in terms of the total number of required MBSs andor time complexity.

Object detection is a crucial task for autonomous driving. In addition to requiring high accuracy to ensure safety, object detection for autonomous driving also requires real-time inference speed to guarantee prompt vehicle control, as well as small model size and energy efficiency to enable embedded system deployment. In this work, we propose SqueezeDet, a fully convolutional neural network for object detection that aims to simultaneously satisfy all of the above constraints. In our network we use convolutional layers not only to extract feature maps, but also as the output layer to compute bounding boxes and class probabilities. The detection pipeline of our model only contains a single forward pass of a neural network, thus it is extremely fast. Our model is fully-convolutional, which leads to small model size and better energy efficiency. Finally, our experiments show that our model is very accurate, achieving state-of-the-art accuracy on the KITTI benchmark.

Graphs are used as models in all areas of computer science examples are state space graphs, control flow graphs, syntax graphs, UML-type models of all kinds, network layouts, social networks, dependency graphs, and so forth. Once such graphical models are constructed, they can be analysed and transformed to verify their correctness within a domain, discover new properties, or produce new equivalent andor optimised versions.   Graphs as Models main focus is the exchange and collaboration of researchers from different backgrounds. The workshop serves as platform to boost inter- and transdisciplinary research and wants to serve as leeway for new ideas. Thus, besides classical research presentations, the workshop is highly geared toward numerous interactive sessions.   The second edition of the Graphs as Models workshop was held on - June  in Eindhoven, The Netherlands, colocated with the th European Joint Conferences on Theory and Practice of Software ETAPS .

More than two thirds of mental health problems have their onset during childhood or adolescence. Identifying children at risk for mental illness later in life and predicting the type of illness is not easy. We set out to develop a platform to define subtypes of childhood social-emotional development using longitudinal, multifactorial trait-based measures. Subtypes discovered through this study could ultimately advance psychiatric knowledge of the early behavioural signs of mental illness. To this extent we have examined two types of models latent class mixture models and GP-based models. Our findings indicate that while GP models come close in accuracy of predicting future trajectories, LCMMs predict the trajectories as well in a fraction of the time. Unfortunately, neither of the models are currently accurate enough to lead to immediate clinical impact. The available data related to the development of childhood mental health is often sparse with only a few time points measured and require novel methods with improved efficiency and accuracy.

To avoid the exhaustive search over locations and scales, current state-of-the-art object detection systems usually involve a crucial component generating a batch of candidate object proposals from images. In this paper, we present a simple yet effective approach for segmenting object proposals via a deep architecture of recursive neural networks RNNs, which hierarchically groups regions for detecting object candidates over scales. Unlike traditional methods that mainly adopt fixed similarity measures for merging regions or finding object proposals, our approach adaptively learns the region merging similarity and the objectness measure during the process of hierarchical region grouping. Specifically, guided by a structured loss, the RNN model jointly optimizes the cross-region similarity metric with the region merging process as well as the objectness prediction. During inference of the object proposal generation, we introduce randomness into the greedy search to cope with the ambiguity of grouping regions. Extensive experiments on standard benchmarks, e.g., PASCAL VOC and ImageNet, suggest that our approach is capable of producing object proposals with high recall while well preserving the object boundaries and outperforms other existing methods in both accuracy and efficiency.

This paper introduces ALYSIA Automated LYrical SongwrIting Application. ALYSIA is based on a machine learning model using Random Forests, and we discuss its success at pitch and rhythm prediction. Next, we show how ALYSIA was used to create original pop songs that were subsequently recorded and produced. Finally, we discuss our vision for the future of Automated Songwriting for both co-creative and autonomous systems.

In this paper we consider a model of spreading information in heterogeneous systems wherein we have two kinds of objects. Some of them are active and others are passive. Active objects can, if they possess information, share it with an encountered passive object. We focus on a particular case such that active objects communicate independently with randomly chosen passive objects. Such model is motivated by two real-life scenarios. The first one is a very dynamic system of mobile devices distributing information among stationary devices. The second is an architecture wherein clients communicate with several servers and can leave some information learnt from other servers. The main question we investigate is how many rounds is needed to deliver the information to all objects under the assumption that at the beginning exactly one object has the information?   In this paper we provide mathematical models of such process and show rigid and very precise mathematical analysis for some special cases important from practical point of view. Some mathematical results are quite surprising -- we find relation of investigated process to both coupon collectors problem as well as the birthday paradox. Additionally, we present simulations for showing behaviour for general parameters

Deep neural networks are widely used in machine learning applications. However, the deployment of large neural networks models can be difficult to deploy on mobile devices with limited power budgets. To solve this problem, we propose Trained Ternary Quantization TTQ, a method that can reduce the precision of weights in neural networks to ternary values. This method has very little accuracy degradation and can even improve the accuracy of some models , , -layer ResNet on CIFAR- and AlexNet on ImageNet. And our AlexNet model is trained from scratch, which means its as easy as to train normal full precision model. We highlight our trained quantization method that can learn both ternary values and ternary assignment. During inference, only ternary values -bit weights and scaling factors are needed, therefore our models are nearly x smaller than full-precision models. Our ternary models can also be viewed as sparse binary weight networks, which can potentially be accelerated with custom circuit. Experiments on CIFAR- show that the ternary models obtained by trained quantization method outperform full-precision models of ResNet-,, by ., ., ., respectively. On ImageNet, our model outperforms full-precision AlexNet model by . of Top- accuracy and outperforms previous ternary models by .

Image CAPTCHA, aiming at effectively distinguishing human users from malicious script attacks, has been an important mechanism to protect online systems from spams and abuses. Despite the increasing interests in developing and deploying image CAPTCHAs, the usability aspect of those CAPTCHAs has hardly been explored systematically. In this paper, the universal design factors of image CAPTCHAs, such as image layouts, quantities, sizes, tilting angles and colors were experimentally evaluated through the following four dimensions eye-tracking, efficiency, effectiveness and satisfaction. The cognitive processes revealed by eye-tracking indicate that the distribution of eye gaze is equally assigned to each candidate image and irrelevant to the variation of image contents. In addition, the gazing plot suggests that more than  of the participants inspected CAPTCHA images row-by-row, which is more efficient than scanning randomly. Those four-dimensional evaluations essentially suggest that square and horizontal rectangle are the preferred layout image quantities may not exceed  while the image color is insignificant. Meanwhile, the image size and tilting angle are suggested to be larger than  pixels x  pixels and within - degrees, respectively. Basing on those usability experiment results, we proposed a design guideline that is expected to be useful for developing more usable image CAPTCHAs.

While existing works about non-orthogonal multiple access NOMA have indicated that NOMA can yield a significant performance gain over orthogonal multiple access OMA with fixed resource allocation, it is not clear whether such a performance gain will diminish when optimal resource TimeFrequencyPower allocation is carried out. In this paper, the performance comparison between NOMA and conventional OMA systems is investigated, from an optimization point of view. Firstly, by using the idea of power splitting, a closed-form expression for the optimum sum rate of NOMA systems is derived. Then, with rigorous mathematical proofs, we reveal the fact that NOMA can always outperform conventional OMA systems, even if both are equipped with the optimal resource allocation policies. Finally, computer simulations are conducted to validate the accuracy of the analytical results.

Text CAPTCHA has been an effective means to protect online systems from spams and abuses caused by automatic scripts which pretend to be human beings. However, nearly all the Text CAPTCHA designs in nowadays are based on English characters, which may not be the most user-friendly option for non-English speakers. Therefore, under the background of globalization, there is an increasing interest in designing local-language CAPTCHA, which is expected to be more usable for native speakers. However, systematic studies on the usability of localized CAPTCHAs are rare, and a general procedure for the design of usable localized CAPTCHA is still unavailable. Here, we comprehensively explored the design of CAPTCHAs based on Chinese characters from a usability perspective cognitive processes of solving alphanumeric and Chinese CAPTCHAs are analyzed, followed by a usability comparison of those two types of CAPTCHAs and the evaluation of intrinsic design factors of Chinese CAPTCHAs. It was found that Chinese CAPTCHAs could be equally usable comparing with alphanumeric ones. Meanwhile, guidelines for the design of usable Chinese CAPTCHAs were also presented. Moreover, those design practices were also summarized as a general procedure which is expected to be applicable for the design of CAPTCHAs based on other languages.

Recognition of handwritten words continues to be an important problem in document analysis and recognition. Existing approaches extract hand-engineered features from word images--which can perform poorly with new data sets. Recently, deep learning has attracted great attention because of the ability to learn features from raw data. Moreover they have yielded state-of-the-art results in classification tasks including character recognition and scene recognition. On the other hand, word recognition is a sequential problem where we need to model the correlation between characters. In this paper, we propose using deep Conditional Random Fields deep CRFs for word recognition. Basically, we combine CRFs with deep learning, in which deep features are learned and sequences are labeled in a unified framework. We pre-train the deep structure with stacked restricted Boltzmann machines RBMs for feature learning and optimize the entire network with an online learning algorithm. The proposed model was evaluated on two datasets, and seen to perform significantly better than competitive baseline models. The source code is available at httpsgithub.comganggitdeepCRFs.

Dense object detection and temporal tracking are needed across applications domains ranging from people-tracking to analysis of satellite imagery over time. The detection and tracking of malignant skin cancers and benign moles poses a particularly challenging problem due to the general uniformity of large skin patches, the fact that skin lesions vary little in their appearance, and the relatively small amount of data available. Here we introduce a novel data synthesis technique that merges images of individual skin lesions with full-body images and heavily augments them to generate significant amounts of data. We build a convolutional neural network CNN based system, trained on this synthetic data, and demonstrate superior performance to traditional detection and tracking techniques. Additionally, we compare our system to humans trained with simple criteria. Our system is intended for potential clinical use to augment the capabilities of healthcare providers. While domain-specific, we believe the methods invoked in this work will be useful in applying CNNs across domains that suffer from limited data availability.

Visual restoration and recognition are traditionally addressed in pipeline fashion, i.e. denoising followed by classification. Instead, observing correlations between the two tasks, for example clearer image will lead to better categorization and vice visa, we propose a joint framework for visual restoration and recognition for handwritten images, inspired by advances in deep autoencoder and multi-modality learning. Our model is a -pathway deep architecture with a hidden-layer representation which is shared by multi-inputs and outputs, and each branch can be composed of a multi-layer deep model. Thus, visual restoration and classification can be unified using shared representation via non-linear mapping, and model parameters can be learnt via backpropagation. Using MNIST and USPS data corrupted with structured noise, the proposed framework performs at least  better in classification than separate pipelines, as well as clearer recovered images. The noise model and the reproducible source code is available at urlhttpsgithub.comganggitjointmodel.

Software estimation is a crucial task in software engineering. Software estimation encompasses cost, effort, schedule, and size. The importance of software estimation becomes critical in the early stages of the software life cycle when the details of software have not been revealed yet. Several commercial and non-commercial tools exist to estimate software in the early stages. Most software effort estimation methods require software size as one of the important metric inputs and consequently, software size estimation in the early stages becomes essential. One of the approaches that has been used for about two decades in the early size and effort estimation is called use case points. Use case points method relies on the use case diagram to estimate the size and effort of software projects. Although the use case points method has been widely used, it has some limitations that might adversely affect the accuracy of estimation. This paper presents some techniques using fuzzy logic and neural networks to improve the accuracy of the use case points method. Results showed that an improvement up to  can be obtained using the proposed approach.

Robust perception-action models should be learned from training data with diverse visual appearances and realistic behaviors, yet current approaches to deep visuomotor policy learning have been generally limited to in-situ models learned from a single vehicle or a simulation environment. We advocate learning a generic vehicle motion model from large scale crowd-sourced video data, and develop an end-to-end trainable architecture for learning to predict a distribution over future vehicle egomotion from instantaneous monocular camera observations and previous vehicle state. Our model incorporates a novel FCN-LSTM architecture, which can be learned from large-scale crowd-sourced vehicle action data, and leverages available scene segmentation side tasks to improve performance under a privileged learning paradigm.

Deep convolution neural networks CNN have demonstrated advanced performance on single-label image classification, and various progress also have been made to apply CNN methods on multi-label image classification, which requires to annotate objects, attributes, scene categories etc. in a single shot. Recent state-of-the-art approaches to multi-label image classification exploit the label dependencies in an image, at global level, largely improving the labeling capacity. However, predicting small objects and visual concepts is still challenging due to the limited discrimination of the global visual features. In this paper, we propose a Regional Latent Semantic Dependencies model RLSD to address this problem. The utilized model includes a fully convolutional localization architecture to localize the regions that may contain multiple highly-dependent labels. The localized regions are further sent to the recurrent neural networks RNN to characterize the latent semantic dependencies at the regional level. Experimental results on several benchmark datasets show that our proposed model achieves the best performance compared to the state-of-the-art models, especially for predicting small objects occurred in the images. In addition, we set up an upper bound model RLSDft-RPN using bounding box coordinates during training, the experimental results also show that our RLSD can approach the upper bound without using the bounding-box annotations, which is more realistic in the real world.

We propose a scheme for training a computerized agent to perform complex human tasks such as highway steering. The scheme is designed to follow a natural learning process whereby a human instructor teaches a computerized trainee. The learning process consists of five elements i unsupervised feature learning ii supervised imitation learning iii supervised reward induction iv supervised safety module construction and v reinforcement learning. We implemented the last four elements of the scheme using deep convolutional networks and applied it to successfully create a computerized agent capable of autonomous highway steering over the well-known racing game Assetto Corsa. We demonstrate that the use of the last four elements is essential to effectively carry out the steering task using vision alone, without access to a driving simulator internals, and operating in wall-clock time. This is made possible also through the introduction of a safety network, a novel way for preventing the agent from performing catastrophic mistakes during the reinforcement learning stage.

Our main goal is to discover the main factors influencing students academic trajectory and students academic evolution within such environment. Our results indicate strong correlation in this virtual learning environment between student average and some factors like students English level despite the fact that Arabic language is the teaching language, students age, students gender, students over-stay and students place of residence inside or outside Syria. Our results indicate also a need to modify the academic trajectory of students by changing the prerequisites of few courses delivered as a part of BIT diploma like Advanced DBA II, Data Security. In this research, the results also highlight the effect of the Syrian Crisis on students. Finally, weve suggested some future recommendations based on our observations and results to develop the current information system in SVU in order to help us to deduce some indicators more easily.

Extending our own and others earlier approaches to reasoning about termination of probabilistic programs, we propose and prove a new rule for termination with probability one, also known as almost-certain termination. The rule uses both non-strict super martingales and guarantees of progress, together, and it seems to cover significant cases that earlier methods do not. In particular, it suffices for termination of the unbounded symmetric random walk in both one- and two dimensions for the first, we give a proof for the second, we use a theorem of Foster to argue that a proof exists. Non-determinism i.e. demonic choice is supported but we do currently restrict to discrete distributions.

This article introduces Globular, an online proof assistant for the formalization and verification of proofs in higher-dimensional category theory. The tool produces graphical visualizations of higher-dimensional proofs, assists in their construction with a point-and-click interface, and performs type checking to prevent incorrect rewrites. Hosted on the web, it has a low barrier to use, and allows hyperlinking of formalized proofs directly from research papers. It allows the formalization of proofs from logic, topology and algebra which are not formalizable by other methods, and we give several examples.

Superoptimization requires the estimation of the best program for a given computational task. In order to deal with large programs, superoptimization techniques perform a stochastic search. This involves proposing a modification of the current program, which is accepted or rejected based on the improvement achieved. The state of the art method uses uniform proposal distributions, which fails to exploit the problem structure to the fullest. To alleviate this deficiency, we learn a proposal distribution over possible modifications using Reinforcement Learning. We provide convincing results on the superoptimization of Hackers Delight programs.

In an independence model, the triplets that represent conditional independences between singletons are called elementary. It is known that the elementary triplets represent the independence model unambiguously under some conditions. In this paper, we show how this representation helps performing some operations with independence models, such as finding the dominant triplets or a minimal independence map of an independence model, or computing the union or intersection of a pair of independence models, or performing causal reasoning. For the latter, we rephrase in terms of conditional independences some of Pearls results for computing causal effects.

We construct two series of linear codes over finite ring mathbbFqxx and Galois ring GRp,m respectively reaching the Griesmer bound. They derive two series of codes over finite field mathbbFq by Gray map. The first series of codes over mathbbFq derived from mathbbFqxx are linear and also reach the Griesmer bound in some cases. Many of linear codes over finite field we constructed have two Hamming non-zero weights.

We consider the problem of clustering noisy finite-length observations of stationary ergodic random processes according to their generative models without prior knowledge of the model statistics and the number of generative models. Two algorithms, both using the L-distance between estimated power spectral densities PSDs as a measure of dissimilarity, are analyzed. The first one, termed nearest neighbor process clustering NNPC is new and relies on partitioning the nearest neighbor graph of the observations via spectral clustering. The second algorithm, simply referred to as k-means KM, consists of a single k-means iteration with farthest point initialization and was considered before in the literature, albeit with a different dissimilarity measure and with asymptotic performance results only. We prove that both algorithms succeed with high probability in the presence of noise and missing entries, and even when the generative process PSDs overlap significantly, all provided that the observation length is sufficiently large. Our results quantify the tradeoff between the overlap of the generative process PSDs, the observation length, the fraction of missing entries, and the noise variance. Furthermore, we prove that treating the finite-length observations of stationary ergodic random processes as vectors in Euclidean space and clustering them using the thresholding-based subspace clustering TSC algorithm, the subspace clustering cousin of NNPC, results in performance strictly inferior to that of NNPC. We argue that the underlying cause is to be found in TSC employing spherical distance as dissimilarity measure, thereby ignoring the stationary process structure of the observations. Finally, we provide extensive numerical results for synthetic and real data and find that NNPC outperforms state-of-the-art algorithms in human motion sequence clustering.

Scene parsing is challenging for unrestricted open vocabulary and diverse scenes. In this paper, we exploit the capability of global context information by different-region-based context aggregation through our pyramid pooling module together with the proposed pyramid scene parsing network PSPNet. Our global prior representation is effective to produce good quality results on the scene parsing task, while PSPNet provides a superior framework for pixel-level prediction tasks. The proposed approach achieves state-of-the-art performance on various datasets. It came first in ImageNet scene parsing challenge , PASCAL VOC  benchmark and Cityscapes benchmark. A single PSPNet yields new record of mIoU score as . on PASCAL VOC  and . on Cityscapes.

Recently, multidimensional signal reconstruction using a low number of measurements is of great interest. Therefore, an effective sampling scheme which should acquire the most information of signal using a low number of measurements is required. In this paper, we study a novel cube-based method for sampling and reconstruction of multidimensional signals. First, inspired by the block-based compressive sensing BCS, we divide a group of pictures GoP in a video sequence into cubes. By this way, we can easily store the measurement matrix and also easily can generate the sparsifying basis. The reconstruction process also can be done in parallel. Second, along with the Kronecker structure of the sampling matrix, we design a weight matrix based on the human visuality system, i.e. perceptually. We will also benefit from different weighted ell-minimization methods for reconstruction. Furthermore, conventional methods for BCS consider an equal number of samples for all blocks. However, the sparsity order of blocks in natural images could be different and, therefore, a various number of samples could be required for their reconstruction. Motivated by this point, we will adaptively allocate the samples for each cube in a video sequence. Our aim is to show that our simple linear sampling approach can be competitive with the other state-of-the-art methods.

Visible light communications VLC have been recently proposed as a promising and efficient solution to indoor ubiquitous broadband connectivity. In this paper, non-orthogonal multiple access, which has been recently proposed as an effective scheme for fifth generation G wireless networks, is considered in the context of VLC systems, under different channel uncertainty models. To this end, we first derive a novel closed-form expression for the bit-error-rate BER under perfect channel state information CSI. Capitalizing on this, we quantify the effect of noisy and outdated CSI by deriving a simple approximated expression for the former and a tight upper bound for the latter. The offered results are corroborated by respective results from extensive Monte Carlo simulations and are used to provide useful insights on the effect of imperfect CSI knowledge on the system performance. It was shown that, while noisy CSI leads to slight degradation in the BER performance, outdated CSI can cause detrimental performance degradation if the order of the users channel gains change as a result of mobility

Cloud computing has become indispensable in todays computer landscape. The flexibility it offers for customers as well as for providers has become a crucial factor for large parts of the computer industry. Virtualization is the key technology that allows for sharing of hardware resources among different customers. The controlling software component, called hypervisor, provides a virtualized view of the computer resources and ensures separation of different guest virtual machines. However, this important cornerstone of cloud computing is not necessarily trustworthy. To mitigate this threat AMD introduced Secure Encrypted Virtualization, short SEV. SEV is a processor extension that encrypts guest memory in order to prevent a potentially malicious hypervisor from accessing guest data. In this paper we analyse whether the proposed features can resist a malicious hypervisor and discuss the trade-offs imposed by additional protection mechanisms. To do so, we developed a model of SEVs security capabilities based on the available documentation as actual silicon implementations are not yet on the market. We found that the currently proposed version of SEV is not up to the task owing to three design shortcomings. First, as with standard AMD-V, under SEV, the virtual machine control block is not encrypted and handled directly by the hypervisor, allowing him to bypass VM memory encryption by executing conveniently chosen gadgets. Secondly, the general purpose registers are not encrypted upon vmexit, leaking potentially sensitive data. Finally, the control of the nested pagetables allows a malicious hypervisor to closely control the execution of a VM and attack it with memory replay attacks.

We examine the complexity of inference in Bayesian networks specified by logical languages. We consider representations that range from fragments of propositional logic to function-free first-order logic with equality in doing so we cover a variety of plate models and of probabilistic relational models. We study the complexity of inferences when network, query and domain are the input the inferential and the combined complexity, when the network is fixed and query and domain are the input the querydata complexity, and when the network and query are fixed and the domain is the input the domain complexity. We draw connections with probabilistic databases and liftability results, and obtain complexity classes that range from polynomial to exponential levels.

In image processing, a segmentation is a process of partitioning an image into multiple sets of pixels, that are defined as super-pixels. Each super-pixel is characterized by a label or parameter. Here, we are proposing a method for determining the super-pixels based on the thresholding of the image. This approach is quite useful for studying the images showing vesicular textures.

This paper analyzes the achievable tradeoff between cachesize and downloadrate in decentralized caching systems with the uncoded cache placement originally proposed by Maddah-Ali and Niesen. It proposes two novel delivery schemes that take advantage of the multicasting opportunities that arise when a file is demanded by multiple users. These delivery schemes are extensions of known ones to the regime where the file size is finite. Numerical evaluations for the case of file uniform popularity show that the proposed schemes outperform previous ones for all value of the cache size.

It has been shown that for a general-valued constraint language Gamma the following statements are equivalent  any instance of operatornameVCSPGamma can be solved to optimality using a constant level of the Sherali-Adams LP hierarchy  any instance of operatornameVCSPGamma can be solved to optimality using the third level of the Sherali-Adams LP hierarchy  the support of Gamma satisfies the bounded width condition, i.e., it contains weak near-unanimity operations of all arities.   We show that if the support of Gamma violates the bounded with condition then not only is operatornameVCSPGamma not solved by a constant level of the Sherali-Adams LP hierarchy but it is also not solved by Omegan levels of the Lasserre SDP hierarchy also known as the sum-of-squares SDP hierarchy. For Gamma corresponding to linear equations in an Abelian group, this result follows from existing work on inapproximability of Max-CSPs. By a breakthrough result of Lee, Raghavendra, and Steurer STOC, our result implies that for any Gamma whose support violates the bounded width condition no SDP relaxation of polynomial-size solves operatornameVCSPGamma.   We establish our result by proving that various reductions preserve exact solvability by the Lasserre SDP hierarchy up to a constant factor in the level of the hierarchy. Our results hold for general-valued constraint languages, i.e., sets of functions on a fixed finite domain that take on rational or infinite values, and thus also hold in notable special cases of ,infty-valued languages CSPs, ,-valued languages Min-CSPsMax-CSPs, and mathbbQ-valued languages finite-valued CSPs.

Uniquely human abilities may arise from special-purpose brain circuitry, or from concerted general capacity increases due to our outsized brains. We forward a novel hypothesis of the relation between computational capacity and brain size, linking mathematical formalisms of grammars with the allometric increases in cortical-subcortical ratios that arise in large brains. In sum, i thalamocortical loops compute formal grammars ii successive cortical regions describe grammar rewrite rules of increasing size iii cortical-subcortical ratios determine the quantity of stacks in single-stack pushdown grammars iii quantitative increase of stacks yields grammars with qualitatively increased computational power. We arrive at the specific conjecture that human brain capacity is equivalent to that of indexed grammars, far short of full Turing-computable recursively enumerable systems. The work provides a candidate explanatory account of a range of existing human and animal data, addressing longstanding questions of how repeated similar brain algorithms can be successfully applied to apparently dissimilar computational tasks e.g., perceptual versus cognitive, phonological versus syntactic and how quantitative increases to brains can confer qualitative changes to their computational repertoire.

A restricted Boltzmann machine RBM is an undirected graphical model constructed for discrete or continuous random variables, with two layers, one hidden and one visible, and no conditional dependency within a layer. In recent years, RBMs have risen to prominence due to their connection to deep learning. By treating a hidden layer of one RBM as the visible layer in a second RBM, a deep architecture can be created. RBMs are thought to thereby have the ability to encode very complex and rich structures in data, making them attractive for supervised learning. However, the generative behavior of RBMs is largely unexplored. In this paper, we discuss the relationship between RBM parameter specification in the binary case and the tendency to undesirable model properties such as degeneracy, instability and uninterpretability. We also describe the difficulties that arise in likelihood-based and Bayes fitting of such highly flexible models, especially as Gibbs sampling quasi-Bayes methods are often advocated for the RBM model structure.

The rational camera model recently introduced in  provides a general methodology for studying abstract nonlinear imaging systems and their multi-view geometry. This paper builds on this framework to study physical realizations of rational cameras. More precisely, we give an explicit account of the mapping between between physical visual rays and image points missing in the original description, which allows us to give simple analytical expressions for direct and inverse projections. We also consider primitive camera models, that are orbits under the action of various projective transformations, and lead to a general notion of intrinsic parameters. The methodology is general, but it is illustrated concretely by an in-depth study of two-slit cameras, that we model using pairs of linear projections. This simple analytical form allows us to describe models for the corresponding primitive cameras, to introduce intrinsic parameters with a clear geometric meaning, and to define an epipolar tensor characterizing two-view correspondences. In turn, this leads to new algorithms for structure from motion and self-calibration.

Cloud services have been used very widely, but configuration of the parameters, including the efficient allocation of resources, is an important objective for the system architect. The article is devoted to solving the problem of choosing the architecture of computers based on simulation and developed program for monitoring computing resources. Techniques were developed aimed at providing the required quality of service and efficient use of resources. The article describes the monitoring program of computing resources and time efficiency of the target application functions. On the basis of this application the technique is shown and described in the experiment, designed to ensure the requirements for quality of service, by isolating one process from the others on different virtual machines inside the hypervisor.

We are studying d-dimensional geometric problems that have algorithms with -d appearing in the exponent of the running time, for example, in the form of n-d or nk-d. This means that these algorithms perform somewhat better in low dimensions, but the running time is almost the same r all large values d of the dimension. Our main result is showing that for some of these problems the dependence on -d is best possible under a standard complexity assumption. We show that, assuming the Exponential Time Hypothesis,   --- d-dimensional Euclidean TSP on n points cannot be solved in time On-d-epsilon for any epsilon, and   --- the problem of finding a set of k pairwise nonintersecting d-dimensional unit ballsaxis parallel unit cubes cannot be solved in time fknok-d for any computable function f.   These lower bounds essentially match the known algorithms for these problems. To obtain these results, we first prove lower bounds on the complexity of Constraint Satisfaction Problems CSPs whose constraint graphs are d-dimensional grids. We state the complexity results on CSPs in a way to make them convenient starting points for problem-specific reductions to particular d-dimensional geometric problems and to be reusable in the future for further results of similar flavor.

Recognizing when people have false beliefs is crucial for understanding their actions. We introduce the novel problem of identifying when people in abstract scenes have incorrect beliefs. We present a dataset of scenes, each visually depicting an -frame story in which a character has a mistaken belief. We then create a representation of characters beliefs for two tasks in human action understanding predicting who is mistaken, and when they are mistaken. Experiments suggest that our method for identifying mistaken characters performs better on these tasks than simple baselines. Diagnostics on our model suggest it learns important cues for recognizing mistaken beliefs, such as gaze. We believe models of peoples beliefs will have many applications in action understanding, robotics, and healthcare.

This report presents an adaptive work-efficient approach for implementing the Connected Components algorithm on GPUs. The results show a considerable increase in performance up to .times over current state-of-the-art solutions.

Deep learning has gained great popularity due to its widespread success on many inference problems. We consider the application of deep learning to the sparse linear inverse problem encountered in compressive sensing, where one seeks to recover a sparse signal from a few noisy linear measurements. In this paper, we propose two novel neural-network architectures that decouple prediction errors across layers in the same way that the approximate message passing AMP algorithms decouple them across iterations through Onsager correction. We show numerically that our learned AMP network significantly improves upon Gregor and LeCuns learned ISTA when both use soft-thresholding shrinkage. We then show that additional improvements result from jointly learning the shrinkage functions together with the linear transforms. Finally, we propose a network design inspired by an unfolding of the recently proposed vector AMP VAMP algorithm, and show that it outperforms all previously considered networks. Interestingly, the linear transforms and shrinkage functions prescribed by VAMP coincide with the values learned through backpropagation, yielding an intuitive explanation for the design of this deep network.

The generalized linear model GLM, where a random vector boldsymbolx is observed through a noisy, possibly nonlinear, function of a linear transform output boldsymbolzboldsymbolAx, arises in a range of applications such as robust regression, binary classification, quantized compressed sensing, phase retrieval, photon-limited imaging, and inference from neural spike trains. When boldsymbolA is large and i.i.d. Gaussian, the generalized approximate message passing GAMP algorithm is an efficient means of MAP or marginal inference, and its performance can be rigorously characterized by a scalar state evolution. For general boldsymbolA, though, GAMP can misbehave. Damping and sequential-updating help to robustify GAMP, but their effects are limited. Recently, a vector AMP VAMP algorithm was proposed for additive white Gaussian noise channels. VAMP extends AMPs guarantees from i.i.d. Gaussian boldsymbolA to the larger class of rotationally invariant boldsymbolA. In this paper, we show how VAMP can be extended to the GLM. Numerical experiments show that the proposed GLM-VAMP is much more robust to ill-conditioning in boldsymbolA than damped GAMP.

Ring signatures are cryptographic protocols designed to allow any member of a group to produce a signature on behalf of the group, without revealing the individual signers identity. This offers group members a level of anonymity not attainable through generic digital signature schemes. We call this property plausible deniability, or anonymity with respect to an anonymity set. We concentrate in particular on implementing privacy on the blockchain, introducing a unique ring signature scheme that works with existing blockchain systems. We implement a unique ring signature URS scheme using secpk, creating the first implementation compatible with blockchain libraries in this way, so as for easy implementation as an Ethereum smart contract. We review the privacy and security properties offered by the scheme we have constructed, and compare its efficiency with other commonly suggested approaches to privacy on the blockchain.

In this paper, we investigate for the first time the benefits of wireless caching for the physical layer security PLS of wireless networks. In particular, a caching scheme enabling power-efficient PLS is proposed for cellular video streaming with constrained backhaul capacity. By sharing video data across a subset of base stations BSs through both caching and backhaul loading, secure cooperative transmission of several BSs is dynamically enabled in accordance with the cache status, the channel conditions, and the backhaul capacity. Thereby, caching reduces the data sharing overhead over the capacity-constrained backhaul links. More importantly, caching introduces additional secure degrees of freedom and enables a power-efficient design. We investigate the optimal caching and transmission policies for minimizing the total transmit power while providing quality of service QoS and guaranteeing secrecy during video delivery. A two-stage non-convex mixed-integer optimization problem is formulated, which optimizes the caching policy in an offline video caching stage and the cooperative transmission policy in an online video delivery stage. As the problem is NP-hard, suboptimal polynomial-time algorithms are proposed for low-complexity cache training and delivery control, respectively. Sufficient optimality conditions, under which the proposed schemes attain global optimal solutions, are also provided. Simulation results show that the proposed schemes achieve low secrecy outage probability and high power efficiency simultaneously.

We present a set-oriented graph-based framework for continuous-time optimal transport over nonlinear dynamical systems. Our approach allows us to recover provably optimal control laws for steering a given initial distribution in phase space to a final distribution in prescribed finite time for the case of nonlinear control-affine systems. The action of the controlled vector fields is approximated by a continuous-time flow on a graph obtained by discretizing the phase space. The edge weights of this graph are obtained by computing infinitesimal generators of the Perron-Frobenius operator of the control vector fields. The problem is reduced to a modified Monge-Kantorovich optimal transport on this graph, motivated by the Brenier-Benamou fluid dynamics formulation. The well-posedness of the optimal transport problem on graph is related to controllability of the underlying dynamical system. The resulting convex problem is solved via state-of-the-art solvers to global optimality. Using our computational framework, we study optimal transport in dynamical systems arising in chaotic fluid dynamics and non-holonomic vehicle dynamics. The solutions to the optimal transport problem elucidate the role played by invariant manifolds, lobe-dynamics and almost-invariant sets in efficient transport of distributions. Our work connects set-oriented operator-theoretic methods in dynamical systems with optimal mass transportation theory, and also opens up new directions in design of efficient feedback control strategies for nonlinear multi-agent and swarm systems operating in nonlinear ambient flow fields.

This paper proposes a person-centric and online approach to the challenging problem of localization and prediction of actions and interactions in videos. Typically, localization or recognition is performed in an offline manner where all the frames in the video are processed together. This prevents timely localization and prediction of actions and interactions - an important consideration for many tasks including surveillance and human-machine interaction.   In our approach, we estimate human poses at each frame and train discriminative appearance models using the superpixels inside the pose bounding boxes. Since the pose estimation per frame is inherently noisy, the conditional probability of pose hypotheses at current time-step frame is computed using pose estimations in the current frame and their consistency with poses in the previous frames. Next, both the superpixel and pose-based foreground likelihoods are used to infer the location of actors at each time through a Conditional Random. The issue of visual drift is handled by updating the appearance models, and refining poses using motion smoothness on joint locations, in an online manner. For online prediction of action interaction confidences, we propose an approach based on Structural SVM that operates on short video segments, and is trained with the objective that confidence of an action or interaction increases as time progresses. Lastly, we quantify the performance of both detection and prediction together, and analyze how the prediction accuracy varies as a time function of observed action interaction at different levels of detection performance. Our experiments on several datasets suggest that despite using only a few frames to localize actions interactions at each time instant, we are able to obtain competitive results to state-of-the-art offline methods.

Extending the success of deep neural networks to natural language understanding and symbolic reasoning requires complex operations and external memory. Recent neural program induction approaches have attempted to address this problem, but are typically limited to differentiable memory, and consequently cannot scale beyond small synthetic tasks. In this work, we propose the Manager-Programmer-Computer framework, which integrates neural networks with non-differentiable memory to support abstract, scalable and precise operations through a friendly neural computer interface. Specifically, we introduce a Neural Symbolic Machine, which contains a sequence-to-sequence neural programmer, and a non-differentiable computer that is a Lisp interpreter with code assist. To successfully apply REINFORCE for training, we augment it with approximate gold programs found by an iterative maximum likelihood training process. NSM is able to learn a semantic parser from weak supervision over a large knowledge base. It achieves new state-of-the-art performance on WebQuestionsSP, a challenging semantic parsing dataset, with weak supervision. Compared to previous approaches, NSM is end-to-end, therefore does not rely on feature engineering or domain specific knowledge.

The discovery of inductive invariants lies at the heart of static program verification. This paper describes our efforts to apply candidate-based invariant generation in GPUVerify, a static checker of programs that run on GPUs. We study a set of  GPU programs that contain loops, drawn from a number of open source suites and vendor SDKs. Among this set,  benchmarks require provision of loop invariants for verification to succeed.   We describe the methodology we used to incrementally improve the invariant generation capabilities of GPUVerify to handle these benchmarks, through candidate-based invariant generation. We also describe a set of experiments that we used to examine the effectiveness of our rules for candidate generation, assessing rules based on their generality the extent to which they generate candidate invariants, hit rate the extent to which the generated candidates hold, effectiveness the extent to which provable candidates actually help in allowing verification to succeed, and influence the extent to which the success of one generation rule depends on candidates generated by another rule. We believe that our methodology for devising and evaluation candidate generation rules may serve as a useful framework for other researchers interested in candidate-based invariant generation.   The candidates produced by GPUVerify help to verify  of these  programs. An increase in precision, however, has created sluggishness in GPUVerify because more time is spent on computing inductive invariants. To speed up this process, we have investigated four under-approximating program analyses that aim to reject false candidates quickly and a framework whereby these analyses can run in sequence or in parallel. We examine the speedups associated with our under-approximating analyses across two platforms, running Windows and Linux.

In this work we investigate intra-day patterns of activity on a population of , users of mobile health wearable devices and apps. We show that  using intra-day step and sleep data recorded from passive trackers significantly improves classification performance on self-reported chronic conditions related to mental health and nervous system disorders,  Convolutional Neural Networks achieve top classification performance vs. baseline models when trained directly on multivariate time series of activity data, and  jointly predicting all condition classes via multi-task learning can be leveraged to extract features that generalize across data sets and achieve the highest classification performance.

In this paper we propose to learn a mapping from image pixels into a dense template grid through a fully convolutional network. We formulate this task as a regression problem and train our network by leveraging upon manually annotated facial landmarks in-the-wild. We use such landmarks to establish a dense correspondence field between a three-dimensional object template and the input image, which then serves as the ground-truth for training our regression system. We show that we can combine ideas from semantic segmentation with regression networks, yielding a highly-accurate quantized regression architecture.   Our system, called DenseReg, allows us to estimate dense image-to-template correspondences in a fully convolutional manner. As such our network can provide useful correspondence information as a stand-alone system, while when used as an initialization for Statistical Deformable Models we obtain landmark localization results that largely outperform the current state-of-the-art on the challenging W benchmark. We thoroughly evaluate our method on a host of facial analysis tasks, and also demonstrate its use for other correspondence estimation tasks, such as modelling of the human ear. DenseReg code is made available at httpalpguler.comDenseReg.html along with supplementary materials.

We consider the problem of off-policy evaluation---estimating the value of a target policy using data collected by another policy---under the contextual bandit model. We establish a minimax lower bound on the mean squared error MSE, and show that it is matched up to constant factors by the inverse propensity scoring IPS estimator. Since in the multi-armed bandit problem the IPS is suboptimal Li et. al, , our result highlights the difficulty of the contextual setting with non-degenerate context distributions. We further consider improvements on this minimax MSE bound, given access to a reward model. We show that the existing doubly robust approach, which utilizes such a reward model, may continue to suffer from high variance even when the reward model is perfect. We propose a new estimator called SWITCH which more effectively uses the reward model and achieves a superior bias-variance tradeoff compared with prior work. We prove an upper bound on its MSE and demonstrate its benefits empirically on a diverse collection of datasets, often seeing orders of magnitude improvements over a number of baselines.

The many-body localized MBL phase is characterized by a complete set of quasi-local integrals of motion and area-law entanglement of excited eigenstates. We study the effect of non-Abelian continuous symmetries on MBL, considering the case of SU symmetric disordered spin chains. The SU symmetry imposes strong constraints on the entanglement structure of the eigenstates, precluding conventional MBL. We construct a fixed-point Hamiltonian, which realizes a non-ergodic but non-MBL phase characterized by eigenstates having logarithmic scaling of entanglement with the system size, as well as an incomplete set of quasi-local integrals of motion. We study the response of such a phase to local symmetric perturbations, finding that even weak perturbations induce multi-spin resonances. We conclude that the non-ergodic phase is generally unstable and that SU symmetry implies thermalization. The approach introduced in this work can be used to study dynamics in disordered systems with non-Abelian symmetries, and provides a starting point for searching non-ergodic phases beyond conventional MBL.

In this paper, we provide detailed analysis of the achievable throughput of infrastructure-based vehicular network with a finite traffic density under a cooperative communication strategy, which explores combined use of vehicle-to-infrastructure VI communications, vehicle-to-vehicle VV communications, mobility of vehicles and cooperations among vehicles and infrastructure to facilitate the data transmission. A closed form expression of the achievable throughput is obtained, which reveals the relationship between the achievable throughput and its major performance-impacting parameters such as distance between adjacent infrastructure points, radio ranges of infrastructure and vehicles, transmission rates of VI and VV communications and vehicular density. Numerical and simulation results show that the proposed cooperative communication strategy significantly increases the throughput of vehicular networks, compared with its non-cooperative counterpart, even when the traffic density is low. Our results shed insight on the optimum deployment of vehicular network infrastructure and optimum design of cooperative communication strategies in vehicular networks to maximize the throughput.

Model Predictive Control MPC of an unknown system that is modelled by Gaussian Process GP techniques is studied in this paper. Using GP, the variances computed during the modelling and inference processes allow us to take model uncertainty into account. The main issue in using MPC to control systems modelled by GP is the propagation of such uncertainties within the control horizon. In this paper, two approaches to solve this problem, called GPMPC and GPMPC, are proposed. With GPMPC, the original Stochastic Model Predictive Control SMPC problem is relaxed to a deterministic nonlinear MPC based on a basic linearized GP local model. The resulting optimization problem, though non-convex, can be solved by the Sequential Quadratic Programming SQP. By incorporating the model variance into the state vector, an extended local model is derived. This model allows us to relax the non-convex MPC problem to a convex one which can be solved by an active-set method efficiently. The performance of both approaches is demonstrated by applying them to two trajectory tracking problems. Results show that both GPMPC and GPMPC produce effective controls but GPMPC is much more efficient computationally.

Learning the representation and the similarity metric in an end-to-end fashion with deep networks have demonstrated outstanding results for clustering and retrieval. However, these recent approaches still suffer from the performance degradation stemming from the local metric training procedure which is unaware of the global structure of the embedding space.   We propose a global metric learning scheme for optimizing the deep metric embedding with the learnable clustering function and the clustering metric NMI in a novel structured prediction framework.   Our experiments on CUB-, Cars, and Stanford online products datasets show state of the art performance both on the clustering and retrieval tasks measured in the NMI and RecallK evaluation metrics.

We propose a learning-from-demonstration approach for grounding actions from expert data and an algorithm for using these actions to perform a task in new environments. Our approach is based on an application of sampling-based motion planning to search through the tree of discrete, high-level actions constructed from a symbolic representation of a task. Recursive sampling-based planning is used to explore the space of possible continuous-space instantiations of these actions. We demonstrate the utility of our approach with a magnetic structure assembly task, showing that the robot can intelligently select a sequence of actions in different parts of the workspace and in the presence of obstacles. This approach can better adapt to new environments by selecting the correct high-level actions for the particular environment while taking human preferences into account.

Decentralized optimization algorithms have received much attention due to the recent advances in network information processing. However, conventional decentralized algorithms based on projected gradient descent are incapable of handling high dimensional constrained problems, as the projection step becomes computationally prohibitive to compute. To address this problem, this paper adopts a projection-free optimization approach, a.k.a.the Frank-Wolfe FW or conditional gradient algorithm. We first develop a decentralized FW DeFW algorithm from the classical FW algorithm. The convergence of the proposed algorithm is studied by viewing the decentralized algorithm as an inexact FW algorithm. Using a diminishing step size rule and letting t be the iteration number, we show that the DeFW algorithms convergence rate is cal Ot for convex objectives is cal Ot for strongly convex objectives with the optimal solution in the interior of the constraint set and is cal Osqrtt towards a stationary point for smooth but non-convex objectives. We then show that a consensus-based DeFW algorithm meets the above guarantees with two communication rounds per iteration. Furthermore, we demonstrate the advantages of the proposed DeFW algorithm on low-complexity robust matrix completion and communication efficient sparse learning. Numerical results on synthetic and real data are presented to support our findings.

Inference of correspondences between images from different modalities is an extremely important perceptual ability that enables humans to understand and recognize cross-modal concepts. In this paper, we consider an instance of this problem that involves matching photographs of building interiors with their corresponding floorplan. This is a particularly challenging problem because a floorplan, as a stylized architectural drawing, is very different in appearance from a color photograph. Furthermore, individual photographs by themselves depict only a part of a floorplan e.g., kitchen, bathroom, and living room. We propose the use of a number of different neural network architectures for this task, which are trained and evaluated on a novel large-scale dataset of  million floorplan images and  million associated photographs. Experimental evaluation reveals that our neural network architectures are able to identify visual cues that result in reliable matches across these two quite different modalities. In fact, the trained networks are able to even outperform human subjects in several challenging image matching problems. Our result implies that neural networks are effective at perceptual tasks that require long periods of reasoning even for humans to solve.

The human visual system excels at detecting local blur of visual images, but the underlying mechanism is mysterious. Traditional views of blur such as reduction in local or global high-frequency energy and loss of local phase coherence have fundamental limitations. For example, they cannot well discriminate flat regions from blurred ones. Here we argue that high-level semantic information is critical in successfully detecting local blur. Therefore, we resort to deep neural networks that are proficient in learning high-level features and propose the first end-to-end local blur mapping algorithm based on a fully convolutional network FCN. We empirically show that high-level features of deeper layers indeed play a more important role than low-level features of shallower layers in resolving challenging ambiguities for this task. We test the proposed method on a standard blur detection benchmark and demonstrate that it significantly advances the state-of-the-art ODS F-score of .. In addition, we explore the use of the generated blur map in three applications, including blur region segmentation, blur degree estimation, and blur magnification.

Essential Tremor is the most common neurological movement disorder. This progressive disease causes uncontrollable rhythmic motions -most often affecting the patients dominant upper extremity- that occur during volitional movement and make it difficult for the patient to perform everyday tasks. Medication may also become ineffective as the disorder progresses. Deep brain stimulation DBS of the thalamus is an effective means of treating this condition when medication fails. In current use, however, clinicians set the patients stimulator to apply stimulation at all times -whether it is needed or not. This practice leads to excess power use, and more rapid depletion of batteries that require surgical replacement. In the work described here, for the first time, neural sensing of movement using chronically-implanted cortical electrodes is used to enable or disable stimulation for tremor. Therapeutic stimulation is delivered only when the patient is actively using their effected limb, thereby reducing the total stimulation applied, and potentially extending the lifetime of surgically-implanted batteries. This work, which involves both implanted and external subsystems, paves the way for the future fully-implanted closed-loop deep brain stimulators.

On general object recognition, Deep Convolutional Neural Networks DCNNs achieve high accuracy. In particular, ResNet and its improvements have broken the lowest error rate records. In this paper, we propose a method to successfully combine two ResNet improvements, ResDrop and PyramidNet. We confirmed that the proposed network outperformed the conventional methods on CIFAR-, the proposed network achieved an error rate of . in contrast to PiramidNet achieving that of . and ResNeXt ..

This paper proposes a novel MAP inference framework for Markov Random Field MRF in parallel computing environments. The inference framework, dubbed Swarm Fusion, is a natural generalization of the Fusion Move method. Every thread in a case of multi-threading environments maintains and updates a solution. At each iteration, a thread can generate arbitrary number of solution proposals and take arbitrary number of concurrent solutions from the other threads to perform multi-way fusion in updating its solution. The framework is general, making popular existing inference techniques such as alpha-expansion, fusion move, parallel alpha-expansion, and hierarchical fusion, its special cases. We have evaluated the effectiveness of our approach against competing methods on three problems of varying difficulties, in particular, the stereo, the optical flow, and the layered depthmap estimation problems.

This paper proposes an algorithm that turns a regular video capturing urban scenes into a high-quality endless animation, known as a Cinemagraph. The creation of a Cinemagraph usually requires a static camera in a carefully configured scene. The task becomes challenging for a regular video with a moving camera and objects. Our approach first warps an input video into the viewpoint of a reference camera. Based on the warped video, we propose effective temporal analysis algorithms to detect regions with static geometry and dynamic appearance, where geometric modeling is reliable and visually attractive animations can be created. Lastly, the algorithm applies a sequence of video processing techniques to produce a Cinemagraph movie. We have tested the proposed approach on numerous challenging real scenes. To our knowledge, this work is the first to automatically generate Cinemagraph animations from regular movies in the wild.

Early detection and prognosis of breast cancer are feasible by utilizing histopathological grading of biopsy specimens. This research is focused on detection and grading of nuclear pleomorphism in histopathological images of breast cancer. The proposed method consists of three internal steps. First, unmixing colors of HE is used in the preprocessing step. Second, nuclei boundaries are extracted incorporating the center of cancerous nuclei which are detected by applying morphological operations and Difference of Gaussian filter on the preprocessed image. Finally, segmented nuclei are scored to accomplish one parameter of the Nottingham grading system for breast cancer. In this approach, the nuclei area, chromatin density, contour regularity, and nucleoli presence, are features for nuclear pleomorphism scoring. Experimental results showed that the proposed algorithm, with an accuracy of ., made significant advancement in detecting cancerous nuclei compared to existing methods in the related literature.

Most navigation systems use data from satellites to provide drivers with the shortest-distance, shortest-time or highway-preferred paths. However, when the routing decisions are made for advanced vehicles, there are other factors affecting cost, such as vehicle powertrain type, battery state of charge SOC and the change of component efficiencies under traffic conditions, which are not considered by traditional routing systems. The impact of the trade-off between distance and traffic on the cost of the trip might change with the type of vehicle technology and component dynamics. As a result, the least-cost paths might be different from the shortest-distance or shortest-time paths. In this work, a novel routing strategy has been proposed where the decision-making process benefits from the aforementioned information to result in a least-cost path for drivers. We integrate vehicle powertrain dynamics into route optimization and call this strategy as Vehicle Powertrain Connected Route Optimization VPCRO. We find that the optimal paths might change significantly for all types of vehicle powertrains when VPCRO is used instead of shortest-distance strategy. About  and  of trips were replaced by different optimal paths with VPCRO when the vehicle type was Conventional Vehicle CV and Electrified Vehicle EV, respectively. Changed routes had reduced travel costs on an average of  up to a maximum of  for CVs and on an average of  up to a maximum of  for EVs. Moreover, it was observed that  and  of trips had different optimal paths for a plug-in hybrid electric vehicle, when initial battery SOC changed from  to  and , respectively. Paper shows that using sensory information from vehicle powertrain for route optimization plays an important role to minimize travel costs.

We evaluate the uncertainty quality in neural networks using anomaly detection. We extract uncertainty measures e.g. entropy from the predictions of candidate models, use those measures as features for an anomaly detector, and gauge how well the detector differentiates known from unknown classes. We assign higher uncertainty quality to candidate models that lead to better detectors. We also propose a novel method for sampling a variational approximation of a Bayesian neural network, called One-Sample Bayesian Approximation OSBA. We experiment on two datasets, MNIST and CIFAR. We compare the following candidate neural network models Maximum Likelihood, Bayesian Dropout, OSBA, and --- for MNIST --- the standard variational approximation. We show that Bayesian Dropout and OSBA provide better uncertainty information than Maximum Likelihood, and are essentially equivalent to the standard variational approximation, but much faster.

Automatically discovering image categories in unlabeled natural images is one of the important goals of unsupervised learning. However, the task is challenging and even human beings define visual categories based on a large amount of prior knowledge. In this paper, we similarly utilize prior knowledge to facilitate the discovery of image categories. We present a novel end-to-end network to map unlabeled images to categories as a clustering network. We propose that this network can be learned with contrastive loss which is only based on weak binary pair-wise constraints. Such binary constraints can be learned from datasets in other domains as transferred similarity functions, which mimic a simple knowledge transfer. We first evaluate our experiments on the MNIST dataset as a proof of concept, based on predicted similarities trained on Omniglot, showing a  accuracy which significantly outperforms clustering based approaches. Then we evaluate the discovery performance on Cifar-, STL-, and ImageNet, which achieves both state-of-the-art accuracy and shows it can be scalable to various large natural images.

In this paper, we consider the problem of event classification with multi-variate time series data consisting of heterogeneous continuous and categorical variables. The complex temporal dependencies between the variables combined with sparsity of the data makes the event classification problem particularly challenging. Most state-of-art approaches address this either by designing hand-engineered features or breaking up the problem over homogeneous variates. In this work, we propose and compare three representation learning algorithms over symbolized sequences which enables classification of heterogeneous time-series data using a deep architecture. The proposed representations are trained jointly along with the rest of the network architecture in an end-to-end fashion that makes the learned features discriminative for the given task. Experiments on three real-world datasets demonstrate the effectiveness of the proposed approaches.

This paper addresses the problem of Structure from Motion SfM for indoor panoramic image streams, extremely challenging even for the state-of-the-art due to the lack of textures and minimal parallax. The key idea is the fusion of single-view and multi-view reconstruction techniques via geometric relationship detection e.g., detecting D lines as coplanar in D. Rough geometry suffices to perform such detection, and our approach utilizes rough surface normal estimates from an image-to-normal deep network to discover geometric relationships among lines. The detected relationships provide exact geometric constraints in our line-based linear SfM formulation. A constrained linear least squares is used to reconstruct a D model and camera motions, followed by the bundle adjustment. We have validated our algorithm on challenging datasets, outperforming various state-of-the-art reconstruction techniques.

Advancement in intelligent transportation systems with complex operations requires autonomous planning and management to avoid collisions in day-to-day traffic. As failure andor inadequacy in traffic safety system are life-critical, such collisions must be detected and resolved in an efficient way to manage continuously rising traffic. In this paper, we address different types of collision scenarios along with their early detection and resolution techniques in a complex railway system. In order to handle collisions dynamically in distributed manner, a novel agent based solution approach is proposed using the idea of max-sum algorithm, where each agent train agent, station agent, and junction agent communicates and cooperates with others to generate a good feasible solution that keeps the system in a safe state, i.e., collision free. We implement the proposed mechanism in Java Agent DEvelopment Framework JADE. The results are evaluated with exhaustive experiments and compared with different existing collision handling methods to show the efficiency of our proposed approach.

In this paper, we prove the precise computational complexity of deciding satisfiability of first-order quantified formulas over the theory of fixed-size bit-vectors. This problem is known to be solvable in exponential space and to be NEXPTIME-hard. We show that this problem is complete for the complexity class AEXPpoly -- the class of problems decidable by an alternating Turing machine using exponential space and polynomial number of alternations between existential and universal states.

In this paper we paint a broad picture of the Internet content delivery market, by taking into consideration both economical and technical challenges that might drive the interactions among the stakeholders in the future. We focus on a few disrupting factors, namely ubiquitous encryption, traffic boost, network scalability, latency needs and network control and try to figure out whether the current model CDN is robust against their variation, which optimization can be envisioned and how the most accredited option ICN can be of help.

Meeting the diverse delay requirements of next-generation wireless communication networks is one of the most critical goals of wireless system design. Though the delay of point-to-point communications has been well investigated using classical queueing theory, the delay of multi-point to multi-point communications has not been explored in depth. The main technical difficulty lies in the interacting queues problem, in which the service rate is coupled with the statuses of other queues. In this article, we elaborate on the main challenges of delay analysis in large wireless networks. Several promising approaches to bypass these difficulties are proposed and summarized to provide useful guidance.

Portfolio management is the decision-making process of allocating an amount of fund into different financial investment products. Cryptocurrencies are electronic and decentralized alternatives to government-issued money, with Bitcoin as the best-known example of a cryptocurrency. This paper presents a model-less convolutional neural network with historic prices of a set of financial assets as its input, outputting portfolio weights of the set. The network is trained with . years price data from a cryptocurrency exchange. The training is done in a reinforcement manner, maximizing the accumulative return, which is regarded as the reward function of the network. Backtest trading experiments with trading period of  minutes is conducted in the same market, achieving -fold returns in . months periods. Some recently published portfolio selection strategies are also used to perform the same back-tests, whose results are compared with the neural network. The network is not limited to cryptocurrency, but can be applied to any other financial markets.

We study the problem of receive beamforming in uplink cascade multiple-input multiple-output MIMO systems as an instance of that of cascade multiterminal source coding for lossy function computation. Using this connection, we develop two coding schemes for the second and show that their application leads to beamforming schemes for the first. In the first coding scheme, each terminal in the cascade sends a description of the source that it observes the decoder reconstructs all sources, lossily, and then computes an estimate of the desired function. This scheme improves upon standard routing in that every terminal only compresses the innovation of its source w.r.t. the descriptions that are sent by the previous terminals in the cascade. In the second scheme, the desired function is computed gradually in the cascade network, and each terminal sends a finer description of it. In the context of uplink cascade MIMO systems, the application of these two schemes leads to centralized receive-beamforming and distributed receive-beamforming, respectively. Numerical results illustrate the performance of the proposed methods and show that they outperform standard routing.

While the statistical and resilience properties of the Internet are no more changing significantly across time, the Darknet, a network devoted to keep anonymous its traffic, still experiences rapid changes to improve the security of its users. Here, we study the structure of the Darknet and we find that its topology is rather peculiar, being characterized by non-homogenous distribution of connections -- typical of scale-free networks --, very short path lengths and high clustering -- typical of small-world networks -- and lack of a core of highly connected nodes.   We propose a model to reproduce such features, demonstrating that the mechanisms used to improve cyber-security are responsible for the observed topology. Unexpectedly, we reveal that its peculiar structure makes the Darknet much more resilient than the Internet -- used as a benchmark for comparison at a descriptive level -- to random failures, targeted attacks and cascade failures, as a result of adaptive changes in response to the attempts of dismantling the network across time.

Point pair features are a popular representation for free form D object detection and pose estimation. In this paper, their performance in an industrial random bin picking context is investigated. A new method to generate representative synthetic datasets is proposed. This allows to investigate the influence of a high degree of clutter and the presence of self similar features, which are typical to our application. We provide an overview of solutions proposed in literature and discuss their strengths and weaknesses. A simple heuristic method to drastically reduce the computational complexity is introduced, which results in improved robustness, speed and accuracy compared to the naive approach.

Communicating and sharing intelligence among agents is an important facet of achieving Artificial General Intelligence. As a first step towards this challenge, we introduce a novel framework for image generation Message Passing Multi-Agent Generative Adversarial Networks MPM GANs. While GANs have recently been shown to be very effective for image generation and other tasks, these networks have been limited to mostly single generator-discriminator networks. We show that we can obtain multi-agent GANs that communicate through message passing to achieve better image generation. The objectives of the individual agents in this framework are two fold a co-operation objective and a competing objective. The co-operation objective ensures that the message sharing mechanism guides the other generator to generate better than itself while the competing objective encourages each generator to generate better than its counterpart. We analyze and visualize the messages that these GANs share among themselves in various scenarios. We quantitatively show that the message sharing formulation serves as a regularizer for the adversarial training. Qualitatively, we show that the different generators capture different traits of the underlying data distribution.

In this paper, new upper and lower bounds are proposed for the capacity of discrete-time Laguerre channel. Laguerre behavior is used to model various types of optical systems and networks such as optical amplifiers, short distance visible light communication systems with direct detection and coherent code division multiple access CDMA networks. Bounds are derived for short distance visible light communication systems and coherent CDMA networks. These bounds are separated in three main cases when both average and peak power constraints are imposed, when peak power constraint is inactive and when only peak power constraint is active.

We study information theoretic methods for ranking biomarkers. In clinical trials there are two, closely related, types of biomarkers predictive and prognostic, and disentangling them is a key challenge. Our first step is to phrase biomarker ranking in terms of optimizing an information theoretic quantity. This formalization of the problem will enable us to derive rankings of predictiveprognostic biomarkers, by estimating different, high dimensional, conditional mutual information terms. To estimate these terms, we suggest efficient low dimensional approximations, and we derive an empirical Bayes estimator, which is suitable for small or sparse datasets. Finally, we introduce a new visualisation tool that captures the prognostic and the predictive strength of a set of biomarkers. We believe this representation will prove to be a powerful tool in biomarker discovery.

Conventional approaches to image de-fencing have limited themselves to using only image data in adjacent frames of the captured video of an approximately static scene. In this work, we present a method to harness disparity using a stereo pair of fenced images in order to detect fence pixels. Tourists and amateur photographers commonly carry smartphonesphablets which can be used to capture a short video sequence of the fenced scene. We model the formation of the occluded frames in the captured video. Furthermore, we propose an optimization framework to estimate the de-fenced image using the total variation prior to regularize the ill-posed problem.

When creating a new domain-specific language DSL it is common to embed it as a part of a flexible host language, rather than creating it entirely from scratch. The semantics of an embedded DSL EDSL is either given directly as a set of functions shallow embedding, or an AST is constructed that is later processed deep embedding. Typically, the deep embedding is used when the EDSL specifies domain-specific optimizations DSO in a form of AST transformations.   In this paper we show that deep embedding is not necessary to specify most optimizations. We define language semantics as action functions that are executed during parsing. These actions build incrementally a new, arbitrary complex program function.   The EDSL designer is able to specify many aspects of the semantics as a runnable code, such as variable scoping rules, custom type checking, arbitrary control flow structures, or DSO. A sufficiently powerful staging mechanism helps assembling the code from different actions, as well as evaluate the semantics in arbitrarily many stages. In the end, we obtain code that is as efficient as one written by hand.   We never create any object representation of the code. No external traversing algorithm is used to process the code. All program fragments are functions with their entire semantics embedded within the function bodies. This approach allows reusing the code between EDSL and the host language, as well as combining actions of many different EDSLs.

This paper applies the randomized incremental construction RIC framework to computing the Hausdorff Voronoi diagram of a family of k clusters of points in the plane. The total number of points is n. The diagram is a generalization of Voronoi diagrams based on the Hausdorff distance function. The combinatorial complexity of the Hausdorff Voronoi diagram is Onm, where m is the total number of crossings between pairs of clusters. For non-crossing clusters m, our algorithm works in expected On log n  k log n log k time and deterministic   On space. For arbitrary clusters mOn, the algorithm runs in expected Omn log k log n time and Om n log k space. When clusters cross, bisectors are disconnected curves resulting in disconnected Voronoi regions that challenge the incremental construction. This paper applies the RIC paradigm to a Voronoi diagram with disconnected regions and disconnected bisectors, for the first time.

We present an end-to-end trainable deep convolutional neural network DCNN for semantic segmentation with built-in awareness of semantically meaningful boundaries. Semantic segmentation is a fundamental remote sensing task, and most state-of-the-art methods rely on DCNNs as their workhorse. A major reason for their success is that deep networks learn to accumulate contextual information over very large windows receptive fields. However, this success comes at a cost, since the associated loss of effecive spatial resolution washes out high-frequency details and leads to blurry object boundaries. Here, we propose to counter this effect by combining semantic segmentation with semantically informed edge detection, thus making class-boundaries explicit in the model, First, we construct a comparatively simple, memory-efficient model by adding boundary detection to the Segnet encoder-decoder architecture. Second, we also include boundary detection in FCN-type models and set up a high-end classifier ensemble. We show that boundary detection significantly improves semantic segmentation with CNNs. Our high-end ensemble achieves   overall accuracy on the ISPRS Vaihingen benchmark.

Sketching is an important means of communication in software engineering practice. Yet, there is little research investigating the use of sketches. We want to contribute a better understanding of sketching, in particular its use during program comprehension. We propose a controlled experiment to investigate the effectiveness and efficiency of program comprehension with the support of sketches as well as what sketches are used in what way.

Online content publishers often use catchy headlines for their articles in order to attract users to their websites. These headlines, popularly known as clickbaits, exploit a users curiosity gap and lure them to click on links that often disappoint them. Existing methods for automatically detecting clickbaits rely on heavy feature engineering and domain knowledge. Here, we introduce a neural network architecture based on Recurrent Neural Networks for detecting clickbaits. Our model relies on distributed word representations learned from a large unannotated corpora, and character embeddings learned via Convolutional Neural Networks. Experimental results on a dataset of news headlines show that our model outperforms existing techniques for clickbait detection with an accuracy of . with F-score of . and ROC-AUC of ..

Existing person re-identification models are poor for scaling up to large data required in real-world applications due to  Complexity They employ complex models for optimal performance resulting in high computational cost for training at a large scale  Inadaptability Once trained, they are unsuitable for incremental update to incorporate any new data available. This work proposes a truly scalable solution to re-id by addressing both problems. Specifically, a Highly Efficient Regression HER model is formulated by embedding the Fishers criterion to a ridge regression model for very fast re-id model learning with scalable memorystorage usage. Importantly, this new HER model supports faster than real-time incremental model updates therefore making real-time active learning feasible in re-id with human-in-the-loop. Extensive experiments show that such a simple and fast model not only outperforms notably the state-of-the-art re-id methods, but also is more scalable to large data with additional benefits to active learning for reducing human labelling effort in re-id deployment.

Current person re-identification re-id methods assume that  pre-labelled training data are available for every camera pair,  the gallery size for re-identification is moderate. Both assumptions scale poorly to real-world applications when camera network size increases and gallery size becomes large. Human verification of automatic model ranked re-id results becomes inevitable. In this work, a novel human-in-the-loop re-id model based on Human Verification Incremental Learning HVIL is formulated which does not require any pre-labelled training data to learn a model, therefore readily scalable to new camera pairs. This HVIL model learns cumulatively from human feedback to provide instant improvement to re-id ranking of each probe on-the-fly enabling the model scalable to large gallery sizes. We further formulate a Regularised Metric Ensemble Learning RMEL model to combine a series of incrementally learned HVIL models into a single ensemble model to be used when human feedback becomes unavailable.

Evaluation of hydrocarbon reservoir requires classification of petrophysical properties from available dataset. However, characterization of reservoir attributes is difficult due to the nonlinear and heterogeneous nature of the subsurface physical properties. In this context, present study proposes a generalized one class classification framework based on Support Vector Data Description SVDD to classify a reservoir characteristic water saturation into two classes Class high and Class low from four logs namely gamma ray, neutron porosity, bulk density, and P sonic using an imbalanced dataset. A comparison is carried out among proposed framework and different supervised classification algorithms in terms of g metric means and execution time. Experimental results show that proposed framework has outperformed other classifiers in terms of these performance evaluators. It is envisaged that the classification analysis performed in this study will be useful in further reservoir modeling.

Polar codes are the first class of constructive channel codes achieving the symmetric capacity of the binary-input discrete memoryless channels. But the corresponding code length is limited to the power of two. In this paper, we establish a systematic framework to design the rate-compatible punctured polar RCPP codes with arbitrary code length. A new theoretic tool, called polar spectra, is proposed to count the number of paths on the code tree with the same number of zeros or ones respectively. Furthermore, a spectrum distance SD SD and a joint spectrum distance JSD are presented as performance criteria to optimize the puncturing tables. For the capacity-zero puncturing mode punctured bits are unknown to the decoder, we propose a quasi-uniform puncturing algorithm, analyze the number of equivalent puncturings and prove that this scheme can maximize SD and JSD. Similarly, for the capacity-one mode punctured bits are known to the decoder, we also devise a reversal quasi-uniform puncturing scheme and prove that it has the maximum SD and JSD. Both schemes have a universal puncturing table without any exhausted search. These optimal RCPP codes outperform the performance of turbo codes in LTE wireless communication systems.

In this paper, we explore the possibility to apply machine learning to make diagnostic predictions using discomfort drawings. A discomfort drawing is an intuitive way for patients to express discomfort and pain related symptoms. These drawings have proven to be an effective method to collect patient data and make diagnostic decisions in real-life practice. A dataset from real-world patient cases is collected for which medical experts provide diagnostic labels. Next, we extend a factorized multimodal topic model, Inter-Battery Topic Model IBTM, to train a system that can make diagnostic predictions given an unseen discomfort drawing. Experimental results show reasonable predictions of diagnostic labels given an unseen discomfort drawing. The positive result indicates a significant potential of machine learning to be used for parts of the pain diagnostic process and to be a decision support system for physicians and other health care personnel.

We investigate the contextual multi-armed bandit problem in an adversarial setting and introduce an online algorithm that asymptotically achieves the performance of the best contextual bandit arm selection strategy under certain conditions. We show that our algorithm is highly efficient and provides significantly improved performance with a guaranteed performance upper bound in a strong mathematical sense. We have no statistical assumptions on the context vectors and the loss of the bandit arms, hence our results are guaranteed to hold even in adversarial environments. We use a tree notion in order to partition the space of context vectors in a nested structure. Using this tree, we construct a large class of context dependent bandit arm selection strategies and adaptively combine them to achieve the performance of the best strategy. We use the hierarchical nature of introduced tree to implement this combination with a significantly low computational complexity, thus our algorithm can be efficiently used in applications involving big data. Through extensive set of experiments involving synthetic and real data, we demonstrate significant performance gains achieved by the proposed algorithm with respect to the state-of-the-art adversarial bandit algorithms.

We augment a tree T with a shortcut pq to minimize the largest distance between any two points along the resulting augmented tree Tpq. We study this problem in a continuous and geometric setting where T is a geometric tree in the Euclidean plane, where a shortcut is a line segment connecting any two points along the edges of T, and we consider all points on Tpq i.e., vertices and points along edges when determining the largest distance along Tpq. We refer to the largest distance between any two points along edges as the continuous diameter to distinguish it from the discrete diameter, i.e., the largest distance between any two vertices.   We establish that a single shortcut is sufficient to reduce the continuous diameter of a geometric tree T if and only if the intersection of all diametral paths of T is neither a line segment nor a single point. We determine an optimal shortcut for a geometric tree with n straight-line edges in On log n time. Apart from the running time, our results extend to geometric trees whose edges are rectifiable curves. The algorithm for trees generalizes our algorithm for paths.

Drawing inspiration from the theory of linear decomposable systems, we provide a method, based on linear matrix inequalities LMIs, which makes it possible to prove the convergence or consensus of a set of interacting agents with polynomial dynamic. We also show that the use of a generalised version of the famous Kalman-Yakubovic-Popov lemma allows the development of an LMI test whose size does not depend on the number of agents. The method is validated experimentally on two academic examples.

While machine learning approaches to image restoration offer great promise, current methods risk training one-trick ponies that perform well only for image corruption of a particular level of difficulty--such as a certain level of noise or blur. First, we examine the weakness of a one-trick pony model and demonstrate that training general models to handle arbitrary levels of corruption is indeed non-trivial. Then, we propose an on-demand learning algorithm for training image restoration models with deep convolutional neural networks. The main idea is to exploit a feedback mechanism to self-generate training instances where they are needed most, thereby learning models that can generalize across difficulty levels. On four restoration tasks---image inpainting, pixel interpolation, image deblurring, and image denoising---and three diverse datasets, our approach consistently outperforms both the status quo training procedure and curriculum learning alternatives.

Successful transfer of the results of research projects into practice is of great interest to all project participants. It can be assumed that different transfer mediums fulfill technology transfer TT with different levels of success and that they are impaired by different kinds of barriers. The goal of this study is to gain a better understanding about the different mediums used for TT in software engineering, and to identify barriers weakening the success of the application of such mediums. We conducted an exploratory study implemented by a survey in the context of a German research project with a broad range of used mediums. The main reported barriers were low expectations of usefulness, no awareness of existence, lack of resources, or inadequateness in terms of outdated material or being in an immature state. We interpreted our results as symptoms of a lack of a dissemination plan in the project. Further work will be needed to explore the implications for the transfer of research results knowledge and techniques to practice.

Epidemic models are increasingly used in real-world networks to understand diffusion phenomena such as the spread of diseases, emotions, innovations, failures or the transport of information such as news, memes in social on-line networks. A new analysis of the prevalence, the expected number of infected nodes in a network, is presented and physically interpreted. The analysis method is based on spectral decomposition and leads to a universal, analytic curve, that can bound the time-varying prevalence in any finite time interval. Moreover, that universal curve also applies to various types of Susceptible-Infected-Susceptible SIS and Susceptible-Infected-Removed SIR infection processes, with both homogenous and heterogeneous infection characteristics curing and infection rates, in temporal and even disconnected graphs and in SIS processes with and without self-infections. The accuracy of the universal curve is comparable to that of well-established mean-field approximations.

Efficient robotic exploration of an unknown, sensor limited, global-information-deficient environments poses unique challenges to path planning algorithms. In these difficult environments, no deterministic guarantees on path completion and mission success can be made in general. Integrated Exploration IE, which strives to combine localization and exploration, must be solved in order to create an autonomous robotic system capable of long term operation in new and challenging environments. This paper formulates a probabilistic framework which allows the creation of exploration algorithms providing probabilistic guarantees of success. A novel connection is made between the Hamiltonian Path Problem and exploration. The Guaranteed Probabilistic Information Explorer G-PIE is developed for the IE problem, providing a probabilistic guarantee on path completion, and asymptotic optimality of exploration. A receding horizon formulation, dubbed RH-PIE, is presented which addresses the exponential complexity present in G-PIE. The RH-PIE planner is then verified via autonomous, hardware-in-the-loop experiments.

A High Performance Computing alternative to traditional Krylov methods, pipelined Krylov solvers offer better scalability in the strong scaling limit compared to standard Krylov methods for large and sparse linear systems. The typical synchronization bottleneck is mitigated by overlapping time-consuming global communication phases with local computations in the algorithm. This paper describes a general framework for deriving the pipelined variant of any Krylov algorithm. The proposed framework was implicitly used to derive the pipelined Conjugate Gradient p-CG method in Hiding Global Synchronization Latency in the Preconditioned Conjugate Gradient Algorithm, by P. Ghysels and W. Vanroose, Parallel Computing, -, . The pipelining framework is subsequently illustrated by formulating a pipelined version of the BiCGStab method for the solution of large unsymmetric linear systems on parallel hardware. A residual replacement strategy is proposed to account for the possible loss of attainable accuracy and robustness by the pipelined BiCGStab method. It is shown that the pipelined algorithm improves scalability on distributed memory machines, leading to significant speedups compared to standard preconditioned BiCGStab.

We propose a new modeling approach that is a generalization of generative and discriminative models. The core idea is to use an implicit parameterization of a joint probability distribution by specifying only the conditional distributions. The proposed scheme combines the advantages of both worlds -- it can use powerful complex discriminative models as its parts, having at the same time better generalization capabilities. We thoroughly evaluate the proposed method for a simple classification task with artificial data and illustrate its advantages for real-word scenarios on a semantic image segmentation problem.

The concept of uncertainty is posed in almost any complex system including parallel robots as an outstanding instance of dynamical robotics systems. As suggested by the name, uncertainty, is some missing information that is beyond the knowledge of human thus we may tend to handle it properly to minimize the side-effects through the control process.   Type-II fuzzy logic has shown its superiority over traditional fuzzy logic when dealing with uncertainty. Type-II fuzzy logic controllers are however newer and more promising approaches that have been recently applied to various fields due to their significant contribution especially when noise as an important instance of uncertainty emerges. During the design of Type-I fuzzy logic systems, we presume that we are almost certain about the fuzzy membership functions which is not true in many cases. Thus TFLS as a more realistic approach dealing with practical applications might have a lot to offer. Type-II fuzzy logic takes into account a higher level of uncertainty, in other words, the membership grade for a type-II fuzzy variable is no longer a crisp number but rather is itself a type-I linguistic term. In this thesis the effects of uncertainty in dynamic control of a parallel robot is considered. More specifically, it is intended to incorporate the Type-II Fuzzy Logic paradigm into a model based controller, the so-called computed torque control method, and apply the result to a  degrees of freedom parallel manipulator.   ...

Deep neural networks DNNs have proven to be quite effective in a vast array of machine learning tasks, with recent examples in cyber security and autonomous vehicles. Despite the superior performance of DNNs in these applications, it has been recently shown that these models are susceptible to a particular type of attack that exploits a fundamental flaw in their design. This attack consists of generating particular synthetic examples referred to as adversarial samples. These samples are constructed by slightly manipulating real data-points in order to fool the original DNN model, forcing it to mis-classify previously correctly classified samples with high confidence. Addressing this flaw in the model is essential if DNNs are to be used in critical applications such as those in cyber security. Previous work has provided various defense mechanisms by either augmenting the training set or enhancing model complexity. However, after a thorough analysis, we discover that DNNs protected by these defense mechanisms are still susceptible to adversarial samples, indicating that there are no theoretical guarantees of resistance provided by these mechanisms. To the best of our knowledge, we are the first to investigate this issue shared across previous research work and to propose a unifying framework for protecting DNN models by integrating a data transformation module with the DNN. More importantly, we provide a theoretical guarantee for protection under our proposed framework. We evaluate our method and several other existing solutions on both MNIST, CIFAR-, and a malware dataset, to demonstrate the generality of our proposed method and its potential for handling cyber security applications. The results show that our framework provides better resistance compared to state-of-art solutions while experiencing negligible degradation in accuracy.

We study multi-player turn-based games played on a directed graph, where the number of players and vertices can be infinite. An outcome is assigned to every play of the game. Each player has a preference relation on the set of outcomes which allows him to compare plays. We focus on the recently introduced notion of weak subgame perfect equilibrium weak SPE. This is a variant of the classical notion of SPE, where players who deviate can only use strategies deviating from their initial strategy in a finite number of histories. Having an SPE in a game implies having a weak SPE but the contrary is generally false.   We propose general conditions on the structure of the game graph and on the preference relations of the players that guarantee the existence of a weak SPE, that additionally is finite-memory. From this general result, we derive two large classes of games for which there always exists a weak SPE i the games with a finite-range outcome function, and ii the games with a finite underlying graph and a prefix-independent outcome function. For the second class, we identify conditions on the preference relations that guarantee memoryless strategies for the weak SPE.

In this paper we present strategies for mapping the dialog act annotations of the LEGO corpus into the communicative functions of the ISO - standard. Using these strategies, we obtained an additional  dialogs annotated according to the standard. This is particularly important given the reduced amount of existing data in those conditions due to the recency of the standard. Furthermore, these are dialogs from a widely explored corpus for dialog related tasks. However, its dialog annotations have been neglected due to their high domain-dependency, which renders them unuseful outside the context of the corpus. Thus, through our mapping process, we both obtain more data annotated according to a recent standard and provide useful dialog act annotations for a widely explored corpus in the context of dialog research.

The trajectory tracking problem for multivariable linear systems is considered. Two different techniques are examined the output regulation theory ORT and the flatness based tracking FBT. ORT and FBT are two different approaches to solve the tracking problem, and both methods have different restrictions. The tracking controller of the ORT furthermore depends on the solution of the so-called regulator equations. In this paper, a special analytic solution of the regulator equations is presented. Additionally, based on this analytic solution, a link from the ORT to the FBT approach is provided, and the connection of both tracking controllers is highlighted. It is shown how the ORT controller can be converted to the FBT controller and that both methods lead to identical control laws for a certain class of systems.

We consider massive heterogeneous datasets with intrinsic network structure, i.e., big data over networks. These datasets can be modelled by graph signals, which are defined over large-scale irregular graphs representing complex networks. We show that semi-supervised learning of the entire underlying graph signal based on incomplete information provided by few initial labels can be reduced to a compressed sensing recovery problem within the cosparse analysis model. This reduction provides two things First, it allows to apply highly developed compressed sensing methods to the learning problem. In particular, by implementing a recent primal-dual method for convex optimization, we obtain a sparse label propagation algorithm. Moreover, by casting the learning problem within compressed sensing, we are able to derive sufficient conditions on the graph structure and available label information, such that sparse label propagation is accurate.

In this paper, the problem of energy efficiency in cellular heterogeneous networks HetNets is investigated using radio resource and power management combined with the base station BS ONOFF switching. The objective is to minimize the total power consumption of the network while satisfying the quality of service QoS requirements of each connected user. We consider the case of co-existing macrocell BS, small cell BSs, and private femtocell access points FAPs. Three different network scenarios are investigated, depending on the status of the FAPs, i.e., HetNets without FAPs, HetNets with closed FAPs, and HetNets with semi-closed FAPs. A unified framework is proposed to simultaneously allocate spectrum resources to users in an energy efficient manner and switch off redundant small cell BSs. The high complexity dual decomposition technique is employed to achieve optimal solutions for the problem. A low complexity iterative algorithm is also proposed and its performances are compared to those of the optimal technique. The particularly interesting case of semi-closed FAPs, in which the FAPs accept to serve external users, achieves the highest energy efficiency due to increased degrees of freedom. In this paper, a cooperation scheme between FAPs and mobile operator is also investigated. The incentives for FAPs, e.g., renewable energy sharing and roaming prices, enabling cooperation are discussed to be considered as a useful guideline for inter-operator agreements.

Zeroth-order derivative-free optimization attracts a lot of attention in machine learning, because explicit gradient calculations may be computationally expensive or infeasible. To handle large scale problems both in volume and dimension, recently asynchronous doubly stochastic zeroth-order algorithms were proposed. The convergence rate of existing asynchronous doubly stochastic zeroth order algorithms is OfracsqrtT also for the sequential stochastic zeroth-order optimization algorithms. In this paper, we focus on the finite sums of smooth but not necessarily convex functions, and propose an asynchronous doubly stochastic zeroth-order optimization algorithm using the accelerated technology of variance reduction AsyDSZOVR. Rigorous theoretical analysis show that the convergence rate can be improved from OfracsqrtT the best result of existing algorithms to OfracT. Also our theoretical results is an improvement to the ones of the sequential stochastic zeroth-order optimization algorithms.

Recommendation plays an increasingly important role in our daily lives. Recommender systems automatically suggest items to users that might be interesting for them. Recent studies illustrate that incorporating social trust in Matrix Factorization methods demonstrably improves accuracy of rating prediction. Such approaches mainly use the trust scores explicitly expressed by users. However, it is often challenging to have users provide explicit trust scores of each other. There exist quite a few works, which propose Trust Metrics to compute and predict trust scores between users based on their interactions. In this paper, first we present how social relation can be extracted from users ratings to items by describing Hellinger distance between users in recommender systems. Then, we propose to incorporate the predicted trust scores into social matrix factorization models. By analyzing social relation extraction from three well-known real-world datasets, which both trust and recommendation data available, we conclude that using the implicit social relation in social recommendation techniques has almost the same performance compared to the actual trust scores explicitly expressed by users. Hence, we build our method, called Hell-TrustSVD, on top of the state-of-the-art social recommendation technique to incorporate both the extracted implicit social relations and ratings given by users on the prediction of items for an active user. To the best of our knowledge, this is the first work to extend TrustSVD with extracted social trust information. The experimental results support the idea of employing implicit trust into matrix factorization whenever explicit trust is not available, can perform much better than the state-of-the-art approaches in user rating prediction.

Although altmetrics and other web-based alternative indicators are now commonplace in publishers websites, they can be difficult for research evaluators to use because of the time or expense of the data, the need to benchmark in order to assess their values, the high proportion of zeros in some alternative indicators, and the time taken to calculate multiple complex indicators. These problems are addressed here by a a field normalisation formula, the Mean Normalised Log-transformed Citation Score MNLCS that allows simple confidence limits to be calculated and is similar to a proposal of Lundberg, b field normalisation formulae for the proportion of cited articles in a set, the Equalised Mean-based Normalised Proportion Cited EMNPC and the Mean-based Normalised Proportion Cited MNPC, to deal with mostly uncited data sets, c a sampling strategy to minimise data collection costs, and d free unified software to gather the raw data, implement the sampling strategy, and calculate the indicator formulae and confidence limits. The approach is demonstrated but not fully tested by comparing the Scopus citations, Mendeley readers and Wikipedia mentions of research funded by Wellcome, NIH, and MRC in three large fields for -. Within the results, statistically significant differences in both citation counts and Mendeley reader counts were found even for sets of articles that were less than six months old. Mendeley reader counts were more precise than Scopus citations for the most recent articles and all three funders could be demonstrated to have an impact in Wikipedia that was significantly above the world average.

In this paper we extend the principle of proportional representation to rankings. We consider the setting where alternatives need to be ranked based on approval preferences. In this setting, proportional representation requires that cohesive groups of voters are represented proportionally in each initial segment of the ranking. Proportional rankings are desirable in situations where initial segments of different lengths may be relevant, e.g., hiring decisions if it is unclear how many positions are to be filled, the presentation of competing proposals on a liquid democracy platform if it is unclear how many proposals participants are taking into consideration, or recommender systems if a ranking has to accommodate different user types. We study the proportional representation provided by several ranking methods and prove theoretical guarantees. Furthermore, we experimentally evaluate these methods and present preliminary evidence as to which methods are most suitable for producing proportional rankings.

Recently, Mobile-Edge Computing MEC has arisen as an emerging paradigm that extends cloud-computing capabilities to the edge of the Radio Access Network RAN by deploying MEC servers right at the Base Stations BSs. In this paper, we envision a collaborative joint caching and processing strategy for on-demand video streaming in MEC networks. Our design aims at enhancing the widely used Adaptive BitRate ABR streaming technology, where multiple bitrate versions of a video can be delivered so as to adapt to the heterogeneity of user capabilities and the varying of network connection bandwidth. The proposed strategy faces two main challenges i not only the videos but their appropriate bitrate versions have to be effectively selected to store in the caches, and ii the transcoding relationships among different versions need to be taken into account to effectively utilize the processing capacity at the MEC servers. To this end, we formulate the collaborative joint caching and processing problem as an Integer Linear Program ILP that minimizes the backhaul network cost, subject to the cache storage and processing capacity constraints. Due to the NP-completeness of the problem and the impractical overheads of the existing offline approaches, we propose a novel online algorithm that makes cache placement and video scheduling decisions upon the arrival of each new request. Extensive simulations results demonstrate the significant performance improvement of the proposed strategy over traditional approaches in terms of cache hit ratio increase, backhaul traffic and initial access delay reduction.

In this paper we compare the performance of distributed learning using Apache SPARK and MPI by implementing a distributed linear learning algorithm from scratch on the two programming frameworks. We then explore the performance gap and show how SPARK learning can be accelerated, by reducing computational cost as well as communication-related overheads, to reduce the relative loss in performance versus MPI from x to x. With these different implementations at hand, we will illustrate how the optimal parameters of the algorithm depend strongly on the characteristics of the framework on which it is executed. We will show that carefully tuning a distributed algorithm to trade-off communication and computation can improve performance by orders of magnitude. Hence, understanding system aspects of the framework and their implications, and then correctly adapting the algorithm proves to be the key to performance.

Android malware has been on the rise in recent years due to the increasing popularity of Android and the proliferation of third party application markets. Emerging Android malware families are increasingly adopting sophisticated detection avoidance techniques and this calls for more effective approaches for Android malware detection. Hence, in this paper we present and evaluate an n-gram opcode features based approach that utilizes machine learning to identify and categorize Android malware. This approach enables automated feature discovery without relying on prior expert or domain knowledge for pre-determined features. Furthermore, by using a data segmentation technique for feature selection, our analysis is able to scale up to -gram opcodes. Our experiments on a dataset of  samples showed an f-measure of  using the n-gram opcode based approach. We also provide empirical findings that illustrate factors that have probable impact on the overall n-gram opcodes performance trends.

Human creativity is the ultimate driving force behind scientific progress. While the building blocks of innovations are often embodied in existing knowledge, it is creativity that blends seemingly disparate ideas. Existing studies have made striding advances in quantifying creativity of scientific publications by investigating their citation relationships. Yet, little is known hitherto about the underlying mechanisms governing scientific creative processes, largely due to that a papers references, at best, only partially reflect its authors actual information consumption. This work represents an initial step towards fine-grained understanding of creative processes in scientific enterprise. In specific, using two web-scale longitudinal datasets . million papers and . billion web requests spanning  years, we directly contrast authors information consumption behaviors against their knowledge products. We find that, of . papers across all scientific fields, . of their creativity can be readily explained by information consumed by their authors. Further, by leveraging these findings, we develop a predictive framework that accurately identifies the most critical knowledge to fostering target scientific innovations. We believe that our framework is of fundamental importance to the study of scientific creativity. It promotes strategies to stimulate and potentially automate creative processes, and provides insights towards more effective designs of information recommendation platforms.

Convolutional neural networks CNN pre-trained on ImageNet are the backbone of most state-of-the-art approaches. In this paper, we present a new set of pre-trained models with popular state-of-the-art architectures for the Caffe framework. The first release includes Residual Networks ResNets with generation script as well as the batch-normalization-variants of AlexNet and VGG. All models outperform previous models with the same architecture. The models and training code are available at httpwww.inf-cv.uni-jena.deResearchCNNModels.html and httpsgithub.comcvjenacnn-models

By combining dielectric, THz and far-infrared techniques, we have collected temperature-dependent broadband dielectric spectra of water and aqueous LiCl solutions extending up to  THz. We demonstrate that the spectral features observed in pure water are also found in LiCl solutions, which enables their detailed investigation when approaching the glass transition under cooling. The low-temperature THz data reveal the presence of a boson peak showing up in water just as in other dipolar liquids. We find that the controversial wing-like excess contribution, observed in the room-temperature spectra of water, to a large extent is caused by this peak and cannot be ascribed to the so-called excess wing, known to occur in dipolar liquids at low temperatures.

Nowadays Big Data are becoming more and more important. Many sectors of our economy are now guided by data-driven decision processes. Big Data and business intelligence applications are facilitated by the MapReduce programming model while, at infrastructural layer, cloud computing provides flexible and cost effective solutions for allocating on demand large clusters. In such systems, capacity allocation, which is the ability to optimally size minimal resources for achieve a certain level of performance, is a key challenge to enhance performance for MapReduce jobs and minimize cloud resource costs. In order to do so, one of the biggest challenge is to build an accurate performance model to estimate job execution time of MapReduce systems. Previous works applied simulation based models for modeling such systems. Although this approach can accurately describe the behavior of Big Data clusters, it is too computationally expensive and does not scale to large system. We try to overcome these issues by applying machine learning techniques. More precisely we focus on Support Vector Regression SVR which is intrinsically more robust w.r.t other techniques, like, e.g., neural networks, and less sensitive to outliers in the training set. To better investigate these benefits, we compare SVR to linear regression.

This work investigates the parameter estimation performance of super-resolution line spectral estimation using atomic norm minimization. The focus is on analyzing the algorithms accuracy of inferring the frequencies and complex magnitudes from noisy observations. When the Signal-to-Noise Ratio is reasonably high and the true frequencies are separated by Ofracn, the atomic norm estimator is shown to localize the correct number of frequencies, each within a neighborhood of size Osqrtfraclog nn sigma of one of the true frequencies. Here n is half the number of temporal samples and sigma is the Gaussian noise variance. The analysis is based on a primal-dual witness construction procedure. The obtained error bound matches the Cramer-Rao lower bound up to a logarithmic factor. The relationship between resolution separation of frequencies and precision or accuracy of the estimator is highlighted. Our analysis also reveals that the atomic norm minimization can be viewed as a convex way to solve a ell-norm regularized, nonlinear and nonconvex least-squares problem to global optimality.

Martingale concentration inequalities constitute a powerful mathematical tool in the analysis of problems in a wide variety of fields ranging from probability and statistics to information theory and machine learning. Here we apply techniques borrowed from this field to quantum hypothesis testing, which is the problem of discriminating quantum states belonging to two different sequences rhonn and sigmann. We obtain upper bounds on the finite blocklength type II Stein- and Hoeffding errors, which, for i.i.d. states, are in general tighter than the corresponding bounds obtained by Audenaert, Mosonyi and Verstraete Journal of Mathematical Physics, , . We also derive finite blocklength bounds and moderate deviation results for pairs of sequences of correlated states satisfying a non-homogeneous factorization property. Examples of such sequences include Gibbs states of spin chains with translation-invariant finite range interaction, as well as finitely correlated quantum states. We apply our results to find bounds on the capacity of a certain class of classical-quantum channels with memory, which satisfy a so-called channel factorization property- both in the finite blocklength and moderate deviation regimes.

In this paper we propose an approach for articulated tracking of multiple people in unconstrained videos. Our starting point is a model that resembles existing architectures for single-frame pose estimation but is several orders of magnitude faster. We achieve this in two ways  by simplifying and sparsifying the body-part relationship graph and leveraging recent methods for faster inference, and  by offloading a substantial share of computation onto a feed-forward convolutional architecture that is able to detect and associate body joints of the same person even in clutter. We use this model to generate proposals for body joint locations and formulate articulated tracking as spatio-temporal grouping of such proposals. This allows to jointly solve the association problem for all people in the scene by propagating evidence from strong detections through time and enforcing constraints that each proposal can be assigned to one person only. We report results on a public MPII Human Pose benchmark and on a new dataset of videos with multiple people. We demonstrate that our model achieves state-of-the-art results while using only a fraction of time and is able to leverage temporal information to improve state-of-the-art for crowded scenes.

Deep neural networks are powerful black box predictors that have recently achieved impressive performance on a wide spectrum of tasks. Quantifying predictive uncertainty in neural networks is a challenging and yet unsolved problem. Bayesian neural networks, which learn a distribution over weights, are currently the state-of-the-art for estimating predictive uncertainty however these require significant modifications to the training procedure and are computationally expensive compared to standard non-Bayesian neural neural networks. We propose an alternative to Bayesian neural networks, that is simple to implement, readily parallelisable and yields high quality predictive uncertainty estimates. Through a series of experiments on classification and regression benchmarks, we demonstrate that our method produces well-calibrated uncertainty estimates which are as good or better than approximate Bayesian neural networks. To assess robustness to dataset shift, we evaluate the predictive uncertainty on test examples from known and unknown distributions, and show that our method is able to express higher uncertainty on unseen data. We demonstrate the scalability of our method by evaluating predictive uncertainty estimates on ImageNet.

Modeling and control strategies for a design of an autonomous three wheeled mobile robot with front wheel steer is presented. Although, the three-wheel vehicle design with front wheel steer is common in automotive vehicles used often in public transport, but its advantages in navigation and localization of autonomous vehicles is seldom utilized. We present the system model for such a robotic vehicle. A PID controller for speed control is designed for the model obtained and has been implemented in a digital control framework. The trajectory control framework, which is a challenging task for such a three-wheeled robot has also been presented in the paper. The derived system model has been verified using experimental results obtained for the robot vehicle design. Controller performance and robustness issues have also been discussed briefly.

We show how to extend traditional intrinsic image decompositions to incorporate further layers above albedo and shading. It is hard to obtain data to learn a multi-layer decomposition. Instead, we can learn to decompose an image into layers that are like this by authoring generative models for each layer using proxy examples that capture the Platonic ideal Mondrian images for albedo rendered D primitives for shading material swatches for shading detail. Our method then generates image layers, one from each model, that explain the image. Our approach rests on innovation in generative models for images. We introduce a Convolutional Variational Auto Encoder conv-VAE, a novel VAE architecture that can reconstruct high fidelity images. The approach is general, and does not require that layers admit a physical interpretation.

In this paper we propose two ways of incomplete data representation. The first one is a generalization of a flag representation, where a vector with missing attributes is filled with some values and joined with flag vectors indicating missing components. Our generalization uses pointed affine subspaces, which in addition to flag representation allows to perform various affine transformations of data, as whitening or dimensionality reduction. We show how to embed such affine subspaces into a vector space and how to define a proper scalar product. In the second approach, we represent missing data points by degenerated Gaussian densities, which additionally model the uncertainty connected with missing features. This representation allows to construct an analogue of RBF kernel on incomplete data space.

We are interested in learning customers video preferences from their historic viewing patterns and geographical location. We consider a Bayesian latent factor modeling approach for this task. In order to tune the complexity of the model to best represent the data, we make use of Bayesian nonparameteric techniques. We describe an inference technique that can scale to large real-world data sets. Finally we show results obtained by applying the model to a large internal Netflix data set, that illustrates that the model was able to capture interesting relationships between viewing patterns and geographical location.

The two-receiver broadcast packet erasure channel with feedback and memory is studied. Memory is modeled using a finite- state Markov chain representing a channel state. Two scenarios are considered i when the transmitter has causal knowledge of the channel state i.e., the state is visible, and ii when the channel state is unknown at the transmitter, but observations of it are available at the transmitter through feedback i.e., the state is hidden. In both scenarios, matching outer and inner bounds are derived on the rates of communication and the capacity region is determined. It is shown that similar results carry over to channels with memory and delayed feedback, and memoryless compound channels with feedback. When the state is visible, the capacity region has a single-letter characterization and is in terms of a linear program. Two optimal coding schemes are devised that use feedback to keep track of the sentreceived packets via a network of queues a probabilistic scheme and a deterministic backpressure-like algorithm. The former bases its decisions solely on the past channel state information and the latter follows a max-weight queue-based policy. The performance of the algorithms are analyzed using the frameworks of rate-stability in networks of queues, max-flow min-cut duality in networks, and finite-horizon Lyapunov drift analysis. When the state is hidden, the capacity region does not have a single-letter characterization and is, in this sense, uncomputable. Approximations of the capacity region are provided and two optimal coding algorithms are outlined. The first algorithm is a probabilistic coding scheme that bases its decisions on the past L feedback sequences and its achievable rate-region approaches the capacity region exponentially fast in L. The second algorithm is a backpressure-like algorithm that performs optimally in the long run.

We introduce a novel algorithm of community detection that maintains dynamically a community structure of a large network that evolves with time. The algorithm maximizes the modularity index thanks to the construction of a randomized hierarchical clustering based on a Monte Carlo Markov Chain MCMC method. Interestingly, it could be seen as a dynamization of Louvain algorithm see Blondel et Al,  where the aggregation step is replaced by the hierarchical instrumental probability.

Noise injection NI is an off-the-shelf method to mitigate over-fitting in neural networks NNs. The recent developments in Bernoulli NI as implemented in the dropout and shakeout procedures demonstrates the efficiency and feasibility of NI in regularizing deep NNs. We propose whiteout, a new regularization technique via injection of adaptive Gaussian noises into deep NNs. We show that whiteout is associated with a deterministic optimization objective function in generalized linear models with a closed-form penalty term which has connections with the bridge, lasso, ridge, and elastic net penalization and it can be also extended to offer regularization similar to the adaptive lasso and group lasso regression. We also demonstrate that whiteout can be viewed as robust learning of NN model in the presence of small perturbations in input and hidden nodes. Compared to dropout, whiteout has better performance in training data of relatively small sizes with the sparsity introduced through the l regularization. Compared to shakeout, the penalized objective function in whiteout is more stable given the continuity of Gaussian noises. We establish theoretically that the noise-perturbed empirical loss function with whiteout converges almost surely to the ideal loss function, and the estimates of NN parameters obtained from minimizing the former loss function are consistent with those obtained from minimizing the ideal loss function. Computationally, whiteout can be incorporated in the back-propagation algorithm and is computationally efficient. The superiority of whiteout over dropout and shakeout in training NNs in classification is demonstrated using the MNIST and CIFAR- data.

Large-scale integration of emerging nanoscale non-volatile memory devices, e.g. resistive random-access memory RRAM, can enable a new generation of neuromorphic computers that can solve a wide range of machine learning problems. Such hybrid CMOS-RRAM neuromorphic architectures will result in several orders of magnitude reduction in energy consumption at a very small form factor, and herald autonomous learning machines capable of self-adapting to their environment. However, the progress in this area has been impeded from the realization that the actual memory devices fall well short of their expected behavior. In this work, we discuss the challenges associated with these memory devices and their use in neuromorphic computing circuits, and propose pathways to overcome these limitations by introducing dendritic learning.

We study the design of schedules for multi-commodity multicast. In this problem, we are given an undirected graph G and a collection of source-destination pairs, and the goal is to schedule a minimum-length sequence of matchings that connects every source with its respective destination. Multi-commodity multicast models a classic information dissemination problem in networks where the primary communication constraint is the number of connections that a given node can make, not link bandwidth. Multi-commodity multicast and its special cases, broadcast and multicast, are all NP-complete and the best approximation factors known are widetildeOsqrtlog n, Olog nloglog n, and Olog kloglog k, respectively, where n is the number of nodes and k is the number of terminals in the multicast instance.   Multi-commodity multicast is closely related to the problem of finding a subgraph of optimal poise, where the poise is defined as the sum of the maximum degree of the subgraph and the maximum distance between any source-destination pair in the subgraph. We first show that for any instance of the multicast problem, the minimum poise subgraph can be approximated to within a factor of Olog k log n with respect to the value of a natural LP relaxation in an n-node graph with k source-destination pairs. This is the first upper bound on the integrality gap of the natural LP all previous algorithms, both combinatorial and LP-based, yielded approximations with respect to the integer optimum. Using this integrality gap upper bound, we obtain our main result an Olog klog n-approximation for multi-commodity multicast for planar graphs. In addition, the techniques used also give an Olog n-approximation for radio gossip in planar graphs. This is the first bound for radio gossip given that doesnt rely on the maximum degree of the graph.

Rotoscoping, the detailed delineation of scene elements through a video shot, is a painstaking task of tremendous importance in professional post-production pipelines. While pixel-wise segmentation techniques can help for this task, professional rotoscoping tools rely on parametric curves that offer the artists a much better interactive control on the definition, editing and manipulation of the segments of interest. Sticking to this prevalent rotoscoping paradigm, we propose a novel framework to capture and track the visual aspect of an arbitrary object in a scene, given a first closed outline of this object. This model combines a collection of local foregroundbackground appearance models spread along the outline, a global appearance model of the enclosed object and a set of distinctive foreground landmarks. The structure of this rich appearance model allows simple initialization, efficient iterative optimization with exact minimization at each step, and on-line adaptation in videos. We demonstrate qualitatively and quantitatively the merit of this framework through comparisons with tools based on either dynamic segmentation with a closed curve or pixel-wise binary labelling.

Network functions virtualization NFV -- deploying network functions in software on commodity machines -- allows operators to employ rich chains of NFs to realize custom performance, security, and compliance policies, and ensure high performance by dynamically adding instances andor failing over. Because NFs are stateful, it is important to carefully manage their state, especially during such dynamic actions. Crucially, state management must  offer good performance to match the needs of modern networks  ensure NF chain-wide properties and  not require the operator to manage low-level state management details. We present StreamNF, an NFV framework that satisfies the above requirements. To do so, StreamNF leverages an external state store with novel caching strategies and offloading of state operations, and chain-level logical packet clocks and packet loggingreplay. Extensive evaluation of a StreamNF prototype built atop Apache Storm shows that the significant benefits of StreamNF in terms of state management performance and chain-wide properties come at a modest per-packet latency cost.

Objective The advent of High-Performance Computing HPC in recent years has led to its increasing use in brain study through computational models. The scale and complexity of such models are constantly increasing, leading to challenging computational requirements. Even though modern HPC platforms can often deal with such challenges, the vast diversity of the modeling field does not permit for a single acceleration or homogeneous platform to effectively address the complete array of modeling requirements. Approach In this paper we propose and build BrainFrame, a heterogeneous acceleration platform, incorporating three distinct acceleration technologies, a Dataflow Engine, a Xeon Phi and a GP-GPU. The PyNN framework is also integrated into the platform. As a challenging proof of concept, we analyze the performance of BrainFrame on different instances of a state-of-the-art neuron model, modeling the Inferior- Olivary Nucleus using a biophysically-meaningful, extended Hodgkin-Huxley representation. The model instances take into account not only the neuronal- network dimensions but also different network-connectivity circumstances that can drastically change application workload characteristics. Main results The synthetic approach of three HPC technologies demonstrated that BrainFrame is better able to cope with the modeling diversity encountered. Our performance analysis shows clearly that the model directly affect performance and all three technologies are required to cope with all the model use cases.

In an isolated single-particle quantum system a spatial disorder can induce Anderson localization. Being a result of interference, this phenomenon is expected to be fragile in the face of dissipation. Here we show that dissipation can drive a disordered system into a steady state with tunable localization properties. This can be achieved with a set of identical dissipative operators, each one acting non-trivially only on a pair of neighboring sites. Operators are parametrized by a uniform phase, which controls selection of Anderson modes contributing to the state. On the microscopic level, quantum trajectories of a system in a localized steady regime exhibit intermittent dynamics consisting of long-time sticking events near selected modes interrupted by jumps between them.

From a sequence of similarity networks, with edges representing certain similarity measures between nodes, we are interested in detecting a change-point which changes the statistical property of the networks. After the change, a subset of anomalous nodes which compares dissimilarly with the normal nodes. We study a simple sequential change detection procedure based on node-wise average similarity measures, and study its theoretical property. Simulation and real-data examples demonstrate such a simply stopping procedure has reasonably good performance. We further discuss the faulty sensor isolation estimating anomalous nodes using community detection.

More than  algorithms have been developed for exact string matching within the last  years. We show by experiments that the naive algorithm exploiting SIMD instructions of modern CPUs with symbols compared in a special order is the fastest one for patterns of length up to about  symbols and extremely good for longer patterns and small alphabets. The algorithm compares  or  characters in parallel by applying SSE or AVX instructions, respectively. Moreover, it uses loop peeling to further speed up the searching phase. We tried several orders for comparisons of pattern symbols and the increasing order of their probabilities in the text was the best.

We show that the KLS constant for n-dimensional isotropic logconcave measures is On, improving on the current best bound of Onsqrtlog n. As corollaries we obtain the same improved bound on the thin-shell estimate, Poincare constant and exponential concentration constant and an alternative proof of this bound for the isotropic constant it also follows that the ball walk for sampling from an isotropic logconcave density in bf Rn converges in On. steps from a warm start.

Nowadays, social networks of ever increasing size are studied by researchers from a range of disciplines. The data underlying these networks is often automatically gathered from APIs, websites or existing databases. As a result, the quality of this data is typically not manually validated, and the resulting networks may be based on false, biased or incomplete data. In this paper, we investigate the effect of data quality issues on the analysis of large networks. We focus on the global board interlock network, in which nodes represent firms across the globe, and edges model social ties between firms -- shared board members holding a position at both firms. First, we demonstrate how we can automatically assess the completeness of a large dataset of  million firms, in which data is missing not at random. Second, we present a novel method to increase the accuracy of the entries in our data. By comparing the expected and empirical characteristics of the resulting network topology, we develop a technique that automatically prunes and merges duplicate nodes and edges. Third, we use a case study of the board interlock network of Sweden to show how poor quality data results in incorrect network topologies, biased centrality values and abnormal influence spread under a well-known diffusion model. Finally, we demonstrate how our data quality assessment methods help restore the correct network structure, ultimately allowing us to derive meaningful and correct results from analyzing the network.

Measuring centrality in a social network, especially in bipartite mode, poses several challenges such as requirement of full knowledge of the network topology and lack of properly detection of top-k behavioral representative users. In this paper, to overcome the aforementioned challenging issues, we propose an accurate centrality measure, called HellRank, to identify central nodes in bipartite social networks. HellRank is based on the Hellinger distance between two nodes on the same side of a bipartite network. We theoretically analyze the impact of the Hellinger distance on a bipartite network and find an upper and lower bounds for this distance. The computation of HellRank centrality measure can be distributed by letting each node uses only local information on its immediate neighbors and therefore do not need a central entity to have full knowledge of the network topological structure. We experimentally evaluate performance of the HellRank measure in correlation with other centrality measures on real-world networks. The results show partial ranking similarity between the HellRank and the other conventional metrics according to the Kendall and Spearman rank correlation coefficient.

Using molecular dynamics simulations, we study the transient response of a binary Lennard-Jones glass subjected to periodic shear deformation. The amorphous solid is modelled as the three-dimensional Kob-Andersen binary mixture at a low temperature. The cyclic loading is applied to slowly annealed, quiescent samples, which induces irreversible particle rearrangements at large strain amplitudes, leading to stress-strain hysteresis and a drift of the potential energy towards higher values. We find that the initial response to cyclic shear near the critical strain amplitude involves disconnected clusters of atoms with large nonaffine displacements. In contrast, the amplitude of shear stress oscillations decreases after a certain number of cycles, which is accompanied by the initiation and subsequent growth of a shear band.

A Helly circular-arc graph is the intersection graph of a set of arcs on a circle having the Helly property. We introduce essential obstacles, which are a refinement of the notion of obstacles, and prove that essential obstacles are precisely the minimal forbidden induced circular-arc subgraphs for the class of Helly circular-arc graphs. We show that it is possible to find in linear time, in any given obstacle, some minimal forbidden induced subgraph for the class of Helly circular-arc graphs contained as an induced subgraph. Moreover, relying on an existing linear-time algorithm for finding induced obstacles in circular-arc graphs, we conclude that it is possible to find in linear time an induced essential obstacle in any circular-arc graph that is not a Helly circular-arc graph. The problem of finding a forbidden induced subgraph characterization, not restricted only to circular-arc graphs, for the class of Helly circular-arc graphs remains unresolved. As a partial answer to this problem, we find the minimal forbidden induced subgraph characterization for the class of Helly circular-arc graphs restricted to graphs containing no induced claw and no induced -wheel. Furthermore, we show that there is a linear-time algorithm for finding, in any given graph that is not a Helly circular-arc graph, an induced subgraph isomorphic to claw, -wheel, or some minimal forbidden induced subgraph for the class of Helly circular-arc graphs.

The disjoint set union problem is a basic problem in data structures with a wide variety of applications. We extend a known efficient sequential algorithm for this problem to obtain a simple and efficient concurrent wait-free algorithm running on an asynchronous parallel random access machine APRAM. Crucial to our result is the use of randomization. Under a certain independence assumption, for a problem instance in which there are n elements, m operations, and p processes, our algorithm does Thetam alphan, mnp  lognpm   expected work, where the expectation is over the random choices made by the algorithm and alpha is a functional inverse of Ackermanns function. In addition, each operation takes Olog n steps with high probability. Our algorithm is significantly simpler and more efficient than previous algorithms proposed by Anderson and Woll. Under our independence assumption, our algorithm achieves almost-linear speed-up for applications in which all or most of the processes can be kept busy.

We show how to construct highly symmetric algorithms for matrix multiplication. In particular, we consider algorithms which decompose the matrix multiplication tensor into a sum of rank- tensors, where the decomposition itself consists of orbits under some finite group action. We show how to use the representation theory of the corresponding group to derive simple constraints on the decomposition, which we solve by hand for n,,,, recovering Strassens algorithm in a particularly symmetric form and new algorithms for larger n. While these new algorithms do not improve the known upper bounds on tensor rank or the matrix multiplication exponent, they are beautiful in their own right, and we point out modifications of this idea that could plausibly lead to further improvements. Our constructions also suggest further patterns that could be mined for new algorithms, including a tantalizing connection with lattices. In particular, using lattices we give the most transparent proof to date of Strassens algorithm the same proof works for all n, to yield a decomposition with n - n   terms.

Network quantization is one of network compression techniques employed to reduce the redundancy of deep neural networks. It compresses the size of the storage for a large number of network parameters in a neural network by quantizing them and encoding the quantized values into binary codewords of smaller sizes. In this paper, we aim to design network quantization schemes that minimize the expected loss due to quantization while maximizing the compression ratio. To this end, we analyze the quantitative relation of quantization errors to the loss function of a neural network and identify that the Hessian-weighted distortion measure is locally the right objective function that we need to optimize for minimizing the loss due to quantization. As a result, Hessian-weighted k-means clustering is proposed for clustering network parameters to quantize when fixed-length binary encoding follows. When optimal variable-length binary codes, e.g., Huffman codes, are employed for further compression of quantized values after clustering, we derive that the network quantization problem can be related to the entropy-constrained scalar quantization ECSQ problem in information theory and consequently propose two solutions of ECSQ for network quantization, i.e., uniform quantization and an iterative algorithm similar to Lloyds algorithm for k-means clustering. Finally, using the simple uniform quantization followed by Huffman coding, our experiment results show that the compression ratios of ., . and . are achievable i.e., the sizes of the compressed models are ., . and . of the original model sizes for LeNet, ResNet and AlexNet, respectively, at no or marginal performance loss.

Artificial intelligence offers the potential to automate challenging data-processing tasks in collider physics. To establish its prospects, we explore to what extent deep learning with convolutional neural networks can discriminate quark and gluon jets better than observables designed by physicists. Our approach builds upon the paradigm that a jet can be treated as an image, with intensity given by the local calorimeter deposits. We supplement this construction by adding color to the images, with red, green and blue intensities given by the transverse momentum in charged particles, transverse momentum in neutral particles, and pixel-level charged particle counts. Overall, the deep networks match or outperform traditional jet variables. We also find that, while various simulations produce different quark and gluon jets, the neural networks are surprisingly insensitive to these differences, similar to traditional observables. This suggests that the networks can extract robust physical information from imperfect simulations.

Inspired by the design patterns of object-oriented software architecture, we offer an initial set of privacy patterns. Our intent is to describe the most important ways in which software systems can offer privacy to their stakeholders. We express our privacy patterns as class diagrams in the UML Universal Modelling Language, because this is a commonly-used language for expressing the high-level architecture of an object-oriented system. In this initial set of privacy patterns, we sketch how each of Westins four states of privacy can be implemented in a software system. In addition to Westins states of Solitude, Intimacy, Anonymity, and Reserve, we develop a privacy pattern for an institutionalised form of Intimacy which we call Confidence.

Barrier functions also called certificates have been an important tool for the verification of hybrid systems, and have also played important roles in optimization and multi-objective control. The extension of a barrier function to a controlled system results in a control barrier function. This can be thought of as being analogous to how Sontag extended Lyapunov functions to control Lyapunov functions in order to enable controller synthesis for stabilization tasks. A control barrier function enables controller synthesis for safety requirements specified by forward invariance of a set using a Lyapunov-like condition. This paper develops several important extensions to the notion of a control barrier function. The first involves robustness under perturbations to the vector field defining the system. Input-to-State stability conditions are given that provide for forward invariance, when disturbances are present, of a relaxation of set rendered invariant without disturbances. A control barrier function can be combined with a control Lyapunov function in a quadratic program to achieve a control objective subject to safety guarantees. The second result of the paper gives conditions for the control law obtained by solving the quadratic program to be Lipschitz continuous and therefore to gives rise to well-defined solutions of the resulting closed-loop system.

Sentiment analysis is one of the fastest growing research areas in computer science, making it challenging to keep track of all the activities in the area. We present a computer-assisted literature review, where we utilize both text mining and qualitative coding, and analyze , papers from Scopus. We find that the roots of sentiment analysis are in the studies on public opinion analysis at the beginning of th century and in the text subjectivity analysis performed by the computational linguistics community in s. However, the outbreak of computer-based sentiment analysis only occurred with the availability of subjective texts on the Web. Consequently,  of the papers have been published after . Sentiment analysis papers are scattered to multiple publication venues, and the combined number of papers in the top- venues only represent ca.  of the papers in total. We present the top- cited papers from Google Scholar and Scopus and a taxonomy of research topics. In recent years, sentiment analysis has shifted from analyzing online product reviews to social media texts from Twitter and Facebook. Many topics beyond product reviews like stock markets, elections, disasters, medicine, software development and cyberbullying extend the utilization of sentiment analysis

This paper considers a scenario in which an Alice-Bob pair wishes to communicate in secret in the presence of an active Eve, who is capable of jamming as well as eavesdropping in Full-Duplex FD mode. As countermeasure, Bob also operates in FD mode, using a subset of its antennas to act as receiver, and the remaining antennas to act as jammer and transmit noise. With a goal to maximize the achievable secrecy degrees of freedom S.D.o.F. of the system, we provide the optimal transmitreceive antennas allocation at Bob, based on which we determine in closed form the maximum achievable S.D.o.F.. We further investigate the adverse scenario in which Eve knows Bobs transmission strategy and optimizes its transmitreceive antennas allocation in order to minimize the achievable S.D.o.F.. For that case we find the worst-case achievable S.D.o.F.. We also provide a method for constructing the precoding matrices of Alice and Bob, based on which the maximum S.D.o.F. can be achieved. Numerical results validate the theoretical findings and demonstrate the performance of the proposed method in realistic settings.

We consider spin systems on the integer lattice graph mathbbZd with nearest-neighbor interactions. We develop a combinatorial framework for establishing that exponential decay with distance of spin correlations, specifically the strong spatial mixing condition SSM, implies rapid mixing of a large class of Markov chains. As a first application of our method we prove that SSM implies Olog n mixing of systematic scan dynamics under mild conditions on an n-vertex d-dimensional cube of the integer lattice graph mathbbZd. Systematic scan dynamics are widely employed in practice but have proved hard to analyze. A second application of our technology concerns the Swendsen-Wang dynamics for the ferromagnetic Ising and Potts models. We show that SSM implies an O bound for the relaxation time i.e., the inverse spectral gap. As a by-product of this implication we observe that the relaxation time of the Swendsen-Wang dynamics in square boxes of mathbbZ is O throughout the subcritical regime of the q-state Potts model, for all q ge . We also use our combinatorial framework to give a simple coupling proof of the classical result that SSM entails optimal mixing time of the Glauber dynamics. Although our results in the paper focus on d-dimensional cubes in mathbbZd, they generalize straightforwardly to arbitrary regions of mathbbZd and to graphs with subexponential growth.

Capacity of vehicular networks with infrastructure support is both an interesting and challenging problem as the capacity is determined by the inter-play of multiple factors including vehicle-to-infrastructure VI communications, vehicle-to-vehicle VV communications, density and mobility of vehicles, and cooperation among vehicles and infrastructure. In this paper, we consider a typical delay-tolerant application scenario with a subset of vehicles, termed Vehicles of Interest VoIs, having download requests. Each VoI downloads a distinct large-size file from the Internet and other vehicles without download requests assist the delivery of the files to the VoIs. A cooperative communication strategy is proposed that explores the combined use of VI communications, VV communications, mobility of vehicles and cooperation among vehicles and infrastructure to improve the capacity of vehicular networks. An analytical framework is developed to model the data dissemination process using this strategy, and a closed form expression of the achievable capacity is obtained, which reveals the relationship between the capacity and its major performance-impacting parameters such as inter-infrastructure distance, radio ranges of infrastructure and vehicles, sensing range of vehicles, transmission rates of VI and VV communications, vehicular density and proportion of VoIs. Numerical result shows that the proposed cooperative communication strategy significantly boosts the capacity of vehicular networks, especially when the proportion of VoIs is low. Our results provide guidance on the optimum deployment of vehicular network infrastructure and the design of cooperative communication strategy to maximize the capacity.

In this article, we present a one-field monolithic fictitious domain FD method for simulation of general fluid-structure interactions FSI. One-field means only one velocity field is solved in the whole domain, based upon the use of an appropriate L projection. Monolithic means the fluid and solid equations are solved synchronously rather than sequentially. We argue that the proposed method has the same generality and robustness as FD methods with distributed Lagrange multiplier DLM but is significantly more computationally efficient because of one-field whilst being very straightforward to implement. The method is described in detail, followed by the presentation of multiple computational examples in order to validate it across a wide range of fluid and solid parameters and interactions.

In big data systems, the infrastructure is such that large amounts of data are hosted away from the users. In such a system information security is considered as a major challenge. From a customer perspective, one of the big risks in adopting big data systems is in trusting the provider who designs and owns the infrastructure from accessing user data. Yet there does not exist much in the literature on detection of insider attacks. In this work, we propose a new system architecture in which insider attacks can be detected by utilizing the replication of data on various nodes in the system. The proposed system uses a two-step attack detection algorithm and a secure communication protocol to analyze processes executing in the system. The first step involves the construction of control instruction sequences for each process in the system. The second step involves the matching of these instruction sequences among the replica nodes. Initial experiments on real-world hadoop and spark tests show that the proposed system needs to consider only  of the code to analyze a program and incurs . time overhead. The proposed security system can be implemented and built for any big data system due to its extrinsic workflow.

The method presented extends a given regression neural network to make its performance improve. The modification affects the learning procedure only, hence the extension may be easily omitted during evaluation without any change in prediction. It means that the modified model may be evaluated as quickly as the original one but tends to perform better.   This improvement is possible because the modification gives better expressive power, provides better behaved gradients and works as a regularization. The knowledge gained by the temporarily extended neural network is contained in the parameters shared with the original neural network.   The only cost is an increase in learning time.

The surge of mobile data traffic forces network operators to cope with capacity shortage. The deployment of small cells in G networks is meant to reduce latency, backhaul traffic and increase radio access capacity. In this context, mobile edge computing technology will be used to manage dedicated cache space in the radio access network. Thus, mobile network operators will be able to provision OTT content providers with new caching services to enhance the quality of experience of their customers on the move. In turn, the cache memory in the mobile edge network will become a shared resource. Hence, we study a competitive caching scheme where contents are stored at given price set by the mobile network operator. We first formulate a resource allocation problem for a tagged content provider seeking to minimize the expected missed cache rate. The optimal caching policy is derived accounting for popularity and availability of contents, the spatial distribution of small cells, and the caching strategies of competing content providers. It is showed to induce a specific order on contents to be cached based on their popularity and availability. Next, we study a game among content providers in the form of a generalized Kelly mechanism with bounded strategy sets and heterogeneous players. Existence and uniqueness of the Nash equilibrium are proved. Finally, extensive numerical results validate and characterize the performance of the model.

For an object classification system, the most critical obstacles towards real-world applications are often caused by large intra-class variability, arising from different lightings, occlusion and corruption, in limited sample sets. Most methods in the literature would fail when the training samples are heavily occluded, corrupted or have significant illumination or viewpoint variations. Besides, most of the existing methods and especially deep learning-based methods, need large training sets to achieve a satisfactory recognition performance. Although using the pre-trained network on a generic large-scale dataset and fine-tune it to the small-sized target dataset is a widely used technique, this would not help when the content of base and target datasets are very different. To address these issues, we propose a joint projection and low-rank dictionary learning method using dual graph constraints JP-LRDL. The proposed joint learning method would enable us to learn the features on top of which dictionaries can be better learned, from the data with large intra-class variability. Specifically, a structured class-specific dictionary is learned and the discrimination is further improved by imposing a graph constraint on the coding coefficients, that maximizes the intra-class compactness and inter-class separability. We also enforce low-rank and structural incoherence constraints on sub-dictionaries to make them more compact and robust to variations and outliers and reduce the redundancy among them, respectively. To preserve the intrinsic structure of data and penalize unfavourable relationship among training samples simultaneously, we introduce a projection graph into the framework, which significantly enhances the discriminative ability of the projection matrix and makes the method robust to small-sized and high-dimensional datasets.

We investigate the fundamental conditions on the sampling pattern, i.e., locations of the sampled entries, for finite completability of a low-rank tensor given some components of its Tucker rank. In order to find the deterministic necessary and sufficient conditions, we propose an algebraic geometric analysis on the Tucker manifold, which allows us to incorporate multiple rank components in the proposed analysis in contrast with the conventional geometric approaches on the Grassmannian manifold. This analysis characterizes the algebraic independence of a set of polynomials defined based on the sampling pattern, which is closely related to finite completion. Probabilistic conditions are then studied and a lower bound on the sampling probability is given, which guarantees that the proposed deterministic conditions on the sampling patterns for finite completability hold with high probability. Furthermore, using the proposed geometric approach for finite completability, we propose a sufficient condition on the sampling pattern that ensures there exists exactly one completion for the sampled tensor.

We present a distributed non-Bayesian learning algorithm for the problem of parameter estimation with Gaussian noise. The algorithm is expressed as explicit updates on the parameters of the Gaussian beliefs i.e. means and precision. We show a convergence rate of Ok with the constant term depending on the number of agents and the topology of the network. Moreover, we show almost sure convergence to the optimal solution of the estimation problem for the general case of time-varying directed graphs.

Superpixels group perceptually similar pixels to create visually meaningful entities while heavily reducing the number of primitives. As of these properties, superpixel algorithms have received much attention since their naming in . By today, publicly available and well-understood superpixel algorithms have turned into standard tools in low-level vision. As such, and due to their quick adoption in a wide range of applications, appropriate benchmarks are crucial for algorithm selection and comparison. Until now, the rapidly growing number of algorithms as well as varying experimental setups hindered the development of a unifying benchmark. We present a comprehensive evaluation of  state-of-the-art superpixel algorithms utilizing a benchmark focussing on fair comparison and designed to provide new and relevant insights. To this end, we explicitly discuss parameter optimization and the importance of strictly enforcing connectivity. Furthermore, by extending well-known metrics, we are able to summarize algorithm performance independent of the number of generated superpixels, thereby overcoming a major limitation of available benchmarks. Furthermore, we discuss runtime, robustness against noise, blur and affine transformations, implementation details as well as aspects of visual quality. Finally, we present an overall ranking of superpixel algorithms which redefines the state-of-the-art and enables researchers to easily select appropriate algorithms and the corresponding implementations which themselves are made publicly available as part of our benchmark at davidstutz.deprojectssuperpixel-benchmark.

In this paper, we propose a SaaS service which prevents shoplifting using image analysis and ERP. In Japan, total damage of shoplifting reaches  billion yen and more than  small shops gave up their businesses because of shoplifting. Based on recent cloud technology and data analysis technology, we propose a shoplifting prevention service with image analysis of security camera and ERP data check for small shops. We evaluated stream analysis of security camera movie using online machine learining framework Jubatus.

We review Bhat et als paper where a class of bounded, continuous time-invariant finite time stabilizing feedback laws are derived for the double integrator and Lyapunov theory is employed in establishing finite-time convergence.

If you are an artificial intelligence researcher, you should look to video games as ideal testbeds for the work you do. If you are a video game developer, you should look to AI for the technology that makes completely new types of games possible. This chapter lays out the case for both of these propositions. It asks the question what can video games do for AI, and discusses how in particular general video game playing is the ideal testbed for artificial general intelligence research. It then asks the question what can AI do for video games, and lays out a vision for what video games might look like if we had significantly more advanced AI at our disposal. The chapter is based on my keynote at IJCCI , and is written in an attempt to be accessible to a broad audience.

Set Cover is a classic NP-hard problem as shown by Slavik  the greedy algorithm gives an approximation ratio of ln n - ln ln n  Theta. A series of works by Lund  Yannakakis , Feige , Moshkovitz  have shown that, under the assumption P neq NP, it is impossible to obtain a polynomial-time approximation ratio with approximation ratio  - alpha ln n, for any constant alpha  .   In this note, we show that under the Exponential Time Hypothesis a stronger complexity-theoretic assumptions than P neq NP, there are no polynomial-time algorithms achieving approximation ratio ln n - C ln ln n, where C is some universal constant. Thus, the greedy algorithm achieves an essentially optimal approximation ratio up to the coefficient of ln ln n.

Signal-based Surveillance systems such as Closed Circuits Televisions CCTV have been widely installed in public places. Those systems are normally used to find the events with security interest, and play a significant role in public safety. Though such systems are still heavily reliant on human labour to monitor the captured information, there have been a number of automatic techniques proposed to analysing the data. This article provides an overview of automatic surveillance event detection techniques . Despite its popularity in research, it is still too challenging a problem to be realised in a real world deployment. The challenges come from not only the detection techniques such as signal processing and machine learning, but also the experimental design with factors such as data collection, evaluation protocols, and ground-truth annotation. Finally, this article propose that multi-disciplinary research is the path towards a solution to this problem.

Modern software systems are increasingly dependent on third-party libraries. It is widely recognized that using mature and well-tested third-party libraries can improve developers productivity, reduce time-to-market, and produce more reliable software. Todays open-source repositories provide a wide range of libraries that can be freely downloaded and used. However, as software libraries are documented separately but intended to be used together, developers are unlikely to fully take advantage of these reuse opportunities. In this paper, we present a novel approach to automatically identify third-party library usage patterns, i.e., collections of libraries that are commonly used together by developers. Our approach employs hierarchical clustering technique to group together software libraries based on external client usage. To evaluate our approach, we mined a large set of over , popular libraries from Maven Central Repository and investigated their usage by over , client systems from the Github repository. Our experiments show that our technique is able to detect the majority  of highly consistent and cohesive library usage patterns across a considerable number of client systems.

We study response selection for multi-turn conversation in retrieval based chatbots. Existing works either ignores relationships among utterances, or misses important information in context when matching a response with a highly abstract context vector finally. We propose a new session based matching model to address both problems. The model first matches a response with each utterance on multiple granularities, and distills important matching information from each pair as a vector with convolution and pooling operations. The vectors are then accumulated in a chronological order through a recurrent neural network RNN which models the relationships among the utterances. The final matching score is calculated with the hidden states of the RNN. Empirical study on two public data sets shows that our model can significantly outperform the state-of-the-art methods for response selection in multi-turn conversation.

Temporal logic provided an appealing approach to specifying properties of operating systems and other reactive software by making referencing the state graph implicitly. This paper shows how to get the same effect, with a finer control over specification and a compositional notion of state, using ordinary working mathematics, without the weight of formal logic, by using parametric state variables.

Although problems relating to specific image correction have been explored intensively, the problem of simultaneous diagnosis for multiple photographic defects remains relatively untouched. Solutions to this problem attempt to predict the existence, severity, and locations of common defects. This paper proposes a first attempt at a solution to the general defect diagnosis problem based on our novel dataset. We formulate the defect diagnosis problem as a multi-task prediction problem and utilize multi-column deep neural networks DNN to approach the problem. We propose DNN models with holistic and multi-patch inputs and combine their predicted scores to integrate multi-scale information. During experiments, we validate the complementarity of both kinds of inputs. We also validate that our combined predictions have a more consistent ranking correlation with our ground truth than the average of individual users judgments. Furthermore, we apply the fully convolutional version of our trained model to visualize defect severity heat maps, which can effectively identify defective regions of input images. We propose that our work will provide casual photographers with better experiences when using image editing software to improve image quality. Another promising avenue for future application involves the equipping of photo summarization systems with defect cues to focus more on defect-free photos.

In this paper, the production decisions across multiple energy suppliers in smart grid, powering cellular networks are investigated. The suppliers are characterized by different offered prices and pollutant emissions levels. The challenge is to decide the amount of energy provided by each supplier to each of the operators such that their profitability is maximized while respecting the maximum tolerated level of CO emissions. The cellular operators are characterized by their offered quality of service QoS to the subscribers and the number of users that determines their energy requirements. Stochastic geometry is used to determine the average power needed to achieve the target probability of coverage for each operator. The total average power requirements of all networks are fed to an optimization framework to find the optimal amount of energy to be provided from each supplier to the operators. The generalized alpha-fair utility function is used to avoid production bias among the suppliers based on profitability of generation. Results illustrate the production behavior of the energy suppliers versus QoS level, cost of energy, capacity of generation, and level of fairness.

We introduce type annotations as a flexible typing mechanism for graph systems and discuss their advantages with respect to classical typing based on graph morphisms. In this approach the type system is incorporated with the graph and elements can adapt to changes in context by changing their type annotations. We discuss some case studies in which this mechanism is relevant.

Bigraphs are an emerging modeling formalism for structures in ubiquitous computing. Besides an algebraic notation, which can be adopted to provide an algebraic syntax for bigraphs, the bigraphical theory introduces a visual concrete syntax which is intuitive and unambiguous at the same time the standard visual notation can be customized and thus tailored to domain-specific requirements. However, in contrast to modeling standards based on the Meta-Object Facility MOF and domain-specific languages typically used in model-driven engineering MDE, the bigraphical theory lacks a precise definition of an abstract syntax for bigraphical modeling languages. As a consequence, available modeling and analysis tools use proprietary formats for representing bigraphs internally and persistently, which hampers the exchange of models across tool boundaries. Moreover, tools can be hardly integrated with standard MDE technologies in order to build sophisticated tool chains and modeling environments, as required for systematic engineering of large systems or fostering experimental work to evaluate the bigraphical theory in real-world applications. To overcome this situation, we propose an abstract syntax for bigraphs which is compliant to the Essential MOF EMOF standard defined by the Object Management Group OMG. We use typed graphs as a formal underpinning of EMOF-based models and present a canonical mapping which maps bigraphs to typed graphs in a natural way. We also discuss application-specific variation points in the graph-based representation of bigraphs. Following standard techniques from software product line engineering, we present a framework to customize the graph-based representation to support a variety of application scenarios.

We propose a new approach for modelling the process of RNA folding as a graph transformation guided by the global value of free energy. Since the folding process evolves towards a configuration in which the free energy is minimal, the global behaviour resembles the one of a self-adaptive system. Each RNA configuration is a graph and the evolution of configurations is constrained by precise rules that can be described by a graph grammar.

Graph Transformation GraTra provides a formal, declarative means of specifying model transformation. In practice, GraTra rule applications are often programmed via an additional language with which the order of rule applications can be suitably controlled.   Story-Driven Modelling SDM is a dialect of programmed GraTra, originally developed as part of the Fujaba CASE tool suite. Using an intuitive, UML-inspired visual syntax, SDM provides usual imperative control flow constructs such as sequences, conditionals and loops that are fairly simple, but whose interaction with individual GraTra rules is nonetheless non-trivial. In this paper, we present the first results of our ongoing work towards providing a formal step semantics for SDM, which focuses on the execution of an SDM specification.

Nowadays, graph databases are employed when relationships between entities are in the scope of database queries to avoid performance-critical join operations of relational databases. Graph queries are used to query and modify graphs stored in graph databases. Graph queries employ graph pattern matching that is NP-complete for subgraph isomorphism. Graph database views can be employed that keep ready answers in terms of precalculated graph pattern matches for often stated and complex graph queries to increase query performance. However, such graph database views must be kept consistent with the graphs stored in the graph database.   In this paper, we describe how to use incremental graph pattern matching as technique for maintaining graph database views. We present an incremental maintenance algorithm for graph database views, which works for imperatively and declaratively specified graph queries. The evaluation shows that our maintenance algorithm scales when the number of nodes and edges stored in the graph database increases. Furthermore, our evaluation shows that our approach can outperform existing approaches for the incremental maintenance of graph query results.

The frequency scarcity imposed by fast growing demand for mobile data service requires promising spectrum aggregation systems. The so-called higher-order statistics HOS of the channel capacity is a suitable metric on the system performance. While prior relevant works have improved our knowledge on the HOS characterization of spectrum aggregation systems, an analytical framework encompassing generalized fading models of interest is not yet available. In this paper, we pursue a detailed HOS analysis of kappa-mu and kappa-mu shadowed fading channels by deriving novel and exact expressions. Furthermore, the simplified HOS expressions for the asymptotically low and high signal-to-noise regimes are derived. Several important statistical measures, such as amount of fading, amount of dispersion, reliability, skewness, and kurtosis, are obtained by using the HOS results. More importantly, the useful implications of system and fading parameters on spectrum aggregation systems are investigated for channel selection. Finally, all derived expressions are validated via Monte-Carlo simulations.

Closed kinematic chains are created whenever multiple robot arms concurrently manipulate a single object. The closed-chain constraint, when coupled with robot joint limits, dramatically changes the connectivity of the configuration space. We propose a regrasping move, termed IK-switch, which allows efficiently bridging components of the configuration space that are otherwise mutually disconnected. This move, combined with several other developments, such as a method to stabilize the manipulated object using the environment, a new tree structure, and a compliant control scheme, enables us to address complex closed-chain manipulation tasks, such as flipping a chair frame, which is otherwise impossible to realize using a single arm or existing multi-arm planning methods.

Correlation functions are often employed to quantify the relationships among interdependent variables or sets of data. Recently, a new class of correlation functions, called Forrelation, has been introduced by Aaronson and Ambainis for studying the query complexity of quantum devices. It was found that there exists a quantum query algorithm solving -fold Forrelation problems with an exponential quantum speedup over all possible classical means, which represents essentially the largest possible separation between quantum and classical query complexities. Here we report an experimental study probing the -fold and -fold Forrelations encoded in nuclear spins. The major experimental challenge is to control the spin fluctuation to within a threshold value, which is achieved by developing a set of optimized GRAPE pulse sequences. Overall, our small-scale implementation indicates that the quantum query algorithm is capable of determine the values of Forrelations within an acceptable accuracy required for demonstrating quantum supremacy, given the current technology and in the presence of experimental noise.

Boundary incompleteness raises great challenges to automatic prostate segmentation in ultrasound images. Shape prior can provide strong guidance in estimating the missing boundary, but traditional shape models often suffer from hand-crafted descriptors and local information loss in the fitting procedure. In this paper, we attempt to address those issues with a novel framework. The proposed framework can seamlessly integrate feature extraction and shape prior exploring, and estimate the complete boundary with a sequential manner. Our framework is composed of three key modules. Firstly, we serialize the static D prostate ultrasound images into dynamic sequences and then predict prostate shapes by sequentially exploring shape priors. Intuitively, we propose to learn the shape prior with the biologically plausible Recurrent Neural Networks RNNs. This module is corroborated to be effective in dealing with the boundary incompleteness. Secondly, to alleviate the bias caused by different serialization manners, we propose a multi-view fusion strategy to merge shape predictions obtained from different perspectives. Thirdly, we further implant the RNN core into a multiscale Auto-Context scheme to successively refine the details of the shape prediction map. With extensive validation on challenging prostate ultrasound images, our framework bridges severe boundary incompleteness and achieves the best performance in prostate boundary delineation when compared with several advanced methods. Additionally, our approach is general and can be extended to other medical image segmentation tasks, where boundary incompleteness is one of the main challenges.

The query-by-image video retrieval QBIVR task has been attracting considerable research attention recently. However, most existing methods represent a video by either aggregating or projecting all its frames into a single datum point, which may easily cause severe information loss. In this paper, we propose an efficient QBIVR framework to enable an effective and efficient video search with image query. We first define a similarity-preserving distance metric between an image and its orthogonal projection in the subspace of the video, which can be equivalently transformed to a Maximum Inner Product Search MIPS problem.   Besides, to boost the efficiency of solving the MIPS problem, we propose two asymmetric hashing schemes, which bridge the domain gap of images and videos. The first approach, termed Inner-product Binary Coding IBC, preserves the inner relationships of images and videos in a common Hamming space. To further improve the retrieval efficiency, we devise a Bilinear Binary Coding BBC approach, which employs compact bilinear projections instead of a single large projection matrix. Extensive experiments have been conducted on four real-world video datasets to verify the effectiveness of our proposed approaches as compared to the state-of-the-arts.

Algorithmic dimensions quantify the algorithmic information density of individual points and may be defined in terms of Kolmogorov complexity. This work uses these dimensions to bound the classical Hausdorff and packing dimensions of intersections and Cartesian products of fractals in Euclidean spaces. This approach shows that a known intersection formula for Borel sets holds for arbitrary sets, and it significantly simplifies the proof of a known product formula. Both of these formulas are prominent, fundamental results in fractal geometry that are taught in typical undergraduate courses on the subject.

In this paper, we address learning problems for high dimensional data. Previously, oblivious random projection based approaches that project high dimensional features onto a random subspace have been used in practice for tackling high-dimensionality challenge in machine learning. Recently, various non-oblivious randomized reduction methods have been developed and deployed for solving many numerical problems such as matrix product approximation, low-rank matrix approximation, etc. However, they are less explored for the machine learning tasks, e.g., classification. More seriously, the theoretical analysis of excess risk bounds for risk minimization, an important measure of generalization performance, has not been established for non-oblivious randomized reduction methods. It therefore remains an open problem what is the benefit of using them over previous oblivious random projection based approaches. To tackle these challenges, we propose an algorithmic framework for employing non-oblivious randomized reduction method for general empirical risk minimizing in machine learning tasks, where the original high-dimensional features are projected onto a random subspace that is derived from the data with a small matrix approximation error. We then derive the first excess risk bound for the proposed non-oblivious randomized reduction approach without requiring strong assumptions on the training data. The established excess risk bound exhibits that the proposed approach provides much better generalization performance and it also sheds more insights about different randomized reduction approaches. Finally, we conduct extensive experiments on both synthetic and real-world benchmark datasets, whose dimension scales to O, to demonstrate the efficacy of our proposed approach.

We present a new benchmark dataset for video question answering VideoQA designed to evaluate algorithms capability of spatio-temporal event understanding. Existing datasets either require very high-level reasoning from multi-modal information to find answers, or is mostly composed of the questions that can be answered by watching a single frame. Therefore, they are not suitable to evaluate models real capacity and flexibility for VideoQA. To overcome such critical limitations, we focus on event-centric questions that require understanding temporal relation between multiple events in videos. An interesting idea in dataset construction process is that question-answer pairs are automatically generated from Super Mario video gameplays given a set of question templates. We also tackle VideoQA problem in the new dataset, referred to as MarioQA, by proposing spatio-temporal attention models based on deep neural networks. Our experiments show that the proposed deep neural network models with attention have meaningful performance improvement over several baselines.

Cloud computing provides a great opportunity for scientists, as it enables large-scale experiments that cannot are too long to run on local desktop machines. Cloud-based computations can be highly parallel, long running and data-intensive, which is desirable for many kinds of scientific experiments. However, to unlock this power, we need a user-friendly interface and an easy-to-use methodology for conducting these experiments. For this reason, we introduce here a formal model of a cloud-based platform and the corresponding open-source implementation. The proposed solution allows to conduct experiments without having a deep technical understanding of cloud-computing, HPC, fault tolerance, or data management in order to leverage the benefits of cloud computing. In the current version, we have focused on biophysics and structural chemistry experiments, based on the analysis of big data from synchrotrons and atomic force microscopy. The domain experts noted the time savings for computing and data management, as well as user-friendly interface.

Supervised topic models can help clinical researchers find interpretable cooccurence patterns in count data that are relevant for diagnostics. However, standard formulations of supervised Latent Dirichlet Allocation have two problems. First, when documents have many more words than labels, the influence of the labels will be negligible. Second, due to conditional independence assumptions in the graphical model the impact of supervised labels on the learned topic-word probabilities is often minimal, leading to poor predictions on heldout data. We investigate penalized optimization methods for training sLDA that produce interpretable topic-word parameters and useful heldout predictions, using recognition networks to speed-up inference. We report preliminary results on synthetic data and on predicting successful anti-depressant medication given a patients diagnostic history.

Application of formal models provides many benefits for the software and system development, however, the learning curve of formal languages could be a critical factor for an industrial project. Thus, a natural language specification that reflects all the aspects of the formal model might help to understand the model and be especially useful for the stakeholders who do not know the corresponding formal language. Moreover, an automated generation of the documentation from the model would replace manual updates of the documentation for the cases the model is modified. This paper presents an ongoing work on generating natural language specifications from formal models. Our goal is to generate documentation in English from the basic modelling artefacts, such as data types, state machines, and architectural components. To allow further formal analysis of the generated specification, we restrict English to its subset, Attempto Controlled English.

This paper provides an overview of common challenges in teaching of logic and formal methods to Computer Science and IT students. We discuss our experiences from the course IN Applied Logic in Engineering, introduced as a logic for everybody elective course at at TU Munich, Germany, to engage pupils studying Computer Science, IT and engineering subjects on Bachelor and Master levels. Our goal was to overcome the bias that logic and formal methods are not only very complicated but also very boring to study and to apply. In this paper, we present the core structure of the course, provide examples of exercises and evaluate the course based on the students surveys.

Traffic load-balancing in datacenters alleviates hot spots and improves network utilization. In this paper, a stable in-network load-balancing algorithm is developed in the setting of software-defined networking. A control plane configures a data plane over successive intervals of time. While the MaxWeight algorithm can be applied in this setting and offers certain throughput optimality properties, its bang-bang control structure rewards single flows on each interval and prohibits link-capacity sharing. This paper develops a new algorithm that is throughput-optimal and allows link-capacity sharing, leading to low queue occupancy. The algorithm deliberately imitates weighted fair queueing, which provides fairness and graceful interaction with TCP traffic. Inspired by insights from the analysis, a heuristic improvement is also developed to operate with practical switches and TCP flows. Simulations from a network simulator shows that the algorithm outperforms the widely-used equal-cost multipath ECMP technique.

This paper presents our ongoing work on spatio-temporal models for formal analysis and property-based testing. Our proposed framework aims at reducing the impedance mismatch between formal methods and practitioners. We introduce a set of formal methods and explain their interplay and benefits in terms of usability.

Feature point matching for camera localization suffers from scalability problems. Even when feature descriptors associated with D scene points are locally unique, as coverage grows, similar or repeated features become increasingly common. As a result, the standard distance ratio-test used to identify reliable image feature points is overly restrictive and rejects many good candidate matches. We propose a simple coarse-to-fine strategy that uses conservative approximations to robust local ratio-tests that can be computed efficiently using global approximate k-nearest neighbor search. We treat these forward matches as votes in camera pose space and use them to prioritize back-matching within candidate camera pose clusters, exploiting feature co-visibility captured by clustering the D model camera pose graph. This approach achieves state-of-the-art camera localization results on a variety of popular benchmarks, outperforming several methods that use more complicated data structures and that make more restrictive assumptions on camera pose. We also carry out diagnostic analyses on a difficult test dataset containing globally repetitive structure that suggest our approach successfully adapts to the challenges of large-scale image localization.

In the classic Vehicle Routing Problem VRP a fleet of of vehicles has to visit a set of customers while minimising the operations costs. We study a rich variant of the VRP featuring split deliveries, an heterogeneous fleet, and vehicle-commodity incompatibility constraints. Our goal is twofold define the cheapest routing and the most adequate fleet.   To do so, we split the problem into two interdependent components a fleet design component and a routing component. First, we define two Mixed Integer Programming MIP formulations for each component. Then we discuss several improvements in the form of valid cuts and symmetry breaking constraints.   The main contribution of this paper is a comparison of the four resulting models for this Rich VRP. We highlight their strengths and weaknesses with extensive experiments.   Finally, we explore a lightweight integration with Constraint Programming CP. We use a fast CP model which gives good solutions and use the solution to warm-start our models.

The subset sum problem, also referred as SSP, is a NP-Hard computational problem. SSP has its applications in broad domains like cryptography, number theory, operation research and complexity theory. The most famous algorithm for solving SSP is Backtracking Algorithm which has exponential time complexity. Therefore, our goal is to design and develop better alternate enumeration techniques for faster generation of SSP solutions. Given the set of first n natural numbers which is denoted by Xn and a target sum S, we propose various alternate enumeration techniques which find all the subsets of Xn that add up to sum S.   In this paper, we present the mathematics behind this exponential problem. We analyze the distribution of power set of Xn and present formulas which show definite patterns and relations among these subsets. We introduce three major distributions for power set of Xn Sum Distribution, Length-Sum Distribution and Element Distribution. These distributions are prepossessing procedures for various alternate enumeration techniques for solving SSP. We propose novel algorithms Subset Generation using Sum Distribution, Subset Generation using Length-Sum Distribution, Basic Bucket Algorithm, Maximum and Minimum Frequency Driven Bucket Algorithms and Local Search using Maximal and Minimal Subsets for enumerating SSP.   We compare the performance of these approaches against the traditional backtracking algorithm. The efficiency and effectiveness of these algorithms are presented with the help of these experimental results. Furthermore, we studied the over solution set of subsets generated by various algorithms to get the complete solution for subset sum problem. Finally, we present a conjecture about upper bound on the number of subsets that has to be enumerated to get all solutions for Subset Sum Problem.

In the polytope membership problem, a convex polytope K in Rd is given, and the objective is to preprocess K into a data structure so that, given a query point q in Rd, it is possible to determine efficiently whether q in K. We consider this problem in an approximate setting and assume that d is a constant. Given an approximation parameter varepsilon  , the query can be answered either way if the distance from q to Ks boundary is at most varepsilon times Ks diameter. Previous solutions to the problem were on the form of a space-time trade-off, where logarithmic query time demands Ovarepsilond- storage, whereas storage Ovarepsilond- admits roughly Ovarepsilond- query time. In this paper, we present a data structure that achieves logarithmic query time with storage of only Ovarepsilond-, which matches the worst-case lower bound on the complexity of any varepsilon-approximating polytope. Our data structure is based on a new technique, a hierarchy of ellipsoids defined as approximations to Macbeath regions.   As an application, we obtain major improvements to approximate Euclidean nearest neighbor searching. Notably, the storage needed to answer varepsilon-approximate nearest neighbor queries for a set of n points in Olog fracnvarepsilon time is reduced to Onvarepsilond. This halves the exponent in the varepsilon-dependency of the existing space bound of roughly Onvarepsilond, which has stood for  years Har-Peled, .

This paper presents a deep neural network-based approach to image quality assessment IQA. The network can be trained end-to-end and comprises  convolutional layers and  pooling layers for feature extraction, and  fully connected layers for regression, which makes it significantly deeper than related IQA methods. An unique feature of the proposed architecture is that it can be used with slight adaptations in a no-reference NR as well as in a full-reference FR IQA setting. Our approach is purely data-driven and does not rely on hand-crafted features or other types of prior domain knowledge about the human visual system or image statistics. The network estimates perceived quality patchwise the overall image quality is calculated as the average of these patchwise scores. In order to consider the locally non-uniform distribution of perceived quality in images, we introduce a spatial attention mechanism which performs a weighted aggregation of the patchwise scores. We evaluate the proposed approach on the LIVE, CISQ and TID databases and show superior performance to state-of-the-art NR and FR IQA methods. Finally, cross-database evaluation shows a high ability to generalize between different datasets, indicating a high robustness of the learned features.

Core-periphery structure and community structure are two typical meso-scale structures in complex networks. Though the community detection has been extensively investigated from different perspectives, the definition and the detection of core-periphery structure have not been attracted enough attention. Furthermore, the detection problem of the core-periphery and community structure was separately investigated previously. In this paper, we develop a unified framework to simultaneously detect core-periphery structure and community structure in complex networks. Moreover, there are several extra advantages of our algorithm our method can detect not only single but also multiple core-periphery structures the overlapping nodes belonging to different communities can be identified by adjusting the size of core, different scales of core-periphery structures can be detected. The good performance of the method has been validated on synthetic and real complex networks. So we provide a basic framework to detect the two typical meso-scale structures core-periphery structure and community structure.

This paper focuses on Byzantine attack detection for Gaussian two-way relay network. In this network, two source nodes communicate with each other with the help of an amplify-and-forward relay which may perform Byzantine attacks by forwarding altered symbols to the sources. For simple investigating the detectability of attacks conducted in Gaussian channels, we focus on the MA channel of the network, while assuming the BC channel is noiseless. Upon such model, we propose a attack detection scheme implemented in the sources. Specifically, we consider a open wireless propagation environment that allows the symbols, forwarded by the relay, to go through a continuous channel and arrive to the sources. With the observations of the source, we develop a detection scheme for the source by comparing the joint empirical distribution of its received and transmitted signals with the known channel statistics. The main contribution of this paper is to prove that if and only if the Gaussian relay network satisfies a non-manipulable channel condition, the proposed detection scheme can detect arbitrary attacks that allows the stochastic distributions of altered symbols to vary arbitrarily and depend on each other. No pre-shared secret or secret transmission is needed for the detection. Furthermore, we also prove that for the considered Gaussian two-way relay networks, the non-manipulable channel condition is always satisfied. This result indicates that arbitrary attacks conducted in MA Gaussian channels are detectable by only using observations, while providing a base for attack detection in more general Gaussian networks.

Once referred to as the missing circuit component, memristor has come long way across to be recognized and taken as important to future circuit designs. The memristor due to its ability to memorize the state, switch between different resistance level, smaller size and low leakage currents makes it useful for a wide range of intelligent memory and computing applications. This overview paper highlights broadly provides the uses of memristor in the implementation of cognitive cells for different imaging and pattern matching applications.

Revealing hidden features in unlabeled data is called unsupervised feature learning, which plays an important role in pretraining a deep neural network. Here we provide a statistical mechanics analysis of the unsupervised learning in a restricted Boltzmann machine with binary synapses. A message passing equation to infer the hidden feature is derived, and furthermore, variants of this equation are analyzed. A statistical analysis by replica theory describes the thermodynamic properties of the model. Our analysis confirms an entropy crisis preceding the non-convergence of the message passing equation, suggesting a discontinuous phase transition as a key characteristic of the restricted Boltzmann machine. Continuous phase transition is also confirmed depending on the embedded feature strength in the data. The mean-field result under the replica symmetric assumption agrees with that obtained by running message passing algorithms on single instances of finite sizes. Interestingly, in an approximate Hopfield model, the entropy crisis is absent, and a continuous phase transition is observed instead. We also develop an iterative equation to infer the hyper-parameter temperature hidden in the data, which in physics corresponds to iteratively imposing Nishimori condition. Our study provides insights towards understanding the thermodynamic properties of the restricted Boltzmann machine learning, and moreover important theoretical basis to build simplified deep networks.

A low-rank matrix with diffuse entries can be efficiently reconstructed after observing a few of its entries, at random, and then solving a convex program. In many applications, in addition to these measurements, potentially valuable prior knowledge about the column and row spaces of the matrix is also available to the practitioner. In this paper, we incorporate this prior knowledge in matrix completion---by minimizing a weighted nuclear norm---and precisely quantify any improvements. In particular, in theory, we find that reliable prior knowledge reduces the sample complexity of matrix completion by a logarithmic factor the observed improvement is considerably more magnified in numerical simulations. We also present similar results for the closely related problem of matrix recovery from generic linear measurements.

Let GV,A be a directed graph without parallel arcs, and let Ssubseteq V be a set of vertices. Let the sequence SSsubseteq Ssubseteq Ssubseteqcdots be defined as follows S is obtained from S by adding all out-neighbors of vertices in S. For kgeqslant , Sk is obtained from Sk- by adding all vertices w such that for some vertex vin Sk-, w is the unique out-neighbor of v in Vsetminus Sk-. We set MSScup Scupcdots, and call S a emphpower dominating set for G if MSVG. The minimum cardinality of such a set is called the emphpower domination number of G. In this paper, we determine the power domination numbers of de Bruijn and Kautz digraphs.

Stereo reconstruction from rectified images has recently been revisited within the context of deep learning. Using a deep Convolutional Neural Network to obtain patch-wise matching cost volumes has resulted in state of the art stereo reconstruction on classic datasets like Middlebury and Kitti. By introducing this cost into a classical stereo pipeline, the final results are improved dramatically over non-learning based cost models. However these pipelines typically include hand engineered post processing steps to effectively regularize and clean the result. Here, we show that it is possible to take a more holistic approach by training a fully end-to-end network which directly includes regularization in the form of a densely connected Conditional Random Field CRF that acts as a prior on inter-pixel interactions. We demonstrate that our approach on both synthetic and real world datasets outperforms an alternative end-to-end network and compares favorably to more hand engineered approaches.

We propose new sequent calculus systems for orthologic also known as minimal quantum logic which satisfy the cut elimination property. The first one is a very simple system relying on the involutive status of negation. The second one incorporates the notion of focusing coming from linear logic to add constraints on proofs and thus to facilitate proof search. We demonstrate how to take benefits from the new systems in automatic proof search for orthologic.

With the growing use of popular social media services like Facebook and Twitter it is hard to collect all content from the networks without access to the core infrastructure or paying for it. Thus, if all content cannot be collected one must consider which data are of most importance. In this work we present a novel User-guided Social Media Crawling method USMC that is able to collect data from social media, utilizing the wisdom of the crowd to decide the order in which user generated content should be collected, to cover as many user interactions as possible. USMC is validated by crawling  Facebook public pages, containing  million users and . billion interactions, and it is compared with two other crawling methods. The results show that it is possible to cover approximately  of the interactions on a Facebook page by sampling just  of its posts, and at the same time reduce the crawling time by . What is more, the social network constructed from the  sample has more than  of the users and edges compared to the social network created from all posts, and has very similar degree distribution.

This paper proposes a first attempt to build an end-to-end speech-to-text translation system, which does not use source language transcription during learning or decoding. We propose a model for direct speech-to-text translation, which gives promising results on a small French-English synthetic corpus. Relaxing the need for source language transcription would drastically change the data collection methodology in speech translation, especially in under-resourced scenarios. For instance, in the former project DARPA TRANSTAC speech translation from spoken Arabic dialects, a large effort was devoted to the collection of speech transcripts and a prerequisite to obtain transcripts was often a detailed transcription guide for languages with little standardized spelling. Now, if end-to-end approaches for speech-to-text translation are successful, one might consider collecting data by asking bilingual speakers to directly utter speech in the source language from target language text utterances. Such an approach has the advantage to be applicable to any unwritten source language.

Scarce data is a major challenge to scaling robot learning to truly complex tasks, as we need to generalize locally learned policies over different contexts. Bayesian optimization approaches to contextual policy search CPS offer data-efficient policy learning that generalize over a context space. We propose to improve data- efficiency by factoring typically considered contexts into two components target- type contexts that correspond to a desired outcome of the learned behavior, e.g. target position for throwing a ball and environment type contexts that correspond to some state of the environment, e.g. initial ball position or wind speed. Our key observation is that experience can be directly generalized over target-type contexts. Based on that we introduce Factored Contextual Policy Search with Bayesian Optimization for both passive and active learning settings. Preliminary results show faster policy generalization on a simulated toy problem.

Given a string S of length n, the classic string indexing problem is to preprocess S into a compact data structure that supports efficient subsequent pattern queries. In the emphdeterministic variant the goal is to solve the string indexing problem without any randomization at preprocessing time or query time. In the emphpacked variant the strings are stored with several character in a single word, giving us the opportunity to read multiple characters simultaneously. Our main result is a new string index in the deterministic emphand packed setting. Given a packed string S of length n over an alphabet sigma, we show how to preprocess S in On deterministic time and space On such that given a packed pattern string of length m we can support queries in deterministic time Oleftmalpha  log m  log log sigmaright,  where alpha  w  log sigma is the number of characters packed in a word of size w  Thetalog n. Our query time is always at least as good as the previous best known bounds and whenever several characters are packed in a word, i.e., log sigma ll w, the query times are faster.

Modern imaging systems typically use single-carrier short pulses for transducer excitation. Coded signals together with pulse compression are successfully used in radar and communication to increase the amount of transmitted energy. Previous research verified significant improvement in SNR and imaging depth for ultrasound imaging with coded signals. Since pulse compression needs to be applied at each transducer element, the implementation of coded excitation CE in array imaging is computationally complex. Applying pulse compression on the beamformer output reduces the computational load but also degrades both the axial and lateral point spread function PSF compromising image quality. In this work we present an approach for efficient implementation of pulse compression by integrating it into frequency domain beamforming. This method leads to significant reduction in the amount of computations without affecting axial resolution. The lateral resolution is dictated by the factor of savings in computational load. We verify the performance of our method on a Verasonics imaging system and compare the resulting images to time-domain processing. We show that up to  fold reduction in computational complexity can be achieved in a typical imaging setups. The efficient implementation makes CE a feasible approach in array imaging paving the way to enhanced SNR as well as improved imaging depth and frame-rate.

Metric facility location and K-means are well-known problems of combinatorial optimization. Both admit a fairly simple heuristic called single-swap, which adds, drops or swaps open facilities until it reaches a local optimum. For both problems, it is known that this algorithm produces a solution that is at most a constant factor worse than the respective global optimum. In this paper, we show that single-swap applied to the weighted metric uncapacitated facility location and weighted discrete K-means problem is tightly PLS-complete and hence has exponential worst-case running time.

A novel analytical approach to the synthesis of electrical e.g. analogue, digital or microwave filters is proposed. This approach allows to obtain lowest possible degree filters with given involved specification including e.g. many pass and stop bands, narrow transition bands, high attenuation at the stop bands and low magnitude oscillations at the pass bands. Comparison to other existing approaches is given.

We present the Video Ladder Network VLN for efficiently generating future video frames. VLN is a neural encoder-decoder model augmented at all layers by both recurrent and feedforward lateral connections. At each layer, these connections form a lateral recurrent residual block, where the feedforward connection represents a skip connection and the recurrent connection represents the residual. Thanks to the recurrent connections, the decoder can exploit temporal summaries generated from all layers of the encoder. This way, the top layer is relieved from the pressure of modeling lower-level spatial and temporal details. Furthermore, we extend the basic version of VLN to incorporate ResNet-style residual blocks in the encoder and decoder, which help improving the prediction results. VLN is trained in self-supervised regime on the Moving MNIST dataset, achieving competitive results while having very simple structure and providing fast inference.

Bibliometrics is successful in measuring impact, because the target is clearly defined the publishing scientist who is still active and working. Thus, citations are a target-oriented metric which measures impact on science. In contrast, societal impact measurements based on altmetrics are as a rule intended to measure impact in a broad sense on all areas of society e.g. science, culture, politics, and economics. This tendency is especially reflected in the efforts to design composite indicators e.g. the Altmetric attention score. We deem appropriate that not only the impact measurement using citations is target-oriented citations measure the impact of papers on scientists, but also the measurement of impact using altmetrics. Impact measurements only make sense, if the target group - the recipient of academic papers - is clearly defined. Thus, we extend in this study the field-normalized reader impact indicator proposed by us in an earlier study, which is based on Mendeley data the mean normalized reader score, MNRS, to a target-oriented field-normalized impact indicator e.g., MNRSED measures reader impact on the sector of educational donation, i.e., teaching. This indicator can show - as demonstrated in empirical examples - the ability of journals, countries, and academic institutions to publish papers which are below or above the average impact of papers on a specific sector in society e.g., the educational or teaching sector. For example, the method allows to measure the impact of scientific papers on students - controlling for the field in which the papers have been published and their publication year.

The emergence of large stores of transactional data generated by increasing use of digital devices presents a huge opportunity for policymakers to improve their knowledge of the local environment and thus make more informed and better decisions. A research frontier is hence emerging which involves exploring the type of measures that can be drawn from data stores such as mobile phone logs, Internet searches and contributions to social media platforms, and the extent to which these measures are accurate reflections of the wider population. This paper contributes to this research frontier, by exploring the extent to which local commuting patterns can be estimated from data drawn from Twitter. It makes three contributions in particular. First, it shows that simple heuristics drawn from geolocated Twitter data offer a good proxy for local commuting patterns one which outperforms the major existing method for estimating these patterns the radiation model. Second, it investigates sources of error in the proxy measure, showing that the model performs better on short trips with higher volumes of commuters it also looks at demographic biases but finds that, surprisingly, measurements are not significantly affected by the fact that the demographic makeup of Twitter users differs significantly from the population as a whole. Finally, it looks at potential ways of going beyond simple heuristics by incorporating temporal information into models.

The management of identities on the Internet has evolved from the traditional approach where each service provider stores and manages identities to a federated identity management system where the identity management is delegated to a set of identity providers. On the one hand, federated identity ensures usability and provides economic benefits to service providers. On the other hand, it poses serious privacy threats to users as well as service providers. The current technology, which is prevalently deployed on the Internet, allows identity providers to track the users behavior across a broad range of services.   In this work, we propose PRIMA, a universal credential-based authentication system for supporting federated identity management in a privacy-preserving manner. Basically, PRIMA does not require any interaction between service providers and identity providers during the authentication process, thus preventing identity providers to profile users behavior. Moreover, throughout the authentication process, PRIMA provides a mechanism for controlled disclosure of the users private information. We have conducted comprehensive evaluations of the system to show the feasibility of our approach. Our performance analysis shows that an identity provider can process , to , requests per second when the key size is varied from  to -bit, respectively.

Bootstrap is commonly used as a tool for non-parametric statistical inference to estimate meaningful parameters in Variable Selection Models. However, for massive dataset that has exponential growth rate, the computation of Bootstrap Variable Selection BootVS can be a crucial issue. In this paper, we propose the method of Variable Selection with Bag of Little Bootstraps BLBVS on General Linear Regression and extend it to Generalized Linear Model for selecting important parameters and assessing the quality of estimators computation efficiency by analyzing results of multiple bootstrap sub-samples. The introduced method best suits large datasets which have parallel and distributed computing structures. To test the performance of BLBVS, we compare it with BootVS from different aspects via empirical studies. The results of simulations show our method has excellent performance. A real data analysis, Risk Forecast of Credit Cards, is also presented to illustrate the computational superiority of BLBVS on large scale datasets, and the result demonstrates the usefulness and validity of our proposed method.

Benefiting from its high efficiency and simplicity, Simple Linear Iterative Clustering SLIC remains one of the most popular over-segmentation tools. However, due to explicit enforcement of spatial similarity for region continuity, the boundary adaptation of SLIC is sub-optimal. It also has drawbacks on convergence rate as a result of both the fixed search region and separately doing the assignment step and the update step. In this paper, we propose an alternative approach to fix the inherent limitations of SLIC. In our approach, each pixel actively searches its corresponding segment under the help of its neighboring pixels, which naturally enables region coherence without being harmful to boundary adaptation. We also jointly perform the assignment and update steps, allowing high convergence rate. Extensive evaluations on Berkeley segmentation benchmark verify that our method outperforms competitive methods under various evaluation metrics. It also has the lowest time cost among existing methods approximately fps for a x image on a single CPU core.

In this paper, we consider the patient similarity matching problem over a cancer cohort of more than , patients. Our approach first leverages on WordVec framework to embed ICD codes into vector-valued representation. We then propose a sequential algorithm for case-control matching on this representation space of diagnosis codes. The novel practice of applying the sequential matching on the vector representation lifted the matching accuracy measured through multiple clinical outcomes. We reported the results on a large-scale dataset to demonstrate the effectiveness of our method. For such a large dataset where most clinical information has been codified, the new method is particularly relevant.

The purpose of this article is to illustrate the role of connections and symmetries in the Wheeled Inverted Pendulum WIP mechanism - an underactuated system with rolling constraints - popularized commercially as the Segway, and thereby arrive at a set of simpler dynamical equations that could serve as the starting point for more complex feedback control designs. The first part of the article views the nonholonomic constraints enforced by the rolling assumption as defining an Ehresmann connection on a fiber bundle. The resulting equations are the reduced Euler-Lagrange equations, which are identical to the Lagrange dAlembert equations of motion. In the second part we explore conserved quantities, in particular, nonholonomic momenta. To do so, we first introduce the notion of a symmetry group, whose action leaves both the Lagrangian and distribution invariant. We examine two symmetry groups - SE  and SE times mathbbS. The first group leads to the purely kinematic case while the second gives rise to nonholonomic momentum equations.

We study pseudodeterministic constructions, i.e., randomized algorithms which output the same solution on most computation paths. We establish unconditionally that there is an infinite sequence pnn in mathbbN of increasing primes and a randomized algorithm A running in expected sub-exponential time such that for each n, on input pn, A outputs pn with probability . In other words, our result provides a pseudodeterministic construction of primes in sub-exponential time which works infinitely often.   This result follows from a much more general theorem about pseudodeterministic constructions. A property Q subseteq , is gamma-dense if for large enough n, Q cap ,n geq gamma n. We show that for each c   at least one of the following holds  There is a pseudodeterministic polynomial time construction of a family Hn of sets, Hn subseteq ,n, such that for each nc-dense property Q in mathsfDTIMEnc and every large enough n, Hn cap Q neq emptyset or  There is a deterministic sub-exponential time construction of a family Hn of sets, Hn subseteq ,n, such that for each nc-dense property Q in mathsfDTIMEnc and for infinitely many values of n, Hn cap Q neq emptyset.   We provide further algorithmic applications that might be of independent interest. Perhaps intriguingly, while our main results are unconditional, they have a non-constructive element, arising from a sequence of applications of the hardness versus randomness paradigm.

Pulmonary emphysema is traditionally subcategorized into three subtypes, which have distinct radiological appearances on computed tomography CT and can help with the diagnosis of chronic obstructive pulmonary disease COPD. Automated texture-based quantification of emphysema subtypes has been successfully implemented via supervised learning of these three emphysema subtypes. In this work, we demonstrate that unsupervised learning on a large heterogeneous database of CT scans can generate texture prototypes that are visually homogeneous and distinct, reproducible across subjects, and capable of predicting accurately the three standard radiological subtypes. These texture prototypes enable automated labeling of lung volumes, and open the way to new interpretations of lung CT scans with finer subtyping of emphysema.

In this short communication, we provide an overview of a relatively newly provided source of altmetrics data which could possibly be used for societal impact measurements in scientometrics. Recently, Altmetric - a start-up providing publication level metrics - started to make data for publications available which have been mentioned in policy-related documents. Using data from Altmetric, we study how many papers indexed in the Web of Science WoS are mentioned in policy-related documents. We find that less than . of the papers published in different subject categories are mentioned at least once in policy-related documents. Based on our results, we recommend that the analysis of WoS publications with at least one policy-related mention is repeated regularly annually. Mentions in policy-related documents should not be used for impact measurement until new policy-related sites are tracked.

Online models that allow recourse are highly effective in situations where classical models are too pessimistic. One such problem is the online machine covering problem on identical machines. In this setting jobs arrive one by one and must be assigned to machines with the objective of maximizing the minimum machine load. When a job arrives, we are allowed to reassign some jobs as long as their total size is at most proportional to the processing time of the arriving job. The proportionality constant is called the migration factor of the algorithm.   Using a new rounding procedure specially tailored for online problems, we design a varepsilon-competitive algorithm using migration factor tildeOvarepsilon. At every arrival we run an adaptation of the Largest Processing Time first LPT algorithm. Since the new job can cause a complete change of the assignment of smaller jobs, a low migration factor is achieved by carefully exploiting the highly symmetric structure obtained by our rounding.   We also study local search algorithms for the machine covering problem, and show that jump and swap optimality have an approximation ratio which lies in the interval ., . and can be adapted to the online context with a small constant as migration factor. Our lower bound is obtained by a nice construction based on Sylvesters sequence.

WTA Winner Take All hashing has been successfully applied in many large scale vision applications. This hashing scheme was tailored to take advantage of the comparative reasoning or order based information, which showed significant accuracy improvements. In this paper, we identify a subtle issue with WTA, which grows with the sparsity of the datasets. This issue limits the discriminative power of WTA. We then propose a solution for this problem based on the idea of Densification which provably fixes the issue. Our experiments show that Densified WTA Hashing outperforms Vanilla WTA both in image classification and retrieval tasks consistently and significantly.

Privacy-preserving Near-neighbor search PP-NNS is a well-studied problem in the literature. The overwhelming growth in the size of current datasets and the lack of any truly secure server in the online world render the existing solutions impractical either due to their high computational requirements or the non-realistic assumptions which potentially compromise privacy. PP-NNS with multiple semi-honest data owners having query time sub-linear in the number of users has been proposed as an open research direction. In this paper, we provide the first such algorithm which has a sub-linear query time and the ability to handle semi-honest honest but curious parties. Our algorithm can further manage the situation where a large chunk of the server information is being compromised. Probabilistic embedding based on Locality Sensitive Hashing LSH is the algorithm of choice for sub-linear near-neighbor search in high dimensions. However, we show that LSH is not suitable for semi-honest setting, and particularly when the server information is compromisable. LSH allows estimation of any pairwise distances between users, which can be easily compromised to learn user attributes using the idea of triangulation. We suggest a novel methodology which overcomes this LSH vulnerability. At the heart of our proposal lies a secure probabilistic embedding scheme generated from a novel probabilistic transformation over appropriate LSH family. Our secure embeddings combined with advances in multi-party computation result in an efficient PP-NNS algorithm suitable for massive-scale datasets without strong assumptions on the behavior of parties involved. We demonstrate the validity of our claims by experimentally showing the effectiveness of our solution in hiding the sensitive variables in medical records without compromising the precision-recall of the retrieval.

This paper proposes a chaotic map-based multicast scheme for multiuser speech wireless communication and implements it in an ARM platform. The scheme compresses the digital audio signal decoded by a sound card and then encrypts it with a three-level chaotic encryption scheme. First, the position of every bit of the compressed data is permuted randomly with a pseudo-random number sequence PRNS generated by a -D chaotic map. Then, the obtained data are further permuted in the level of byte with a PRNS generated by a -D chaotic map. Finally, it is operated with a multiround chaotic stream cipher. The whole system owns the following merits the redundancy in the original audio file is reduced effectively and the corresponding unicity distance is increased the balancing point between a high security level of the system and real-time conduction speed is achieved well. In the ARM implementation, the framework of communication of multicast-multiuser in a subnet and the Internet Group Manage Protocol is adopted to obtain the function of communication between one client and other ones. Comprehensive test results were provided to show the feasibility and security performance of the whole system.

We present a new music dataset that can be used for several music analysis tasks. Our major goal is to go beyond the existing limitations of available music datasets, which are either the small size of datasets with raw audio tracks, the availability and legality of the music data, or the lack of meta-data for artists analysis or song ratings for recommender systems. Existing datasets such as GTZAN, TagATune, and Million Song suffer from the previous limitations. It is however essential to establish such benchmark datasets to advance the field of music analysis, like the ImageNet dataset which made possible the large success of deep learning techniques in computer vision. In this paper, we introduce the Free Music Archive FMA which contains , songs and  genres spanning . days of song listening and meta-data including artist name, song title, music genre, and track counts. For research purposes, we define two additional datasets from the original one a small genre-balanced dataset of , song data and  genres compassing . hours of raw audio and a medium genre-unbalanced dataset of , data and  genres offering . days of track listening, both datasets come with meta-data and Echonest audio features. For all datasets, we provide a train-test splitting for future algorithms comparisons.

Recently, a higher dimensional Eisenstein-Jacobi networks, has been proposed in , which is shown that they have better average distance with more number of nodes than a single dimensional EJ networks. Some communication algorithms such as one-to-all and all-to-all communications are well known and used in interconnection networks. In one-to-all communication, a source node sends a message to every other node in the network. Whereas, in all-to-all communication, every node is considered as a source node and sends its message to every other node in the network. In this paper, an improved one-to-all communication algorithm in higher dimensional EJ networks is presented. The paper shows that the proposed algorithm achieves a lower average number of steps to receiving the broadcasted message. In addition, since the links are assumed to be half-duplex, the all-to-all broadcasting algorithm is divided into three phases. The simulation results are discussed and showed that the improved one-to-all algorithm achieves better traffic performance than the well-known one-to-all algorithm and has . less total number of senders

User demand on the computational resources of cloud computing platforms varies over time. These variations in demand can be predictable or unpredictable, resulting in souttime-varying and bursty fluctuations in demand. Furthermore, demand can arrive in batches, and users whose demands are not met can be impatient. We demonstrate how to compute the expected revenue loss over a finite time horizon in the presence of all these model characteristics through the use of matrix analytic methods. We then illustrate how to use this knowledge to make frequent short term provisioning decisions --- transient provisioning. It is seen that taking each of the characteristics of fluctuating user demand predictable, unpredictable, batchy into account can result in a substantial reduction of losses. Moreover, our transient provisioning framework allows for a wide variety of system behaviors to be modeled and gives simple expressions for expected revenue loss which are straightforward to evaluate numerically.

Diagnosis of a clinical condition is a challenging task, which often requires significant medical investigation. Previous work related to diagnostic inferencing problems mostly consider multivariate observational data e.g. physiological signals, lab tests etc.. In contrast, we explore the problem using free-text medical notes recorded in an electronic health record EHR. Complex tasks like these can benefit from structured knowledge bases, but those are not scalable. We instead exploit raw text from Wikipedia as a knowledge source. Memory networks have been demonstrated to be effective in tasks which require comprehension of free-form text. They use the final iteration of the learned representation to predict probable classes. We introduce condensed memory neural networks C-MemNNs, a novel model with iterative condensation of memory representations that preserves the hierarchy of features in the memory. Experiments on the MIMIC-III dataset show that the proposed model outperforms other variants of memory networks to predict the most probable diagnoses given a complex clinical scenario.

We present a new parallel algorithm for solving triangular systems with multiple right hand sides TRSM. TRSM is used extensively in numerical linear algebra computations, both to solve triangular linear systems of equations as well as to compute factorizations with triangular matrices, such as Cholesky, LU, and QR. Our algorithm achieves better theoretical scalability than known alternatives, while maintaining numerical stability, via selective use of triangular matrix inversion. We leverage the fact that triangular inversion and matrix multiplication are more parallelizable than the standard TRSM algorithm. By only inverting triangular blocks along the diagonal of the initial matrix, we generalize the usual way of TRSM computation and the full matrix inversion approach. This flexibility leads to an efficient algorithm for any ratio of the number of right hand sides to the triangular matrix dimension. We provide a detailed communication cost analysis for our algorithm as well as for the recursive triangular matrix inversion. This cost analysis makes it possible to determine optimal block sizes and processor grids a priori. Relative to the best known algorithms for TRSM, our approach can require asymptotically fewer messages, while performing optimal amounts of computation and communication in terms of words sent.

We examine non-dual relational extensions of rough set approximations and find an extension which satisfies surprisingly many of the usual rough set properties. We then use this definition to give an explanation for an observation made by Samanta and Chakraborty in their recent paper P. Samanta and M.K. Chakraborty. Interface of rough set systems and modal logics A survey. Transactions on Rough Sets XIX, pages -, .

The combinatorial stochastic semi-bandit problem is an extension of the classical multi-armed bandit problem in which an algorithm pulls more than one arm at each stage and the rewards of all pulled arms are revealed. One difference with the single arm variant is that the dependency structure of the arms is crucial. Previous works on this setting either used a worst-case approach or imposed independence of the arms. We introduce a way to quantify the dependency structure of the problem and design an algorithm that adapts to it. The algorithm is based on linear regression and the analysis develops techniques from the linear bandit literature. By comparing its performance to a new lower bound, we prove that it is optimal, up to a poly-logarithmic factor in the number of pulled arms.

Musical frequencies in Just Intonation are comprised of rational numbers. The structure of rational numbers is determined by prime factorisations. Just Intonation frequencies can be split into two components. The larger component uses only integer powers of the first two primes,  and . The smaller component decomposes into a series of microtonal adjustments, one for each prime number  and above present in the original frequency. The larger -limit component can be notated using scientific pitch notation modified to use Pythagorean tuning. The microtonal adjustments can be notated using rational commas which are built up from prime commas. This gives a notation system for the whole of free-JI, called Rational Comma Notation. RCN is compact since all microtonal adjustments can be represented by a single notational unit based on a rational number. RCN has different versions depending on the choice of algorithm to assign a prime comma to each prime number. Two existing algorithms SAG and KG are found in the literature. A novel algorithm DR is developed based on discussion of mathematical and musical criteria for algorithm design. Results for DR are presented for primes below . Some observations are made about these results and their applications, including shorthand notation and pitch class lattices. Results for DR are compared with those for SAG and KG. Translation is possible between any two free-JI notations and any two versions of RCN since they all represent the same underlying set of rational numbers.

The rapid advances in sensors and ultra-low power wireless communication has enabled a new generation of wireless sensor networks Wireless Body Area Networks WBAN. To the best of our knowledge the current paper is the first to address broadcast in WBAN. We first analyze several broadcast strategies inspired from the area of Delay Tolerant Networks DTN. The proposed strategies are evaluated via the OMNET simulator that we enriched with realistic human body mobility models and channel models issued from the recent research on biomedical and health informatics. Contrary to the common expectation, our results show that existing research in DTN cannot be transposed without significant modifications in WBANs area. That is, existing broadcast strategies for DTNs do not perform well with human body mobility. However, our extensive simulations give valuable insights and directions for designing efficient broadcast in WBAN. Furthermore, we propose a novel broadcast strategy that outperforms the existing ones in terms of end-to-end delay, network coverage and energy consumption. Additionally, we performed investigations of independent interest related to the ability of all the studied strategies to ensure the total order delivery property when stressed with various packet rates. These investigations open new and challenging research directions.

We investigate the computational power of affine automata AfAs introduced in . In particular, we present a simpler proof for how to change the cutpoint for any affine language and a method how to reduce error in bounded error case. Moreover, we address to the question of  by showing that any affine language can be recognized by an AfA with certain limitation on the entries of affine states and transition matrices. Lastly, we present the first languages shown to be not recognized by AfAs with bounded-error.

Recommender systems play an essential role in the modern business world. They recommend favorable items like books, movies, and search queries to users based on their past preferences. Applying similar ideas and techniques to Monte Carlo simulations of physical systems boosts their efficiency without sacrificing accuracy. Exploiting the quantum to classical mapping inherent in the continuous-time quantum Monte Carlo methods, we construct a classical molecular gas model to reproduce the quantum distributions. We then utilize powerful molecular simulation techniques to propose efficient quantum Monte Carlo updates. The recommender engine approach provides a general way to speed up the quantum impurity solvers.

Quasi-stationary distributions QSDsarise from stochastic processes that exhibit transient equilibrium behaviour on the way to absorption QSDs are often mathematically intractable and even drawing samples from them is not straightforward. In this paper the framework of Sequential Monte Carlo samplers is utilized to simulate QSDs and several novel resampling techniques are proposed to accommodate models with reducible state spaces, with particular focus on preserving particle diversity on discrete spaces. Finally an approach is considered to estimate eigenvalues associated with QSDs, such as the decay parameter.

Attention-based neural encoder-decoder frameworks have been widely adopted for image captioning. Most methods force visual attention to be active for every generated word. However, the decoder likely requires little to no visual information from the image to predict non-visual words such as the and of. Other words that may seem visual can often be predicted reliably just from the language model e.g., sign after behind a red stop or phone following talking on a cell. In this paper, we propose a novel adaptive attention model with a visual sentinel. At each time step, our model decides whether to attend to the image and if so, to which regions or to the visual sentinel. The model decides whether to attend to the image and where, in order to extract meaningful information for sequential word generation. We test our method on the COCO image captioning  challenge dataset and FlickrK. Our approach sets the new state-of-the-art by a significant margin.

Universal security over a network with linear network coding has been intensively studied. However, previous linear codes and code pairs used for this purpose were linear over a larger field than that used on the network. In this work, we introduce new parameters relative dimensionrank support profile and relative generalized matrix weights for code pairs that are linear over the field used in the network, measuring the universal security performance of these code pairs. For one code and non-square matrices, generalized metrix weights coincide with the existing Delsarte generalized weights, hence we prove the conection between these latter weights and secure network coding. The proposed new parameters enable us to use optimal universal secure linear codes on noiseless networks for all possible parameters, as opposed to previous works, and also enable us to add universal security to the recently proposed list-decodable rank-metric codes by Guruswami et al. We give several properties of the new parameters monotonicity, Singleton-type lower and upper bounds, a duality theorem, and definitions and characterizations of equivalences and degenerateness of linear codes. Finally, we show that our parameters strictly extend relative dimensionlength profile and relative generalized Hamming weights, respectively, and relative dimensionintersection profile and relative generalized rank weights, respectively. The duality theorems for generalized Hamming weights and generalized rank weights can be deduced as special cases of the duality theorem for generalized matrix weights.

Ontologies in different natural languages often differ in quality in terms of richness of schema or richness of internal links. This difference is markedly visible when comparing a rich English language ontology with a non-English language counterpart. Discovering alignment between them is a useful endeavor as it serves as a starting point in bridging the disparity. In particular, our work is motivated by the absence of inter-language links for predicates in the localised versions of DBpedia. In this paper, we propose and demonstrate an ad-hoc system to find possible owlequivalentProperty links between predicates in ontologies of different natural languages. We seek to achieve this mapping by using pre-existing inter-language links of the resources connected by the given predicate. Thus, our methodology stresses on semantic similarity rather than lexical. Moreover, through an evaluation, we show that our system is capable of outperforming a baseline system that is similar to the one used in recent OAEI campaigns.

The need for safety in transportation systems has increased the popularity and applicability of Vehicular Ad-Hoc Networks VANETs in recent years. On-time reception and processing of alarms caused by possible accidents as well as the preventive actions have important roles in reducing human and financial losses in road accidents. In such cases, the performance of safety applications should be evaluated and guaranteed to show whether or not they can ensure the safety of humans and cars. In this paper, we analyze the behavior of Vehicular Ad-Hoc Networks by checking the real-time properties of the IEEE .p protocol using a Colored Petri Net model. To analyze the performance of related standards, simulations are conducted using CPNTools. Standards from European Telecommunications Standards Institute ETSI, and Vehicle Safety Communications VSC are evaluated in this research. We will show that such standards may not completely fulfill the safety requirements in particular situations.

Todays colleges and universities consist of highly complex structures that dictate interactions between the administration, faculty, and student body. These structures can play a role in dictating the efficiency of policy enacted by the administration and determine the effect that curriculum changes in one department have on other departments. Despite the fact that the features of these complex structures have a strong impact on the institutions, they remain by-and-large unknown in many cases. In this paper we study the academic structure of our home institution of Trinity College in Hartford, CT using the major and minor patterns between graduating students to build a temporal multiplex network describing the interactions between different departments. Using recent network science techniques developed for such temporal networks we identify the evolving community structures that organize departments interactions, as well as quantify the interdisciplinary centrality of each department. We implement this framework for Trinity College, finding practical insights and applications, but also present it as a general framework for colleges and universities to better understand their own structural makeup in order to better inform academic and administrative policy.

This paper considers asymptotic performance of distributed detection in large connected sensor networks. Contrasting to canonical parallel networks where a single node has access to local decisions from all other sensors, each node can only exchange information with its direct neighbors in the present setting. We establish that, with each node employing an identical one-bit quantizer for local information exchange, a novel consensus reaching approach can achieve the optimal asymptotic performance of centralized detection. The statement is true under three different detection frameworks the Bayesian criterion where the maximum a posteriori detector is optimal the Neyman-Pearson criterion with both a constant and an exponential constraint on the type-I error probability. The key to achieving the optimal asymptotic performance is the use of a one-bit quantizer with controllable threshold that results in desired consensus error bounds. In addition, we examine non-asymptotic performance of the proposed approach and show that the type-I and type-II error probabilities at each node can be made arbitrarily close to the centralized ones simultaneously when a continuity condition is satisfied.

The framework of entropic dynamics ED allows one to derive quantum mechanics as an application of entropic inference. In this work we derive the classical limit of quantum mechanics in the context of ED. Our goal is to find conditions so that the center of mass CM of a system of N particles behaves as a classical particle. What is of interest is that Plancks constant remains finite at all steps in the calculation and that the classical motion is obtained as the result of a central limit theorem. More explicitly we show that if the system is sufficiently large, and if the CM is initially uncorrelated with other degrees of freedom, then the CM follows a smooth trajectory and obeys the classical Hamilton-Jacobi with a vanishing quantum potential.

State space modelling is an efficient and flexible method for statistical inference of a broad class of time series and other data. This paper describes an R package KFAS for state space modelling with the observations from an exponential family, namely Gaussian, Poisson, binomial, negative binomial and gamma distributions. After introducing the basic theory behind Gaussian and non-Gaussian state space models, an illustrative example of Poisson time series forecasting is provided. Finally, a comparison to alternative R packages suitable for non-Gaussian time series modelling is presented.

Automated photo tagging has established itself as one of the most compelling applications of deep learning. While deep convolutional neural networks have repeatedly demonstrated top performance on standard datasets for classification, there are a number of often overlooked but important considerations when deploying this technology in a real-world scenario. In this paper, we present our efforts in developing a large-scale photo-tagging system for Flickr photo search. We discuss topics including how to select the tags that matter most to our users, develop lightweight, high-performance models for tag prediction, and leverage the power of large amounts of noisy data for training. Our results demonstrate that, for real-world datasets, training exclusively with noisy data yields performance nearly on par with the standard paradigm of first pre-training on clean data and then fine-tuning. We advocate for the approach of harnessing user-generated data in large-scale systems.

The FlowNet demonstrated that optical flow estimation can be cast as a learning problem. However, the state of the art with regard to the quality of the flow has still been defined by traditional methods. Particularly on small displacements and real-world data, FlowNet cannot compete with variational methods. In this paper, we advance the concept of end-to-end learning of optical flow and make it work really well. The large improvements in quality and speed are caused by three major contributions first, we focus on the training data and show that the schedule of presenting data during training is very important. Second, we develop a stacked architecture that includes warping of the second image with intermediate optical flow. Third, we elaborate on small displacements by introducing a sub-network specializing on small motions. FlowNet . is only marginally slower than the original FlowNet but decreases the estimation error by more than . It performs on par with state-of-the-art methods, while running at interactive frame rates. Moreover, we present faster variants that allow optical flow computation at up to fps with accuracy matching the original FlowNet.

This article describes an implementation of a nonparametric Bayesian approach to solving binary classification problems on graphs. We consider a hierarchical Bayesian approach with a randomly scaled Gaussian prior. We have two simulated data examples and two examples using real data to illustrate our proposed methods.

We develop a probabilistic framework for deep learning based on the Deep Rendering Mixture Model DRMM, a new generative probabilistic model that explicitly capture variations in data due to latent task nuisance variables. We demonstrate that max-sum inference in the DRMM yields an algorithm that exactly reproduces the operations in deep convolutional neural networks DCNs, providing a first principles derivation. Our framework provides new insights into the successes and shortcomings of DCNs as well as a principled route to their improvement. DRMM training via the Expectation-Maximization EM algorithm is a powerful alternative to DCN back-propagation, and initial training results are promising. Classification based on the DRMM and other variants outperforms DCNs in supervised digit classification, training -x faster while achieving similar accuracy. Moreover, the DRMM is applicable to semi-supervised and unsupervised learning tasks, achieving results that are state-of-the-art in several categories on the MNIST benchmark and comparable to state of the art on the CIFAR benchmark.

In this chapter, we present CORrelation ALignment CORAL, a simple yet effective method for unsupervised domain adaptation. CORAL minimizes domain shift by aligning the second-order statistics of source and target distributions, without requiring any target labels. In contrast to subspace manifold methods, it aligns the original feature distributions of the source and target domains, rather than the bases of lower-dimensional subspaces. It is also much simpler than other distribution matching methods. CORAL performs remarkably well in extensive evaluations on standard benchmark datasets. We first describe a solution that applies a linear transformation to source features to align them with target features before classifier training. For linear classifiers, we propose to equivalently apply CORAL to the classifier weights, leading to added efficiency when the number of classifiers is small but the number and dimensionality of target examples are very high. The resulting CORAL Linear Discriminant Analysis CORAL-LDA outperforms LDA by a large margin on standard domain adaptation benchmarks. Finally, we extend CORAL to learn a nonlinear transformation that aligns correlations of layer activations in deep neural networks DNNs. The resulting Deep CORAL approach works seamlessly with DNNs and achieves state-of-the-art performance on standard benchmark datasets. Our code is available aturlhttpsgithub.comVisionLearningGroupCORAL

When faced with complex choices, users refine their own preference criteria as they explore the catalogue of options. In this paper we propose an approach to preference elicitation suited for this scenario. We extend Coactive Learning, which iteratively collects manipulative feedback, to optionally query example critiques. User critiques are integrated into the learning model by dynamically extending the feature space. Our formulation natively supports constructive learning tasks, where the option catalogue is generated on-the-fly. We present an upper bound on the average regret suffered by the learner. Our empirical analysis highlights the promise of our approach.

Semi-supervised learning algorithms reduce the high cost of acquiring labeled training data by using both labeled and unlabeled data during learning. Deep Convolutional Networks DCNs have achieved great success in supervised tasks and as such have been widely employed in the semi-supervised learning. In this paper we leverage the recently developed Deep Rendering Mixture Model DRMM, a probabilistic generative model that models latent nuisance variation, and whose inference algorithm yields DCNs. We develop an EM algorithm for the DRMM to learn from both labeled and unlabeled data. Guided by the theory of the DRMM, we introduce a novel non-negativity constraint and a variational inference term. We report state-of-the-art performance on MNIST and SVHN and competitive results on CIFAR. We also probe deeper into how a DRMM trained in a semi-supervised setting represents latent nuisance variation using synthetically rendered images. Taken together, our work provides a unified framework for supervised, unsupervised, and semi-supervised learning.

Heart diseases constitute a global health burden, and the problem is exacerbated by the error-prone nature of listening to and interpreting heart sounds. This motivates the development of automated classification to screen for abnormal heart sounds. Existing machine learning-based systems achieve accurate classification of heart sound recordings but rely on expert features that have not been thoroughly evaluated on noisy recordings. Here we propose a segmental convolutional neural network architecture that achieves automatic feature learning from noisy heart sound recordings. Our experiments show that our best model, trained on noisy recording segments acquired with an existing hidden semi-markov model-based approach, attains a classification accuracy of . on the  PhysioNetCinC Challenge dataset, compared to the . accuracy of the state-of-the-art statistical classifier trained and evaluated on the same dataset. Our results indicate the potential of using neural network-based methods to increase the accuracy of automated classification of heart sound recordings for improved screening of heart diseases.

Development of additive manufacturing in last decade greatly improves tissue engineering. During the manufacturing of porous scaffold, simplified but functionally equivalent models are getting focused for practically reasons. Scaffolds can be classified into regular porous scaffolds and irregular porous scaffolds. Several methodologies are developed to design these scaffolds. A novel method is proposed in this paper using anisotropic radial basis function ARBF interpolation. This is method uses geometric models such as volumetric meshes as input and proves to be flexible because geometric models are able to capture the characteristics of complex tissues easily. Moreover, this method is straightforward and easy to implement.

Colorization is an ambiguous problem, with multiple viable colorizations for a single grey-level image. However, previous methods only produce the single most probable colorization. Our goal is to model the diversity intrinsic to the problem of colorization and produce multiple colorizations that display long-scale spatial co-ordination. We learn a low dimensional embedding of color fields using a variational autoencoder VAE. We construct loss terms for the VAE decoder that avoid blurry outputs and take into account the uneven distribution of pixel colors. Finally, we develop a conditional model for the multi-modal distribution between grey-level image and the color field embeddings. Samples from this conditional model result in diverse colorization. We demonstrate that our method obtains better diverse colorizations than a standard conditional variational autoencoder model.

This paper addresses reconstruction of linear dynamic networks from heterogeneous datasets. Those datasets consist of measurements from linear dynamical systems in multiple experiment subjected to different experimental conditions, e.g., changesperturbations in parameters, disturbance or noise. A main assumption is that the Boolean structures of the underlying networks are the same in all experiments. The ARMAX model is adopted to parameterize the general linear dynamic network representation Dynamical Structure Function DSF, which provides the Granger Causality graph as a special case. The network identification is performed by integrating all available datasets, which resorts to group sparsity to assure both network sparsity and the consistency of Boolean structures over datasets. In terms of solving the problem, a treatment by the iterative reweighted l method is used, together with its implementations via proximal methods and ADMM for large-dimensional networks.

A graph is chordal if every cycle of length at least four contains a chord, that is, an edge connecting two nonconsecutive vertices of the cycle. Several classical applications in sparse linear systems, database management, computer vision, and semidefinite programming can be reduced to finding the minimum number of edges to add to a graph so that it becomes chordal, known as the minimum chordal completion problem MCCP. In this article we propose a new formulation for the MCCP which does not rely on finding perfect elimination orderings of the graph, as has been considered in previous work. We introduce several families of facet-defining inequalities for cycle subgraphs and investigate the underlying separation problems, showing that some key inequalities are NP-Hard to separate. We also show general properties of the proposed polyhedra, indicating certain conditions and methods through which facets and inequalities associated with the polytope of a certain graph can be adapted in order to become valid and eventually facet-defining for some of its subgraphs or supergraphs. Numerical studies combining heuristic separation methods based on a threshold rounding and lazy-constraint generation indicate that our approach substantially outperforms existing methods for the MCCP, solving many benchmark graphs to optimality for the first time.

We consider the problem of inferring the dynamics of unknown i.e. hidden nodes from a set of observed trajectories and we study analytically the average prediction error given by the Extended Plefka Expansion applied to it, as presented in . We focus on a stochastic linear dynamics of continuous degrees of freedom interacting via random Gaussian couplings in the infinite network size limit. The expected error on the hidden time courses can be found as the equal-time hidden-to-hidden covariance of the probability distribution conditioned on observations. In the stationary regime, we analyze the phase diagram in the space of relevant parameters, namely the ratio between the numbers of observed and hidden nodes, the degree of symmetry of the interactions and the amplitudes of the hidden-to-hidden and hidden-to-observed couplings relative to the decay constant of the internal hidden dynamics. In particular, we identify critical regions in parameter space where the inference error diverges, and determine the corresponding scaling behaviour.

The large-system performance of MAP estimation is studied considering a general distortion function when the observation vector is received through a linear system with additive white Gaussian noise. The analysis considers the system matrix to be chosen from a large class of random ensembles. We take a statistical mechanical approach by introducing a spin glass corresponding to the estimator, and employing the replica method for the large-system analysis. In contrast to earlier replica based studies, our analysis evaluates the general replica ansatz of the corresponding spin glass and determines the asymptotic distortion of the estimator for any structure of the replica correlation matrix. Consequently, the replica symmetric as well as the replica symmetry breaking ansatz with b steps of breaking is deduced from the given general replica ansatz. The generality of our distortion function lets us derive a more general form of the maximum-a-posterior decoupling principle. Based on the general replica ansatz, we show that for any structure of the replica correlation matrix, the vector-valued system decouples into a bank of equivalent decoupled linear systems followed by maximum-a-posterior estimators. The structure of the decoupled linear system is further studied under both the replica symmetry and the replica symmetry breaking assumptions. For b steps of symmetry breaking, the decoupled system is found to be an additive system with a noise term given as the sum of an independent Gaussian random variable with b correlated impairment terms. The general decoupling property of the maximum-a-posterior estimator leads to the idea of a replica simulator which represents the replica ansatz through the state evolution of a transition system described by its corresponding decoupled system. As an application of our study, we investigate large compressive sensing systems.

The intermediate map responses of a Convolutional Neural Network CNN contain information about an image that can be used to extract contextual knowledge about it. In this paper, we present a core sampling framework that is able to use these activation maps from several layers as features to another neural network using transfer learning to provide an understanding of an input image. Our framework creates a representation that combines features from the test data and the contextual knowledge gained from the responses of a pretrained network, processes it and feeds it to a separate Deep Belief Network. We use this representation to extract more information from an image at the pixel level, hence gaining understanding of the whole image. We experimentally demonstrate the usefulness of our framework using a pretrained VGG- model to perform segmentation on the BAERI dataset of Synthetic Aperture RadarSAR imagery and the CAMVID dataset.

Invariance to nuisance transformations is one of the desirable properties of effective representations. We consider transformations that form a emphgroup and propose an approach based on kernel methods to derive local group invariant representations. Locality is achieved by defining a suitable probability distribution over the group which in turn induces distributions in the input feature space. We learn a decision function over these distributions by appealing to the powerful framework of kernel methods and generate local invariant random feature maps via kernel approximations. We show uniform convergence bounds for kernel approximation and provide excess risk bounds for learning with these features. We evaluate our method on three real datasets, including Rotated MNIST and CIFAR-, and observe that it outperforms competing kernel based approaches. The proposed method also outperforms deep CNN on Rotated-MNIST and performs comparably to the recently proposed group-equivariant CNN.

We propose an approach for learning category-level semantic segmentation purely from image-level classification tags indicating presence of categories. It exploits localization cues that emerge from training classification-tasked convolutional networks, to drive a self-supervision process that automatically labels a sparse, diverse training set of points likely to belong to classes of interest. Our approach has almost no hyperparameters, is modular, and allows for very fast training of segmentation in less than  minutes. It obtains competitive results on the VOC  segmentation benchmark. More, significantly the modularity and fast training of our framework allows new classes to efficiently added for inference.

We calculate the probability distribution of entanglement entropy S across a cut of a finite one dimensional spin chain of length L at an infinite randomness fixed point using Fishers strong randomness renormalization group RG. Using the random transverse-field Ising model as an example, the distribution is shown to take the form pSL sim L-psik, where k  S  log LL, the large deviation function psik is found explicitly, and L is a nonuniversal microscopic length. We discuss the implications of such a distribution on numerical techniques that rely on entanglement, such as matrix product state MPS based techniques. Our results are verified with numerical RG simulations, as well as the actual entanglement entropy distribution for the random transverse-field Ising model which we calculate for large L via a mapping to Majorana fermions.

Set functions with convenient properties such as submodularity appear in application areas of current interest, such as algorithmic game theory, and allow for improved optimization algorithms. It is natural to ask e.g., in the context of data driven optimization how robust such properties are, and whether small deviations from them can be tolerated. We consider two such questions in the important special case of linear set functions.   One question that we address is whether any set function that approximately satisfies the modularity equation linear functions satisfy the modularity equation exactly is close to a linear function. The answer to this is positive in a precise formal sense as shown by Kalton and Roberts  and further improved by Bondarenko, Prymak, and Radchenko . We revisit their proof idea that is based on expander graphs, and provide significantly stronger upper bounds by combining it with new techniques. Furthermore, we provide improved lower bounds for this problem.   Another question that we address is that of how to learn a linear function h that is close to an approximately linear function f, while querying the value of f on only a small number of sets. We present a deterministic algorithm that makes only linearly many in the number of items nonadaptive queries, by this improving over a previous algorithm of Chierichetti, Das, Dasgupta and Kumar  that is randomized and makes more than a quadratic number of queries. Our learning algorithm is based on a Hadamard transform.

With the rising demand for solar energy installation, there is a pressing need for utilities to regulate the voltages at the distribution level. In grids with high penetration of photovoltaic PV systems, voltage fluctuations can occur at the distribution systems, resulting in inverter tripping and insufficient power to meet the load. We present a linear model for voltage rise versus PV output power. This model can be used to study the effect of increasing PV system capacities on distribution system voltages. It is observed that voltage fluctuations have greater correlation with the location of the PV systems on the grid than with the PV system capacities, i.e., more randomness and disorder in the behavior of voltage occurs with PV systems with larger line impedance.

This paper addresses harmonic magnification due to resonance circuits resulting from interaction between uncertain grid impedance and converter. The source of harmonic may be either the grid or inverter. It is demonstrated that unknown and unpredictable grid impedance may result in variable resonance frequency, which challenges robust design of LCL filter of inverter.

In recent work, Stalnaker proposes a logical framework in which belief is realized as a weakened form of knowledge. Building on Stalnakers core insights, and using frameworks developed in previous work by Bjorndahl and Baltag et al., we employ topological tools to refine and, we argue, improve on this analysis. The structure of topological subset spaces allows for a natural distinction between what is known and roughly speaking what is knowable we argue that the foundational axioms of Stalnakers system rely intuitively on both of these notions. More precisely, we argue that the plausibility of the principles Stalnaker proposes relating knowledge and belief relies on a subtle equivocation between an evidence-in-hand conception of knowledge and a weaker evidence-out-there notion of what could come to be known. Our analysis leads to a trimodal logic of knowledge, knowability, and belief interpreted in topological subset spaces in which belief is definable in terms of knowledge and knowability. We provide a sound and complete axiomatization for this logic as well as its uni-modal belief fragment. We then consider weaker logics that preserve suitable translations of Stalnakers postulates, yet do not allow for any reduction of belief. We propose novel topological semantics for these irreducible notions of belief, generalizing our previous semantics, and provide sound and complete axiomatizations for the corresponding logics.

Most existing works on physical-layer PHY cooperation beyond routing focus on how to best use a given, static relay network--while wireless networks are anything but static. In this paper, we pose a different set of questions given that we have multiple devices within range, which relays do we use for PHY cooperation, to maintain a consistent target performance? How can we efficiently adapt, as network conditions change? And how important is it, in terms of performance, to adapt? Although adapting to the best path when routing is a well understood problem, how to do so over PHY cooperation networks is an open question. Our contributions are  We demonstrate via theoretical evaluation, a diminishing returns trend as the number of deployed relays increases.  Using a simple algorithm based on network metrics, we efficiently select the sub-network to use at any given time to maintain a target reliability.  When streaming video from Netflix, we experimentally show using measurements from a WARP radio testbed employing DIQIF relaying that our adaptive PHY cooperation scheme provides a throughput gain of x over nonadaptive PHY schemes, and a gain of x over genie-aided IP-level adaptive routing.

This article addresses the visual area coverage problem using a team of Unmanned Aerial Vehicles UAVs. The UAVs are assumed to be equipped with a downward facing camera covering all points of interest within a circle on the ground. The diameter of this circular conic-section increases as the UAV flies at a larger height, yet the quality of the observed area is inverse proportional to the UAVs height. The objective is to provide a distributed control algorithm that maximizes a combined coverage-quality criterion by adjusting the UAVs altitude. Simulation studies are offered to highlight the effectiveness of the suggested scheme.

This article examines the problem of visual area coverage by a network of Mobile Aerial Agents MAAs. Each MAA is assumed to be equipped with a downwards facing camera with a conical field of view which covers all points within a circle on the ground. The diameter of that circle is proportional to the altitude of the MAA, whereas the quality of the covered area decreases with the altitude. A distributed control law that maximizes a joint coverage-quality criterion by adjusting the MAAs spatial coordinates is developed. The effectiveness of the proposed control scheme is evaluated through simulation studies.

This paper studies Value-at-Risk VaR problems in short- and long-horizon Markov decision processes MDPs with finite state space and two different reward functions. Firstly we examine the effects of two reward functions under two criteria in a short-horizon MDP. We show that under the VaR criterion, when the original reward function is on both current and next states, the reward simplification will change the VaR. Secondly, for long-horizon MDPs, we estimate the Pareto front of the total reward distribution set with the aid of spectral theory and the central limit theorem. Since the estimation is for a Markov process with the simplified reward function only, we present a transformation algorithm for the Markov process with the original reward function, in order to estimate the Pareto front with an intact total reward distribution.

The detection and identification of extreme weather events in large scale climate simulations is an important problem for risk management, informing governmental policy decisions and advancing our basic understanding of the climate system. Recent work has shown that fully supervised convolutional neural networks CNNs can yield acceptable accuracy for classifying well-known types of extreme weather events when large amounts of labeled data are available. However, there are many different types of spatially localized climate patterns of interest including hurricanes, extra-tropical cyclones, weather fronts, blocking events, etc. found in simulation data for which labeled data is not available at large scale for all simulations of interest. We present a multichannel spatiotemporal encoder-decoder CNN architecture for semi-supervised bounding box prediction and exploratory data analysis. This architecture is designed to fully model multi-channel simulation data, temporal dynamics and unlabelled data within a reconstruction and prediction framework so as to improve the detection of a wide range of extreme weather events. Our architecture can be viewed as a D convolutional autoencoder with an additional modified one-pass bounding box regression loss. We demonstrate that our approach is able to leverage temporal information and unlabelled data to improve localization of extreme weather events. Further, we explore the representations learned by our model in order to better understand this important data, and facilitate further work in understanding and mitigating the effects of climate change.

Clustering is a fundamental problem in statistics and machine learning. Lloyds algorithm, proposed in , is still possibly the most widely used clustering algorithm in practice due to its simplicity and empirical performance. However, there has been little theoretical investigation on the statistical and computational guarantees of Lloyds algorithm. This paper is an attempt to bridge this gap between practice and theory. We investigate the performance of Lloyds algorithm on clustering sub-Gaussian mixtures. Under an appropriate initialization for labels or centers, we show that Lloyds algorithm converges to an exponentially small clustering error after an order of log n iterations, where n is the sample size. The error rate is shown to be minimax optimal. For the two-mixture case, we only require the initializer to be slightly better than random guess.   In addition, we extend the Lloyds algorithm and its analysis to community detection and crowdsourcing, two problems that have received a lot of attention recently in statistics and machine learning. Two variants of Lloyds algorithm are proposed respectively for community detection and crowdsourcing. On the theoretical side, we provide statistical and computational guarantees of the two algorithms, and the results improve upon some previous signal-to-noise ratio conditions in literature for both problems. Experimental results on simulated and real data sets demonstrate competitive performance of our algorithms to the state-of-the-art methods.

We consider the task of learning a classifier for semantic segmentation using weak supervision in the form of image labels which specify the object classes present in the image. Our method uses deep convolutional neural networks CNNs and adopts an Expectation-Maximization EM based approach. We focus on the following three aspects of EM i initialization ii latent posterior estimation E-step and iii the parameter update M-step. We show that saliency and attention maps, our bottom-up and top-down cues respectively, of simple images provide very good cues to learn an initialization for the EM-based algorithm. Intuitively, we show that before trying to learn to segment complex images, it is much easier and highly effective to first learn to segment a set of simple images and then move towards the complex ones. Next, in order to update the parameters, we propose minimizing the combination of the standard softmax loss and the KL divergence between the true latent posterior and the likelihood given by the CNN. We argue that this combination is more robust to wrong predictions made by the expectation step of the EM method. We support this argument with empirical and visual results. Extensive experiments and discussions show that i our method is very simple and intuitive ii requires only image-level labels and iii consistently outperforms other weakly-supervised state-of-the-art methods with a very high margin on the PASCAL VOC  dataset.

In this paper, we propose an accurate edge detector using richer convolutional features RCF. Since objects in nature images have various scales and aspect ratios, the automatically learned rich hierarchical representations by CNNs are very critical and effective to detect edges and object boundaries. And the convolutional features gradually become coarser with receptive fields increasing. Based on these observations, our proposed network architecture makes full use of multiscale and multi-level information to perform the image-to-image edge prediction by combining all of the useful convolutional features into a holistic framework. It is the first attempt to adopt such rich convolutional features in computer vision tasks. Using VGG network, we achieve sArt results on several available datasets. When evaluating on the well-known BSDS benchmark, we achieve ODS F-measure of textbf. while retaining a fast speed textbf FPS. Besides, our fast version of RCF achieves ODS F-measure of textbf. with textbf FPS.

Let E be a set of inequalities between finite Sigma-terms. Let Vomega and Vr denote the varieties of all omega-continuous ordered Sigma-algebras and regular ordered Sigma-algebras satisfying E, respectively. We prove that the free Vr-algebra RX on generators X is the subalgebra of the corresponding free Vomega-algebra FomegaX determined by those elements of FomegaX denoted by the regular Sigma-coterms. We actually establish this fact as a special case of a more general construction for families of algebras specified by syntactically restricted completeness and continuity properties. Thus our result is also applicable to ordered regular algebras of higher order.

Robot footstep planning strategies can be divided in two main approaches discrete searches and continuous optimizations. While discrete searches have been broadly applied, continuous optimizations approaches have been restricted for humanoid platforms. This article introduces a generalized continuous-optimization approach for multilegged footstep planning which can be adapted to different platforms, regardless the number and geometry of legs. This approach leverages Mixed-Integer Convex Programming to account for the non-convex constraints that represent footstep rotation and obstacle avoidance. The planning problem is formulated as an optimization problem which considers robot geometry and reachability with linear constraints, and can be efficiently solved using optimization software. To demonstrate the functionality and adaptability of the planner, a set of tests are performed on a BHR hexapod and a LittleDog quadruped on scenarios which cant be easily handled with discrete searches, such tests are solved efficiently in fractions of a second. This work represents, to the knowledge of the authors, the first successful implementation of a continuous optimization-based multilegged footstep planner.

This paper will discuss the challenges in tooling around the management and utilization of knowledge space structures, via standardized APIs for external Adaptive Learning Systems ALS to consume. It then describes how these challenges are addressed in a graph based knowledge management framework application designed for external ALSs.

This paper develops a novel channel estimation approach for multi-user millimeter wave mmWave wireless systems with large antenna arrays. By exploiting the inherent mmWave channel sparsity, we propose a novel simultaneous-estimation with iterative fountain training SWIFT framework, in which the average number of channel measurements is adapted to various channel conditions. To this end, the base station BS and each user continue to measure the channel with a random subset of transmitreceive beamforming directions until the channel estimate converges. We formulate the channel estimation process as a compressed sensing problem and apply a sparse estimation approach to recover the virtual channel information. As SWIFT does not adapt the BSs transmitting beams to any single user, we are able to estimate all user channels simultaneously. Simulation results show that SWIFT can significantly outperform existing random-beamforming based approaches that use a fixed number of measurements, over a range of signal-to-noise ratios and channel coherence times.

The randomness from a quantum random number generator QRNG relies on the accurate characterization of its devices. However, device imperfections and inaccurate characterizations can result in wrong entropy estimation and bias in practice, which highly affects the genuine randomness generation and may even induce the disappearance of quantum randomness in an extreme case. Here we experimentally demonstrate a measurement-device-independent MDI QRNG based on time-bin encoding to achieve certified quantum randomness even when the measurement devices are uncharacterized and untrusted. The MDI-QRNG is randomly switched between the regular randomness generation mode and a test mode, in which four quantum states are randomly prepared to perform measurement tomography in real-time. With a clock rate of  MHz, the MDI-QRNG generates a final random bit rate of . Kbps. Such implementation with an all-fiber setup provides an approach to construct a fully-integrated MDI-QRNG with trusted but error-prone devices in practice.

The field of connectomics faces unprecedented big data challenges. To reconstruct neuronal connectivity, automated pixel-level segmentation is required for petabytes of streaming electron microscopy data. Existing algorithms provide relatively good accuracy but are unacceptably slow, and would require years to extract connectivity graphs from even a single cubic millimeter of neural tissue. Here we present a viable real-time solution, a multi-pass pipeline optimized for shared-memory multicore systems, capable of processing data at near the terabyte-per-hour pace of multi-beam electron microscopes. The pipeline makes an initial fast-pass over the data, and then makes a second slow-pass to iteratively correct errors in the output of the fast-pass. We demonstrate the accuracy of a sparse slow-pass reconstruction algorithm and suggest new methods for detecting morphological errors. Our fast-pass approach provided many algorithmic challenges, including the design and implementation of novel shallow convolutional neural nets and the parallelization of watershed and object-merging techniques. We use it to reconstruct, from image stack to skeletons, the full dataset of Kasthuri et al.  GB capturing , cubic microns in a matter of hours on a single multicore machine rather than the weeks it has taken in the past on much larger distributed systems.

Consider a distributed control problem with a communication channel connecting the observer of a linear stochastic system to the controller. The goal of the controller is to minimize a quadratic cost function in the state variables and control signal, known as the linear quadratic regulator LQR. We study the fundamental tradeoff between the communication rate r bitssec and the limsup of the expected cost b. We obtain a lower bound on a certain cost function, which quantifies the minimum mutual information between the channel input and output, given the past, that is compatible with a target LQR cost. The rate-cost function has operational significance in multiple scenarios of interest among other, it allows us to lower bound the minimum communication rate for fixed and variable length quantization, and for control over a noisy channel. Our results extend and generalize an earlier explicit expression, due to Tatikonda el al., for the scalar Gaussian case to the vector, non-Gaussian, and partially observed one. The bound applies as long as the system noise has a probability density function. Apart from standard dynamic programming arguments, our proof technique leverages the Shannon lower bound on the rate-distortion function and proposes new estimates for information measures of linear combinations of random vectors.

Consider a distributed control problem with a communication channel connecting the observer of a linear stochastic system to the controller. The goal of the controller is to minimize a quadratic cost function in the state variables and control signal, known as the linear quadratic regulator LQR. We study the fundamental tradeoff between the communication rate r bitssec and the limsup of the expected cost b. In the companion paper, which can be read independently of the current one, we show a lower bound on a certain cost function, which quantifies the minimum mutual information between the channel input and output, given the past, that is compatible with a target LQR cost. The bound applies as long as the system noise has a probability density function, and it holds for a general class of codes that can take full advantage of the memory of the data observed so far and that are not constrained to have any particular structure. In this paper, we prove that the bound can be approached by a simple variable-length lattice quantization scheme, as long as the system noise satisfies a smoothness condition. The quantization scheme only quantizes the innovation, that is, the difference between the controllers belief about the current state and the encoders state estimate. Our proof technique leverages some recent results on nonasymptotic high resolution vector quantization.

Predictive business process monitoring methods exploit logs of completed cases of a process in order to make predictions about running cases thereof. Existing methods in this space are tailor-made for specific prediction tasks. Moreover, their relative accuracy is highly sensitive to the dataset at hand, thus requiring users to engage in trial-and-error and tuning when applying them in a specific setting. This paper investigates Long Short-Term Memory LSTM neural networks as an approach to build consistently accurate models for a wide range of predictive process monitoring tasks. First, we show that LSTMs outperform existing techniques to predict the next event of a running case and its timestamp. Next, we show how to use models for predicting the next task in order to predict the full continuation of a running case. Finally, we apply the same approach to predict the remaining time, and show that this approach outperforms existing tailor-made methods.

We consider an autonomous navigation problem, whereby a traveler aims at traversing an environment in which an adversary tries to set an ambush. A two players zero sum game is introduced. Players strategies are computed as random path distributions, a realization of which is the path chosen by the traveler. A parallel is drawn between the discrete problem, where the traveler moves on a network, and the continuous problem, where the traveler moves in the plane. Analytical optimal policies are derived. Using assumptions from the Minimal Cut - Maximal Flow literature, the optimal value of the game is shown to be related to the maximum flow on the environment in both the discrete and the continuous cases, when the reward function for the ambusher is uniform. A linear program is introduced that allows for the computation of optimal policies, compatible with non-uniform reward functions. In order to relax the assumptions for the computation of the players optimal strategies of the continuous game, a network is created, inspired by recently introduced sampling based motion planning techniques, and the linear program is adapted for continuous constraints.

Although Generative Adversarial Networks achieve state-of-the-art results on a variety of generative tasks, they are regarded as highly unstable and prone to miss modes. We argue that these bad behaviors of GANs are due to the very particular functional shape of the trained discriminators in high dimensional spaces, which can easily make training stuck or push probability mass in the wrong direction, towards that of higher concentration than that of the data generating distribution. We introduce several ways of regularizing the objective, which can dramatically stabilize the training of GAN models. We also show that our regularizers can help the fair distribution of probability mass across the modes of the data generating distribution, during the early phases of training and thus providing a unified solution to the missing modes problem.

Deep D Convolutional Neural Networks D-CNN are traditionally used for object recognition, video data analytics and human gesture recognition. In this paper, we present a novel application of D-CNNs in understanding difficult-to-manufacture features from computer-aided design CAD models to develop a decision support tool for cyber-enabled manufacturing. Traditionally, design for manufacturability DFM rules are hand-crafted and used to accelerate the engineering product design cycle by integrating manufacturability analysis during the design stage. Such a practice relies on the experience and training of the designer to create a complex component that is manufacturable. However, even after careful design, the inclusion of certain features might cause the part to be non-manufacturable. In this paper, we develop a framework using Deep D-CNNs to learn salient features from a CAD model of a mechanical part and determine if the part can be manufactured or not. CAD models of different manufacturable and non-manufacturable parts are generated using a solid modeling kernel and then converted into D voxel data using a fast GPU-accelerated voxelization algorithm. The voxel data is used to train a D-CNN model for manufacturability classification. Feature space and filter visualization is also performed to understand the learning capability in the context of manufacturability features. We demonstrate that the proposed D-CNN based DFM framework is able to learn the DFM rules for non-manufacturable features without a human prior. The framework can be extended to identify a large variety of difficult-to-manufacture features at multiple spatial scales leading to a real-time decision support system for DFM.

We address the problem of the bit error rate BER performance gap between the sub-optimal and optimal linear precoder LP for a multiuser MU multiple input and multiple output MIMO broadcast systems in this paper. Particularly, mobile users suffer noise enhancement effect due to a sub-optimal LP that can be suppressed by an optimal LP matrix. A sub-optimal LP matrix such as a linear zero-forcing LZF precoder performs in high signal to noise ratio SNR regime only, in contrast, an optimal precoder for instance a linear minimum mean-square-error LMMSE precoder outperforms in both low and high SNR scenarios. These kinds of precoder illustrates the BER gap distance at least . when it is used in itself in a MU MIMO systems. Thus, we propose and design a unified linear precoding ULP matrix using a precoding selection technique that combines the sub-optimal and optimal LP matrix for a multi-user MIMO systems to ensure zero BER performance gap in this paper. The numerical results show that our proposed ULP technique offers significant performance in both low and high SNR scenarios.

Let P be a set of n points in the plane. We show how to find, for a given integer k, the smallest-area axis-parallel rectangle that covers k points of P in Onk log n nlog n time. We also consider the problem of, given a value alpha, covering as many points of P as possible with an axis-parallel rectangle of area at most alpha. For this problem we give a randomized -varepsilon-approximation that works in near-linear time in Onvarepsilonlog n log varepsilon time we find an axis-parallel rectangle of area at most alpha that covers at least -varepsilonkappa points, where kappa is the maximum possible number of points that could be covered.

Computational techniques are extensively applied in nonlinear science. However, while the use of computers for research has been expressive, the evaluation of numerical results does not grow in the same pace. Hammel et al. Journal of Complexity, , , -- were pioneers in the numerical reliability field and have proved a theorem that a pseudo-orbit of a logistic map is shadowed by a true orbit within a distance of - for  iterates. But the simulation of the logistic map with less than  iterates presents an error greater than - in a modern computer, performing a test based on the concept of multiple pseudo-orbits and symbolic computing.

This paper addresses the problem of human re-identification across non-overlapping cameras in crowds.Re-identification in crowded scenes is a challenging problem due to large number of people and frequent occlusions, coupled with changes in their appearance due to different properties and exposure of cameras. To solve this problem, we model multiple Personal, Social and Environmental PSE constraints on human motion across cameras. The personal constraints include appearance and preferred speed of each individual assumed to be similar across the non-overlapping cameras. The social influences constraints are quadratic in nature, i.e. occur between pairs of individuals, and modeled through grouping and collision avoidance. Finally, the environmental constraints capture the transition probabilities between gates entrances  exits in different cameras, defined as multi-modal distributions of transition time and destination between all pairs of gates. We incorporate these constraints into an energy minimization framework for solving human re-identification. Assigning - correspondence while modeling PSE constraints is NP-hard. We present a stochastic local search algorithm to restrict the search space of hypotheses, and obtain - solution in the presence of linear and quadratic PSE constraints. Moreover, we present an alternate optimization using Frank-Wolfe algorithm that solves the convex approximation of the objective function with linear relaxation on binary variables, and yields an order of magnitude speed up over stochastic local search with minor drop in performance. We evaluate our approach using Cumulative Matching Curves as well - assignment on several thousand frames of Grand Central, PRID and DukeMTMC datasets, and obtain significantly better results compared to existing re-identification methods.

We study whether for a given planar family F there is an m such that any finite set of points can be -colored such that any member of F that contains at least m points contains two points with different colors. We conjecture that if F is a family of pseudo-disks, then m is sufficient. We prove that when F is the family of all homothetic copies of a given convex polygon, then such an m exists. We also study the problem in higher dimensions.

A key limitation of sampling algorithms for approximate inference is that it is difficult to quantify their approximation error. Widely used sampling schemes, such as sequential importance sampling with resampling and Metropolis-Hastings, produce output samples drawn from a distribution that may be far from the target posterior distribution. This paper shows how to upper-bound the symmetric KL divergence between the output distribution of a broad class of sequential Monte Carlo SMC samplers and their target posterior distributions, subject to assumptions about the accuracy of a separate gold-standard sampler. The proposed method applies to samplers that combine multiple particles, multinomial resampling, and rejuvenation kernels. The experiments show the technique being used to estimate bounds on the divergence of SMC samplers for posterior inference in a Bayesian linear regression model and a Dirichlet process mixture model.

Medical image segmentation requires consensus ground truth segmentations to be derived from multiple expert annotations. A novel approach is proposed that obtains consensus segmentations from experts using graph cuts GC and semi supervised learning SSL. Popular approaches use iterative Expectation Maximization EM to estimate the final annotation and quantify annotators performance. Such techniques pose the risk of getting trapped in local minima. We propose a self consistency SC score to quantify annotator consistency using low level image features. SSL is used to predict missing annotations by considering global features and local image consistency. The SC score also serves as the penalty cost in a second order Markov random field MRF cost function optimized using graph cuts to derive the final consensus label. Graph cut obtains a global maximum without an iterative procedure. Experimental results on synthetic images, real data of Crohns disease patients and retinal images show our final segmentation to be accurate and more consistent than competing methods.

In this paper we study the task of approach of two mobile agents having the same limited range of vision and moving asynchronously in the plane. This task consists in getting them in finite time within each others range of vision. The agents execute the same deterministic algorithm and are assumed to have a compass showing the cardinal directions as well as a unit measure. On the other hand, they do not share any global coordinates system like GPS, cannot communicate and have distinct labels. Each agent knows its label but does not know the label of the other agent or the initial position of the other agent relative to its own. The route of an agent is a sequence of segments that are subsequently traversed in order to achieve approach. For each agent, the computation of its route depends only on its algorithm and its label. An adversary chooses the initial positions of both agents in the plane and controls the way each of them moves along every segment of the routes, in particular by arbitrarily varying the speeds of the agents. A deterministic approach algorithm is a deterministic algorithm that always allows two agents with any distinct labels to solve the task of approach regardless of the choices and the behavior of the adversary. The cost of a complete execution of an approach algorithm is the length of both parts of route travelled by the agents until approach is completed. Let Delta and l be the initial distance separating the agents and the length of the shortest label, respectively. Assuming that Delta and l are unknown to both agents, does there exist a deterministic approach algorithm always working at a cost that is polynomial in Delta and l? In this paper, we provide a positive answer to the above question by designing such an algorithm.

A spin wave majority fork-like structure with feature size of ,nm, is presented and investigated, through micromagnetic simulations. The structure consists of three merging out-of-plane magnetization spin wave buses and four magneto-electric cells serving as three inputs and an output. The information of the logic signals is encoded in the phase of the transmitted spin waves and subsequently stored as direction of magnetization of the magneto-electric cells upon detection. The minimum dimensions of the structure that produce an operational majority gate are identified. For all input combinations, the detection scheme employed manages to capture the majority phase result of the spin wave interference and ignore all reflection effects induced by the geometry of the structure.

Social gaming is today a pervasive phenomenon. Driven by the advent of social networks and the digitization of game distribution. In this paper the impact of digitization and so-cial networks such as Facebook on digital games is de-scribed and evaluated. This impact follows several vectors, including the introduction of new game formats and extend-ing the traditional audiences for games, which in turn has increased industrial revenue. The industry is in turn shaped by new business model such as Free-to-Play, digital distri-bution and the use of viral social features. These changes do not only appear irreversible, but more importantly, play a part in shaping the future of digital game design, notably for mobile devices. The paper presents new knowledge from controlled live experiments from a casual social game across Facebook and mobile platforms, finding positive re-turns by adding social gameplay features. This suggests that not only social network games, but also casual mobile games can benefit from deeper social gameplay mechanics. Given the impact of social features on gameplay, Game An-alytics will need to evolve to be able to handle requirements that arise from the introduction of social features, e.g. how to measure engagement against social features and shaping organic and viral spreading of a game.

This paper considers Electromagnetic Compatibility EMC aspects in the context of Power Line Communication PLC systems. It offers a complete overview of both narrow band PLC and broad band PLC EMC norms. How to interpret and translate such norms and measurement procedures into typical constraints used by designers of communication systems, is discussed. In particular, the constraints to the modulated signal spectrum are considered and the ability of pulse shaped OFDM PS-OFDM, used in most of the PLC standards as IEEE P and P., to fulfill them is analyzed. In addition, aiming to improve the spectrum management ability, a novel scheme named Pulse Shaped Cyclic Block Filtered Multitone modulation PS-CB-FMT is introduced and compared to PS-OFDM. It is shown that, PS-CB-FMT offers better ability to fulfill the norms which translates in higher system capacity.

Traditionally, wireless cellular systems have been designed to operate in Frequency Division Duplexing FDD paired bands that allocates the same amount of spectrum for both downlink DL and uplink UL communication. Such design is very convenient under symmetric DLUL traffic conditions, as it used to be the case when the voice transmission was the predominant service. However, with the overwhelming advent of data services, bringing along large asymmetries between DL and UL, the conventional FDD solution becomes inefficient. In this regard, flexible duplexing concepts aim to derive procedures for improving the spectrum utilization, by adjusting resources to the actual traffic demand. In this work we review these concepts and propose the use of unpaired Time Division Duplexing TDD spectrum on the unused resources for small eNBs SeNB, so that user equipment UEs associated to those SeNB could be served either in DL or UL. This proposal alleviates the saturated DL in FDD-based system through user offloading towards the TDD-based system. The flexible duplexing concept is analyzed from three points of view a regulation, b Long Term Evolution LTEstandardization, and c technical solutions.

Non-uniform blind deblurring for general dynamic scenes is a challenging computer vision problem since blurs are caused by camera shake, scene depth as well as multiple object motions. To remove these complicated motion blurs, conventional energy optimization based methods rely on simple assumptions such that blur kernel is partially uniform or locally linear. Moreover, recent machine learning based methods also depend on synthetic blur datasets generated under these assumptions. This makes conventional deblurring methods fail to remove blurs where blur kernel is difficult to approximate or parameterize e.g. object motion boundaries. In this work, we propose a multi-scale convolutional neural network that restores blurred images caused by various sources in an end-to-end manner. Furthermore, we present multi-scale loss function that mimics conventional coarse-to-fine approaches. Moreover, we propose a new large scale dataset that provides pairs of realistic blurry image and the corresponding ground truth sharp image that are obtained by a high-speed camera. With the proposed model trained on this dataset, we demonstrate empirically that our method achieves the state-of-the-art performance in dynamic scene deblurring not only qualitatively, but also quantitatively.

Generative adversarial learning is a popular new approach to training generative models which has been proven successful for other related problems as well. The general idea is to maintain an oracle D that discriminates between the experts data distribution and that of the generative model G. The generative model is trained to capture the experts distribution by maximizing the probability of D misclassifying the data it generates. Overall, the system is emphdifferentiable end-to-end and is trained using basic backpropagation. This type of learning was successfully applied to the problem of policy imitation in a model-free setup. However, a model-free approach does not allow the system to be differentiable, which requires the use of high-variance gradient estimations. In this paper we introduce the Model based Adversarial Imitation Learning MAIL algorithm. A model-based approach for the problem of adversarial imitation learning. We show how to use a forward model to make the system fully differentiable, which enables us to train policies using the stochastic gradient of D. Moreover, our approach requires relatively few environment interactions, and fewer hyper-parameters to tune. We test our method on the MuJoCo physics simulator and report initial results that surpass the current state-of-the-art.

Detecting people in images is a challenging problem. Differences in pose, clothing and lighting, along with other factors, cause a lot of variation in their appearance. To overcome these issues, we propose a system based on fused range and thermal infrared images. These measurements show considerably less variation and provide more meaningful information. We provide a brief introduction to the sensor technology used and propose a calibration method. Several data fusion algorithms are compared and their performance is assessed on a simulated data set. The results of initial experiments on real data are analyzed and the measurement errors and the challenges they present are discussed. The resulting fused data are used to efficiently detect people in a fixed camera set-up. The system is extended to include person tracking.

Have you ever taken a picture only to find out that an unimportant background object ended up being overly salient? Or one of those team sports photos where your favorite player blends with the rest? Wouldnt it be nice if you could tweak these pictures just a little bit so that the distractor would be attenuated and your favorite player will stand-out among her peers? Manipulating images in order to control the saliency of objects is the goal of this paper. We propose an approach that considers the internal color and saliency properties of the image. It changes the saliency map via an optimization framework that relies on patch-based manipulation using only patches from within the same image to achieve realistic looking results. Applications include object enhancement, distractors attenuation and background decluttering. Comparing our method to previous ones shows significant improvement, both in the achieved saliency manipulation and in the realistic appearance of the resulting images.

Neuroimaging modalities such as functional magnetic resonance imaging fMRI and electroencephalography EEG provide information about neurological functions in complementary spatiotemporal resolutions therefore, fusion of these modalities is expected to provide better understanding of brain activity. In this paper, we jointly analyze fMRI and multi-channel EEG signals collected during an auditory oddball task with the goal of capturing brain activity patterns that differ between patients with schizophrenia and healthy controls. Rather than selecting a single electrode or matricizing the third-order tensor that can be naturally used to represent multi-channel EEG signals, we preserve the multi-way structure of EEG data and use a coupled matrix and tensor factorization CMTF model to jointly analyze fMRI and EEG signals. Our analysis reveals that i joint analysis of EEG and fMRI using a CMTF model can capture meaningful temporal and spatial signatures of patterns that behave differently in patients and controls, and ii these differences and the interpretability of the associated components increase by including multiple electrodes from frontal, motor and parietal areas, but not necessarily by including all electrodes in the analysis.

We propose a novel measure for template matching named Deformable Diversity Similarity -- based on the diversity of feature matches between a target image window and the template. We rely on both local appearance and geometric information that jointly lead to a powerful approach for matching. Our key contribution is a similarity measure, that is robust to complex deformations, significant background clutter, and occlusions. Empirical evaluation on the most up-to-date benchmark shows that our method outperforms the current state-of-the-art in its detection accuracy while improving computational complexity.

Despite recent advances, the remaining bottlenecks in deep generative models are necessity of extensive training and difficulties with generalization from small number of training examples. Both problems may be addressed by conditional generative models that are trained to adapt the generative distribution to additional input data. So far this idea was explored only under certain limitations such as restricting the input data to be a single object or multiple objects representing the same concept. In this work we develop a new class of deep generative model called generative matching networks which is inspired by the recently proposed matching networks for one-shot learning in discriminative tasks and the ideas from meta-learning. By conditioning on the additional input dataset, generative matching networks may instantly learn new concepts that were not available during the training but conform to a similar generative process, without explicit limitations on the number of additional input objects or the number of concepts they represent. Our experiments on the Omniglot dataset demonstrate that generative matching networks can significantly improve predictive performance on the fly as more additional data is available to the model and also adapt the latent space which is beneficial in the context of feature extraction.

Shang and Hyndman  proposed grouped functional time series forecasting approach as a combination of individual forecasts using generalized least squares regression. We modify their methodology using generalized exponential smoothing technique for the most disaggregated series in order to obtain more robust predictor. We show some properties of our proposals using simulations and real data related to electricity demand prediction.

Many people enjoy classical symphonic music. Its diverse instrumentation makes for a rich listening experience. This diversity adds to the conductors expressive freedom to shape the sound according to their imagination. As a result, the same piece may sound quite differently from one conductor to another. Differences in interpretation may be noticeable subjectively to listeners, but they are sometimes hard to pinpoint, presumably because of the acoustic complexity of the sound. We describe a computational model that interprets dynamics---expressive loudness variations in performances---in terms of the musical score, highlighting differences between performances of the same piece. We demonstrate experimentally that the model has predictive power, and give examples of conductor ideosyncrasies found by using the model as an explanatory tool. Although the present model is still in active development, it may pave the road for a consumer-oriented companion to interactive classical music understanding.

Orthogonal sets of idempotents are used to design sets of unitary matrices, known as constellations, such that the modulus of the determinant of the difference of any two distinct elements is greater than . It is shown that unitary matrices in general are derived from orthogonal sets of idempotents reducing the design problem to a construction problem of unitary matrices from such sets. The quality of the constellations constructed in this way and the actual differences between the unitary matrices can be determined algebraically from the idempotents used.   This has applications to the design of unitary space time constellations.

Linear regression is a fundamental building block in many face detection and tracking algorithms, typically used to predict shape displacements from image features through a linear mapping. This paper presents a Functional Regression solution to the least squares problem, which we coin Continuous Regression, resulting in the first real-time incremental face tracker. Contrary to prior work in Functional Regression, in which B-splines or Fourier series were used, we propose to approximate the input space by its first-order Taylor expansion, yielding a closed-form solution for the continuous domain of displacements. We then extend the continuous least squares problem to correlated variables, and demonstrate the generalisation of our approach. We incorporate Continuous Regression into the cascaded regression framework, and show its computational benefits for both training and testing. We then present a fast approach for incremental learning within Cascaded Continuous Regression, coined iCCR, and show that its complexity allows real-time face tracking, being  times faster than the state of the art. To the best of our knowledge, this is the first incremental face tracker that is shown to operate in real-time. We show that iCCR achieves state-of-the-art performance in the -VW dataset, the most recent, large-scale benchmark for face tracking.

Let R be a finite principal ideal ring and S the Galois extension of R of degree m. For k and k, positive integers we determine the number of free S-linear codes B of length l with the property k  rankSB and k  rankR Bcap Rl. This corrects a wrong result which was given in the case of finite fields.

In this paper we propose a low-cost high-speed imaging line scan system. We replace an expensive industrial line scan camera and illumination with a custom-built set-up of cheap off-the-shelf components, yielding a measurement system with comparative quality while costing about  times less. We use a low-cost linear D image sensor, cheap optics including a LED-based or LASER-based lighting and an embedded platform to process the images. A step-by-step method to design such a custom high speed imaging system and select proper components is proposed. Simulations allowing to predict the final image quality to be obtained by the set-up has been developed. Finally, we applied our method in a lab, closely representing the real-life cases. Our results shows that our simulations are very accurate and that our low-cost line scan set-up acquired image quality compared to the high-end commercial vision system, for a fraction of the price.

Extrusion based D Printing EDP is an Additive Manufacturing AM technique that extrudes thermoplastic polymer in order to build up components using a layerwise approach. Hereby, AM typically requires long production times in comparison to mass production processes such as Injection Molding. Failures during the AM process are often only noticed after build completion and frequently lead to part rejection because of dimensional inaccuracy or lack of mechanical performance, resulting in an important loss of time and material. A solution to improve the accuracy and robustness of a manufacturing technology is the integration of sensors to monitor and control process state-variables online. In this way, errors can be rapidly detected and possibly compensated at an early stage. To achieve this, we integrated a modular D laser triangulation scanner into an EDP machine and analyzed feedback signals. A D laser triangulation scanner was selected here owing to the very compact size, achievable accuracy and the possibility of capturing geometrical D data. Thus, our implemented system is able to provide both quantitative and qualitative information. Also, in this work, first steps towards the development of a quality control loop for EDP processes are presented and opportunities are discussed.

Group-Lasso gLasso identifies important explanatory factors in predicting the response variable by considering the grouping structure over input variables. However, most existing algorithms for gLasso are not scalable to deal with large-scale datasets, which are becoming a norm in many applications. In this paper, we present a divide-and-conquer based parallel algorithm DC-gLasso to scale up gLasso in the tasks of regression with grouping structures. DC-gLasso only needs two iterations to collect and aggregate the local estimates on subsets of the data, and is provably correct to recover the true model under certain conditions. We further extend it to deal with overlappings between groups. Empirical results on a wide range of synthetic and real-world datasets show that DC-gLasso can significantly improve the time efficiency without sacrificing regression accuracy.

Combining new, low-cost thermal infrared and time-of-flight range sensors provides new opportunities. In this position paper we explore the possibilities of combining these sensors and using their fused data for person detection. The proposed calibration approach for this sensor combination differs from the traditional stereo camera calibration in two fundamental ways. A first distinction is that the spectral sensitivity of the two sensors differs significantly. In fact, there is no sensitivity range overlap at all. A second distinction is that their resolution is typically very low, which requires special attention. We assume a situation in which the sensors relative position is known, but their orientation is unknown. In addition, some of the typical measurement errors are discussed, and methods to compensate for them are proposed. We discuss how the fused data could allow increased accuracy and robustness without the need for complex algorithms requiring large amounts of computational power and training data.

Spiking Neural Networks SNN are more closely related to brain-like computation and inspire hardware implementation. This is enabled by small networks that give high performance on standard classification problems. In literature, typical SNNs are deep and complex in terms of network structure, weight update rules and learning algorithms. This makes it difficult to translate them into hardware. In this paper, we first develop a simple -layered network in software which compares with the state of the art on four different standard data-sets within SNNs and has improved efficiency. For example, it uses lower number of neurons  x, synapses . x and epochs for training  x for the Fisher Iris classification problem. The efficient network is based on effective population coding and synapse-neuron co-design. Second, we develop a computationally efficient  x and accurate correlation of . method to evaluate the performance of the network without standard recognition tests. Third, we show that the method produces a robustness metric that can be used to evaluate noise tolerance.

Intrinsic brain activity is characterized by highly structured co-activations between different regions, whose origin is still under debate. In this paper, we address the question whether it is possible to unveil how the underlying anatomical connectivity shape the brains spontaneous correlation structure. We start from the assumption that in order for two nodes to exhibit large covariation, they must be exposed to similar input patterns from the entire network. We then acknowledge that information rarely spreads only along an unique route, but rather travels along all possible paths. In real networks the strength of local perturbations tends to decay as they propagate away from the sources, leading to a progressive attenuation of the original information content and, thus, of their influence. We use these notions to derive a novel analytical measure, mathcalT , which quantifies the similarity of the whole-network input patterns arriving at any two nodes only due to the underlying topology, in what is a generalization of the matching index. We show that this measure of topological similarity can indeed be used to predict the contribution of network topology to the expected correlation structure, thus unveiling the mechanism behind the tight but elusive relationship between structure and function in complex networks. Finally, we use this measure to investigate brain connectivity, showing that information about the topology defined by the complex fabric of brain axonal pathways specifies to a large extent the time-average functional connectivity observed at rest.

Multitask learning has been applied successfully to a range of tasks, mostly morphosyntactic. However, little is known on when MTL works and whether there are data characteristics that help to determine its success. In this paper we evaluate a range of semantic sequence labeling tasks in a MTL setup. We examine different auxiliary tasks, amongst which a novel setup, and correlate their impact to data-dependent conditions. Our results show that MTL is not always effective, significant improvements are obtained only for  out of  tasks. When successful, auxiliary tasks with compact and more uniform label distributions are preferable.

Knowledge Graphs KG constitute a flexible representation of complex relationships between entities particularly useful for biomedical data. These KG, however, are very sparse with many missing edges facts and the visualisation of the mesh of interactions nontrivial. Here we apply a compositional model to embed nodes and relationships into a vectorised semantic space to perform graph completion. A visualisation tool based on Convolutional Neural Networks and Self-Organised Maps SOM is proposed to extract high-level insights from the KG. We apply this technique to a subset of CTD, containing interactions of compounds with human genes  proteins and show that the performance is comparable to the one obtained by structural models.

Shape analysis is very often performed by segmenting the shape into smooth surface parts that can be further classified using a set of predefined primitives such as planes, cylinders or spheres. Hence the shape is generally assumed to be manifold and smooth or to be an assembly of primitive parts. In this paper we propose an approach which does not make any assumption on the shape properties but rather learns its characteristics through a statistical analysis of local shape variations. Armed solely with a local probing operator, we are able to perform a non local analysis of the shape yielding a shape dictionary which encodes its structures. Our method relies on a novel description of shape variations, called Local Probing Field LPF, which describes how a generic pattern is transformed onto the shape. By carefully optimizing the position and orientation of these descriptors we are able to capture shape similarities and gather them into a geometrically relevant dictionary over which the shape decomposes sparsely. Furthermore, this analysis also reveals the local dimensions of the shape. Our shape representation has several potential applications here we demonstrate its efficiency for shape resampling and point set denoising.

This article is intended to an introductory lecture in material physics, in which the modern computational group theory and the electronic structure calculation are in collaboration. The effort of mathematicians in field of the group theory, have ripened as a new trend, called computer algebra, outcomes of which now can be available as handy computational packages, and would also be useful to physicists with practical purposes. This article, in the former part, explains how to use the computer algebra for the applications in the solid-state simulation, by means of one of the computer algebra package, the GAP system. The computer algebra enables us to obtain various group theoretical properties with ease, such as the representations, the character tables, the subgroups, etc. Furthermore it would grant us a new perspective of material design, which could be executed in mathematically rigorous and systematic way. Some technical details and some computations which require the knowledge of a little higher mathematics but computable easily by the computer algebra are also given. The selected topics will provide the reader with some insights toward the dominating role of the symmetry in crystal, or, the mathematical first principles in it. In the latter part of the article, we analyze the relation between the structural symmetry and the electronic structure in C as an example to the sysmem without periodicity. The principal object of the study is to illustrate the hierarchical change of the quantum-physical properties of the molecule, in accordance with the reduction of the symmetry as it descends down in the ladder of subgroups. In order to serve the common interest of the researchers, the details of the computations the required initial data and the small programs developed for the purpose are explained as minutely as possible.

The information presented in this paper defines LogLog-Beta. LogLog-Beta is a new algorithm for estimating cardinalities based on LogLog counting. The new algorithm uses only one formula and needs no additional bias corrections for the entire range of cardinalities, therefore, it is more efficient and simpler to implement. Our simulations show that the accuracy provided by the new algorithm is as good as or better than the accuracy provided by either of HyperLogLog or HyperLogLog. In addition to LogLog-Beta we also provide another one-formula estimator for cardinalities based on order statistics, a modification of an algorithm developed by Lumbroso.

This paper addresses the task of estimating the D pose of a known D object from a single RGB-D image. Most modern approaches solve this task in three steps i Compute local features ii Generate a pool of pose-hypotheses iii Select and refine a pose from the pool. This work focuses on the second step. While all existing approaches generate the hypotheses pool via local reasoning, e.g. RANSAC or Hough-voting, we are the first to show that global reasoning is beneficial at this stage. In particular, we formulate a novel fully-connected Conditional Random Field CRF that outputs a very small number of pose-hypotheses. Despite the potential functions of the CRF being non-Gaussian, we give a new and efficient two-step optimization procedure, with some guarantees for optimality. We utilize our global hypotheses generation procedure to produce results that exceed state-of-the-art for the challenging Occluded Object Dataset.

Cross-entropy loss together with softmax is arguably one of the most common used supervision components in convolutional neural networks CNNs. Despite its simplicity, popularity and excellent performance, the component does not explicitly encourage discriminative learning of features. In this paper, we propose a generalized large-margin softmax L-Softmax loss which explicitly encourages intra-class compactness and inter-class separability between learned features. Moreover, L-Softmax not only can adjust the desired margin but also can avoid overfitting. We also show that the L-Softmax loss can be optimized by typical stochastic gradient descent. Extensive experiments on four benchmark datasets demonstrate that the deeply-learned features with L-softmax loss become more discriminative, hence significantly boosting the performance on a variety of visual classification and verification tasks.

This paper proposes a deep learning architecture based on Residual Network that dynamically adjusts the number of executed layers for the regions of the image. This architecture is end-to-end trainable, deterministic and problem-agnostic. It is therefore applicable without any modifications to a wide range of computer vision problems such as image classification, object detection and image segmentation. We present experimental results showing that this model improves the computational efficiency of Residual Networks on the challenging ImageNet classification and COCO object detection datasets. Additionally, we evaluate the computation time maps on the visual saliency dataset cat and find that they correlate surprisingly well with human eye fixation positions.

Differential privacy is a popular privacy model within the research community because of the strong privacy guarantee it offers, namely that the presence or absence of any individual in a data set does not significantly influence the results of analyses on the data set. However, enforcing this strict guarantee in practice significantly distorts data andor limits data uses, thus diminishing the analytical utility of the differentially private results. In an attempt to address this shortcoming, several relaxations of differential privacy have been proposed that trade off privacy guarantees for improved data utility. In this work, we argue that the standard formalization of differential privacy is stricter than required by the intuitive privacy guarantee it seeks. In particular, the standard formalization requires indistinguishability of results between any pair of neighbor data sets, while indistinguishability between the actual data set and its neighbor data sets should be enough. This limits the data controllers ability to adjust the level of protection to the actual data, hence resulting in significant accuracy loss. In this respect, we propose individual differential privacy, an alternative differential privacy notion that offers em the same privacy guarantees as standard differential privacy to individuals even though not to groups of individuals. This new notion allows the data controller to adjust the distortion to the actual data set, which results in less distortion and more analytical accuracy. We propose several mechanisms to attain individual differential privacy and we compare the new notion against standard differential privacy in terms of the accuracy of the analytical results.

Many sensor applications are interested in computing a function over measurements e.g., sum, average, max as opposed to collecting all sensor data. Today, such data aggregation is done in a cluster-head. Sensor nodes transmit their values sequentially to a cluster-head node, which calculates the aggregation function and forwards it to the base station. In contrast, this paper explores the possibility of computing a desired function over the air. We devise a solution that enables sensors to transmit coherently over the wireless medium so that the cluster-head directly receives the value of the desired function. We present analysis and preliminary results that demonstrate that such a design yield a large improvement in network throughput.

Various kinds of k-nearest neighbor KNN based classification methods are the bases of many well-established and high-performance pattern-recognition techniques, but both of them are vulnerable to their parameter choice. Essentially, the challenge is to detect the neighborhood of various data sets, while utterly ignorant of the data characteristic. This article introduces a new supervised classification method the extend natural neighbor ENaN method, and shows that it provides a better classification result without choosing the neighborhood parameter artificially. Unlike the original KNN based method which needs a prior k, the ENaNE method predicts different k in different stages. Therefore, the ENaNE method is able to learn more from flexible neighbor information both in training stage and testing stage, and provide a better classification result.

We report from the Do Not Disturb Challenge, where  volunteers disabled notification alerts for  hours across all devices. We isolated the effect of the absence of notifications on the participants through an experimental study design we compared self-reported feedback from the day without notifications against a baseline day. The evidence indicates that notifications have locked us in a dilemma without notifications, participants felt less distracted and more productive. But, they also felt no longer able to be as responsive as expected, which made some participants anxious. And, they felt less connected with ones social group. Moreover, we found evidence that people may start to feel overloaded by notifications in contrast to previous reports, more about half of the participants began to disable or manage notifications more consciously after the study.

One of the basic aspects of Massive MIMO MaMi that is in the focus of current investigations is its potential of using low-cost and energy-efficient hardware. It is often claimed that MaMi will allow for using analog-to-digital converters ADCs with very low resolutions and that this will result in overall improvement of energy efficiency. In this contribution, we perform a parametric energy efficiency analysis of MaMi uplink for the entire base station receiver system with varying ADC resolutions. The analysis shows that, for a wide variety of system parameters, ADCs with intermediate bit resolutions  -  bits are optimal in energy efficiency sense, and that using very low bit resolutions results in degradation of energy efficiency.

Coverage problems are central in optimization and have a wide range of applications in data mining and machine learning. While several distributed algorithms have been developed for coverage problems, the existing methods suffer from several limitations, e.g., they all achieve either suboptimal approximation guarantees or suboptimal space and memory complexities. In addition, previous algorithms developed for submodular maximization assume oracle access, and ignore the computational complexity of communicating large subsets or computing the size of the union of the subsets in this subfamily. In this paper, we develop an improved distributed algorithm for the k-cover and the set cover with lambda outliers problems, with almost optimal approximation guarantees, almost optimal memory complexity, and linear communication complexity running in only four rounds of computation. Finally, we perform an extensive empirical study of our algorithms on a number of publicly available real data sets, and show that using sketches of size  to  times smaller than the input, one can solve the coverage maximization problem with quality very close to that of the state-of-the-art single-machine algorithm.

This paper examines the problem of locating outlier columns in a large, otherwise low-rank matrix, in settings where the data are noisy, or where the overall matrix has missing elements. We propose a randomized two-step inference framework, and establish sufficient conditions on the required sample complexities under which these methods succeed with high probability in accurately locating the outliers for each task. Comprehensive numerical experimental results are provided to verify the theoretical bounds and demonstrate the computational efficiency of the proposed algorithm.

We introduce the novel task of PanoVid - automatic cinematography in panoramic circ videos. Given a circ video, the goal is to direct an imaginary camera to virtually capture natural-looking normal field-of-view NFOV video. By selecting where to look within the panorama at each time step, PanoVid aims to free both the videographer and the end viewer from the task of determining what to watch. Towards this goal, we first compile a dataset of circ videos downloaded from the web, together with human-edited NFOV camera trajectories to facilitate evaluation. Next, we propose AutoCam, a data-driven approach to solve the PanoVid task. AutoCam leverages NFOV web video to discriminatively identify space-time glimpses of interest at each time instant, and then uses dynamic programming to select optimal human-like camera trajectories. Through experimental evaluation on multiple newly defined PanoVid performance measures against several baselines, we show that our method successfully produces informative videos that could conceivably have been captured by human videographers.

The architecture of neural Turing machines is differentiable end to end and is trainable with gradient descent methods. Due to their large unfolded depth Neural Turing Machines are hard to train and because of their linear access of complete memory they do not scale. Other architectures have been studied to overcome these difficulties. In this report we focus on improving the quality of prediction of the original linear memory architecture on copy and repeat copy tasks. Copy task predictions on sequences of length six times larger than those the neural Turing machine was trained on prove to be highly accurate and so do predictions of repeat copy tasks for sequences with twice the repetition number and twice the sequence length neural Turing machine was trained on.

The paper defines a non-cooperative simultaneous finite game to study coalition structure formation with intra and inter-coalition externalities. The novelty of the game is that the game definition embeds a textitcoalition structure formation mechanism. This mechanism portions a set of strategies of the game into partition-specific strategy domains, what makes every partition to be a non-cooperative game with partition-specific payoffs for every player. The mechanism includes a maximum coalition size, a set of eligible partitions with coalitions sizes no greater than this number which also serves as a restriction for a maximum number of deviators and a coalition structure formation rule. The paper defines a family of nested non-cooperative games parametrized by a size of a maximum coalition size. Every game in the family has an equilibrium in mixed strategies. The equilibrium can generate more than one coalition and encompasses intra and inter group externalities, what makes it different from the Shapley value. Presence of individual payoff allocation makes it different from a strong Nash, coalition-proof equilibrium, and some other equilibrium concepts. The accompanying papers demonstrate applications of the proposed toolkit.

In type theory one usually defines data types inductively. Over the years, many principles have been invented, such as inductive families, and inductive-recursive and inductive-inductive definitions. More recently, higher inductive types have been proposed in the context of homotopy type theory. Specific instances of higher inductive types have been successfully used in formalisations of homotopy theory and in formalising type theory in type theory. However, a general definition and theory of higher inductive types is still lacking. As an intermediate goal, we give a principle which unifies ordinary, indexed and inductive-inductive definitions, extended with path constructors from higher inductive types, but with no non-trivial structure between paths, i.e. we consider sets only. For this reason, we call these types quotient inductive-inductive types. We give an initial algebra semantics for these definitions, give the induction principle, and show that these two interpretations coincide.

Applying generic media-agnostic summarization to music allows for higher efficiency in automatic processing, storage, and communication of datasets while also alleviating copyright issues. This process has already been proven useful in the context of music genre classification. In this paper, we generalize conclusions from previous work by evaluating the impact of generic summarization in music from a probabilistic perspective and agnostic relative to certain tasks. We estimate Gaussian distributions for original and summarized songs and compute their relative entropy to measure how much information is lost in the summarization process. Based on this observation, we further propose a simple yet expressive summarization method that objectively outperforms previous methods and is better suited to avoid copyright issues. We present results suggesting that relative entropy is a good predictor of summarization performance in the context of tasks relying on a bag-of-features model.

Clausal proofs have become a popular approach to validate the results of SAT solvers. However, validating clausal proofs in the most widely supported format DRAT is expensive even in highly optimized implementations. We present a new format, called LRAT, which extends the DRAT format with hints that facilitate a simple and fast validation algorithm. Checking validity of LRAT proofs can be implemented using trusted systems such as the languages supported by theorem provers. We demonstrate this by implementing two certified LRAT checkers, one in Coq and one in ACL.

In this paper we briefly review the main methodological aspects concerned with the application of the Bayesian approach to model choice and model averaging in the context of variable selection in regression models. This includes prior elicitation, summaries of the posterior distribution and computational strategies. We then examine and compare various publicly available tt R-packages for its practical implementation summarizing and explaining the differences between packages and giving recommendations for applied users. We find that all packages reviewed lead to very similar results, but there are potentially important differences in flexibility and efficiency of the packages.

The computational cost of solving an inverse problem governed by PDEs, using multiple experiments, increases linearly with the number of experiments. A recently proposed method to decrease this cost uses only a small number of random linear combinations of all experiments for solving the inverse problem. This approach applies to inverse problems where the PDE solution depends linearly on the right-hand side function that models the experiment. As this method is stochastic in essence, the quality of the obtained reconstructions can vary, in particular when only a small number of combinations are used. We develop a Bayesian formulation for the definition and computation of encoding weights that lead to a parameter reconstruction with the least uncertainty. We call these weights A-optimal encoding weights. Our framework applies to inverse problems where the governing PDE is nonlinear with respect to the inversion parameter field. We formulate the problem in infinite dimensions and follow the optimize-then-discretize approach, devoting special attention to the discretization and the choice of numerical methods in order to achieve a computational cost that is independent of the parameter discretization. We elaborate our method for a Helmholtz inverse problem, and derive the adjoint-based expressions for the gradient of the objective function of the optimization problem for finding the A-optimal encoding weights. The proposed method is potentially attractive for real-time monitoring applications, where one can invest the effort to compute optimal weights offline, to later solve an inverse problem repeatedly, over time, at a fraction of the initial cost.

Material recognition for real-world outdoor surfaces has become increasingly important for computer vision to support its operation in the wild. Computational surface modeling that underlies material recognition has transitioned from reflectance modeling using in-lab controlled radiometric measurements to image-based representations based on internet-mined images of materials captured in the scene. We propose to take a middle-ground approach for material recognition that takes advantage of both rich radiometric cues and flexible image capture. We realize this by developing a framework for differential angular imaging, where small angular variations in image capture provide an enhanced appearance representation and significant recognition improvement. We build a large-scale material database, Ground Terrain in Outdoor Scenes GTOS database, geared towards real use for autonomous agents. The database consists of over , images covering  classes of outdoor ground terrain under varying weather and lighting conditions. We develop a novel approach for material recognition called a Differential Angular Imaging Network DAIN to fully leverage this large dataset. With this novel network architecture, we extract characteristics of materials encoded in the angular and spatial gradients of their appearance. Our results show that DAIN achieves recognition performance that surpasses single view or coarsely quantized multiview images. These results demonstrate the effectiveness of differential angular imaging as a means for flexible, in-place material recognition.

Attention Deficit Hyperactivity Disorder ADHD and Autism Spectrum Disorder ASD are neurodevelopmental conditions which impact on a significant number of children and adults. Currently, the diagnosis of such disorders is done by experts who employ standard questionnaires and look for certain behavioural markers through manual observation. Such methods for their diagnosis are not only subjective, difficult to repeat, and costly but also extremely time consuming. In this work, we present a novel methodology to aid diagnostic predictions about the presenceabsence of ADHD and ASD by automatic visual analysis of a persons behaviour. To do so, we conduct the questionnaires in a computer-mediated way while recording participants with modern RGBD ColourDepth sensors. In contrast to previous automatic approaches which have focussed only detecting certain behavioural markers, our approach provides a fully automatic end-to-end system for directly predicting ADHD and ASD in adults. Using state of the art facial expression analysis based on Dynamic Deep Learning and D analysis of behaviour, we attain classification rates of  for Controls vs Condition ADHDASD group and  for Comorbid ADHDASD vs ASD only group. We show that our system is a potentially useful time saving contribution to the diagnostic field of ADHD and ASD.

In this letter, we consider the Voronoi tesselation induced by a homogeneous and stationary Poisson point process of unit density in a square. We show that the mean cell size is less than unity when the seed is located exactly at the boundary, and it can be larger than unity when the seed lies close to the boundary. In addition, we calculate the second moment of the cell size at two locations, at the corner and at the edge but far from the corner, and illustrate that the two-parameter Gamma distribution, with location-dependent parameters, provides a good fit. As a potential application, we use the Gamma approximations to study the degree distribution for secure in-connectivity in wireless sensor networks deployed over a bounded domain.

The main subject studied in this dissertation is a multi-layered social network MSN and its analysis. One of the crucial problems in multi-layered social network analysis is community extraction. To cope with this problem the CLECC measure Cross Layered Edge Clustering Coefficient was proposed in the thesis. It is an edge measure which expresses how much the neighbors of two given users are similar each other. Based on this measure the CLECC algorithm for community extraction in the multi-layered social networks was designed. The algorithm was tested on the real single-layered social networks SSN and multi-layered social networks MSN, as well as on benchmark networks from GN Benchmark SSN, LFR Benchmark SSN and mLFR Benchmark MSN a special extension of LFR Benchmark, designed as a part of this thesis, which is able to produce multi-layered benchmark networks. The second research problem considered in the thesis was group evolution discovery. Studies on this problem have led to the development of the inclusion measure and the Group Evolution Discovery GED method, which is designed to identify events between two groups in successive time frames in the social network. The method was tested on a real social network and compared with two well-known algorithms regarding accuracy, execution time, flexibility and ease of implementation. Finally, a new approach to prediction of group evolution in the social network was developed. The new approach involves usage of the outputs of the GED method. It is shown, that using even a simple sequence, which consists of several preceding groups sizes and events, as an input for the classifier, the learned model can produce very good results also for simple classifiers.

The SUM problem asks if an input n-set of real numbers contains a triple whose sum is zero. We consider the POL problem, a natural generalization of SUM where we replace the sum function by a constant-degree polynomial in three variables. The motivations are threefold. Raz, Sharir, and de Zeeuw gave a On upper bound on the number of solutions of trivariate polynomial equations when the solutions are taken from the cartesian product of three n-sets of real numbers. We give algorithms for the corresponding problem of counting such solutions. Gro nlund and Pettie recently designed subquadratic algorithms for SUM. We generalize their results to POL. Finally, we shed light on the General Position Testing GPT problem Given n points in the plane, do three of them lie on a line?, a key problem in computational geometry.   We prove that there exist bounded-degree algebraic decision trees of depth Onfracvarepsilon that solve POL, and that POL can be solved in On log log nfrac  log nfrac time in the real-RAM model. Among the possible applications of those results, we show how to solve GPT in subquadratic time when the input points lie on olog nfraclog log nfrac constant-degree polynomial curves. This constitutes a first step towards closing the major open question of whether GPT can be solved in subquadratic time.   To obtain these results, we generalize important tools --- such as batch range searching and dominance reporting --- to a polynomial setting. We expect these new tools to be useful in other applications.

In this paper we formulate structure from motion as a learning problem. We train a convolutional network end-to-end to compute depth and camera motion from successive, unconstrained image pairs. The architecture is composed of multiple stacked encoder-decoder networks, the core part being an iterative network that is able to improve its own predictions. The network estimates not only depth and motion, but additionally surface normals, optical flow between the images and confidence of the matching. A crucial component of the approach is a training loss based on spatial relative differences. Compared to traditional two-frame structure from motion methods, results are more accurate and more robust. In contrast to the popular depth-from-single-image networks, DeMoN learns the concept of matching and, thus, better generalizes to structures not seen during training.

Let C be the unit circle in mathbbR. We can view C as a plane graph whose vertices are all the points on C, and the distance between any two points on C is the length of the smaller arc between them. We consider a graph augmentation problem on C, where we want to place kgeq  emphshortcuts on C such that the diameter of the resulting graph is minimized.   We analyze for each k with leq kleq  what the optimal set of shortcuts is. Interestingly, the minimum diameter one can obtain is not a strictly decreasing function ofk. For example, with seven shortcuts one cannot obtain a smaller diameter than with six shortcuts. Finally, we prove that the optimal diameter is   Thetakfrac for anyk.

This paper presents an example of how demographical characteristics of patients influence their susceptibility to certain medical conditions. In this paper, we investigate the association of health conditions to age of patients in a heterogeneous population. We show that besides the symptoms a patients is having, the age has the potential of aiding the diagnostic process in hospitals. Working with Electronic Health Records EHR, we show that medical conditions group into clusters that share distinctive population age densities. We use Electronic Health Records from Brazil for a period of  months from March of  to July of . The number of patients in the data is . million patients and the number of records is  million records. The findings has the potential of helping in a setting where an automated system undergoes the task of predicting the condition of a patient given their symptoms and demographical information.

We develop normalisation by evaluation NBE for dependent types based on presheaf categories. Our construction is formulated in the metalanguage of type theory using quotient inductive types. We use a typed presentation hence there are no preterms or realizers in our construction, and every construction respects the conversion relation. NBE for simple types uses a logical relation between the syntax and the presheaf interpretation. In our construction, we merge the presheaf interpretation and the logical relation into a proof-relevant logical predicate. We prove normalisation, completeness, stability and decidability of definitional equality. Most of the constructions were formalized in Agda.

We study the dynamics of a few-quantum-particle cloud in the presence of two- and three-body interactions in weakly disordered one-dimensional lattices. The interaction is dramatically enhancing the Anderson localization length xi of noninteracting particles. We launch compact wave packets and show that few-body interactions lead to transient subdiffusion of wave packets, m sim talpha, alpha, on length scales beyond xi. The subdiffusion exponent is independent of the number of particles. Two-body interactions yield alphaapprox. for two and three particles, while three-body interactions decrease it to alphaapprox.. The tails of expanding wave packets exhibit exponential localization with a slowly decreasing exponent. We relate our results to subdiffusion in nonlinear random lattices, and to results on restricted diffusion in high-dimensional spaces like e.g. on comb lattices.

The advent of the attention mechanism in neural machine translation models has improved the performance of machine translation systems by enabling selective lookup into the source sentence. In this paper, the efficiencies of translation using bidirectional encoder attention decoder models were studied with respect to translation involving morphologically rich languages. The English - Tamil language pair was selected for this analysis. First, the use of WordVec embedding for both the English and Tamil words improved the translation results by . BLEU points over the baseline RNNSearch model with . BLEU score. The use of morphological segmentation before word vectorization to split the morphologically rich Tamil words into their respective morphemes before the translation, caused a reduction in the target vocabulary size by a factor of . Also, this model RNNMorph improved the performance of neural machine translation by . BLEU points over the RNNSearch model used over the same corpus. Since the BLEU evaluation of the RNNMorph model might be unreliable due to an increase in the number of matching tokens per sentence, the performances of the translations were also compared by means of human evaluation metrics of adequacy, fluency and relative ranking. Further, the use of morphological segmentation also improved the efficacy of the attention mechanism.

We consider the problem of digitalizing Euclidean line segments from mathbbRd to mathbbZd. Christ em et al. DCG,  showed how to construct a set of em consistent digital segment CDS for d a collection of segments connecting any two points in mathbbZ that satisfies the natural extension of the Euclidean axioms to mathbbZd. In this paper we study the construction of CDSs in higher dimensions.   We show that any total order can be used to create a set of em consistent digital rays CDR in mathbbZd a set of rays emanating from a fixed point p that satisfies the extension of the Euclidean axioms. We fully characterize for which total orders the construction holds and study their Hausdorff distance, which in particular positively answers the question posed by Christ em et al..

Scientific discoveries are increasingly driven by analyzing large volumes of image data. Many new libraries and specialized database management systems DBMSs have emerged to support such tasks. It is unclear, however, how well these systems support real-world image analysis use cases, and how performant are the image analytics tasks implemented on top of such systems. In this paper, we present the first comprehensive evaluation of large-scale image analysis systems using two real-world scientific image data processing use cases. We evaluate five representative systems SciDB, Myria, Spark, Dask, and TensorFlow and find that each of them has shortcomings that complicate implementation or hurt performance. Such shortcomings lead to new research opportunities in making large-scale image analysis both efficient and easy to use.

Continuing demands for increased compute efficiency and communication bandwidth have led to the development of novel interconnect technologies with the potential to outperform conventional electrical interconnects. With a plurality of interconnect technologies to include electronics, photonics, plasmonics, and hybrids thereof, the simple approach of counting on-chip devices to capture performance is insufficient. While some efforts have been made to capture the performance evolution more accurately, they eventually deviate from the observed development pace. Thus, a holistic figure of merit FOM is needed to adequately compare these recent technology paradigms. Here we introduce the Capability-to-Latency-Energy-Amount-Resistance CLEAR FOM derived from device and link performance criteria of both active optoelectronic devices and passive components alike. As such CLEAR incorporates communication delay, energy efficiency, on-chip scaling and economic cost. We show that CLEAR accurately describes compute development including most recent machines. Since this FOM is derived bottom-up, we demonstrate remarkable adaptability to applications ranging from device-level to network and system-level. Applying CLEAR to benchmark device, link, and network performance against fundamental physical compute and communication limits shows that photonics is competitive even for fractions of the die-size, thus making a case for on-chip optical interconnects.

Providing accurate predictions is challenging for machine learning algorithms when the number of features is larger than the number of samples in the data. Prior knowledge can improve machine learning models by indicating relevant variables and parameter values. Yet, this prior knowledge is often tacit and only available from domain experts. We present a novel approach that uses interactive visualization to elicit the tacit prior knowledge and uses it to improve the accuracy of prediction models. The main component of our approach is a user model that models the domain experts knowledge of the relevance of different features for a prediction task. In particular, based on the experts earlier input, the user model guides the selection of the features on which to elicit users knowledge next. The results of a controlled user study show that the user model significantly improves prior knowledge elicitation and prediction accuracy, when predicting the relative citation counts of scientific documents in a specific domain.

Imputing incomplete medical tests and predicting patient outcomes are crucial for guiding the decision making for therapy, such as after an Achilles Tendon Rupture ATR. We formulate the problem of data imputation and prediction for ATR relevant medical measurements into a recommender system framework. By applying MatchBox, which is a collaborative filtering approach, on a real dataset collected from  ATR patients, we aim at offering personalized medical data imputation and prediction. In this work, we show the feasibility of this approach and discuss potential research directions by conducting initial qualitative evaluations.

Recently, we have witnessed the explosive growth of images with complex information and content. In order to effectively and precisely retrieve desired images from a large-scale image database with low time-consuming, we propose the multiple feature fusion image retrieval algorithm based on the texture feature and rough set theory in this paper. In contrast to the conventional approaches that only use the single feature or standard, we fuse the different features with operation of normalization. The rough set theory will assist us to enhance the robustness of retrieval system when facing with incomplete data warehouse. To enhance the texture extraction paradigm, we use the wavelet Gabor function that holds better robustness. In addition, from the perspectives of the internal and external normalization, we re-organize extracted feature with the better combination. The numerical experiment has verified general feasibility of our methodology. We enhance the overall accuracy compared with the other state-of-the-art algorithms.

Simulations of physical phenomena are essential to the expedient design of precision components in aerospace and other high-tech industries. These phenomena are often described by mathematical models involving partial differential equations PDEs without exact solutions. Modern design problems require simulations with a level of resolution that is difficult to achieve in a reasonable amount of time even in effectively parallelized solvers. Though the scale of the problem relative to available computing power is the greatest impediment to accelerating these applications, significant performance gains can be achieved through careful attention to the details of memory accesses. Parallelized PDE solvers are subject to a trade-off in memory management store the solution for each timestep in abundant, global memory with high access costs or in a limited, private memory with low access costs that must be passed between nodes. The GPU implementation of swept time-space decomposition presented here mitigates this dilemma by using private shared memory, avoiding internode communication, and overwriting unnecessary values. It shows significant improvement in the execution time of the PDE solvers in one dimension achieving speedups of -x for large and small problem sizes respectively compared to naive GPU versions and -x compared to parallel CPU versions.

This work presents a new procedure to extract features of grey-level texture images based on the discrete Schroedinger transform. This is a non-linear transform where the image is mapped as the initial probability distribution of a wave function and such distribution evolves in time following the Schroedinger equation from Quantum Mechanics. The features are provided by statistical moments of the distribution measured at different times. The proposed method is applied to the classification of three databases of textures used for benchmark and compared to other well-known texture descriptors in the literature, such as textons, local binary patterns, multifractals, among others. All of them are outperformed by the proposed method in terms of percentage of images correctly classified. The proposal is also applied to the identification of plant species using scanned images of leaves and again it outperforms other texture methods. A test with images affected by Gaussian and salt  pepper noise is also carried out, also with the best performance achieved by the Schroedinger descriptors.

Recent works on bounding the output size of a conjunctive query with functional dependencies and degree bounds have shown a deep connection between fundamental questions in information theory and database theory. We prove analogous output bounds for disjunctive datalog queries, and answer several open questions regarding the tightness and looseness of these bounds along the way. The bounds are intimately related to Shannon-type information inequalities. We devise the notion of a proof sequence of a specific class of Shannon-type information inequalities called Shannon flow inequalities. We then show how the proof sequence can be used as symbolic instructions to guide an algorithm called PANDA, which answers disjunctive datalog queries within the size bound predicted. We show that PANDA can be used as a black-box to devise algorithms matching precisely the fractional hypertree width and the submodular width runtimes for queries with functional dependencies and degree bounds.   Our results improve upon known results in three ways. First, our bounds and algorithms are for the much more general class of disjunctive datalog queries, of which conjunctive queries are a special case. Second, the runtime of PANDA matches precisely the submodular width bound, while the previous algorithm by Marx has a runtime that is polynomial in this bound. Third, our bounds and algorithms work for queries with input cardinality bounds, functional dependencies, and degree bounds.   Overall, our results showed a deep connection between three seemingly unrelated lines of research and, our results on proof sequences for Shannon flow inequalities might be of independent interest.

In this paper, we present a new method for computing approximate geodesic distances. We introduce the wave method for approximating geodesic distances from a point on a manifold mesh. Our method involves the solution of two linear systems of equations. One system of equations is solved repeatedly to propagate the wave on the entire mesh, and one system is solved once after wave propagation is complete in order to compute the approximate geodesic distances up to an additive constant. However, these systems need to be pre-factored only once, and can be solved efficiently at each iteration. All of our tests required approximately between  and  iterations, which were completed in a few seconds. Therefore, this method can approximate geodesic distances quickly, and the approximation is highly accurate.

This work developed novel complex matrix factorization methods for face recognition the methods were complex matrix factorization CMF, sparse complex matrix factorization SpaCMF, and graph complex matrix factorization GraCMF. After real-valued data are transformed into a complex field, the complex-valued matrix will be decomposed into two matrices of bases and coefficients, which are derived from solutions to an optimization problem in a complex domain. The generated objective function is the real-valued function of the reconstruction error, which produces a parametric description. Factorizing the matrix of complex entries directly transformed the constrained optimization problem into an unconstrained optimization problem. Additionally, a complex vector space with N dimensions can be regarded as a N-dimensional real vector space. Accordingly, all real analytic properties can be exploited in the complex field. The ability to exploit these important characteristics motivated the development herein of a simpler framework that can provide better recognition results. The effectiveness of this framework will be clearly elucidated in later sections in this paper.

We study the online estimation of the optimal policy of a Markov decision process MDP. We propose a class of Stochastic Primal-Dual SPD methods which exploit the inherent minimax duality of Bellman equations. The SPD methods update a few coordinates of the value and policy estimates as a new state transition is observed. These methods use small storage and has low computational complexity per iteration. The SPD methods find an absolute-epsilon-optimal policy, with high probability, using mathcalOleftfracmathcalS mathcalAsigma -gammaepsilon right iterationssamples for the infinite-horizon discounted-reward MDP and mathcalOleftfracmathcalS mathcalAHsigma epsilon right for the finite-horizon MDP.

This paper presents an efficient approach to image segmentation that approximates the piecewise-smooth PS functional in  with explicit solutions. By rendering some rational constraints on the initial conditions and the final solutions of the PS functional, we propose two novel formulations which can be approximated to be the explicit solutions of the evolution partial differential equations PDEs of the PS model, in which only one PDE needs to be solved efficiently. Furthermore, an energy term that regularizes the level set function to be a signed distance function is incorporated into our evolution formulation, and the time-consuming re-initialization is avoided. Experiments on synthetic and real images show that our method is more efficient than both the PS model and the local binary fitting LBF model , while having similar segmentation accuracy as the LBF model.

There have been several attempts to mathematically understand neural networks and many more from biological and computational perspectives. The field has exploded in the last decade, yet neural networks are still treated much like a black box. In this work we describe a structure that is inherent to a feed forward neural network. This will provide a framework for future work on neural networks to improve training algorithms, compute the homology of the network, and other applications. Our approach takes a more geometric point of view and is unlike other attempts to mathematically understand neural networks that rely on a functional perspective.

We consider the problem of predicting the next observation given a sequence of past observations. We show that for any distribution over observations, if the mutual information between past observations and future observations is upper bounded by I, then a simple Markov model over the most recent Iepsilon observations obtains expected KL error epsilon--and hence ell error sqrtepsilon--with respect to the optimal predictor that has access to the entire past. For a Hidden Markov Model with n states, I is bounded by log n, a quantity that does not depend on the mixing time. We also establish that this result cannot be improved upon, in the following senses First, a window length of Iepsilon is information-theoretically necessary for expected KL error epsilon, or ell error sqrtepsilon. Second, the dThetaIepsilon samples required to accurately estimate the Markov model when observations are drawn from an alphabet of size d is necessary for any computationally tractable learningprediction algorithm, assuming the hardness of strongly refuting a certain class of CSPs.

Bagging is a device intended for reducing the prediction error of learning algorithms. In its simplest form, bagging draws bootstrap samples from the training sample, applies the learning algorithm to each bootstrap sample, and then averages the resulting prediction rules.   We extend the definition of bagging from statistics to statistical functionals and study the von Mises expansion of bagged statistical functionals. We show that the expansion is related to the Efron-Stein ANOVA expansion of the raw unbagged functional. The basic observation is that a bagged functional is always smooth in the sense that the von Mises expansion exists and is finite of length   resample size M. This holds even if the raw functional is rough or unstable. The resample size M acts as a smoothing parameter, where a smaller M means more smoothing.

We present a data stream algorithm for estimating the size of the maximum matching of a low arboricity graph. Recall that a graph has arboricity alpha if its edges can be partitioned into at most alpha forests and that a planar graph has arboricity alpha. Estimating the size of the maximum matching in such graphs has been a focus of recent data stream research.   A surprising result on this problem was recently proved by Cormode et al. They designed an ingenious algorithm that returned a .alphaepsilon approximation using a single pass over the edges of the graph ordered arbitrarily and Oepsilon-alpha cdot log n cdot logepsilon n space. In this note, we improve the approximation factor to alphaepsilon via a tighter analysis and show that, with a modification of their algorithm, the space required can be reduced to Oepsilon- log n.

Measuring visual similarity is critical for image understanding. But what makes two images similar? Most existing work on visual similarity assumes that images are similar because they contain the same object instance or category. However, the reason why images are similar is much more complex. For example, from the perspective of category, a black dog image is similar to a white dog image. However, in terms of color, a black dog image is more similar to a black horse image than the white dog image. This example serves to illustrate that visual similarity is ambiguous but can be made precise when given an explicit contextual perspective. Based on this observation, we propose the concept of contextual visual similarity. To be concrete, we examine the concept of contextual visual similarity in the application domain of image search. Instead of providing only a single image for image similarity search eg, Google image search, we require three images. Given a query image, a second positive image and a third negative image, dissimilar to the first two images, we define a contextualized similarity search criteria. In particular, we learn feature weights over all the feature dimensions of each image such that the distance between the query image and the positive image is small and their distances to the negative image are large after reweighting their features. The learned feature weights encode the contextualized visual similarity specified by the user and can be used for attribute specific image search. We also show the usefulness of our contextualized similarity weighting scheme for different tasks, such as answering visual analogy questions and unsupervised attribute discovery.

City traffic is a dynamic system of enormous complexity. Modeling and predicting city traffic flow remains to be a challenge task and the main difficulties are how to specify the supply and demands and how to parameterize the model. In this paper we attempt to solve these problems with the help of large amount of floating car data. We propose a coarse-grained cellular automata model that simulates vehicles moving on uniform grids whose size are much larger compared with the microscopic cellular automata model. The car-car interaction in the microscopic model is replaced by the coupling between vehicles and coarse-grained state variables in our model. To parameterize the model, flux-occupancy relations are fitted from the historical data at every grids, which serve as the coarse-grained fundamental diagrams coupling the occupancy and speed. To evaluate the model, we feed it with the historical travel demands and trajectories obtained from the floating car data and use the model to predict road speed one hour into the future. Numerical results show that our model can capture the traffic flow pattern of the entire city and make reasonable predictions. The current work can be considered a prototype for a model-based forecasting system for city traffic.

The hashing methods have attracted much attention for large scale image retrieval. Some deep hashing methods have achieved promising results by taking advantage of the better representation power of deep networks recently. However, existing deep hashing methods treat all hash bits equally. On one hand, a large number of images share the same distance to a query image because of the discrete Hamming distance, which cannot provide fine-grained retrieval since the ranking of these images is ambiguous. On the other hand, different hash bits actually contribute to the image retrieval differently, treating them equally greatly affects the image retrieval accuracy. To address the two problems, we propose the query-adaptive deep weighted hashing QaDWH approach, which can perform fine-grained image retrieval for different queries by weighted Hamming distance. First, a novel deep hashing network is designed to learn the hash codes and corresponding class-wise hash bit weights jointly, so that the learned weights can reflect the importance of different hash bits for different image class. Second, a query-adaptive image retrieval method is proposed, which rapidly generate query images hash bit weights by the fusion of the semantic probability of the query and the learned class-wise weights. Fine-grained image retrieval is then performed by the weighted Hamming distance, which can provide more accurate ranking than the original Hamming distance. Extensive experiments on  widely used datasets show that the proposed approach outperforms state-of-the-art hashing methods.

Given a sufficient statistic for a parametric family of distributions, one can estimate the parameter without access to the data itself. However, the memory or code size for storing the sufficient statistic may nonetheless still be prohibitive. Indeed, for n independent data samples drawn from a k-nomial distribution with dk- degrees of freedom, the length of the code scales as dlog nO. In many applications though, we may not have a useful notion of sufficient statistics e.g., when the parametric family is not an exponential family and also may not need to reconstruct the generating distribution exactly. By adopting a Shannon-theoretic approach in which we consider allow a small error in estimating the generating distribution, we construct various notions of em approximate sufficient statistics and show that the code length can be reduced to fracdlog nO. We also note that the locality assumption that is used to describe the notion of local approximate sufficient statistics when the parametric family is not an exponential family can be dispensed of. We consider errors measured according to the relative entropy and variational distance criteria. For the code construction parts, we leverage Rissanens minimum description length principle, which yields a non-vanishing error measured using the relative entropy. For the converse parts, we use Clarke and Barrons asymptotic expansion for the relative entropy of a parametrized distribution and the corresponding mixture distribution. The limitation of this method is that only a weak converse for the variational distance can be shown. We develop new techniques to achieve vanishing errors and we also prove strong converses for all our statements. The latter means that even if the code is allowed to have a non-vanishing error, its length must still be at least fracdlog n.

This paper proposes a polar code construction scheme that reduces constituent-code supplemented decoding latency. Constituent codes are the sub-codewords with specific patterns. They are used to accelerate the successive cancellation decoding process of polar code without any performance degradation. We modify the traditional construction approach to yield increased number of desirable constituent codes that speeds the decoding process. For n,k polar code, instead of directly setting the k best and n-k worst bits to the information bits and frozen bits, respectively, we swap the locations of some information and frozen bits carefully according to the qualities of their equivalent channels. We conducted the simulation of  and  bits length polar codes with multiple rates and analyzed the decoding latency for various length codes. The numerical results show that the proposed construction scheme generally is able to achieve at least around  latency deduction with an negligible loss in gain with carefully selected optimization threshold.

Many variability management techniques rely on sophisticated language extension or tools to support it. While this can provide dedicated syntax and operational mechanism but it struggling practical adaptation for the cost of adapting new technology as part of development process. We present Self-composable Programming, a language-driven, composition-based variability implementation which takes an object-oriented approach to modeling and composing behaviors in software. Self-composable Programming introduces hierarchical relationship of behavior by providing concepts of abstract function, which modularise commonalities, and specific function which inherits from abstract function and be apply refinement to contain variabilities to fulfill desired functionality. Various object-oriented techniques can applicable in the refinement process including explicit method-based, and implicit traits-based refinement. In order to evaluate the potential independence of behavior from the object by applying object-orientation to function, we compare it to Aspect-oriented Programming both conceptually and empirically.

The proofs of Chaitin and Boolos for Godels Incompleteness Theorem are studied from the perspectives of constructibility and Rosserizability. By Rosserization of a proof we mean that the independence of the true but unprovable sentence can be shown by assuming only the simple consistency of the theory. It is known that Godels own proof for his incompleteness theorem is not Rosserizable, and we show that neither are Kleenes or Boolos proofs. However, we prove a Rosserized version of Chaitins incompleteness theorem. The proofs of Godel, Rosser and Kleene are constructive in the sense that they explicitly construct, by algorithmic ways, the independent sentences from the theory. We show that the proofs of Chaitin and Boolos are not constructive, and they prove only the mere existence of the independent sentences.

The paper introduces RADULS, a new parallel sorter based on radix sort algorithm, intended to organize ultra-large data sets efficiently. For example G -byte records can be sorted with  threads in less than  seconds on Intel Xeon-based workstation. The implementation of RADULS is not only highly optimized to gain such an excellent performance, but also parallelized in a cache friendly manner to make the most of modern multicore architectures. Besides, our parallel scheduler launches a few different procedures at runtime, according to the current parameters of the execution, for proper workload management. All experiments show RADULS to be superior to competing algorithms.

We consider the problem of data augmentation, i.e., generating artificial samples to extend a given corpus of training data. Specifically, we propose attributed-guided augmentation AGA which learns a mapping that allows to synthesize data such that an attribute of a synthesized sample is at a desired value or strength. This is particularly interesting in situations where little data with no attribute annotation is available for learning, but we have access to a large external corpus of heavily annotated samples. While prior works primarily augment in the space of images, we propose to perform augmentation in feature space instead. We implement our approach as a deep encoder-decoder architecture that learns the synthesis function in an end-to-end manner. We demonstrate the utility of our approach on the problems of  one-shot object recognition in a transfer-learning setting where we have no prior knowledge of the new classes, as well as  object-based one-shot scene recognition. As external data, we leverage D depth and pose information from the SUN RGB-D dataset. Our experiments show that attribute-guided augmentation of high-level CNN features considerably improves one-shot recognition performance on both problems.

We consider a new fictitious domain approach of higher order accuracy. To implement Dirichlet conditions we apply the classical Nitsche method combined with a facet-based stabilization ghost penalty. Both techniques are combined with a higher order isoparametric finite element space which is based on a special mesh transformation. The mesh transformation is build upon a higher order accurate level set representation and allows to reduce the problem of numerical integration to problems on domains which are described by piecewise linear level set functions. The combination of this strategy for the numerical integration and the stabilized Nitsche formulation results in an accurate and robust method. We introduce and analyze it and give numerical examples.

As our population ages, neurological impairments and degeneration of the musculoskeletal system yield gait abnormalities, which can significantly reduce quality of life. Gait rehabilitative therapy has been widely adopted to help patients maximize community participation and living independence. To further improve the precision and efficiency of rehabilitative therapy, more objective methods need to be developed based on sensory data. In this paper, an algorithmic framework is proposed to provide classification of gait disorders caused by two common neurological diseases, stroke and Parkinsons Disease PD, from ground contact force GCF data. An advanced machine learning method, multi-task feature learning MTFL, is used to jointly train classification models of a subjects gait in three classes, post-stroke, PD and healthy gait. Gait parameters related to mobility, balance, strength and rhythm are used as features for the classification. Out of all the features used, the MTFL models capture the more important ones per disease, which will help provide better objective assessment and therapy progress tracking. To evaluate the proposed methodology we use data from a human participant study, which includes five PD patients, three post-stroke patients, and three healthy subjects. Despite the diversity of abnormalities, the evaluation shows that the proposed approach can successfully distinguish post-stroke and PD gait from healthy gait, as well as post-stroke from PD gait, with Area Under the Curve AUC score of at least .. Moreover, the methodology helps select important gait features to better understand the key characteristics that distinguish abnormal gaits and design personalized treatment.

Huge amount of data with both space and text information, e.g., geo-tagged tweets, is flooding on the Internet. Such spatio-textual data stream contains valuable information for millions of users with various interests on different keywords and locations. Publishsubscribe systems enable efficient and effective information distribution by allowing users to register continuous queries with both spatial and textual constraints. However, the explosive growth of data scale and user base has posed challenges to the existing centralized publishsubscribe systems for spatio-textual data streams.   In this paper, we propose our distributed publishsubscribe system, called PSStream, which digests a massive spatio-textual data stream and directs the stream to target users with registered interests. Compared with existing systems, PSStream achieves a better workload distribution in terms of both minimizing the total amount of workload and balancing the load of workers. To achieve this, we propose a new workload distribution algorithm considering both space and text properties of the data. Additionally, PSStream supports dynamic load adjustments to adapt to the change of the workload, which makes PSStream adaptive. Extensive empirical evaluation, on commercial cloud computing platform with real data, validates the superiority of our system design and advantages of our techniques on system performance improvement.

The network virtualization allows new on-demand management capabilities, in this work we demonstrate such a service, namely, on-demand efficient monitoring or anonymity. The proposed service is based on network virtualization of expanders or sparsifiers over the physical network. The defined virtual or overlay communication graphs coupled with a multi-hop extension of Valiant randomization based routing lets us monitor the entire traffic in the network, with a very few monitoring nodes.   In particular, we show that using overlay network with expansion properties and Valiant randomized load balancing it is enough to place Om monitor nodes when the length of the overlay path number of intermediate nodes chosen by Valiants routing procedure is Onm.   We propose two randomized routing methods to implement policies for sending messages, and we show that they facilitate efficient monitoring of the entire traffic, such that the traffic is distributed uniformly in the network, and each monitor has equiprobable view of the network flow. In terms of complex networks, our result can be interpreted as a way to enforce the same betweenness centrality to all nodes in the network.   Additionally, we show that our results are useful in employing anonymity services. Thus, we propose monitoring or anonymity services, which can be deployed and shut down on-demand. Our work is the first, as far as we know, to bring such on-demand infrastructure structuring using the cloud network virtualization capability to existing monitoring or anonymity networks. We propose methods to theoretically improve services provided by existing anonymity networks, and optimize the degree of anonymity, in addition providing robustness and reliability to system usage and security.   We believe that, our constructions of overlay expanders and sparsifiers weighted network are of independent interest.

Machine learning analysis of neuroimaging data can accurately predict chronological age in healthy people and deviations from healthy brain ageing have been associated with cognitive impairment and disease. Here we sought to further establish the credentials of brain-predicted age as a biomarker of individual differences in the brain ageing process, using a predictive modelling approach based on deep learning, and specifically convolutional neural networks CNN, and applied to both pre-processed and raw T-weighted MRI data. Firstly, we aimed to demonstrate the accuracy of CNN brain-predicted age using a large dataset of healthy adults N  . Next, we sought to establish the heritability of brain-predicted age using a sample of monozygotic and dizygotic female twins N  . Thirdly, we examined the test-retest and multi-centre reliability of brain-predicted age using two samples within-scanner N   between-scanner N  . CNN brain-predicted ages were generated and compared to a Gaussian Process Regression GPR approach, on all datasets. Input data were grey matter GM or white matter WM volumetric maps generated by Statistical Parametric Mapping SPM or raw data. Brain-predicted age represents an accurate, highly reliable and genetically-valid phenotype, that has potential to be used as a biomarker of brain ageing. Moreover, age predictions can be accurately generated on raw T-MRI data, substantially reducing computation time for novel data, bringing the process closer to giving real-time information on brain health in clinical settings.

This paper considers the jointly optimal pilot and data power allocation in single-cell uplink massive multiple-input-multiple-output MIMO systems. Using the spectral efficiency SE as performance metric and setting a total energy budget per coherence interval, the power control is formulated as optimization problems for two different objective functions the weighted minimum SE among the users and the weighted sum SE. A closed form solution for the optimal length of the pilot sequence is derived. The optimal power control policy for the former problem is found by solving a simple equation with a single variable. Utilizing the special structure arising from imperfect channel estimation, a convex reformulation is found to solve the latter problem to global optimality in polynomial time. The gain of the optimal joint power control is theoretically justified, and is proved to be large in the low SNR regime. Simulation results also show the advantage of optimizing the power control over both pilot and data power, as compared to the cases of using full power and of only optimizing the data powers as done in previous work.

Typical convolutional neural networks CNNs have several millions of parameters and require a large amount of annotated data to train them. In medical applications where training data is hard to come by, these sophisticated machine learning models are difficult to train. In this paper, we propose a method to reduce the inherent complexity of CNNs during training by exploiting the significant redundancy that is noticed in the learnt CNN filters. Our method relies on finding a small set of filters and mixing coefficients to derive every filter in each convolutional layer at the time of training itself, thereby reducing the number of parameters to be trained. We consider the problem of D lung nodule segmentation in CT images and demonstrate the effectiveness of our method in achieving good results with only few training examples.

Removing pixel-wise heterogeneous motion blur is challenging due to the ill-posed nature of the problem. The predominant solution is to estimate the blur kernel by adding a prior, but the extensive literature on the subject indicates the difficulty in identifying a prior which is suitably informative, and general. Rather than imposing a prior based on theory, we propose instead to learn one from the data. Learning a prior over the latent image would require modeling all possible image content. The critical observation underpinning our approach is thus that learning the motion flow instead allows the model to focus on the cause of the blur, irrespective of the image content. This is a much easier learning task, but it also avoids the iterative process through which latent image priors are typically applied. Our approach directly estimates the motion flow from the blurred image through a fully-convolutional deep neural network FCN and recovers the unblurred image from the estimated motion flow. Our FCN is the first universal end-to-end mapping from the blurred image to the dense motion flow. To train the FCN, we simulate motion flows to generate synthetic blurred-image-motion-flow pairs thus avoiding the need for human labeling. Extensive experiments on challenging realistic blurred images demonstrate that the proposed method outperforms the state-of-the-art.

Compositional models were introduce by Jirousek and Shenoy in the general framework of valuation-based systems. They based their theory on an axiomatic system of valuations involving not only the operations of combination and marginalisation, but also of removal. They claimed that this systems covers besides the classical case of discrete probability distributions, also the cases of Gaussian densities and belief functions, and many other systems.   Whereas their results on the compositional operator are correct, the axiomatic basis is not sufficient to cover the examples claimed above. We propose here a different axiomatic system of valuation algebras, which permits a rigorous mathematical theory of compositional operators in valuation-based systems and covers all the examples mentioned above. It extends the classical theory of inverses in semigroup theory and places thereby the present theory into its proper mathematical frame. Also this theory sheds light on the different structures of valuation-based systems, like regular algebras represented by probability potentials, canncellative algebras Gaussian potentials and general separative algebras density functions.

Early diagnosis of interstitial lung diseases is crucial for their treatment, but even experienced physicians find it difficult, as their clinical manifestations are similar. In order to assist with the diagnosis, computer-aided diagnosis CAD systems have been developed. These commonly rely on a fixed scale classifier that scans CT images, recognizes textural lung patterns and generates a map of pathologies. In a previous study, we proposed a method for classifying lung tissue patterns using a deep convolutional neural network CNN, with an architecture designed for the specific problem. In this study, we present an improved method for training the proposed network by transferring knowledge from the similar domain of general texture classification. Six publicly available texture databases are used to pretrain networks with the proposed architecture, which are then fine-tuned on the lung tissue data. The resulting CNNs are combined in an ensemble and their fused knowledge is compressed back to a network with the original architecture. The proposed approach resulted in an absolute increase of about  in the performance of the proposed CNN. The results demonstrate the potential of transfer learning in the field of medical image analysis, indicate the textural nature of the problem and show that the method used for training a network can be as important as designing its architecture.

This paper is the first to review the scene flow estimation field to the best of our knowledge, which analyzes and compares methods, technical challenges, evaluation methodologies and performance of scene flow estimation. Existing algorithms are categorized in terms of scene representation, data source, and calculation scheme, and the pros and cons in each category are compared briefly. The datasets and evaluation protocols are enumerated, and the performance of the most representative methods is presented. A future vision is illustrated with few questions arisen for discussion. This survey presents a general introduction and analysis of scene flow estimation.

Information-centric networking ICN has gained attention from network research communities due to its capability of efficient content dissemination. In-network caching function in ICN plays an important role to achieve the design motivation. However, many researchers on in-network caching have focused on where to cache rather than how to cache the former is known as contents deployment in the network and the latter is known as cache replacement in an ICN element. Although, the cache replacement has been intensively researched in the context of web-caching and content delivery network previously, the conventional approaches cannot be directly applied to ICN due to the fine granularity of cacheable items in ICN, which eventually changes the access patterns.   In this paper, we argue that ICN requires a novel cache replacement algorithm to fulfill the requirements in the design of high performance ICN element. Then, we propose a novel cache replacement algorithm to satisfy the requirements named Compact CLOCK with Adaptive Replacement Compact CAR, which can reduce the consumption of cache memory to one-tenth compared to conventional approaches.

We develop a general problem setting for training and testing the ability of agents to gather information efficiently. Specifically, we present a collection of tasks in which success requires searching through a partially-observed environment, for fragments of information which can be pieced together to accomplish various goals. We combine deep architectures with techniques from reinforcement learning to develop agents that solve our tasks. We shape the behavior of these agents by combining extrinsic and intrinsic rewards. We empirically demonstrate that these agents learn to search actively and intelligently for new information to reduce their uncertainty, and to exploit information they have already acquired.

Autonomous delivery of goods using a MAV is a difficult problem, as it poses high demand on the MAVs control, perception and manipulation capabilities. This problem is especially challenging if the exact shape, location and configuration of the objects are unknown. In this paper, we report our findings during the development and evaluation of a fully integrated system that is energy efficient and enables MAVs to pick up and deliver objects with partly ferrous surface of varying shapes and weights. This is achieved by using a novel combination of an electro-permanent magnetic gripper with a passively compliant structure and integration with detection, control and servo positioning algorithms. The systems ability to grasp stationary and moving objects was tested, as well as its ability to cope with different shapes of the object and external disturbances. We show that such a system can be successfully deployed in scenarios where an object with partly ferrous parts needs to be gripped and placed in a predetermined location.

Amorphous solids are ubiquitous among natural and man-made materials. Often used as structural materials for their attractive mechanical properties, their utility depends critically on their response to applied stresses. Processes underlying such mechanical response, and in particular the yielding behaviour of amorphous solids, are not satisfactorily understood. Although studied extensively-, observed yielding behaviour can be gradual and depend significantly on conditions of study, making it difficult to convincingly validate existing theoretical descriptions of a sharp yielding transition, , , , . Here, we employ oscillatory deformation as a reliable probe of the yielding transition. Through extensive computer simulations for a wide range of system sizes, we demonstrate that cyclically deformed model glasses exhibit a sharply defined yielding transition with characteristics that are independent of preparation history. In contrast to prevailing expectations, , , the statistics of avalanches reveals no signature of the impending transition, but exhibit dramatic, qualitative, changes in character across the transition.

We propose a novel tree-like curvilinear structure reconstruction algorithm based on supervised learning and graph theory. In this work we analyze image patches to obtain the local major orientations and the rankings that correspond to the curvilinear structure. To extract local curvilinear features, we compute oriented gradient information using steerable filters. We then employ Structured Support Vector Machine for ordinal regression of the input image patches, where the ordering is determined by shape similarity to latent curvilinear structure. Finally, we progressively reconstruct the curvilinear structure by looking for geodesic paths connecting remote vertices in the graph built on the structured output rankings. Experimental results show that the proposed algorithm faithfully provides topological features of the curvilinear structures using minimal pixels for various datasets.

Motivated by a recent new type of randomized Distributed Denial of Service DDoS attacks on the Domain Name Service DNS, we develop novel and efficient distinct heavy hitters algorithms and build an attack identification system that uses our algorithms. Heavy hitter detection in streams is a fundamental problem with many applications, including detecting certain DDoS attacks and anomalies. A classic heavy hitter HH in a stream of elements is a key e.g., the domain of a query which appears in many elements e.g., requests. When stream elements consist of a key subkey pairs, domain subdomain a distinct heavy hitter dhh is a key that is paired with a large number of different subkeys. Our dHH algorithms are considerably more practical than previous algorithms. Specifically the new fixed-size algorithms are simple to code and with asymptotically optimal space accuracy tradeoffs. In addition we introduce a new measure, a combined heavy hitter cHH, which is a key with a large combination of distinct and classic weights. Efficient algorithms are also presented for cHH detection. Finally, we perform extensive experimental evaluation on real DNS attack traces, demonstrating the effectiveness of both our algorithms and our DNS malicious queries identification system.

Recently, IoT technologies have been progressed and applications of maintenance area are expected. However, IoT maintenance applications are not spread in Japan yet because of insufficient analysis of real time situation, high cost to collect sensing data and to configure failure detection rules. In this paper, using lambda architecture concept, we propose a maintenance platform in which edge nodes analyze sensing data, detect anomaly, extract a new detection rule in real time and a cloud orders maintenance automatically, also analyzes whole data collected by batch process in detail, updates learning model of edge nodes to improve analysis accuracy.

Inspired by recent advances of deep learning in instance segmentation and object tracking, we introduce video object segmentation problem as a concept of guided instance segmentation. Our model proceeds on a per-frame basis, guided by the output of the previous frame towards the object of interest in the next frame. We demonstrate that highly accurate object segmentation in videos can be enabled by using a convnet trained with static images only. The key ingredient of our approach is a combination of offline and online learning strategies, where the former serves to produce a refined mask from the previous frame estimate and the latter allows to capture the appearance of the specific object instance. Our method can handle different types of input annotations bounding boxes and segments, as well as incorporate multiple annotated frames, making the system suitable for diverse applications. We obtain competitive results on three different datasets, independently from the type of input annotation.

Weighted automata over the max-plus semiring S are closely related to finitely generated semigroups of matrices over S. In this paper, we use results in automata theory to study two quantities associated with sets of matrices the joint spectral radius and the ultimate rank. We prove that these two quantities are not computable over the tropical semiring, i.e. there is no algorithm that takes as input a finite set of matrices M and provides as output the joint spectral radius resp. the ultimate rank of M. On the other hand, we prove that the joint spectral radius is nevertheless approximable and we exhibit restricted cases in which the joint spectral radius and the ultimate rank are computable. To reach this aim, we study the problem of comparing functions computed by weighted automata over the tropical semiring. This problem is known to be undecidable and we prove that it remains undecidable in some specific subclasses of automata.

Fully convolutional models for dense prediction have proven successful for a wide range of visual tasks. Such models perform well in a supervised setting, but performance can be surprisingly poor under domain shifts that appear mild to a human observer. For example, training on one city and testing on another in a different geographic region andor weather condition may result in significantly degraded performance due to pixel-level distribution shift. In this paper, we introduce the first domain adaptive semantic segmentation method, proposing an unsupervised adversarial approach to pixel prediction problems. Our method consists of both global and category specific adaptation techniques. Global domain alignment is performed using a novel semantic segmentation network with fully convolutional domain adversarial learning. This initially adapted space then enables category specific adaptation through a generalization of constrained weak learning, with explicit transfer of the spatial layout from the source to the target domains. Our approach outperforms baselines across different settings on multiple large-scale datasets, including adapting across various real city environments, different synthetic sub-domains, from simulated to real environments, and on a novel large-scale dash-cam dataset.

The previous generation of astronomical instruments tended to consist of single receivers in the focal point of one or more physical reflectors. Because of this, most astronomical data sets were small enough that the raw data could easily be downloaded and processed on a single machine.   In the last decade, several large, complex Radio Astronomy instruments have been built and the SKA is currently being designed. Many of these instruments have been designed by international teams, and, in the case of LOFAR span an area larger than a single country. Such systems are ICT telescopes and consist mainly of complex software. This causes the main operational issues to be related to the ICT systems and not the telescope hardware. However, it is important that the operations of the ICT systems are coordinated with the traditional operational work. Managing the operations of such telescopes therefore requires an approach that significantly differs from classical telescope operations.   The goal of this session is to bring together members of operational teams responsible for such large-scale ICT telescopes. This gathering will be used to exchange experiences and knowledge between those teams. Also, we consider such a meeting as very valuable input for future instrumentation, especially the SKA and its regional centres.

In decision theory an act is a function from a set of conditions to the set of real numbers. The set of conditions is a partition in some algebra of events. The expected value of an act can be calculated when a probability measure is given. We adopt an algebraic point of view by substituting the algebra of events with a finite distributive lattice and the probability measure with a lattice valuation. We introduce a partial order on acts that generalizes the dominance relation and show that the set of acts is a lattice with respect to this order. Finally we analyze some different kinds of comparison between acts, without supposing a common set of conditions for the acts to be compared.

While there has been significant progress on algorithmic aspects of the Lovasz Local Lemma LLL in recent years, a noteworthy exception is when the LLL is used in the context of random permutations. The breakthrough algorithm of Moser  Tardos only works in the setting of independent variables, and does not apply in this context. We resolve this by developing a randomized polynomial-time algorithm for such applications. A noteworthy application is for Latin transversals the best-known general result here Bissacot et al., improving on ErdHos and Spencer, states that any n times n matrix in which each entry appears at most n times, has a Latin transversal. We present the first polynomial-time algorithm to construct such a transversal. We also develop RNC algorithms for Latin transversals, rainbow Hamiltonian cycles, strong chromatic number, and hypergraph packing.   In addition to efficiently finding a configuration which avoids bad-events, the algorithm of Moser  Tardos has many powerful extensions and properties. These include a well-characterized distribution on the output distribution, parallel algorithms, and a partial resampling variant. We show that our algorithm has nearly all of the same useful properties as the Moser-Tardos algorithm, and present a comparison of this aspect with recent works on the LLL in general probability spaces.

This research evaluates the performance of an Artificial Neural Network based prediction system that was employed on the Shanghai Stock Exchange for the period -Sep- to -Oct-. It is a follow-up to a previous paper in which the prices were predicted and published before September . Stock market price prediction remains an important quest for investors and researchers. This research used an Artificial Intelligence system, being an Artificial Neural Network that is feedforward multi-layer perceptron with error backpropagation for prediction, unlike other methods such as technical, fundamental or time series analysis. While these alternative methods tend to guide on trends and not the exact likely prices, neural networks on the other hand have the ability to predict the real value prices, as was done on this research. Nonetheless, determination of suitable network parameters remains a challenge in neural network design, with this research settling on a configuration of  with  training data or -year of training data as a good enough model for stock prediction, as already determined in a previous research by the author. The comparative results indicate that neural network can predict typical stock market prices with mean absolute percentage errors that are as low as . over the ten prediction instances that was studied in this research.

D imaging modalities are becoming increasingly popular and relevant in retinal imaging owing to their effectiveness in highlighting structures in sub-retinal layers. OCT is one such modality which has great importance in the context of analysis of cystoid structures in subretinal layers. Signal to noise ratioSNR of the images obtained from OCT is less and hence automated and accurate determination of cystoid structures from OCT is a challenging task. We propose an automated method for detectingsegmenting cysts in D OCT volumes. The proposed method is biologically inspired and fast aided by the domain knowledge about the cystoid structures. An ensemble learning methodRandom forests is learnt for classification of detected region into cyst region. The method achieves detection and segmentation in a unified setting. We believe the proposed approach with further improvements can be a promising starting point for more robust approach. This method is validated against the training set achieves a mean dice coefficient of . with a standard deviation of .

Model checking of strategic ability under imperfect information is known to be hard. The complexity results range from NP-completeness to undecidability, depending on the precise setup of the problem. No less importantly, fixpoint equivalences do not generally hold for imperfect information strategies, which seriously hampers incremental synthesis of winning strategies. In this paper, we propose translations of ATLir formulae that provide lower and upper bounds for their truth values, and are cheaper to verify than the original specifications. That is, if the expression is verified as true then the corresponding formula of ATLir should also hold in the given model. We begin by showing where the straightforward approach does not work. Then, we propose how it can be modified to obtain guaranteed lower bounds. To this end, we alter the next-step operator in such a way that traversing ones indistinguishability relation is seen as atomic activity. Most interestingly, the lower approximation is provided by a fixpoint expression that uses a nonstandard variant of the next-step ability operator. We show the correctness of the translations, establish their computational complexity, and validate the approach by experiments with a scalable scenario of Bridge play.

Massive multi-user MU multiple-input multiple- output MIMO is widely believed to be a core technology for the upcoming fifth-generation G wireless communication standards. The use of low-precision digital-to-analog converters DACs in MU-MIMO base stations is of interest because it reduces the power consumption, system costs, and raw baseband data rates. In this paper, we develop novel algorithms for downlink precoding in massive MU-MIMO systems with -bit DACs that support higher-order modulation schemes such as -PSK or -QAM. Specifically, we present low-complexity nonlinear precoding algorithms that achieve low error rates when combined with blind or training-based channel-estimation algorithms at the user equipment. These results are in stark contrast to linear-quantized precoding algorithms, which suffer from a high error floor if used with high-order modulation schemes and -bit DACs.

Background. There are many factors that can make of group exercises a challenging setting for older adults. A major one in the elderly population is the difference in the level of skills. In this paper we report on the physical, psychological and social wellbeing outcomes of a novel virtual gym that enables online group-exercises in older adults with different levels of skills.   Methods. A total of  older adults - years old followed a personalized exercise program based on the OTAGO program for fall prevention, for a period of eight weeks. Participants could join online group exercises using a tablet-based application. Participants were assigned either to a Control group individual training or Social group online group-exercising. Pre- and post- measurements were taken to analyze the physical, psychological and social wellbeing outcomes. The study received ethical approval from the CREATE-NET Ethics Committee on ICT Research Involving Human Beings Application N. -.   Results. There were improvements in both the Social and Control groups in terms of physical outcomes. Interestingly though, while in the Control group fitter individuals tended to adhere more to the training, this was not the case for the Social group, where the initial level had no effect on adherence. For psychological and social wellbeing outcomes there were improvements on both groups, regardless of the application used.   Conclusion. Group exercising in a virtual gym can be effective in motivating and enabling individuals who are less fit to train as much as fitter individuals. This not only indicates the feasibility of training together despite differences in physical skills but also suggests that online exercise can reduce the effect of skills on adherence in a social context. Longer term interventions with more participants are instead recommended to assess impacts on wellbeing.

This letter reports the influence of noisy channels on JRSP of two-qubit equatorial state. We present a scheme for JRSP of two-qubit equatorial state. We employ two tripartite Greenberger-Horne-Zeilinger GHZ entangled states as the quantum channel linking the parties. We find the success probability to be . However, this probability can be ameliorated to  if the state preparers assist by transmitting individual partial information through classical channel to the receiver non-contemporaneously. Afterward, we investigate the effects of five quantum noises the bit-flip noise, bit-phase flip noise, amplitude-damping noise, phase-damping noise and depolarizing noise on the JRSP process. We obtain the analytical derivation of the fidelities corresponding to each quantum noisy channel, which is a measure of information loss as the qubits are being distributed in these quantum channels. We find that the system loses some of its properties as a consequence of unwanted interactions with environment. For instance, within the domain lambda., the information lost via transmission of qubits in amplitude channel is most minimal, while for .lambdaleq, the information lost in phase flip channel becomes the most minimal. Also, for any given lambda, the information transmitted through depolarizing channel has the least chance of success.

The recently proposed Sequence-to-Sequence seqseq framework advocates replacing complex data processing pipelines, such as an entire automatic speech recognition system, with a single neural network trained in an end-to-end fashion. In this contribution, we analyse an attention-based seqseq speech recognition system that directly transcribes recordings into characters. We observe two shortcomings overconfidence in its predictions and a tendency to produce incomplete transcriptions when language models are used. We propose practical solutions to both problems achieving competitive speaker independent word error rates on the Wall Street Journal dataset without separate language models we reach . WER, while together with a trigram language model, we reach . WER.

Two simple proofs of the triangle inequality for the Jaccard distance in terms of nonnegative, monotone, submodular functions are given and discussed.

Monocular D object parsing is highly desirable in various scenarios including occlusion reasoning and holistic scene interpretation. We present a deep convolutional neural network CNN architecture to localize semantic parts in D image and D space while inferring their visibility states, given a single RGB image. Our key insight is to exploit domain knowledge to regularize the network by deeply supervising its hidden layers, in order to sequentially infer intermediate concepts associated with the final task. To acquire training data in desired quantities with ground truth D shape and relevant concepts, we render D object CAD models to generate large-scale synthetic data and simulate challenging occlusion configurations between objects. We train the network only on synthetic data and demonstrate state-of-the-art performances on real image benchmarks including an extended version of KITTI, PASCAL VOC, PASCALD and IKEA for D and D keypoint localization and instance segmentation. The empirical results substantiate the utility of our deep supervision scheme by demonstrating effective transfer of knowledge from synthetic data to real images, resulting in less overfitting compared to standard end-to-end training.

Most density based stream clustering algorithms separate the clustering process into an online and offline component. Exact summarized statistics are being employed for defining micro-clusters or grid cells during the online stage followed by macro-clustering during the offline stage. This paper proposes a novel alternative to the traditional two phase stream clustering scheme, introducing sketch-based data structures for assessing both stream density and cluster membership with probabilistic accuracy guarantees. A count-min sketch using a damped window model estimates stream density. Bloom filters employing a variation of active-active buffering estimate cluster membership. Instances of both types of sketches share the same set of hash functions. The resulting stream clustering algorithm is capable of detecting arbitrarily shaped clusters while correctly handling outliers and making no assumption on the total number of clusters. Experimental results over a number of real and synthetic datasets illustrate the proposed algorithm quality and efficiency.

Word embeddings based on neural networks are widely used in Natural Language Processing. However, despite their success in capturing semantic information from massive corpora, word embeddings still conflate different meanings of a word into a single vectorial representation and do not benefit from information available in lexical resources. We address this issue by proposing a new model that jointly learns word and sense embeddings and represents them in a unified vector space by exploiting large corpora and knowledge obtained from semantic networks. We evaluate the main features of our approach qualitatively and quantitatively in various tasks, highlighting the advantages of the proposed method with respect to state-of-the-art word- and sense-based models.

Standard approaches in entity identification hard-code boundary detection and type prediction into labels e.g., JohnB-PER SmithI-PER and then perform Viterbi. This has two disadvantages . the runtime complexity grows quadratically in the number of types, and . there is no natural segment-level representation. In this paper, we propose a novel neural architecture that addresses these disadvantages. We frame the problem as multitasking, separating boundary detection and type prediction but optimizing them jointly. Despite its simplicity, this architecture performs competitively with fully structured models such as BiLSTM-CRFs while scaling linearly in the number of types. Furthermore, by construction, the model induces type-disambiguating embeddings of predicted mentions.

Can humans impute missing data with similar proficiency as machines? This is the question we aim to answer in this paper. We present a novel idea of converting observations with missing data to a survey questionnaire, which is presented to crowdworkers for completion. We replicate a multiple imputation framework by having multiple unique crowdworkers complete our questionnaire. Experimental results demonstrate that using our method, it is possible to generate valid imputations for qualitative and quantitative missing data, with results comparable to imputations generated by complex statistical models.

We introduce a novel strategy for learning to extract semantically meaningful features from aerial imagery. Instead of manually labeling the aerial imagery, we propose to predict noisy semantic features automatically extracted from co-located ground imagery. Our network architecture takes an aerial image as input, extracts features using a convolutional neural network, and then applies an adaptive transformation to map these features into the ground-level perspective. We use an end-to-end learning approach to minimize the difference between the semantic segmentation extracted directly from the ground image and the semantic segmentation predicted solely based on the aerial image. We show that a model learned using this strategy, with no additional training, is already capable of rough semantic labeling of aerial imagery. Furthermore, we demonstrate that by finetuning this model we can achieve more accurate semantic segmentation than two baseline initialization strategies. We use our network to address the task of estimating the geolocation and geoorientation of a ground image. Finally, we show how features extracted from an aerial image can be used to hallucinate a plausible ground-level panorama.

A typical viral marketing model identifies influential users in a social network to maximize a single product adoption assuming unlimited user attention, campaign budgets, and time. In reality, multiple products need campaigns, users have limited attention, convincing users incurs costs, and advertisers have limited budgets and expect the adoptions to be maximized soon. Facing these user, monetary, and timing constraints, we formulate the problem as a submodular maximization task in a continuous-time diffusion model under the intersection of a matroid and multiple knapsack constraints. We propose a randomized algorithm estimating the user influence in a network mathcalV nodes, mathcalE edges to an accuracy of epsilon with nmathcalOepsilon randomizations and tildemathcalOnmathcalEnmathcalV computations. By exploiting the influence estimation algorithm as a subroutine, we develop an adaptive threshold greedy algorithm achieving an approximation factor ka k of the optimal when ka out of the k knapsack constraints are active. Extensive experiments on networks of millions of nodes demonstrate that the proposed algorithms achieve the state-of-the-art in terms of effectiveness and scalability.

We provide an illustrative implementation of an analytic, infinitely-differentiable virtual machine, implementing infinitely-differentiable programming spaces and operators acting upon them, as constructed in the paper Operational calculus on programming spaces. Implementation closely follows theorems and derivations of the paper, intended as an educational guide for those transitioning from automatic differentiation to this general theory.

In this paper, we propose Transmission Control Protocol TCP-aware cross layer scheduling algorithms in a multipoint-to-point network such as the uplink of an IEEE . WiMAX network. Inadequate bandwidth allocation to a TCP flow may lead to timeout and since TCP source drops its congestion window cwnd immediately after a timeout, it may affect the average throughput adversely. On the other hand, since the TCP source increases its cwnd only linearly upon the availability of bandwidth, any excess assignment of bandwidth may remain underutilized. The proposed scheduling algorithms address this by allocating the resources based on cwnd and TCP timeout. Moreover, since we focus on uplink scheduling, we consider that only em flow level resource requirement is communicated to the Base Station BS instead of per em packet information. The schedulers also take into account the wireless channel characteristics and are thus cross layer in nature. Through exhaustive simulations, we demonstrate that the proposed schedulers exhibit enhanced throughput and fairness properties when compared to that of Round Robin RR scheduler under different shadowing. We demonstrate a gain between .  to   in throughput and   to   in channel utilization over RR scheduler under different shadowing.

Random backpropagation RBP is a variant of the backpropagation algorithm for training neural networks, where the transpose of the forward matrices are replaced by fixed random matrices in the calculation of the weight updates. It is remarkable both because of its effectiveness, in spite of using random matrices to communicate error information, and because it completely removes the taxing requirement of maintaining symmetric weights in a physical neural system. To better understand random backpropagation, we first connect it to the notions of local learning and the learning channel. Through this connection, we derive several alternatives to RBP, including skipped RBP SRPB, adaptive RBP ARBP, sparse RBP, and their combinations e.g. ASRBP and analyze their computational complexity. We then study their behavior through simulations using the MNIST and CIFAR- bechnmark datasets. These simulations show that most of these variants work robustly, almost as well as backpropagation, and that multiplication by the derivatives of the activation functions is important. As a follow-up, we study also the low-end of the number of bits required to communicate error information over the learning channel. We then provide partial intuitive explanations for some of the remarkable properties of RBP and its variations. Finally, we prove several mathematical results, including the convergence to fixed points of linear chains of arbitrary length, the convergence to fixed points of linear autoencoders with decorrelated data, the long-term existence of solutions for linear systems with a single hidden layer, and the convergence to fixed points of non-linear chains, when the derivative of the activation functions is included.

Mobile robots with complex morphology are essential for traversing rough terrains in Urban Search  Rescue missions USAR. Since teleoperation of the complex morphology causes high cognitive load of the operator, the morphology is controlled autonomously. The autonomous control measures the robot state and surrounding terrain which is usually only partially observable, and thus the data are often incomplete. We marginalize the control over the missing measurements and evaluate an explicit safety condition. If the safety condition is violated, tactile terrain exploration by the body-mounted robotic arm gathers the missing data.

Building neural networks to query a knowledge base a table with natural language is an emerging research topic in NLP. The neural enquirer typically necessitates multiple steps of execution because of the compositionality of queries. In previous studies, researchers have developed either distributed enquirers or symbolic ones for table querying. The distributed enquirer is end-to-end learnable, but is weak in terms of execution efficiency and explicit interpretability. The symbolic enqurier, on the contrary, is efficient during execution but it is very difficult to train especially at initial stages. In this paper, we propose to couple distributed and symbolic execution for natural language queries. The observation is that a fully distributed executor also exhibits meaningful, albeit imperfect, interpretation. We can thus pretrain the symbolic executor with the distributed ones intermediate execution results in a step-by-step fashion. Experiments show that our approach significantly outperforms either the distributed or symbolic executor moreover, we have recovered more than  execution sequences with only groundtruth denotations during training. In summary, the coupled neural enquirer takes advantages of both distributed and symbolic executors, and has high performance, high learning efficiency, high execution efficiency, and high interpretability.

Hand detection is essential for many hand related tasks, e.g. parsing hand pose, understanding gesture, which are extremely useful for robotics and human-computer interaction. However, hand detection in uncontrolled environments is challenging due to the flexibility of wrist joint and cluttered background. We propose a deep learning based approach which detects hands and calibrates in-plane rotation under supervision at the same time. To guarantee the recall, we propose a context aware proposal generation algorithm which significantly outperforms the selective search. We then design a convolutional neural networkCNN which handles object rotation explicitly to jointly solve the object detection and rotation estimation tasks. Experiments show that our method achieves better results than state-of-the-art detection models on widely-used benchmarks such as Oxford and Egohands database. We further show that rotation estimation and classification can mutually benefit each other.

Computational approaches to drug discovery can reduce the time and cost associated with experimental assays and enable the screening of novel chemotypes. Structure-based drug design methods rely on scoring functions to rank and predict binding affinities and poses. The ever-expanding amount of protein-ligand binding and structural data enables the use of deep machine learning techniques for protein-ligand scoring.   We describe convolutional neural network CNN scoring functions that take as input a comprehensive D representation of a protein-ligand interaction. A CNN scoring function automatically learns the key features of protein-ligand interactions that correlate with binding. We train and optimize our CNN scoring functions to discriminate between correct and incorrect binding poses and known binders and non-binders. We find that our CNN scoring function outperforms the AutoDock Vina scoring function when ranking poses both for pose prediction and virtual screening.

Hierarchical architectures are critical to the scalability of reinforcement learning methods. Current hierarchical frameworks execute actions serially, with macro-actions comprising sequences of primitive actions. We propose a novel alternative to these control hierarchies based on concurrent execution of many actions in parallel. Our scheme uses the concurrent compositionality provided by the linearly solvable Markov decision process LMDP framework, which naturally enables a learning agent to draw on several macro-actions simultaneously to solve new tasks. We introduce the Multitask LMDP module, which maintains a parallel distributed representation of tasks and may be stacked to form deep hierarchies abstracted in space and time.

High dynamic range HDR image synthesis from multiple low dynamic range LDR exposures continues to be actively researched. The extension to HDR video synthesis is a topic of significant current interest due to potential cost benefits. For HDR video, a stiff practical challenge presents itself in the form of accurate correspondence estimation of objects between video frames. In particular, loss of data resulting from poor exposures and varying intensity make conventional optical flow methods highly inaccurate. We avoid exact correspondence estimation by proposing a statistical approach via maximum a posterior MAP estimation, and under appropriate statistical assumptions and choice of priors and models, we reduce it to an optimization problem of solving for the foreground and background of the target frame. We obtain the background through rank minimization and estimate the foreground via a novel multiscale adaptive kernel regression technique, which implicitly captures local structure and temporal motion by solving an unconstrained optimization problem. Extensive experimental results on both real and synthetic datasets demonstrate that our algorithm is more capable of delivering high-quality HDR videos than current state-of-the-art methods, under both subjective and objective assessments. Furthermore, a thorough complexity analysis reveals that our algorithm achieves better complexity-performance trade-off than conventional methods.

Learning from weakly-supervised data is one of the main challenges in machine learning and computer vision, especially for tasks such as image semantic segmentation where labeling is extremely expensive and subjective. In this paper, we propose a novel neural network architecture to perform weakly-supervised learning by suppressing irrelevant neuron activations. It localizes objects of interest by learning from image-level categorical labels in an end-to-end manner. We apply this algorithm to a practical challenge of transforming satellite images into a map of settlements and individual buildings. Experimental results show that the proposed algorithm achieves superior performance and efficiency when compared with various baseline models.

We present a framework to understand GAN training as alternating density ratio estimation and approximate divergence minimization. This provides an interpretation for the mismatched GAN generator and discriminator objectives often used in practice, and explains the problem of poor sample diversity. We also derive a family of generator objectives that target arbitrary f-divergences without minimizing a lower bound, and use them to train generative image models that target either improved sample quality or greater sample diversity.

rm CTTrm qe is a version of Churchs type theory that includes quotation and evaluation operators that are similar to quote and eval in the Lisp programming language. With quotation and evaluation it is possible to reason in rm CTTrm qe about the interplay of the syntax and semantics of expressions and, as a result, to formalize syntax-based mathematical algorithms. We present the syntax and semantics of rm CTTrm qe as well as a proof system for rm CTTrm qe. The proof system is shown to be sound for all formulas and complete for formulas that do not contain evaluations. We give several examples that illustrate the usefulness of having quotation and evaluation in rm CTTrm qe.

We present space efficient Monte Carlo algorithms that solve Subset Sum and Knapsack instances with n items using O.n time and polynomial space, where the Ocdot notation suppresses factors polynomial in the input size. Both algorithms assume random read-only access to random bits. Modulo this mild assumption, this resolves a long-standing open problem in exact algorithms for NP-hard problems. These results can be extended to solve Binary Linear Programming on n variables with few constraints in a similar running time. We also show that for any constant kgeq , random instances of k-Sum can be solved using Onk-.polylogn time and Olog n space, without the assumption of random access to random bits.   Underlying these results is an algorithm that determines whether two given lists of length n with integers bounded by a polynomial in n share a common value. Assuming random read-only access to random bits, we show that this problem can be solved using Olog n space significantly faster than the trivial On time algorithm if no value occurs too often in the same list.

Model-based coding, described by John Pierce in , has great potential to reduce the volume of information that needs to be transmitted in moving big data, without loss of information, from one place to another, or in lossless communications via the internet. Compared with ordinary compression methods, this potential advantage of model-based coding in the transmission of data arises from the fact that both the transmitter Alice and the receiver Bob are equipped with a grammar for the kind of data that is to be transmitted, which means that, to achieve lossless transmission of a body of data from Alice and Bob, a relatively small amount of information needs to be sent. Preliminary trials indicate that, with model-based coding, the volume of information to be sent from Alice to Bob to achieve lossless transmission of a given body of data may be less than  of the volume of information that needs to be sent when ordinary compression methods are used.   Until recently, it has not been feasible to convert John Pierces vision into something that may be applied in practice. Now, with the development of the SP theory of intelligence and its realisation in the SP computer model, there is clear potential to realise the three main functions that will be needed unsupervised learning of a grammar for the kind of data that is to be transmitted using a relatively powerful computer that is independent of Alice and Bob the encoding by Alice of any one example of such data in terms of the grammar and, with the grammar, decoding of the encoding by Bob to retrieve the given example. It appears now to be feasible, within reasonable timescales, to bring these capabilities to a level where they may be applied to the transmission of realistically large bodies of data.

This paper presents the design of a supervisory algorithm that monitors safety at road intersections and overrides drivers with a safe input when necessary. The design of the supervisor consists of two parts safety verification and control design. Safety verification is the problem to determine if vehicles will be able to cross the intersection without colliding with current drivers inputs. We translate this safety verification problem into a jobshop scheduling problem, which minimizes the maximum lateness and evaluates if the optimal cost is zero. The zero optimal cost corresponds to the case in which all vehicles can cross each conflict area without collisions. Computing the optimal cost requires solving a Mixed Integer Nonlinear Programming MINLP problem due to the nonlinear second-order dynamics of the vehicles. We therefore estimate this optimal cost by formulating two related Mixed Integer Linear Programming MILP problems that assume simpler vehicle dynamics. We prove that these two MILP problems yield lower and upper bounds of the optimal cost. We also quantify the worst case approximation errors of these MILP problems. We design the supervisor to override the vehicles with a safe control input if the MILP problem that computes the upper bound yields a positive optimal cost. We theoretically demonstrate that the supervisor keeps the intersection safe and is non-blocking. Computer simulations further validate that the algorithms can run in real time for problems of realistic size.

We investigate the task of inferring conversational dependencies between messages in one-on-one online chat, which has become one of the most popular forms of customer service. We propose a novel probabilistic classifier that leverages conversational, lexical and semantic information. The approach is evaluated empirically on a set of customer service chat logs from a Chinese e-commerce website. It outperforms heuristic baselines.

Regression under the small n, large p conditions, of small sample size n and large number of features p in the learning data set, is a recurring setting in which learning from data is difficult. With prior knowledge about relationships of the features, p can effectively be reduced, but explicating such prior knowledge is difficult for experts. In this paper we introduce a new method for eliciting expert prior knowledge about the similarity of the roles of features in the prediction task. The key idea is to use an interactive multidimensional-scaling MDS type scatterplot display of the features to elicit the similarity relationships, and then use the elicited relationships in the prior distribution of prediction parameters. Specifically, for learning to predict a target variable with Bayesian linear regression, the feature relationships are used to construct a Gaussian prior with a full covariance matrix for the regression coefficients. Evaluation of our method in experiments with simulated and real users on text data confirm that prior elicitation of feature similarities improves prediction accuracy. Furthermore, elicitation with an interactive scatterplot display outperforms straightforward elicitation where the users choose feature pairs from a feature list.

We use differential equations based approaches to provide insights into analyzing the dynamics of popular optimization algorithms for machine learning. In particular, we study gradient descent, proximal gradient descent, coordinate gradient descent, proximal coordinate gradient, and Newtons methods as well as their Nesterovs accelerated variants in a unified framework motivated by a natural connection of optimization algorithms to physical systems. Our analysis is applicable to more general algorithms and optimization problems beyond convexity and strong convexity.

The principle of maximum entropy provides a useful method for inferring statistical mechanics models from observations in correlated systems, and is widely used in a variety of fields where accurate data are available. While the assumptions underlying maximum entropy are intuitive and appealing, its adequacy for describing complex empirical data has been little studied in comparison to alternative approaches. Here data from the collective spiking activity of retinal neurons is reanalysed. The accuracy of the maximum entropy distribution constrained by mean firing rates and pairwise correlations is compared to a random ensemble of distributions constrained by the same observables. In general, maximum entropy approximates the true distribution better than the typical or mean distribution from that ensemble. This advantage improves with population size, with groups as small as  being almost always better described by maximum entropy. Failure of maximum entropy to outperform random models is found to be associated with strong correlations in the population.

This paper introduces a deep architecture for segmenting D objects into their labeled semantic parts. Our architecture combines image-based Fully Convolutional Networks FCNs and surface-based Conditional Random Fields CRFs to yield coherent segmentations of D shapes. The image-based FCNs are used for efficient view-based reasoning about D object parts. Through a special projection layer, FCN outputs are effectively aggregated across multiple views and scales, then are projected onto the D object surfaces. Finally, a surface-based CRF combines the projected outputs with geometric consistency cues to yield coherent segmentations. The whole architecture multi-view FCNs and CRF is trained end-to-end. Our approach significantly outperforms the existing state-of-the-art methods in the currently largest segmentation benchmark ShapeNet. Finally, we demonstrate promising segmentation results on noisy D shapes acquired from consumer-grade depth cameras.

In this paper, we study the problem of author identification under double-blind review setting, which is to identify potential authors given information of an anonymized paper. Different from existing approaches that rely heavily on feature engineering, we propose to use network embedding approach to address the problem, which can automatically represent nodes into lower dimensional feature vectors. However, there are two major limitations in recent studies on network embedding  they are usually general-purpose embedding methods, which are independent of the specific tasks and  most of these approaches can only deal with homogeneous networks, where the heterogeneity of the network is ignored. Hence, challenges faced here are two folds  how to embed the network under the guidance of the author identification task, and  how to select the best type of information due to the heterogeneity of the network.   To address the challenges, we propose a task-guided and path-augmented heterogeneous network embedding model. In our model, nodes are first embedded as vectors in latent feature space. Embeddings are then shared and jointly trained according to task-specific and network-general objectives. We extend the existing unsupervised network embedding to incorporate meta paths in heterogeneous networks, and select paths according to the specific task. The guidance from author identification task for network embedding is provided both explicitly in joint training and implicitly during meta path selection. Our experiments demonstrate that by using path-augmented network embedding with task guidance, our model can obtain significantly better accuracy at identifying the true authors comparing to existing methods.

We present a variant of the calculus of deductive systems developed in Lambek , , and give a generalization of the Curry-Howard-Lambek theorem giving an equivalence between the category of typed lambda-calculi and the category of cartesian closed categories and exponential-preserving morphisms that leverages the theory of generalized categories Schoenbaum . We discuss potential applications and extensions.

A multi-way factor analysis model is introduced for tensor-variate data of any order. Each data item is represented as a sparse sum of Kruskal decompositions, a Kruskal-factor analysis KFA. KFA is nonparametric and can infer both the tensor-rank of each dictionary atom and the number of dictionary atoms. The model is adapted for online learning, which allows dictionary learning on large data sets. After KFA is introduced, the model is extended to a deep convolutional tensor-factor analysis, supervised by a Bayesian SVM. The experiments section demonstrates the improvement of KFA over vectorized approaches e.g., BPFA, tensor decompositions, and convolutional neural networks CNN in multi-way denoising, blind inpainting, and image classification. The improvement in PSNR for the inpainting results over other methods exceeds dB in several cases and we achieve state of the art results on Caltech image classification.

We propose a Deep Texture Encoding Network Deep-TEN with a novel Encoding Layer integrated on top of convolutional layers, which ports the entire dictionary learning and encoding pipeline into a single model. Current methods build from distinct components, using standard encoders with separate off-the-shelf features such as SIFT descriptors or pre-trained CNN features for material recognition. Our new approach provides an end-to-end learning framework, where the inherent visual vocabularies are learned directly from the loss function. The features, dictionaries and the encoding representation for the classifier are all learned simultaneously. The representation is orderless and therefore is particularly useful for material and texture recognition. The Encoding Layer generalizes robust residual encoders such as VLAD and Fisher Vectors, and has the property of discarding domain specific information which makes the learned convolutional features easier to transfer. Additionally, joint training using multiple datasets of varied sizes and class labels is supported resulting in increased recognition performance. The experimental results show superior performance as compared to state-of-the-art methods using gold-standard databases such as MINC-, Flickr Material Database, KTH-TIPS-b, and two recent databases D-Light-Field-Material and GTOS. The source code for the complete system are publicly available.

This paper presents a novel algorithm that utilizes a D floorplan to align panorama RGBD scans. While effective panorama RGBD alignment techniques exist, such a system requires extremely dense RGBD image sampling. Our approach can significantly reduce the number of necessary scans with the aid of a floorplan image. We formulate a novel Markov Random Field inference problem as a scan placement over the floorplan, as opposed to the conventional scan-to-scan alignment. The technical contributions lie in multi-modal image correspondence cues between scans and schematic floorplan as well as a novel coverage potential avoiding an inherent stacking bias. The proposed approach has been evaluated on five challenging large indoor spaces. To the best of our knowledge, we present the first effective system that utilizes a D floorplan image for building-scale D pointcloud alignment. The source code and the data will be shared with the community to further enhance indoor mapping research.

We present in this paper a framework for mapping data onto real and complex projective spaces. The resulting projective coordinates provide a multi-scale representation of the data, and capture low dimensional underlying topological features. An initial map is obtained in two steps First, the persistent cohomology of a sparse filtration is used to compute systems of transition functions for real and complex line bundles over neighborhoods of the data. Next, the transition functions are used to produce explicit classifying maps for the induced bundles. A framework for dimensionality reduction in projective space Principal Projective Components is also developed, aimed at decreasing the target dimension of the original map. Several examples are provided as well as theorems addressing choices in the construction.

Effective SDN control relies on the network data collecting capability as well as the quality and timeliness of the data. As open programmable data plane is becoming a reality, we further enhance it with the support of runtime interactive programming in order to cope with application dynamics, optimize data plane resource allocation, and reduce control-plane processing pressure. Based on the latest technologies, we propose the Dynamic Network Probes DNP as a means to support real-time and on-demand network visibility. DNPs serve as an important building block of an integrated networking data analytics platform which involves the network data plane as an active component for in-network computing. In this paper, we show the types of DNPs and their role in the big picture. We have implemented an NP-based hardware prototype to demonstrate the feasibility and efficiency of DNPs. We lay out the research challenges and our future work to realize the omni network visibility based on DNPs.

Representations are fundamental to Artificial Intelligence. Typically, the performance of a learning system depends on its data representation. These data representations are usually hand-engineered based on some prior domain knowledge regarding the task. More recently, the trend is to learn these representations through deep neural networks as these can produce dramatical performance improvements over hand-engineered data representations. In this paper, we present a new incremental learning algorithm, called crossprop, for learning representations based on prior learning experiences. Unlike backpropagation, crossprop minimizes the cross-validation error. Specifically, our algorithm considers the influences of all the past weights on the current squared error, and uses this gradient for incrementally learning the weights in a neural network. This idea is similar to that of tuning the learning system through an offline cross-validation procedure. Crossprop is applicable to incremental learning tasks, where a sequence of examples are encountered by the learning system and they need to be processed one by one and then discarded. The learning system can use each example only once and can spend only a limited amount of computation for an example. From our preliminary experiments, we concluce that crossprop is a promising alternative for backprop for representation learning.

Fourier single-pixel imaging FSI has proven capable of reconstructing high-quality two-dimensional and three-dimensional images. The utilization of the sparsity of natural images in Fourier domain allows high-resolution images to be reconstructed from far fewer measurements than effective image pixels. However, applying original FSI in digital micro-mirror device DMD based high-speed imaging system turns out to be challenging, because the original FSI uses grayscale Fourier basis patterns for illumination while DMDs generate grayscale patterns at a relatively low rate. DMDs are a binary device which can only generate a black-and-white pattern at each instance. In this paper, we adopt binary Fourier patterns for illumination to achieve DMD-based high-speed single-pixel imaging. Binary Fourier patterns are generated by upsampling and then applying error diffusion based dithering to the grayscale patterns. Experiments demonstrate the proposed technique able to achieve static imaging with high quality and dynamic imaging in real time. The proposed technique potentially allows high-quality and high-speed imaging over broad wavebands.

Quantum computing has undergone rapid development in recent years. Owing to limitations on scalability, personal quantum computers still seem slightly unrealistic in the near future. The first practical quantum computer for ordinary users is likely to be on the cloud. However, the adoption of cloud computing is possible only if security is ensured. Homomorphic encryption is a cryptographic protocol that allows computation to be performed on encrypted data without decrypting them, so it is well suited to cloud computing. Here, we first applied homomorphic encryption on IBMs cloud quantum computer platform. In our experiments, we successfully implemented a quantum algorithm for linear equations while protecting our privacy. This demonstration opens a feasible path to the next stage of development of cloud quantum information technology.

Accurately identifying hands in images is a key sub-task for human activity understanding with wearable first-person point-of-view cameras. Traditional hand segmentation approaches rely on a large corpus of manually labeled data to generate robust hand detectors. However, these approaches still face challenges as the appearance of the hand varies greatly across users, tasks, environments or illumination conditions. A key observation in the case of many wearable applications and interfaces is that, it is only necessary to accurately detect the users hands in a specific situational context. Based on this observation, we introduce an interactive approach to learn a person-specific hand segmentation model that does not require any manually labeled training data. Our approach proceeds in two steps, an interactive bootstrapping step for identifying moving hand regions, followed by learning a personalized user specific hand appearance model. Concretely, our approach uses two convolutional neural networks  a gesture network that uses pre-defined motion information to detect the hand region and  an appearance network that learns a person specific model of the hand region based on the output of the gesture network. During training, to make the appearance network robust to errors in the gesture network, the loss function of the former network incorporates the confidence of the gesture network while learning. Experiments demonstrate the robustness of our approach with an F score over . on all challenging datasets across a wide range of illumination and hand appearance variations, improving over a baseline approach by over .

Spectrum resources are facing huge demands and cognitive radio CR can improve the spectrum utilization. Recently, power spectral density PSD map is defined to enable the CR to reuse the frequency resources regarding to the area. For this reason, the sensed PSDs are fused by a Fusion Center FC which the sensed PSDs are collected by the distributed sensors in the area. But, for a given zone, the sensed PSD by neighbor CR sensors may contain a shared common component for a while. This component can be exploited in the theory of the distributed source coding DSC to compress sensing data more. In this paper based on the distributed compressive sensing DCS a method is proposed to compress and reconstruct the PSDs of the sensors when the data transmission is slightly imperfect. Simulation results show the advantages of using proposed method in compressing, reducing overhead and also recovering PSDs.  Proposed method can be used to develop a framework when the holding times of the users are large in comparison with the rate of the spectrum sensing.

Population growth and increasing droughts are creating unprecedented strain on the continued availability of water resources. Since irrigation is a major consumer of fresh water, wastage of resources in this sector could have strong consequences. To address this issue, irrigation water management and prediction techniques need to be employed effectively and should be able to account for the variabilities present in the environment. The different techniques surveyed in this paper can be classified into two categories computational and statistical. Computational methods deal with scientific correlations between physical parameters whereas statistical methods involve specific prediction algorithms that can be used to automate the process of irrigation water prediction. These algorithms interpret semantic relationships between the various parameters of temperature, pressure, evapotranspiration etc. and store them as numerical precomputed entities specific to the conditions and the area used as the data for the training corpus used to train it. We focus on reviewing the computational methods used to determine Evapotranspiration and its implications. We compare the efficiencies of different data mining and machine learning methods implemented in this area, such as Logistic Regression, Decision Tress Classifier, SysFor, Support Vector MachineSVM, Fuzzy Logic techniques, Artifical Neural NetworksANNs and various hybrids of Genetic Algorithms GA applied to irrigation prediction. We also recommend a possible technique for the same based on its superior results in other such time series analysis tasks.

A probabilistic model is proposed by stacking a set of independently trained Gaussian processes to obtain prediction of quantities of interests that require composition of functions. Analytical derivations are provided for first and second-order moments of the stacked Gaussian process using RBF and polynomial kernels. The StackedGP model can be extended to any number of layers and nodes per layer, and it provides flexibility in kernel selection for each node. The proposed nonparametric stacked model is validated using different synthetic datasets and its performance is measured in two real-world applications.

The inability of Moores Law and other figure-of-merits FOMs to accurately explain the technology development of the semiconductor industry demands a holistic merit to guide the industry. Here we introduce a FOM termed CLEAR that accurately postdicts technology developments since the s until today, and predicts photonics as a logical extension to keep-up the pace of information-handling machines. We show that CLEAR Capability-to-Latency-Energy-Amount-Resistance is multi-hierarchical applying to the device, interconnect, and system level. Being a holistic FOM, we show that empirical trends such as Moores Law and the Makimotos wave are special cases of the universal CLEAR merit. Looking ahead, photonic board- and chip-level technologies are able to continue the observed doubling rate of the CLEAR value every  months, while electronic technologies are unable to keep pace.

To enhance system performance of future heterogeneous wireless networks the co-design of PHY, MAC, and higher layer protocols is inevitable. In this work, we present WiSCoP - a novel embedded platform for experimentation, prototyping and implementation of integrated cross-layer network design approaches. WiSCoP is built on top of a Zynq hardware platform integrated with FMCOMMS RF front ends. We demonstrate the flexibility of WiSCoP by using it to prototype a fully standard compliant IEEE .. stack with real-time performance and cross-layer integration.

Measurement has become fundamental to the operation of networks and at-scale services---whether for management, security, diagnostics, optimization, or simply enhancing our collective understanding of the Internet as a complex system. Further, measurements are useful across points of view---from end hosts to enterprise networks and data centers to the wide area Internet. We observe that many measurements are decoupled from the protocols and applications they are designed to illuminate. Worse, current measurement practice often involves the exploitation of side-effects and unintended features of the network or, in other words, the artful piling of hacks atop one another. This state of affairs is a direct result of the relative paucity of diagnostic and measurement capabilities built into todays network stack.   Given our modern dependence on ubiquitous measurement, we propose measurability as an explicit low-level goal of current protocol design, and argue that measurements should be available to all network protocols throughout the stack. We seek to generalize the idea of measurement within protocols, e.g., the way in which TCP relies on measurement to drive its end-to-end behavior. Rhetorically, we pose the question what if the stack had been built with measurability and diagnostic support in mind? We start from a set of principles for explicit measurability, and define primitives that, were they supported by the stack, would not only provide a solid foundation for protocol design going forward, but also reduce the cost and increase the accuracy of measuring the network.

The ability to recognize facial expressions automatically enables novel applications in human-computer interaction and other areas. Consequently, there has been active research in this field, with several recent works utilizing Convolutional Neural Networks CNNs for feature extraction and inference. These works differ significantly in terms of CNN architectures and other factors. Based on the reported results alone, the performance impact of these factors is unclear. In this paper, we review the state of the art in image-based facial expression recognition using CNNs and highlight algorithmic differences and their performance impact. On this basis, we identify existing bottlenecks and consequently directions for advancing this research field. Furthermore, we demonstrate that overcoming one of these bottlenecks - the comparatively basic architectures of the CNNs utilized in this field - leads to a substantial performance increase. By forming an ensemble of modern deep CNNs, we obtain a FER test accuracy of ., outperforming previous works without requiring auxiliary training data or face registration.

It has been widely recognized that uncertainty is an inevitable aspect of diagnosis and treatment of medical disorders. Such uncertainties hence, need to be considered in computerized medical models. The existing medical modeling techniques however, have mainly focused on capturing uncertainty associated with diagnosis of medical disorders while ignoring uncertainty of treatments. To tackle this issue, we have proposed using a fuzzy-based modeling and description technique for capturing uncertainties in treatment plans. We have further contributed a formal framework which allows for goal-oriented modeling and analysis of medical treatments.

Delaunay has shown that the Delaunay complex of a finite set of points P of Euclidean space mathbbRm triangulates the convex hull of P, provided that P satisfies a mild genericity property. Voronoi diagrams and Delaunay complexes can be defined for arbitrary Riemannian manifolds. However, Delaunays genericity assumption no longer guarantees that the Delaunay complex will yield a triangulation stronger assumptions on P are required. A natural one is to assume that P is sufficiently dense. Although results in this direction have been claimed, we show that sample density alone is insufficient to ensure that the Delaunay complex triangulates a manifold of dimension greater than .

We discuss the problem of extending data mining approaches to cases in which data points arise in the form of individual graphs. Being able to find the intrinsic low-dimensionality in ensembles of graphs can be useful in a variety of modeling contexts, especially when coarse-graining the detailed graph information is of interest. One of the main challenges in mining graph data is the definition of a suitable pairwise similarity metric in the space of graphs. We explore two practical solutions to solving this problem one based on finding subgraph densities, and one using spectral information. The approach is illustrated on three test data sets ensembles of graphs two of these are obtained from standard graph generating algorithms, while the graphs in the third example are sampled as dynamic snapshots from an evolving network simulation. We further incorporate these approaches with equation free techniques, demonstrating how such data mining approaches can enhance scientific computation of network evolution dynamics.

We study social choice rules under the utilitarian distortion framework, with an additional metric assumption on the agents costs over the alternatives. In this approach, these costs are given by an underlying metric on the set of all agents plus alternatives. Social choice rules have access to only the ordinal preferences of agents but not the latent cardinal costs that induce them. Distortion is then defined as the ratio between the social cost typically the sum of agent costs of the alternative chosen by the mechanism at hand, and that of the optimal alternative. This model was introduced by Anshelevich et al.  who conjectured that Ranked Pairs, the well-known social choice rule, achieves a distortion of at most . We disprove this conjecture by constructing a sequence of instances which shows that the worst-case distortion of Ranked Pairs is at least . Our lower bound on the worst case distortion of Ranked Pairs matches a previously known upper bound for the Copeland rule, proving that in the worst case, the simpler Copeland rule is at least as good as Ranked Pairs. And as long as we are limited to emphtournament rules, we demonstrate that randomization cannot help achieve an expected worst-case distortion of less than . Using the concept of approximate majorization within the distortion framework, we prove that Copeland and Randomized Dictatorship achieve low constant factor fairness-ratios  and  respectively this approximates essentially all fairness measures, and is a considerable generalization of the work of Anshelevich et al.  who prove similar results for objectives such as the sum and median of agent costs. In addition to all of the above, we outline several interesting directions for further research in this space.

For decades, advances in electronics were directly related to the scaling of CMOS transistors according to Moores law. However, both the CMOS scaling and the classical computer architecture are approaching fundamental and practical limits, and new computing architectures based on emerging devices, such as non-volatile memories e.g. resistive memory RRAM devices, are expected to sustain the exponential growth of computing capability. Here we propose a novel memory-centric, reconfigurable, general purpose computing platform to handle the explosive amount of data in a fast and energy-efficient manner. The proposed computing architecture is based on a single physical resistive memory-centric fabric that can be optimally reconfigured and utilized to perform different computing and data storage tasks in a massively parallel approach. The system can be tailored to achieve maximal energy efficiency based on the data flow by dynamically allocating the basic computing fabric to storage, arithmetic, and analog computing including neuromorphic computing tasks.

We study the optimal sample complexity of a given workload of linear queries under the constraints of differential privacy. The sample complexity of a query answering mechanism under error parameter alpha is the smallest n such that the mechanism answers the workload with error at most alpha on any database of size n. Following a line of research started by Hardt and Talwar STOC , we analyze sample complexity using the tools of asymptotic convex geometry. We study the sensitivity polytope, a natural convex body associated with a query workload that quantifies how query answers can change between neighboring databases. This is the information that, roughly speaking, is protected by a differentially private algorithm, and, for this reason, we expect that a bigger sensitivity polytope implies larger sample complexity. Our results identify the mean Gaussian width as an appropriate measure of the size of the polytope, and show sample complexity lower bounds in terms of this quantity. Our lower bounds completely characterize the workloads for which the Gaussian noise mechanism is optimal up to constants as those having asymptotically maximal Gaussian width.   Our techniques also yield an alternative proof of Pisiers Volume Number Theorem which also suggests an approach to improving the parameters of the theorem.

The decentralized cryptocurrency Bitcoin has experienced great success but also encountered many challenges. One of the challenges has been the long confirmation time and low transaction throughput. Another challenge is the lack of incentives at certain steps of the protocol, raising concerns for transaction withholding, selfish mining, etc. To address these challenges, we propose Solidus, a decentralized cryptocurrency based on permissionless Byzantine consensus. A core technique in Solidus is to use proof of work for leader election to adapt the Practical Byzantine Fault Tolerance PBFT protocol to a permissionless setting. We also design Solidus to be incentive compatible and to mitigate selfish mining. Solidus improves on Bitcoin in confirmation time and provides safety and liveness assuming Byzantine players and the largest coalition of rational players collectively control less than one-third of the computation power.

A method for reconstructing multiple-input multiple-output MIMO channel correlation matrices from lower dimensional channel measurements is presented. Exploiting the symmetry of correlation matrix structure enables reproducing higher dimensional MIMO channel matrices from available lower order measurements. This leads to practically important applications allowing prediction of higher dimensional MIMO system capacity. In particular, we study Kronecker-type MIMO channels suitable for reconstructing full channel matrices from partial information about transmit-receive fading in spatial and polarimetric domains and analyze validity conditions for such models. One of the important channel conditions is Doppler frequency related to non-stationarity in the environment. We present simulations of cluster-type scattering model using x MIMO channel correlation matrices to predict performance of x MIMO system including recovery of angular power spectrum. An example of dual circular polarized x MIMO land mobile satellite measurements in . GHz frequency band illustrates applicability of the method to reconstruct spatial and polarimetric channel correlation matrices for estimating ergodic channel capacity from single-antenna or uni-polarized measurements.

With the increase in mobile traffic and the bandwidth demand, Device-to-Device DD communication underlaying Long Term Evolution LTE networks has gained tremendous interest by the researchers, cellular operators and equipment manufacturers. However, the application of DD communication has been limited to emergency services and it needs to be explored in commercial applications. In this paper, we have introduced a novel commercial DD offloading scheme for users who may be at cell edges, inside isolated environments like basement or large buildings, etc. Our proposed scheme discovers the available idle DD neighbors for such poor channel users and offloads its data to the DD neighbor, which then relays the data to the eNB. We have developed a DD offloading simulation model in MATLAB, have conducted extensive simulations and have observed that the proposed scheme can provide better efficiency to the network as well as satisfy the poor channel users significantly.

To provide sustainable digital agro-advisory services to farmers, seamless flow of information from the farmers to the expertsexpert systems, and vice versa is required. The query generated by the farmers, which may contain multimedia data regarding disease or pest attack in the crops is required to be transmitted to the experts for analysis. Further, after analyzing the query, an alert or advice from the expert system is required to be communicated back to the farmers within some tolerable delay. However, in a country like India, network connectivity is extremely poor in several agricultural regions which makes the end-to-end connectivity between the farmers and the expert system intermittent. Therefore, providing agro-advisory services to farmers in a reasonable time becomes a challenge. In this paper, we propose a Delay Tolerant Network DTN based relay application model which enables agro-advisory services to farmers located in emphNo-network or emphPoor-network zones. In the proposed model, end-to-end communication has been enabled with the help of Device to Device DD communication and by introducing mobile relay nodes which can carry the queries responses, from to the poor or no network zones to from the zones where communication is possible. Implementation of this model has been presented for the tea farmers of West Bengal and Assam, which can be extended for various other applications in future.

The token swapping problem TSP and its colored version are reconfiguration problems on graphs. This paper is concerned with the complexity of the TSP and two new variants namely parallel TSP and parallel colored TSP. For a given graph where each vertex has a unique token on it, the TSP requires to find a shortest way to modify a token placement into another by swapping tokens on adjacent vertices. In the colored version, vertices and tokens are colored and the goal is to relocate tokens so that each vertex has a token of the same color. Their parallel versions allow simultaneous swaps on non-incident edges in one step. We investigate the time complexity of several restricted cases of those problems and show when those problems become tractable and remain intractable.

We present a series of closed-form maximum entropy upper bounds for the differential entropy of a continuous univariate random variable and study the properties of that series. We then show how to use those generic bounds for upper bounding the differential entropy of Gaussian mixture models. This requires to calculate the raw moments and raw absolute moments of Gaussian mixtures in closed-form that may also be handy in statistical machine learning and information theory. We report on our experiments and discuss on the tightness of those bounds.

Milimeter wave mmWave band mobile communications can be a solution to the continuously increasing traffic demand in modern wireless systems. Even though mmWave bands are scarcely occupied, the design of a prospect transceiver should guarantee the efficient coexistence with the incumbent services in these bands. To that end, in this paper, two underlay cognitive transceiver designs are proposed that enable the mmWave spectrum access while controlling the interference to the incumbent users. MmWave systems usually require large antenna arrays to achieve satisfactory performance and thus, they cannot support fully digital transceiver designs due to high demands in hardware complexity and power consumption. Thus, in order to develop efficient solutions, the proposed approaches are based on a hybrid analog-digital pre-coding architecture. In such hybrid designs, the overall beamformer can be factorized in a low dimensional digital counterpart applied in the baseband and in an analog one applied in the RF domain. The first cognitive solution developed in this paper designs the cognitive hybrid pre-coder by maximizing the mutual information between its two ends subject to interference, power and hardware constraints related to the analog counterpart. The second solution aims at reduced complexity requirements and thus derives the hybrid pre-coder by minimizing the Frobenious norm of its difference to the optimal digital only one. A novel solution for the post-coder at the cognitive receiver part is further proposed here based on a hardware constrained Minimum Mean Square Error criterion. Simulations show that the performance of both the proposed hybrid approaches is very close to the one of the fully digital solution for typical wireless environments.

Network management protocols often require timely and meaningful insight about per flow network traffic. This paper introduces Randomized Admission Policy RAP - a novel algorithm for the frequency and top-k estimation problems, which are fundamental in network monitoring. We demonstrate space reductions compared to the alternatives by a factor of up to  on real packet traces and up to  on heavy-tailed workloads. For top-k identification, RAP exhibits memory savings by a factor of between  and  depending on the skew of the workload. These empirical results are backed by formal analysis, indicating the asymptotic space improvement of our probabilistic admission approach. Additionally, we present d-Way RAP, a hardware friendly variant of RAP that empirically maintains its space and accuracy benefits.

The vast majority of current machine learning algorithms are designed to predict single responses or a vector of responses, yet many types of response are more naturally organized as matrices or higher-order tensor objects where characteristics are shared across modes. We present a new machine learning algorithm BaTFLED Bayesian Tensor Factorization Linked to External Data that predicts values in a three-dimensional response tensor using input features for each of the dimensions. BaTFLED uses a probabilistic Bayesian framework to learn projection matrices mapping input features for each mode into latent representations that multiply to form the response tensor. By utilizing a Tucker decomposition, the model can capture weights for interactions between latent factors for each mode in a small core tensor. Priors that encourage sparsity in the projection matrices and core tensor allow for feature selection and model regularization. This method is shown to far outperform elastic net and neural net models on cold start tasks from data simulated in a three-mode structure. Additionally, we apply the model to predict dose-response curves in a panel of breast cancer cell lines treated with drug compounds that was used as a Dialogue for Reverse Engineering Assessments and Methods DREAM challenge.

We introduce the dune-curvilineargrid module. The module provides the self-contained, parallel grid manager, as well as the underlying elementary curvilinear geometry module dune-curvilineargeometry. This work is motivated by the need for reliable and scalable electromagnetic design of nanooptical devices. Curvilinear geometries improve both the accuracy of modeling smooth material boundaries, and the hp-convergence rate of PDE solutions, reducing the necessary computational effort. dune-curvilineargrid provides a large spectrum of features for scalable parallel implementations of Finite Element and Boundary Integral methods over curvilinear tetrahedral geometries, including symbolic polynomial mappings and operations, recursive integration, sparse and dense grid communication, parallel timing and memory footprint diagnostics utilities. It is written in templated C using MPI for parallelization and ParMETIS for grid partitioning, and is provided as a module for the DUNE interface. The dune-curvilineargrid grid manager is continuously developed and improved, and so is this documentation. For the most recent version of the documentation, as well as the source code, please refer to the provided repositories and our website.

Design paradigms of logic circuits with Quantum-dot Cellular Automata QCA have been extensively studied in the recent past. Unfortunately, due to the lack of mature fabrication support, QCA-based circuits often suffer from various types of manufacturing defects and variations, and therefore, are unreliable and error-prone. QCA-based Exclusive-OR XOR gates are frequently used in the construction of several computing subsystems such as adders, linear feedback shift registers, parity generators and checkers. However, none of the existing designs for QCA XOR gates have considered the issue of ensuring fault-tolerance. Simulation results also show that these designs can hardly tolerate any fault. We investigate the applicability of various existing fault-tolerant schemes such as triple modular redundancy TMR, NAND multiplexing, and majority multiplexing in the context of practical realization of QCA XOR gate. Our investigations reveal that these techniques incur prohibitively large area and delay and hence, they are unsuitable for practical scenarios. We propose here realistic designs of QCA XOR gates in terms of area and delay with significantly high fault-tolerance against all types of cell misplacement defects such as cell omission, cell displacement, cell misalignment and extraadditional cell deposition. Furthermore, the absence of any crossing in the proposed designs facilitates low-cost fabrication of such systems.

Among the paradigms for parallel and distributed computing, the one popularized with Linda, and based on tuple spaces, is one of the least used, despite the fact of being intuitive, easy to understand and to use. A tuple space is a repository, where processes can add, withdraw or read tuples by means of atomic operations. Tuples may contain different values, and processes can inspect their content via pattern matching. The lack of a reference implementation for this paradigm has prevented its widespread. In this paper, first we perform an extensive analysis of a number of actual implementations of the tuple space paradigm and summarise their main features. Then, we select four such implementations and compare their performances on four different case studies that aim at stressing different aspects of computing such as communication, data manipulation, and cpu usage. After reasoning on strengths and weaknesses of the four implementations, we conclude with some recommendations for future work towards building an effective implementation of the tuple space paradigm.

We consider a single allocation hub-and-spoke network design problem which allocates each non-hub node to exactly one of given hub nodes so as to minimize the total transportation cost. This paper deals with a case in which the hubs are located in a cycle, which is called a cycle-star hub network design problem. The problem is essentially equivalent to a cycle-metric labeling problem. The problem is useful in the design of networks in telecommunications and airline transportation systems.We propose a -h-approximation algorithm where h denotes the number of hub nodes. Our algorithm solves a linear relaxation problem and employs a dependent rounding procedure. We analyze our algorithm by approximating a given cycle-metric matrix by a convex combination of Monge matrices.

We have studied the phase transition of the contact process near a multiple junction of M semi-infinite chains by Monte Carlo simulations. As opposed to the continuous transitions of the translationally invariant M and semi-infinite M system, the local order parameter is found to be discontinuous for M. Furthermore, the temporal correlation length diverges algebraically as the critical point is approached, but with different exponents on the two sides of the transition. In the active phase, the estimate is compatible with the bulk value, while in the inactive phase it exceeds the bulk value and increases with M. The unusual local critical behavior is explained by a scaling theory with an irrelevant variable, which becomes dangerous in the inactive phase. Quenched spatial disorder is found to make the transition continuous in agreement with earlier renormalization group results.

The increasing complexity of smartphone applications and services necessitate high battery consumption but the growth of smartphones battery capacity is not keeping pace with these increasing power demands. To overcome this problem, researchers gave birth to the Mobile Cloud Computing MCC research area. In this paper we advance on previous ideas, by proposing and implementing the first known Near Field Communication NFC-based computation offloading framework. This research is motivated by the advantages of NFCs short distance communication, with its better security, and its low battery consumption. We design a new NFC communication protocol that overcomes the limitations of the default protocol removing the need for constant user interaction, the one-way communication restraint, and the limit on low data size transfer. We present experimental results of the energy consumption and the time duration of two computationally intensive representative applications i RSA key generation and encryption, and ii gamingpuzzles. We show that when the helper device is more powerful than the device offloading the computations, the execution time of the tasks is reduced. Finally, we show that devices that offload application parts considerably reduce their energy consumption due to the low-power NFC interface and the benefits of offloading.

The  National Security Agency revelations of pervasive monitoring have lead to an encryption rush across the computer and Internet industry. To push back against massive surveillance and protect users privacy, vendors, hosting and cloud providers have widely deployed encryption on their hardware, communication links, and applications. As a consequence, the most of web traffic nowadays is encrypted. However, there is still a significant part of Internet traffic that is not encrypted. It has been argued that both costs and complexity associated with obtaining and deploying X. certificates are major barriers for widespread encryption, since these certificates are required to established encrypted connections. To address these issues, the Electronic Frontier Foundation, Mozilla Foundation, and the University of Michigan have set up Lets Encrypt LE, a certificate authority that provides both free X. certificates and software that automates the deployment of these certificates. In this paper, we investigate if LE has been successful in democratizing encryption we analyze certificate issuance in the first year of LE and show from various perspectives that LE adoption has an upward trend and it is in fact being successful in covering the lower-cost end of the hosting market.

Microtask crowdsourcing is the practice of breaking down an overarching task to be performed into numerous, small, and quick microtasks that are distributed to an unknown, large set of workers. Microtask crowdsourcing has shown potential in other disciplines, but with only a handful of approaches explored to date in software engineering, its potential in our field remains unclear. In this paper, we explore how microtask crowdsourcing might serve as a means of fault localization. We particularly take a first step in assessing whether a crowd of workers can correctly locate known faults in a few lines of code code fragments taken from different open source projects. Through Mechanical Turk, we collected the answers of hundreds of workers to a pre-determined set of template questions applied to the code fragments, with a replication factor of twenty answers per question. Our findings show that a crowd can correctly distinguish questions that cover lines of code that contain a fault from those that do not. We also show that various filters can be applied to identify the most effective subcrowds. Our findings also presented serious limitations in terms of the proportion of lines of code selected for inspection and the cost to collect answers. We describe the design of our experiment, discuss the results, and provide an extensive analysis of different filters and their effects in terms of speed, cost, and effectiveness. We conclude with a discussion of limitations and possible future experiments toward more full-fledged fault localization on a large scale involving more complex faults.

Given an unweighted tree TV,E with terminals K subset V, we show how to obtain a -quality vertex flow and cut sparsifier H with VH  K. We prove that our result is essentially tight by providing a -o lower-bound on the quality of any cut sparsifier for stars. In addition we give improved results for quasi-bipartite graphs. First, we show how to obtain a -quality flow sparsifier with VH  K for such graphs. We then consider the other extreme and construct exact sparsifiers of size Ok, when the input graph is unweighted.

Selective weeding is one of the key challenges in the field of agriculture robotics. To accomplish this task, a farm robot should be able to accurately detect plants and to distinguish them between crop and weeds. Most of the promising state-of-the-art approaches make use of appearance-based models trained on large annotated datasets. Unfortunately, creating large agricultural datasets with pixel-level annotations is an extremely time consuming task, actually penalizing the usage of data-driven techniques. In this paper, we face this problem by proposing a novel and effective approach that aims to dramatically minimize the human intervention needed to train the detection and classification algorithms. The idea is to procedurally generate large synthetic training datasets randomizing the key features of the target environment i.e., crop and weed species, type of soil, light conditions. More specifically, by tuning these model parameters, and exploiting a few real-world textures, it is possible to render a large amount of realistic views of an artificial agricultural scenario with no effort. The generated data can be directly used to train the model or to supplement real-world images. We validate the proposed methodology by using as testbed a modern deep learning based image segmentation architecture. We compare the classification results obtained using both real and synthetic images as training data. The reported results confirm the effectiveness and the potentiality of our approach.

This volume constitutes the pre-proceedings of the Workshop on Coalgebra, Horn Clause Logic Programming and Types CoALP-Ty, held on -- November  in Edinburgh as a mark of the end of the EPSRC Grant Coalgebraic Logic Programming for Type Inference, by E. Komendantskaya and J. Power. This volume consists of extended abstracts describing current research in the following areas   Semantics Lawvere theories and Coalgebra in Logic and Functional Programming   Programming languages Horn Clause Logic for Type Inference in Functional Languages and Beyond   After discussion at the workshop authors of the extended abstracts will be invited to submit a full paper to go through a second round of refereeing and selection for the formal proceedings.

In this work we present a model for analyzing the combined use of broadcast polling and piggybacking in Worldwide Interoperability for Microwave Access WiMAX networks. For an accurate analysis of piggybacking, the model focuses on the realistic case of limited up-link bandwidth and non-trivial queueing capability at the subscriber stations. We first model the activity of a subscriber station using a Markov chain and its queue as an MG system with vacations in order to facilitate the analysis of the piggyback mechanism. We then derive a set of fixed point equations that describe not only the contention process at the network level but also bandwidth allocation to contending and piggybacked requests. Our model uses a minimal set of assumptions and is generic in the sense that it is customizable through a set of parameters. It can also reproduce the system performance in both saturated and non-saturated conditions. After validating our analysis through extensive simulations, we shed light on the aspects of the synergy between broadcast polling and piggybacking and unveil the pros and cons of using the latter.

Even with the recent advances in convolutional neural networks CNN in various visual recognition tasks, the state-of-the-art action recognition system still relies on hand crafted motion feature such as optical flow to achieve the best performance. We propose a multitask learning model ActionFlowNet to train a single stream network directly from raw pixels to jointly estimate optical flow while recognizing actions with convolutional neural networks, capturing both appearance and motion in a single model. We additionally provide insights to how the quality of the learned optical flow affects the action recognition. Our model not only significantly improves action recognition accuracy by a large margin  compared to state-of-the-art CNN-based action recognition models trained without external large scale data and additional optical flow input, but also produces the optical flow as a side product.

Many of todays most widely used computing applications utilize social networking features and allow users to connect, follow each other, share content, and comment on others posts. However, despite the widespread adoption of these features, there is little understanding of the consequences that social networking has on user retention, engagement, and online as well as offline behavior. Here, we study how social networks influence user behavior in a physical activity tracking application. We analyze  million online and offline actions of  million users over the course of  years, and show that social networking leads to a significant increase in users online as well as offline activities. Specifically, we establish a causal effect of how social networks influence user behavior. We show that the creation of new social connections increases user online in-application activity by , user retention by , and user offline real-world physical activity by  about  steps per day. By exploiting a natural experiment we distinguish the effect of social influence of new social connections from the simultaneous increase in users motivation to use the app and take more steps. We show that social influence accounts for  of the observed changes in user behavior, while the remaining  can be explained by the users increased motivation to use the app. Further, we show that subsequent, individual edge formations in the social network lead to significant increases in daily steps. These effects diminish with each additional edge and vary based on edge attributes and user demographics. Finally, we utilize these insights to develop a model that accurately predicts which users will be most influenced by the creation of new social network connections.

We propose a new exponential family of models for random graphs. Starting from the standard exponential random graph model ERGM framework, we propose an extension that addresses some of the well-known issues with ERGMs. Specifically, we solve the problem of computational intractability and degenerate model behavior by an interpretable support restriction.

Managing patients with multimorbidity often results in polypharmacy the prescription of multiple drugs. However, the long-term effects of specific combinations of drugs and diseases are typically unknown. In particular, drugs prescribed for one condition may result in adverse effects for the other. To investigate which types of drugs may affect the further progression of multimorbidity, we query models of diseases and prescriptions that are learned from primary care data. State-of-the-art tractable Bayesian network representations, on which such complex queries can be computed efficiently, are employed for these large medical networks. Our results confirm that prescriptions may lead to unintended negative consequences in further development of multimorbidity in cardiovascular diseases. Moreover, a drug treatment for one disease group may affect diseases of another group.

A fundamental manifestation of wave scattering in a disordered medium is the highly complex intensity pattern the waves acquire due to multi-path interference. Here we show that these intensity variations can be entirely suppressed by adding disorder-specific gain and loss components to the medium. The resulting constant-intensity CI waves in such non-Hermitian scattering landscapes are free of any backscattering and feature perfect transmission through the disorder. An experimental demonstration of these unique wave states is envisioned based on spatially modulated pump beams that can flexibly control the gain and loss components in an active medium.

This paper proposes an efficient identification algorithm for spatial multiplexing SM and Alamouti AL coded orthogonal frequency division multiplexing OFDM signals. The cross-correlation between the received signals from different antennas is exploited to provide a discriminating feature to identify SM-OFDM and AL-OFDM signals. The proposed algorithm requires neither estimation of the channel coefficients and noise power, nor the modulation of the transmitted signal. Moreover, it does not need space-time block code STBC or OFDM block synchronization. The effectiveness of the proposed algorithm is demonstrated through extensive simulation experiments in the presence of diverse transmission impairments, such as time and frequency offsets, Doppler frequency, and spatially correlated fading.

Machine learning is being deployed in a growing number of applications which demand real-time, accurate, and robust predictions under heavy query load. However, most machine learning frameworks and systems only address model training and not deployment.   In this paper, we introduce Clipper, a general-purpose low-latency prediction serving system. Interposing between end-user applications and a wide range of machine learning frameworks, Clipper introduces a modular architecture to simplify model deployment across frameworks and applications. Furthermore, by introducing caching, batching, and adaptive model selection techniques, Clipper reduces prediction latency and improves prediction throughput, accuracy, and robustness without modifying the underlying machine learning frameworks. We evaluate Clipper on four common machine learning benchmark datasets and demonstrate its ability to meet the latency, accuracy, and throughput demands of online serving applications. Finally, we compare Clipper to the TensorFlow Serving system and demonstrate that we are able to achieve comparable throughput and latency while enabling model composition and online learning to improve accuracy and render more robust predictions.

We focus on the maximum regularization parameter for anisotropic total-variation denoising. It corresponds to the minimum value of the regularization parameter above which the solution remains constant. While this value is well know for the Lasso, such a critical value has not been investigated in details for the total-variation. Though, it is of importance when tuning the regularization parameter as it allows fixing an upper-bound on the grid for which the optimal parameter is sought. We establish a closed form expression for the one-dimensional case, as well as an upper-bound for the two-dimensional case, that appears reasonably tight in practice. This problem is directly linked to the computation of the pseudo-inverse of the divergence, which can be quickly obtained by performing convolutions in the Fourier domain.

The aim of this paper is to shed light on the problem of controlling a complex network with minimal control energy. We show first that the control energy depends on the time constant of the modes of the network, and that the closer the eigenvalues are to the imaginary axis of the complex plane, the less energy is required for complete controllability. In the limit case of networks having all purely imaginary eigenvalues e.g. networks of coupled harmonic oscillators, several constructive algorithms for minimum control energy driver node selection are developed. A general heuristic principle valid for any directed network is also proposed the overall cost of controlling a network is reduced when the controls are concentrated on the nodes with highest ratio of weighted outdegree vs indegree.

We consider the following multiplication-based tests to check if a given function f mathbbFqnto mathbbFq is the evaluation of a degree-d polynomial over mathbbFq for q prime.    mathrmTeste,k Pick P,ldots,Pk independent random degree-e polynomials and accept iff the function fPcdots Pk is the evaluation of a degree-dek polynomial.   We prove the robust soundness of the above tests for large values of e, answering a question of Dinur and Guruswami FOCS . Previous soundness analyses of these tests were known only for the case when either e or k. Even for the case k and e, earlier soundness analyses were not robust.   We also analyze a derandomized version of this test, where for example the polynomials P,ldots,Pk can be the same random polynomial P. This generalizes a result of Guruswami et al. STOC .   One of the key ingredients that go into the proof of this robust soundness is an extension of the standard Schwartz-Zippel lemma over general finite fields mathbbFq, which may be of independent interest.

Following the gaze of people inside videos is an important signal for understanding people and their actions. In this paper, we present an approach for following gaze across views by predicting where a particular person is looking throughout a scene. We collect VideoGaze, a new dataset which we use as a benchmark to both train and evaluate models. Given one view with a person in it and a second view of the scene, our model estimates a density for gaze location in the second view. A key aspect of our approach is an end-to-end model that solves the following sub-problems saliency, gaze pose, and geometric relationships between views. Although our model is supervised only with gaze, we show that the model learns to solve these subproblems automatically without supervision. Experiments suggest that our approach follows gaze better than standard baselines and produces plausible results for everyday situations.

This documents presents the final report of a two-year project to evaluate the impact of AbuseHUB, a Dutch clearinghouse for acquiring and processing abuse data on infected machines. The report was commissioned by the Netherlands Ministry of Economic Affairs, a co-funder of the development of AbuseHUB. AbuseHUB is the initiative of  Internet Service Providers, SIDN the registry for the .nl top-level domain and Surfnet the national research and education network operator. The key objective of AbuseHUB is to improve the mitigation of botnets by its members.   We set out to assess whether this objective is being reached by analyzing malware infection levels in the networks of AbuseHUB members and comparing them to those of other Internet Service Providers ISPs. Since AbuseHUB members together comprise over  percent of the broadband market in the Netherlands, it also makes sense to compare how the country as a whole has performed compared to other countries. This report complements the baseline measurement report produced in December  and the interim report from March . We are using the same data sources as in the interim report, which is an expanded set compared to the earlier baseline report and to our  study into botnet mitigation in the Netherlands.

Software safety is a crucial aspect during the development of modern safety-critical systems. Software is becoming responsible for most of the critical functions of systems. Therefore, the software components in the systems need to be tested extensively against their safety requirements to ensure a high level of system safety. However, performing testing exhaustively to test all software behaviours is impossible. Numerous testing approaches exist. However, they do not directly concern the information derived during the safety analysis. STPA Systems-Theoretic Process Analysis is a unique safety analysis approach based on system and control theory, and was developed to identify unsafe scenarios of a complex system including software. In this paper, we present a systematic and semi-automatic testing approach based on STPA to generate test cases from the STPA safety analysis results to help software and safety engineers to recognize and reduce the associated software risks. We also provide an open-source safety-based testing tool called STPA TCGenerator to support the proposed approach. We illustrate the proposed approach with a prototype of a software of the Adaptive Cruise Control System ACC with a stop-and-go function with a Lego-Mindstorms EV robot.

The task of reconstructing a low rank matrix from incomplete linear measurements arises in areas such as machine learning, quantum state tomography and in the phase retrieval problem. In this note, we study the particular setup that the measurements are taken with respect to rank one matrices constructed from the elements of a random tight frame. We consider a convex optimization approach and show both robustness of the reconstruction with respect to noise on the measurements as well as stability with respect to passing to approximately low rank matrices. This is achieved by establishing a version of the null space property of the corresponding measurement map.

Formal verification and testing are complementary approaches which are used in the development process to verify the functional correctness of software. However, the correctness of software cannot ensure the safe operation of safety-critical software systems. The software must be verified against its safety requirements which are identified by safety analysis, to ensure that potential hazardous causes cannot occur. The complexity of software makes defining appropriate software safety requirements with traditional safety analysis techniques difficult. STPA Systems-Theoretic Processes Analysis is a unique safety analysis approach that has been developed to identify system hazards, including the software-related hazards. This paper presents a comprehensive safety engineering approach based on STPA, including software testing and model checking approaches for the purpose of developing safe software. The proposed approach can be embedded within a defined software engineering process or applied to existing software systems, allow software and safety engineers integrate the analysis of software risks with their verification. The application of the proposed approach is illustrated with an automotive software controller.

Barabasi-Alberts Scale Free model is the accepted theory of the evolution of real world networks. Careful comparison of the theory with a wide range of real world graphs, however, has identified shortcomings in the predictions of the theory when compared to the data. In particular, the exponent gamma of the power law distribution of degree is predicted by the model to be identically , whereas the data has values of gamma between . and .. The degree distribution data also tends to fall off at high degrees, which indicates the existence of maximal node degrees for many networks.   In this paper we propose a simple extension to the Scale Free model, which offers far better agreement with the experimental data. This improvement is satisfying, but the model still does not explain why the attachment probabilities should favor high degree nodes, or indeed how constraints arrive in non-physical networks. Using recent advances in the analysis of the entropy of graphs at the node level we propose a first principles derivation for the Scale Free and constraints model from thermodynamic principles, and demonstrate that both preferential attachment and constraints are simply a natural consequence of the nd law of thermodynamics.

Bayesian Optimization BO has become a core method for solving expensive black-box optimization problems. While much research focussed on the choice of the acquisition function, we focus on online length-scale adaption and the choice of kernel function. Instead of choosing hyperparameters in view of maximum likelihood on past data, we propose to use the acquisition function to decide on hyperparameter adaptation more robustly and in view of the future optimization progress. Further, we propose a particular kernel function that includes non-stationarity and local anisotropy and thereby implicitly integrates the efficiency of local convex optimization with global Bayesian optimization. Comparisons to state-of-the art BO methods underline the efficiency of these mechanisms on global optimization benchmarks.

We study properties of some standard network models when the population is split into two types and the connection pattern between the types is varied. The studied models are generalizations of the Erdos-Renyi graph, the configuration model and a preferential attachment graph. For the Erdos-Renyi graph and the configuration model, the focus is on the component structure. We derive expressions for the critical parameter, indicating when there is a giant component in the graph, and study the size of the largest component by aid of simulations. When the expected degrees in the graph are fixed and the connections are shifted so that more edges connect vertices of different types, we find that the critical parameter decreases. The size of the largest component in the supercritical regime can be both increasing and decreasing as the connections change, depending on the combination of types. For the preferential attachment model, we analyze the degree distributions of the two types and derive explicit expressions for the degree exponents. The exponents are confirmed by simulations that also illustrate other properties of the degree structure.

We address the problem of instance-level semantic segmentation, which aims at jointly detecting, segmenting and classifying every individual object in an image. In this context, existing methods typically propose candidate objects, usually as bounding boxes, and directly predict a binary mask within each such proposal. As a consequence, they cannot recover from errors in the object candidate generation process, such as too small or shifted boxes.   In this paper, we introduce a novel object segment representation based on the distance transform of the object masks. We then design an object mask network OMN with a new residual-deconvolution architecture that infers such a representation and decodes it into the final binary object mask. This allows us to predict masks that go beyond the scope of the bounding boxes and are thus robust to inaccurate object candidates. We integrate our OMN into a Multitask Network Cascade framework, and learn the resulting boundary-aware instance segmentation BAIS network in an end-to-end manner. Our experiments on the PASCAL VOC  and the Cityscapes datasets demonstrate the benefits of our approach, which outperforms the state-of-the-art in both object proposal generation and instance segmentation.

We study generalised restricted Boltzmann machines with generic priors for units and weights, interpolating between Boolean and Gaussian variables. We present a complete analysis of the replica symmetric phase diagram of these models, which can be regarded as generalised Hopfield models. We show the way the paramagnetic phase boundary is directly related to the optimal size of the training set necessary for good generalisation in a teacher- student scenario. Moreover we underline the role of the retrieval phase for both inference and learning processes. We show that retrieval is robust for a large class of weight and unit priors, beyond the standard Hopfield scenario.

We provide a dynamic programming algorithm for the monitoring of a fragment of Timed Propositional Temporal Logic TPTL specifications. This fragment of TPTL, which is more expressive than Metric Temporal Logic, is characterized by independent time variables which enable the elicitation of complex real-time requirements. For this fragment, we provide an efficient polynomial time algorithm for off-line monitoring of finite traces. Finally, we provide experimental results on a prototype implementation of our tool in order to demonstrate the feasibility of using our tool in practical applications.

Capturing the beauty of outdoor scenes in an image motivates many amateur and professional photographers and serves as the basis for many image sharing sites. While natural beauty is often considered a subjective property of images, in this paper, we take an objective approach and provide methods for quantifying and predicting the scenicness of an image. Using a dataset containing hundreds of thousands of outdoor images captured throughout Great Britain with crowdsourced ratings of natural beauty, we propose an approach to predict scenicness which explicitly accounts for the variance of human raters. We demonstrate that quantitative measures of scenicness can benefit semantic image understanding, content-aware image processing, and a novel application of cross-view mapping, where the sparsity of labeled ground-level images can be addressed by incorporating unlabeled aerial images in the training and prediction steps. For each application, our methods for scenicness prediction result in quantitative and qualitative improvements over baseline approaches.

Feature pyramids are a basic component in recognition systems for detecting objects at different scales. But recent deep learning object detectors have avoided pyramid representations, in part because they are compute and memory intensive. In this paper, we exploit the inherent multi-scale, pyramidal hierarchy of deep convolutional networks to construct feature pyramids with marginal extra cost. A top-down architecture with lateral connections is developed for building high-level semantic feature maps at all scales. This architecture, called a Feature Pyramid Network FPN, shows significant improvement as a generic feature extractor in several applications. Using FPN in a basic Faster R-CNN system, our method achieves state-of-the-art single-model results on the COCO detection benchmark without bells and whistles, surpassing all existing single-model entries including those from the COCO  challenge winners. In addition, our method can run at  FPS on a GPU and thus is a practical and accurate solution to multi-scale object detection. Code will be made publicly available.

Given samples from an unknown multivariate distribution p, is it possible to distinguish whether p is the product of its marginals versus p being far from every product distribution? Similarly, is it possible to distinguish whether p equals a given distribution q versus p and q being far from each other? These problems of testing independence and goodness-of-fit have received enormous attention in statistics, information theory, and theoretical computer science, with sample-optimal algorithms known in several interesting regimes of parameters. Unfortunately, it has also been understood that these problems become intractable in large dimensions, necessitating exponential sample complexity.   Motivated by the exponential lower bounds for general distributions as well as the ubiquity of Markov Random Fields MRFs in the modeling of high-dimensional distributions, we initiate the study of distribution testing on structured multivariate distributions, and in particular the prototypical example of MRFs the Ising Model. We demonstrate that, in this structured setting, we can avoid the curse of dimensionality, obtaining sample and time efficient testers for independence and goodness-of-fit. Along the way, we develop new tools for bounding the variance of functions of the Ising model, using and improving upon the exchangeable pairs framework developed by Chatterjee. In particular, we prove variance bounds for multi-linear functions of the Ising model in the high-temperature regime.

In the deletion-channel trace reconstruction problem, there is an unknown n-bit source string x. An algorithm is given access to independent traces of x, where a trace is formed by deleting each bit ofx independently with probabilitydelta. The goal of the algorithm is to recoverx exactly with high probability, while minimizing samples number of traces and running time.   Previously, the best known algorithm for the trace reconstruction problem was due to Holensteinetal. it uses exptildeOn samples and running time for any fixed   delta  . It is also what we call a mean-based algorithm, meaning that it only uses the empirical means of the individual bits of the traces. Holensteinetal.also gave a lower bound, showing that any mean-based algorithm must use at least ntildeOmegalog n samples.   In this paper we improve both of these results, obtaining matching upper and lower bounds for mean-based trace reconstruction. For any constant deletion rate   delta  , we give a mean-based algorithm that uses expOn time and traces we also prove that any mean-based algorithm must use at least expOmegan traces. In fact, we obtain matching upper and lower bounds even for delta subconstant and rho  -delta subconstant when log nn ll delta leq  the bound is exp-Thetadelta n, and when sqrtn ll rho leq  the bound is exp-Thetanrho.   Our proofs involve estimates for the maxima of Littlewood polynomials on complex disks. We show that these techniques can also be used to perform trace reconstruction with random insertions and bit-flips in addition to deletions. We also find a surprising result for deletion probabilities delta  , the presence of insertions can actually help with trace reconstruction.

Motivated by many practical applications, in this paper we study em budget feasible mechanisms where the goal is to procure independent sets from matroids. More specifically, we are given a matroid mathcalME,mathcalI where each ground indivisible element is a selfish agent. The cost of each element i.e., for selling the item or performing a service is only known to the element itself. There is a buyer with a budget having additive valuations over the set of elements E. The goal is to design an incentive compatible truthful budget feasible mechanism which procures an independent set of the matroid under the given budget that yields the largest value possible to the buyer. Our result is a deterministic, polynomial-time, individually rational, truthful and budget feasible mechanism with -approximation to the optimal independent set. Then, we extend our mechanism to the setting of matroid intersections in which the goal is to procure common independent sets from multiple matroids. We show that, given a polynomial time deterministic blackbox that returns alpha-approximation solutions to the matroid intersection problem, there exists a deterministic, polynomial time, individually rational, truthful and budget feasible mechanism with alpha -approximation to the optimal common independent set.

Blockchain technology enables the execution of collaborative business processes involving untrusted parties without requiring a central authority. Specifically, a process model comprising tasks performed by multiple parties can be coordinated via smart contracts operating on the blockchain. The consensus mechanism governing the blockchain thereby guarantees that the process model is followed by each party. However, the cost required for blockchain use is highly dependent on the volume of data recorded and the frequency of data updates by smart contracts. This paper proposes an optimized method for executing business processes on top of commodity blockchain technology. The paper presents a method for compiling a process model into a smart contract that encodes the preconditions for executing each task in the process using a space-optimized data structure. The method is empirically compared to a previously proposed baseline by replaying execution logs, including one from a real-life business process, and measuring resource consumption.

We present an approach to capture the D motion of a group of people engaged in a social interaction. The core challenges in capturing social interactions are  occlusion is functional and frequent  subtle motion needs to be measured over a space large enough to host a social group  human appearance and configuration variation is immense and  attaching markers to the body may prime the nature of interactions. The Panoptic Studio is a system organized around the thesis that social interactions should be measured through the integration of perceptual analyses over a large variety of view points. We present a modularized system designed around this principle, consisting of integrated structural, hardware, and software innovations. The system takes, as input,  synchronized video streams of multiple people engaged in social activities, and produces, as output, the labeled time-varying D structure of anatomical landmarks on individuals in the space. Our algorithm is designed to fuse the weak perceptual processes in the large number of views by progressively generating skeletal proposals from low-level appearance cues, and a framework for temporal refinement is also presented by associating body parts to reconstructed dense D trajectory stream. Our system and method are the first in reconstructing full body motion of more than five people engaged in social interactions without using markers. We also empirically demonstrate the impact of the number of views in achieving this goal.

In the framework of computable queries in Database Theory, there are many examples of queries to properties of relational database instances that can be expressed by simple and elegant third order logic mathrmTO formulae. In many of those properties the expressive power of mathrmTO is not required, but the equivalent second order logic mathrmSO formulae can be very complicated or unintuitive. From the point of view of the study of highly expressive query languages, it is then relevant to identify fragments of mathrmTO and, in general, of higher-order logics of order geq  which do have an mathrmSO equivalent formula. In this article we investigate this precise problem as follows. Firstly, we define a general schema of existsTO formulas which consists of existentially quantifying a third-order linear digraph of polynomial length, that is, a sequence of structures that represents a computation, by explicitly stating which operations are the ones which can be involved in the construction of a given structure in the sequence, when applied to the previous one. Then we give a constructive proof of the fact that all existsTO sub formulas of that schema can be translated into an equivalent SO formula. Secondly, aiming to formally characterize the fragment of TO which can be translated to SO, we define a restriction of TO, which we denote TOP, for polynomial TO, and we give a constructive proof on the fact that it collapses to SO. We define TOP as the fragment of TO where valuations can assign to TO relation variables only TO relations whose cardinalities are bounded by a polynomial that depends on the quantifier. Moreover, we define a similar restriction for every higher order logic of order i geq , which we denote mathrmHOi,P, and give a constructive proof of the fact that for all i geq , mathrmHOi,P collapses to SO.

This work initiates a systematic investigation of testing em high-dimensional structured distributions by focusing on testing em Bayesian networks -- the prototypical family of directed graphical models. A Bayesian network is defined by a directed acyclic graph, where we associate a random variable with each node. The value at any particular node is conditionally independent of all the other non-descendant nodes once its parents are fixed. Specifically, we study the properties of identity testing and closeness testing of Bayesian networks. Our main contribution is the first non-trivial efficient testing algorithms for these problems and corresponding information-theoretic lower bounds. For a wide range of parameter settings, our testing algorithms have sample complexity em sublinear in the dimension and are sample-optimal, up to constant factors.

We present a general framework for proving combinatorial prophet inequalities and constructing posted-price mechanisms. Our framework applies to stochastic welfare optimization problems, in which buyers arrive sequentially and make utility-maximizing purchases. Our analysis takes the form of an extension theorem we derive sufficient conditions for achieving welfare bounds in the special case of deterministic valuations, then prove that these bounds extend directly to stochastic settings. Furthermore, our welfare bounds compose in the sense that the welfare guarantees are preserved when buyers participate in many optimization problems simultaneously. Our sufficient conditions have a natural economic interpretation, and our approach is closely connected to the smoothness framework for bounding the price of anarchy of mechanisms. We show that many smooth mechanisms can be recast as posted-price mechanisms with comparable performance guarantees. We illustrate the power of our framework in a range of applications, including combinatorial auctions, matroids, and sparse packing programs, where we unify and improve many of the previously known results.

We show that the square Hellinger distance between two Bayesian networks on the same directed graph, G, is subadditive with respect to the neighborhoods of G. Namely, if P and Q are the probability distributions defined by two Bayesian networks on the same DAG, our inequality states that the square Hellinger distance, HP,Q, between P and Q is upper bounded by the sum, sumv HPv cup Piv, Qv cup Piv, of the square Hellinger distances between the marginals of P and Q on every node v and its parents Piv in the DAG. Importantly, our bound does not involve the conditionals but the marginals of P and Q. We derive a similar inequality for more general Markov Random Fields.   As an application of our inequality, we show that distinguishing whether two Bayesian networks P and Q on the same but potentially unknown DAG satisfy PQ vs drm TVP,Qepsilon can be performed from tildeOSigmad cdot nepsilon samples, where d is the maximum in-degree of the DAG and Sigma the domain of each variable of the Bayesian networks. If P and Q are defined on potentially different and potentially unknown trees, the sample complexity becomes tildeOSigma. nepsilon, whose dependence on n, epsilon is optimal up to logarithmic factors. Lastly, if P and Q are product distributions over ,n and Q is known, the sample complexity becomes Osqrtnepsilon, which is optimal up to constant factors.

Application trends, device technologies and the architecture of systems drive progress in information technologies. However, the former engines of such progress - Moores Law and Dennard Scaling - are rapidly reaching the point of diminishing returns. The time has come for the computing community to boldly confront a new challenge how to secure a foundational future for information technologys continued progress. The computer architecture community engaged in several visioning exercises over the years. Five years ago, we released a white paper, st Century Computer Architecture, which influenced funding programs in both academia and industry. More recently, the IEEE Rebooting Computing Initiative explored the future of computing systems in the architecture, device, and circuit domains. This report stems from an effort to continue this dialogue, reach out to the applications and devicescircuits communities, and understand their trends and vision. We aim to identify opportunities where architecture research can bridge the gap between the application and device domains.

Mobile Edge Computing MEC is an emerging paradigm that provides computing, storage, and networking resources within the edge of the mobile Radio Access Network RAN. MEC servers are deployed on generic computing platform within the RAN and allow for delay-sensitive and context-aware applications to be executed in close proximity to the end users. This approach alleviates the backhaul and core network and is crucial for enabling low-latency, high-bandwidth, and agile mobile services. This article envisages a real-time, context-aware collaboration framework that lies at the edge of the RAN, constituted of MEC servers and mobile devices, and that amalgamates the heterogeneous resources at the edge. Specifically, we introduce and study three strong use cases ranging from mobile-edge orchestration, collaborative caching and processing and multi-layer interference cancellation. We demonstrate the promising benefits of these approaches in facilitating the evolution to G networks. Finally, we discuss the key technical challenges and open-research issues that need to be addressed in order to make an efficient integration of MEC into G ecosystem.

Optimization problems with rank constraints appear in many diverse fields such as control, machine learning and image analysis. Since the rank constraint is non-convex, these problems are often approximately solved via convex relaxations. Nuclear norm regularization is the prevailing convexifying technique for dealing with these types of problem. This paper introduces a family of low-rank inducing norms and regularizers which includes the nuclear norm as a special case. A posteriori guarantees on solving an underlying rank constrained optimization problem with these convex relaxations are provided. We evaluate the performance of the low-rank inducing norms on three matrix completion problems. In all examples, the nuclear norm heuristic is outperformed by convex relaxations based on other low-rank inducing norms. For two of the problems there exist low-rank inducing norms that succeed in recovering the partially unknown matrix, while the nuclear norm fails. These low-rank inducing norms are shown to be representable as semi-definite programs and to have cheaply computable proximal mappings. The latter makes it possible to also solve problems of large size with the help of scalable first-order methods. Finally, it is proven that our findings extend to the more general class of atomic norms. In particular, this allows us to solve corresponding vector-valued problems, as well as problems with other non-convex constraints.

Variants of the must testing approach have been successfully applied in Service Oriented Computing for analysing the compliance between contracts exposed by clients and servers or, more generally, between two peers. It has however been argued that multiparty scenarios call for more permissive notions of compliance because partners usually do not have full coordination capabilities. We propose two new testing preorders, which are obtained by restricting the set of potential observers. For the first preorder, called uncoordinated, we allow only sets of parallel observers that use different parts of the interface of a given service and have no possibility of intercommunication. For the second preorder, that we call individualistic, we instead rely on parallel observers that perceive as silent all the actions that are not in the interface of interest. We have that the uncoordinated preorder is coarser than the classical must testing preorder and finer than the individualistic one. We also provide a characterisation in terms of decorated traces for both preorders the uncoordinated preorder is defined in terms of must-sets and Mazurkiewicz traces while the individualistic one is described in terms of classes of filtered traces that only contain designated visible actions and must-sets.

The discovery of physical laws consistent with empirical observations lies at the heart of applied science and engineering. These laws typically take the form of nonlinear differential equations depending on parameters, dynamical systems theory provides, through the appropriate normal forms, an intrinsic, prototypical characterization of the types of dynamical regimes accessible to a given model. Using an implementation of data-informed geometry learning we directly reconstruct the relevant normal forms a quantitative mapping from empirical observations to prototypical realizations of the underlying dynamics. Interestingly, the state variables and the parameters of these realizations are inferred from the empirical observations, without prior knowledge or understanding, they parametrize the dynamics em intrinsically, without explicit reference to fundamental physical quantities.

Modern humans are frequently faced with the problem of choosing between using the phone or doing something else. In the laboratory, how people choose between two simple activities is well studied but they cannot address how people solve the ubiquitous problem of using the phone in the real world. Here we extended an existing priority-based decision framework to theoretically link the timing of the touchscreen taps to the priority attributed to the corresponding behavior. The inter-event times of the output from this decision process could be fully described by a  parameter model. Next, we recorded the touchscreen interactions from  volunteers for a month-long period and the inter-event times were well described by using the  parameter model. Based on the fitted parameters we find that in  of the users the overall mean priority of smartphone use is higher than any other activity. The underlying priority distributions estimated from the recordings were typically  of the population u-shaped with the priority values concentrated at the extreme values. We conclude that the priority attributed to the smartphone is not fixed and the perceived importance of the smartphone transitions from one extreme to another.

In order to meet the constantly increasing demand by mobile terminals for higher data rates with limited wireless spectrum resource, cognitive radio and spectrum aggregation technologies have attracted much attention due to its capacity in improving spectrum efficiency. Combing cognitive relay and spectrum aggregation technologies, in this paper, we propose a dynamic spectrum aggregation strategy based on the Markov Prediction of the state of spectrum for the cooperatively relay networks on a multi-user and multi-relay scenario aiming at ensuring the user channel capacity and maximizing the network throughput. The spectrum aggregation strategy is executed through two steps. First, predict the state of spectrum through Markov prediction. Based on the prediction results of state of spectrum, a spectrum aggregation strategy is proposed. Simulation results show that the spectrum prediction process can observably lower the outage rate, and the spectrum aggregation strategy can greatly improve the network throughput.

Language generation tasks that seek to mimic human ability to use language creatively are difficult to evaluate, since one must consider creativity, style, and other non-trivial aspects of the generated text. The goal of this paper is to develop evaluation methods for one such task, ghostwriting of rap lyrics, and to provide an explicit, quantifiable foundation for the goals and future directions of this task. Ghostwriting must produce text that is similar in style to the emulated artist, yet distinct in content. We develop a novel evaluation methodology that addresses several complementary aspects of this task, and illustrate how such evaluation can be used to meaningfully analyze system performance. We provide a corpus of lyrics for  rap artists, annotated for stylistic similarity, which allows us to assess the feasibility of manual evaluation for generated verse.

Transcriptional profiling on microarrays to obtain gene expressions has been used to facilitate cancer diagnosis. We propose a deep generative machine learning architecture called DeepCancer that learn features from unlabeled microarray data. These models have been used in conjunction with conventional classifiers that perform classification of the tissue samples as either being cancerous or non-cancerous. The proposed model has been tested on two different clinical datasets. The evaluation demonstrates that DeepCancer model achieves a very high precision score, while significantly controlling the false positive and false negative scores.

In machine learning, error back-propagation in multi-layer neural networks deep learning has been impressively successful in supervised and reinforcement learning tasks. As a model for learning in the brain, however, deep learning has long been regarded as implausible, since it relies in its basic form on a non-local plasticity rule. To overcome this problem, energy-based models with local contrastive Hebbian learning were proposed and tested on a classification task with networks of rate neurons. We extended this work by implementing and testing such a model with networks of leaky integrate-and-fire neurons. Preliminary results indicate that it is possible to learn a non-linear regression task with hidden layers, spiking neurons and a local synaptic plasticity rule.

In this work, we present a new dataset for computational humor, specifically comparative humor ranking, which attempts to eschew the ubiquitous binary approach to humor detection. The dataset consists of tweets that are humorous responses to a given hashtag. We describe the motivation for this new dataset, as well as the collection process, which includes a description of our semi-automated system for data collection. We also present initial experiments for this dataset using both unsupervised and supervised approaches. Our best supervised system achieved . accuracy, suggesting that this task is much more difficult than comparable humor detection tasks. Initial experiments indicate that a character-level model is more suitable for this task than a token-level model, likely due to a large amount of puns that can be captured by a character-level model.

Automatic detection of lymphocyte in HE images is a necessary first step in lots of tissue image analysis algorithms. An accurate and robust automated lymphocyte detection approach is of great importance in both computer science and clinical studies. Most of the existing approaches for lymphocyte detection are based on traditional image processing algorithms andor classic machine learning methods. In the recent years, deep learning techniques have fundamentally transformed the way that a computer interprets images and have become a matchless solution in various pattern recognition problems. In this work, we design a new deep neural network model which extends the fully convolutional network by combining the ideas in several recent techniques, such as shortcut links. Also, we design a new training scheme taking the prior knowledge about lymphocytes into consideration. The training scheme not only efficiently exploits the limited amount of free-form annotations from pathologists, but also naturally supports efficient fine-tuning. As a consequence, our model has the potential of self-improvement by leveraging the errors collected during real applications. Our experiments show that our deep neural network model achieves good performance in the images of different staining conditions or different types of tissues.

We study an uplink multi secondary user SU system having statistical delay constraints, and an average interference constraint to the primary user PU. SUs with heterogeneous interference channel statistics, to the PU, experience heterogeneous delay performances since SUs causing low interference are scheduled more frequently than those causing high interference. We propose a scheduling algorithm that can provide arbitrary average delay guarantees to SUs irrespective of their statistical channel qualities. We derive the algorithm using the Lyapunov technique and show that it yields bounded queues and satisfy the interference constraints. Using simulations, we show its superiority over the Max-Weight algorithm.

Context Systematic literature reviews SLRs are the primary method for aggregating and synthesizing evidence in evidence-based software engineering. Primary study selection is a critical and time-consuming SLR step in which reviewers use titles, abstracts, or even full texts to evaluate thousands of studies to find the dozens of them that are relevant to the research questions. Objective We seek to reduce the effort of primary study selection in SLRs with machine assisted reading techniques. Method In this paper we explore and refactor the state-of-the-art machine assisted reading techniques from both evidence-based medicine and legal electronic discovery to support SLRs. By refactoring those methods, we discovered FASTREAD, which is a new state-of-the-art in machine assisted primary studies for SLRs. Tested on two data sets generated from existing SLRs of Hall, Wahono, et al., FASTREAD outperforms the current state-of-the-art methods. Results Using FASTREAD, it is possible to find  of the studies found by standard manual methods, but after only reading less than  of the candidate studies. Conclusions With the help of FASTREAD, conducting an SLR is much more efficient and less difficult. Software Engineering researchers now have no excuse they should conduct SLRs.

Decision trees have been a very popular class of predictive models for decades due to their interpretability and good performance on categorical features. However, they are not always robust and tend to overfit the data. Additionally, if allowed to grow large, they lose interpretability. In this paper, we present a novel mixed integer programming formulation to construct optimal decision trees of specified size. We take special structure of categorical features into account and allow combinatorial decisions based on subsets of values of such a feature at each node. We show that very good accuracy can be achieved with small trees using moderately-sized training sets. The optimization problems we solve are easily tractable with modern solvers.

In training speech recognition systems, labeling audio clips can be expensive, and not all data is equally valuable. Active learning aims to label only the most informative samples to reduce cost. For speech recognition, confidence scores and other likelihood-based active learning methods have been shown to be effective. Gradient-based active learning methods, however, are still not well-understood. This work investigates the Expected Gradient Length EGL approach in active learning for end-to-end speech recognition. We justify EGL from a variance reduction perspective, and observe that EGLs measure of informativeness picks novel samples uncorrelated with confidence scores. Experimentally, we show that EGL can reduce word errors by , or alternatively, reduce the number of samples to label by , when compared to random sampling.

We study an uplink multi secondary user SU cognitive radio system suffering statistical heterogeneity among SUs channels. This heterogeneity may result in differentiated delay performances to these SUs and result in harmful interference to the PU. We first derive an explicit closed-form expression for the average delay in terms of an arbitrary power-control policy. Then, we propose a delay-optimal closed-form scheduling and power-control policy that can provide the required average delay guarantees to all SUs besides protecting the PU from harmful interference. We support our findings by extensive system simulations and show that it outperforms existing policies substantially.

With the ever-increasing scientific literature, there is a need on a natural language interface to bibliographic information retrieval systems to retrieve related information effectively. In this paper, we propose a natural language interface, NLI-GIBIR, to a graph-based bibliographic information retrieval system. In designing NLI-GIBIR, we developed a novel framework that can be applicable to graph-based bibliographic information retrieval systems. Our framework integrates algorithmsheuristics for interpreting and analyzing natural language bibliographic queries. NLI-GIBIR allows users to search for a variety of bibliographic data through natural language. A series of text- and linguistic-based techniques are used to analyze and answer natural language queries, including tokenization, named entity recognition, and syntactic analysis. We find that our framework can effectively represents and addresses complex bibliographic information needs. Thus, the contributions of this paper are as follows First, to our knowledge, it is the first attempt to propose a natural language interface to graph-based bibliographic information retrieval. Second, we propose a novel customized natural language processing framework that integrates a few original algorithmsheuristics for interpreting and analyzing natural language bibliographic queries. Third, we show that the proposed framework and natural language interface provide a practical solution in building real-world natural language interface-based bibliographic information retrieval systems. Our experimental results show that the presented system can correctly answer  out of  example natural language queries with varying lengths and complexities.

In this paper we study the following multi-robot coordination problem given a graph, where each edge is weighted by the probability of surviving while traversing it, find a set of paths for K robots that maximizes the expected number of nodes collectively visited, subject to constraints on the probability that each robot survives to its destination. We call this problem the Team Surviving Orienteers TSO problem. The TSO problem is motivated by scenarios where a team of robots must traverse a dangerous, uncertain environment, such as aid delivery in disaster or war zones. We present the TSO problem formally along with several variants, which represent survivability-aware counterparts for a wide range of multi-robot coordination problems such as vehicle routing, patrolling, and informative path planning. We propose an approximate greedy approach for selecting paths, and prove that the value of its output is bounded within a factor -e-pslambda of the optimum where ps is the per-robot survival probability threshold, and lambda le  is the approximation factor of an oracle routine for the well-known orienteering problem. Our approach has linear time complexity in the team size and polynomial complexity in the graph size. Using numerical simulations, we verify that our approach is close to the optimum in practice and that it scales to problems with hundreds of nodes and tens of robots.

This paper introduces two new families of non-parametric tests of goodness-of-fit on the compact classical groups. One of them is a family of tests for the eigenvalue distribution induced by the uniform distribution, which is consistent against all fixed alternatives. The other is a family of tests for the uniform distribution on the entire group, which is again consistent against all fixed alternatives. We find the asymptotic distribution under the null and general alternatives. The tests are proved to be asymptotically admissible. Local power is derived and the global properties of the power function against local alternatives are explored.   The new tests are validated on two random walks for which the mixing-time is studied in the literature. The new tests, and several others, are applied to the Markov chain sampler proposed by citejonesrandomized, providing strong evidence supporting the claim that the sampler mixes quickly.

Co-localization is the problem of localizing objects of the same class using only the set of images that contain them. This is a challenging task because the object detector must be built without negative examples that can lead to more informative supervision signals. The main idea of our method is to cluster the feature space of a generically pre-trained CNN, to find a set of CNN features that are consistently and highly activated for an object category, which we call category-consistent CNN features. Then, we propagate their combined activation map using superpixel geodesic distances for co-localization. In our first set of experiments, we show that the proposed method achieves state-of-the-art performance on three related benchmarks PASCAL , PASCAL-, and the Object Discovery dataset. We also show that our method is able to detect and localize truly unseen categories, on six held-out ImageNet categories with accuracy that is significantly higher than previous state-of-the-art. Our intuitive approach achieves this success without any region proposals or object detectors, and can be based on a CNN that was pre-trained purely on image classification tasks without further fine-tuning.

We consider the stabilization of an unstable discrete-time linear system that is observed over a channel corrupted by continuous multiplicative noise. Our main result shows that if the system growth is large enough, then the system cannot be stabilized in a second-moment sense. This is done by showing that the probability that the state magnitude remains bounded must go to zero with time. Our proof technique recursively bounds the conditional density of the system state instead of focusing on the second moment to bound the progress the controller can make. This sidesteps the difficulty encountered in using the standard data-rate theorem style approach that approach does not work because the mutual information per round between the system state and the observation is potentially unbounded.   It was known that a system with multiplicative observation noise can be stabilized using a simple memoryless linear strategy if the system growth is suitably bounded. In this paper, we show that while memory cannot improve the performance of a linear scheme, a simple non-linear scheme that uses one-step memory can do better than the best linear scheme.

Context Early size predictions ESP can lead to errors in effort predictions for software projects. This problem is particular acute in parametric effort models that give extra weight to size factors for example, the COCOMO model assumes that effort is exponentially proportional to project size.   Objective Are effort estimates crippled by bad ESP?   Method Document inaccuracies in early size estimates. Using those error sizes to determine the implications of those inaccuracies via an Monte Carlo perturbation analysis of effort models and an analysis of the equations used in those effort models.   Results While many projects have errors in ESP of up to - , those errors add very little to the overall effort estimate error. Specifically, we find no statistically significant difference in the estimation errors seen after increasing ESP errors from  to - . An analysis of effort estimation models explains why this is so the net additional impact of ESP error is relatively small compared to the other sources of error associated within estimation models.   Conclusion ESP errors effect effort estimates by a relatively minor amount. As soon as a model uses a size estimate and other factors to predict project effort, then ESP errors are not crippling to the process of estimation.

Synthesizing photo-realistic images from text descriptions is a challenging problem in computer vision and has many practical applications. Samples generated by existing text-to-image approaches can roughly reflect the meaning of the given descriptions, but they fail to contain necessary details and vivid object parts. In this paper, we propose stacked Generative Adversarial Networks StackGAN to generate photo-realistic images conditioned on text descriptions. The Stage-I GAN sketches the primitive shape and basic colors of the object based on the given text description, yielding Stage-I low resolution images. The Stage-II GAN takes Stage-I results and text descriptions as inputs, and generates high resolution images with photo-realistic details. The Stage-II GAN is able to rectify defects and add compelling details with the refinement process. Samples generated by StackGAN are more plausible than those generated by existing approaches. Importantly, our StackGAN for the first time generates realistic  x  images conditioned on only text descriptions, while state-of-the-art methods can generate at most  x  images. To demonstrate the effectiveness of the proposed StackGAN, extensive experiments are conducted on CUB and Oxford- datasets, which contain enough object appearance variations and are widely-used for text-to-image generation analysis.

We study the problem of planning paths for a team of robots for visually monitoring an environment. Our work is motivated by surveillance and persistent monitoring applications. We are given a set of target points in a polygonal environment that must be monitored using robots with cameras. The goal is to compute paths for all robots such that every target is visible from at least one path. In its general form, this problem is NP-hard as it generalizes the Art Gallery Problem and the Watchman Route Problem. We study two versions i a geometric version in emphstreet polygons for which we give a polynomial time --approximation algorithm and ii a general version for which we present a practical solution that finds the optimal solution in possibly exponential time. In addition to theoretical proofs, we also present results from simulation studies.

Nanoindentation involves probing a hard diamond tip into a material, where the load and the displacement experienced by the tip is recorded continuously. This load-displacement data is a direct function of materials innate stress-strain behavior. Thus, theoretically it is possible to extract mechanical properties of a material through nanoindentation. However, due to various nonlinearities associated with nanoindentation the process of interpreting load-displacement data into material properties is difficult. Although, simple elastic behavior can be characterized easily, a method to characterize complicated material behavior such as nonlinear viscoelasticity is still lacking. In this study, a nanoindentation-based material characterization technique is developed to characterize soft materials exhibiting nonlinear viscoelasticity. Nanoindentation experiment was modeled in finite element analysis software ABAQUS, where a nonlinear viscoelastic behavior was incorporated using user-defined subroutine UMAT. The model parameters were calibrated using a process called inverse analysis. In this study, a surrogate model-based approach was used for the inverse analysis. The different factors affecting the surrogate model performance are analyzed in order to optimize the performance with respect to the computational cost.

Inspired by recent research, we explore ways to model the highly morphological Finnish language at the level of characters while maintaining the performance of word-level models. We propose a new Character-to-Word-to-Character CWC compositional language model that uses characters as input and output while still internally processing word level embeddings. Our preliminary experiments, using the Finnish Europarl V corpus, indicate that CWC can respond well to the challenges of morphologically rich languages such as high out of vocabulary rates, the prediction of novel words, and growing vocabulary size. Notably, the model is able to correctly score inflectional forms that are not present in the training data and sample grammatically and semantically correct Finnish sentences character by character.

We present a Deep Convolutional Neural Network architecture which serves as a generic image-to-image regressor that can be trained end-to-end without any further machinery. Our proposed architecture the Recursively Branched Deconvolutional Network RBDN develops a cheap multi-context image representation very early on using an efficient recursive branching scheme with extensive parameter sharing and learnable upsampling. This multi-context representation is subjected to a highly non-linear locality preserving transformation by the remainder of our network comprising of a series of convolutionsdeconvolutions without any spatial downsampling. The RBDN architecture is fully convolutional and can handle variable sized images during inference. We provide qualitativequantitative results on  diverse tasks relighting, denoising and colorization and show that our proposed RBDN architecture obtains comparable results to the state-of-the-art on each of these tasks when used off-the-shelf without any post processing or task-specific architectural modifications.

Shibata et al. reported that humans could learn to repeatedly evoke a stimulus-associated functional magnetic resonance imaging fMRI activity pattern in visual areas VV through which visual perceptual learning was achieved without stimulus presentation. Contrary to their attribution of visual improvements to neuroplasticity in adult VV, our Hebbian learning interpretation of these data explains the attainment of better perceptual decisions without plastic VV.

This paper considers a single-cell massive multiple-input multiple-output MIMO system equipped with a base station BS that uses one-bit quantization and investigates the energy efficiency EE and spectral efficiency SE trade-off. We first propose a new precoding scheme and downlink power allocation strategy that results in uplink-downlink SINR duality for one-bit MIMO systems. Taking into account the effect of the imperfect channel state information, we obtain approximate closed-form expressions for the uplink and downlink achievable rates under duality with maximum ratio combiningmatched-filter and zero-forcing processing. We then focus on joint optimization of the competing SE and EE objectives over the number of users, pilot training duration and operating power, using the weighted product method to obtain the EESE Pareto boundary. Numerical results are presented to verify our analytical resultsand demonstrate the fundamental tradeoff between EE and SE for different parameter settings.

Conventional approaches to image de-fencing suffer from non-robust fence detection and are limited to processing images of static scenes. In this position paper, we propose an automatic de-fencing algorithm for images of dynamic scenes. We divide the problem of image de-fencing into the tasks of automated fence detection, motion estimation and fusion of data from multiple frames of a captured video of the dynamic scene. Fences are detected automatically using two approaches, namely, employing Gabor filter and a machine learning method. We cast the fence removal problem in an optimization framework, by modeling the formation of the degraded observations. The inverse problem is solved using split Bregman technique assuming total variation of the de-fenced image as the regularization constraint.

Understanding and analyzing big data is firmly recognized as a powerful and strategic priority. For deeper interpretation of and better intelligence with big data, it is important to transform raw data unstructured, semi-structured and structured data sources, e.g., text, video, image data sets into curated data contextualized data and knowledge that is maintained and made available for use by end-users and applications. In particular, data curation acts as the glue between raw data and analytics, providing an abstraction layer that relieves users from time consuming, tedious and error prone curation tasks. In this context, the data curation process becomes a vital analytics asset for increasing added value and insights.   In this paper, we identify and implement a set of curation APIs and make them available on GitHub to researchers and developers to assist them transforming their raw data into curated data. The curation APIs enable developers to easily add features - such as extracting keyword, part of speech, and named entities such as Persons, Locations, Organizations, Companies, Products, Diseases, Drugs, etc. providing synonyms and stems for extracted information items leveraging lexical knowledge bases for the English language such as WordNet linking extracted entities to external knowledge bases such as Google Knowledge Graph and Wikidata discovering similarity among the extracted information items, such as calculating similarity between string, number, date and time data classifying, sorting and categorizing data into various types, forms or any other distinct class and indexing structured and unstructured data - into their applications.

In this article we present a construction of error correcting codes, that have representation as very sparse matrices and belong to the class of Low Density Parity Check Codes. LDPC codes are in the classical Hamming metric. They are very close to well known Shannon bound. The ability to use graphs for code construction was first discussed by Tanner in  and has been used in a number of very effective implementations. We describe how to construct such codes by using special a family of graphs introduced by Ustimenko and Woldar. Graphs that we used are bipartite, bi-regular, very sparse and do not have short cycles C  . Due to the very low density of such graphs, the obtained codes are fast decodable. We describe how to choose parameters to obtain a desired code rate. We also show results of computer simulations of BER bit error rate of the obtained codes in order to compare them with other known LDPC codes.

Random walks are ubiquitous in the sciences, and they are interesting from both theoretical and practical perspectives. They are one of the most fundamental types of stochastic processes can be used to model numerous phenomena, including diffusion, interactions, and opinions among humans and animals and can be used to extract information about important entities or dense groups of entities in a network. Random walks have been studied for many decades on both regular lattices and especially in the last couple of decades on networks with a variety of structures. In the present article, we survey the theory and applications of random walks on networks, restricting ourselves to simple cases of single and non-adaptive random walkers. We distinguish three main types of random walks discrete-time random walks, node-centric continuous-time random walks, and edge-centric continuous-time random walks. We first briefly survey random walks on a line, and then we consider random walks on various types of networks. We extensively discuss applications of random walks, including ranking of nodes e.g., PageRank, community detection, respondent-driven sampling, and opinion models such as voter models.

In this paper, we establish a novel bottom-up cue named Convex Hull Overlap CHO, and then propose an effective approach to detect salient regions using the combination of the CHO cue and global contrast cue. Our scheme significantly differs from other earlier work in  The hierarchical segmentation model based on Normalized Graph-Cut fits the splitting and merging processes in human visual perception  Previous work only focuses on color and texture cues, while our CHO cue makes up the obvious gap between the spatial region covering and the region saliency. CHO is a kind of improved and enhanced Gestalt cue, while other popular figure-ground cues such as convexity and surroundedness can be regarded as the special cases of CHO. Our experiments on a large number of public data have obtained very positive results.

In this comment, I discuss the use of statistical inference in citation analysis. In a recent paper, Williams and Bornmann argue in favor of the use of statistical inference in citation analysis. I present a critical analysis of their arguments and of similar arguments provided elsewhere in the literature. My conclusion is that the use of statistical inference in citation analysis involves major conceptual difficulties and, consequently, that the usefulness of statistical inference in citation analysis is highly questionable.

We propose a novel coding theoretic framework for mitigating stragglers in distributed learning. We show how carefully replicating data blocks and coding across gradients can provide tolerance to failures and stragglers for Synchronous Gradient Descent. We implement our schemes in python using MPI to run on Amazon EC, and show how we compare against baseline approaches in running time and generalization error.

We present a compressed data structure to store free trajectories of moving objects ships over the sea, for example allowing spatio-temporal queries. Our method, GraCT, uses a k-tree to store the absolute positions of all objects at regular time intervals snapshots, whereas the positions between snapshots are represented as logs of relative movements compressed with Re-Pair. Our experimental evaluation shows important savings in space and time with respect to a fair baseline.

Android, the most popular mobile OS, has around  of the mobile market share. Due to its popularity, it attracts many malware attacks. In fact, people have discovered around one million new malware samples per quarter, and it was reported that over  of these new malware samples are in fact derivatives or variants from existing malware families. In this paper, we first show that runtime behaviors of malwares core functionalities are in fact similar within a malware family. Hence, we propose a framework to combine runtime behavior with static structures to detect malware variants. We present the design and implementation of MONET, which has a client and a backend server module. The client module is a lightweight, in-device app for behavior monitoring and signature generation, and we realize this using two novel interception techniques. The backend server is responsible for large scale malware detection. We collect  malware samples and top  benign apps to carry out extensive experiments of detecting malware variants and defending against malware transformation. Our experiments show that MONET can achieve around  accuracy in detecting malware variants. Furthermore, it can defend against  different obfuscation and transformation techniques, while only incurs around  performance overhead and about  battery overhead. More importantly, MONET will automatically alert users with intrusion details so to prevent further malicious behaviors.

The present document is devoted to structural properties of neural population dynamics and especially their differential flatness. Several applications of differential flatness in the present context can be envisioned, among which trajectory tracking, feedforward to feedback switching, cyclic character, positivity and boundedness.

There is a renaissance in visual analytics systems for data analysis and sharing, in particular, in the current wave of big data applications. We introduce RAVE, a prototype that automates the generation of an interface that uses facets and visualization techniques for exploring and analyzing relevance assessments data sets collected via crowdsourcing. We present a technical description of the main components and demonstrate its use.

Motivated by the need to reason about hybrid systems, we study limits in categories of coalgebras whose underlying functor is a Vietoris polynomial one - intuitively, the topological analogue of a Kripke polynomial functor. Among other results, we prove that every Vietoris polynomial functor admits a final coalgebra if it respects certain conditions concerning separation axioms and compactness. When the functor is restricted to some of the categories induced by these conditions the resulting categories of coalgebras are even complete. As a practical application, we use these developments in the specification and analysis of non-deterministic hybrid systems, in particular to obtain suitable notions of stability, and behaviour.

A Monte Carlo algorithm typically simulates a prescribed number of samples, taking some random real time to complete the computations necessary. This work considers the converse to impose a real-time budget on the computation, so that the number of samples simulated is random. To complicate matters, the real time taken for each simulation may depend on the sample produced, so that the samples themselves are not independent of their number, and a length bias with respect to computation time is introduced.   We propose an anytime framework to address this concern. We firstly introduce a continuous-time Markov jump process to chart the progress of the computation in real time. With respect to the target distribution, the stationary distribution of this process is length-biased by computation time. We introduce a multiple chain construction to eliminate this length bias for any Markov chain Monte Carlo MCMC algorithm. Exploiting this debiasing technique yields MCMC algorithms that may be interrupted at any real time to obtain a sample from the target distribution. We call these class of interruptible algorithms anytime Monte Carlo algorithms.   The utility of these algorithms is demonstrated on a large-scale Sequential Monte Carlo Squared implementation using four billion particles in total, distributed across a cluster of  graphics processing units on the Amazon EC service, providing approximately -way parallelism. The anytime framework is used to impose a real-time budget on move steps, ensuring that all processors are simultaneously ready for the resampling step, demonstrably reducing wait times.

Prediction in a small-sized sample with a large number of covariates, the small n, large p problem, is challenging. This setting is encountered in multiple applications, such as precision medicine, where obtaining additional samples can be extremely costly or even impossible, and extensive research effort has recently been dedicated to finding principled solutions for accurate prediction. However, a valuable source of additional information, domain experts, has not yet been efficiently exploited. We formulate knowledge elicitation generally as a probabilistic inference process, where expert knowledge is sequentially queried to improve predictions. In the specific case of sparse linear regression, where we assume the expert has knowledge about the values of the regression coefficients or about the relevance of the features, we propose an algorithm and computational approximation for fast and efficient interaction, which sequentially identifies the most informative features on which to query expert knowledge. Evaluations of our method in experiments with simulated and real users show improved prediction accuracy already with a small effort from the expert.

The chiral clock spin-glass model with q states, with both competing ferromagnetic-antiferromagnetic and left-right chiral frustrations, is studied in d spatial dimensions by renormalization-group theory. The global phase diagram is calculated in temperature, antiferromagnetic bond concentration p, random chirality strength, and right-chirality concentration c. The system has a ferromagnetic phase, a multitude of different chiral phases, a chiral spin-glass phase, and a critical algebraically ordered phase. The ferromagnetic and chiral phases accumulate at the disordered phase boundary and form a spectrum of devils staircases, where different ordered phases characteristically intercede at all scales of phase-diagram space. Shallow and deep reentrances of the disordered phase, bordered by fragments of regular and temperature-inverted devils staircases, are seen. The extremely rich phase diagrams are presented as continuously and qualitatively changing videos.

We consider the following single-machine scheduling problem, which is often denoted sum fj we are given n jobs to be scheduled on a single machine, where each job j has an integral processing time pj, and there is a nondecreasing, nonnegative cost function fjCj that specifies the cost of finishing j at time Cj the objective is to minimize sumjn fjCj. Bansal  Pruhs recently gave the first constant approximation algorithm with a performance guarantee of . We improve on this result by giving a primal-dual pseudo-polynomial-time algorithm based on the recently introduced knapsack-cover inequalities. The algorithm finds a schedule of cost at most four times the constructed dual solution. Although we show that this bound is tight for our algorithm, we leave open the question of whether the integrality gap of the LP is less than . Finally, we show how the technique can be adapted to yield, for any epsilon , a epsilon -approximation algorithm for this problem.

We present a deterministic oblivious LIFO Stack, FIFO, double-ended and double-ended priority queue as well as an oblivious mergesort and quicksort algorithm. Our techniques and ideas include concatenating queues end-to-end, size balancing of multiple arrays, several multi-level partitionings of an array. Our queues are the first to enable executions of pop and push operations without any change of the data structure controlled by a parameter. This enables interesting applications in computing on encrypted data such as hiding confidential expressions. Mergesort becomes practical using our LIFO queue, ie. it improves prior work STOC  by a factor of more than  in terms of comparisons for all practically relevant queue sizes. We are the first to present double-ended priority and LIFO queues as well as oblivious quicksort which is asymptotically optimal. Aside from theortical analysis, we also provide an empirical evaluation of all queues.

Protecting source code against reverse engineering and theft is an important problem. The goal is to carry out computations using confidential algorithms on an untrusted party while ensuring confidentiality of algorithms. This problem has been addressed for Boolean circuits known as circuit privacy. Circuits corresponding to real-world programs are impractical. Well-known obfuscation techniques are highly practicable, but provide only limited security, e.g., no piracy protection. In this work, we modify source code yielding programs with adjustable performance and security guarantees ranging from indistinguishability obfuscators to non-secure ordinary obfuscation. The idea is to artificially generate misleading statements. Their results are combined with the outcome of a confidential statement using encrypted emphselector variables. Thus, an attacker must guess the encrypted selector variables to disguise the confidential source code. We evaluated our method using more than ten programmers as well as pattern mining across open source code repositories to gain insights of micro-coding patterns that are relevant for generating misleading statements. The evaluation reveals that our approach is effective in that it successfully preserves source code confidentiality.

The alternating direction method of multipliers ADMM is a common optimization tool for solving constrained and non-differentiable problems. We provide an empirical study of the practical performance of ADMM on several nonconvex applications, including l regularized linear regression, l regularized image denoising, phase retrieval, and eigenvector computation. Our experiments suggest that ADMM performs well on a broad class of non-convex problems. Moreover, recently proposed adaptive ADMM methods, which automatically tune penalty parameters as the method runs, can improve algorithm efficiency and solution quality compared to ADMM with a non-tuned penalty.

We propose an algorithm for the non-negative factorization of an occurrence tensor built from heterogeneous networks. We use l norm to model sparse errors over discrete values occurrences, and use decomposed factors to model the embedded groups of nodes. An efficient splitting method is developed to optimize the nonconvex and nonsmooth objective. We study both synthetic problems and a new dataset built from financial documents, resMBS.

Modeling an ontology is a hard and time-consuming task. Although methodologies are useful for ontologists to create good ontologies, they do not help with the task of evaluating the quality of the ontology to be reused. For these reasons, it is imperative to evaluate the quality of the ontology after constructing it or before reusing it. Few studies usually present only a set of criteria and questions, but no guidelines to evaluate the ontology. The effort to evaluate an ontology is very high as there is a huge dependence on the evaluators expertise to understand the criteria and questions in depth. Moreover, the evaluation is still very subjective. This study presents a novel methodology for ontology evaluation, taking into account three fundamental principles i it is based on the Goal, Question, Metric approach for empirical evaluation ii the goals of the methodologies are based on the roles of knowledge representations combined with specific evaluation criteria iii each ontology is evaluated according to the type of ontology. The methodology was empirically evaluated using different ontologists and ontologies of the same domain. The main contributions of this study are i defining a step-by-step approach to evaluate the quality of an ontology ii proposing an evaluation based on the roles of knowledge representations iii the explicit difference of the evaluation according to the type of the ontology iii a questionnaire to evaluate the ontologies iv a statistical model that automatically calculates the quality of the ontologies.

We analyze limited feedback in systems where a multiple-antenna transmitter sends signals to single-antenna receivers with finite-bit ADCs. If channel state information CSI is not available with high resolution at the transmitter and the precoding is not well designed, the inter-user interference is a big decoding challenge for receivers with low-resolution quantization. In this paper, we derive achievable rates with finite-bit ADCs and finite-bit CSI feedback. The performance loss compared to the case with perfect CSI is then analyzed. The results show that the number of bits per feedback should increase linearly with the ADC resolution to restrict the loss.

Molecular Communication MC is a communication strategy that uses molecules as carriers of information, and is widely used by biological cells. As an interdisciplinary topic, it has been studied by biologists, communication theorists and a growing number of information theorists. This paper aims to specifically bring MC to the attention of information theorists. To do this, we first highlight the unique mathematical challenges of studying the capacity of molecular channels. Addressing these problems require use of known, or development of new mathematical tools. Toward this goal, we review a subjective selection of the existing literature on information theoretic aspect of molecular communication. The emphasis here is on the mathematical techniques used, rather than on the setup or modeling of a specific paper. Finally, as an example, we propose a concrete information theoretic problem that was motivated by our study of molecular communication.

Images typically are represented as uniformly sampled data in the form of matrix of pixelsvoxels. Therefore, matrix multiply-and-accumulate MAC forms the core of most state-of-the-art image analysis algorithms. While digital implementation of MAC has generally been the preferred approach, high power consumption is an impediment to adopting it for medical image analysis. In this work, we present a time-domain signal processing architecture which performs MAC operations with bit accuracy while consuming X lower energy than digital implementation. The proposed architecture performs analog computation using mostly digital circuits and is suitable for scaled CMOS technologies. The proposed time-domain MAC architecture is expected to play a central role in empowering the advancement of various on-chip image analysis operations.

Understanding community structure in social media is critical due to its broad applications such as friend recommendations, link predictions and collaborative filtering. However, there is no widely accepted definition of community in literature. Existing work use structure related metrics such as modularity and function related metrics such as ground truth to measure the performance of community detection algorithms, while ignoring an important metric, size of the community.  suggests that the size of community with strong ties in social media should be limited to . As we discovered in this paper, the majority of the communities obtained by many popular community detection algorithms are either very small or very large. Too small communities dont have practical value and too large communities contain weak connections therefore not stable. In this paper, we compare various community detection algorithms considering the following metrics size of the communities, coverage of the communities, extended modularity, triangle participation ratio, and user interest in the same community. We also propose a simple clique based algorithm for community detection as a baseline for the comparison. Experimental results show that both our proposed algorithm and the well-accepted disjoint algorithm InfoMap perform well in all the metrics.

We introduce two information-theoretical invariants for the projective unitary group acting on a finite-dimensional complex Hilbert space PVM- and POVM-dynamical quantum entropies. They quantify the randomness of the successive quantum measurement results in the case where the evolution of the system between each two consecutive measurements is described by a given unitary operator. We study the class of chaotic unitaries, i.e., the ones of maximal entropy or, equivalently, such that they can be represented by suitably rescaled complex Hadamard matrices in some orthonormal bases. We provide necessary conditions for a unitary operator to be chaotic, which become also sufficient for qubits and qutrits. These conditions are expressed in terms of the relation between the trace and the determinant of the operator. We also compute the volume of the set of chaotic unitaries in dimensions two and three, and the average PVM-dynamical entropy over the unitary group in dimension two. We prove that this mean value behaves as the logarithm of the dimension of the Hilbert space, which implies that the probability that the dynamical entropy of a unitary is almost as large as possible approaches unity as the dimension tends to infinity.

Sparsity-constrained optimization is an important and challenging problem that has wide applicability in data mining, machine learning, and statistics. In this paper, we focus on sparsity-constrained optimization in cases where the cost function is a general nonlinear function and, in particular, the sparsity constraint is defined by a graph-structured sparsity model. Existing methods explore this problem in the context of sparse estimation in linear models. To the best of our knowledge, this is the first work to present an efficient approximation algorithm, namely, Graph-structured Matching Pursuit Graph-Mp, to optimize a general nonlinear function subject to graph-structured constraints. We prove that our algorithm enjoys the strong guarantees analogous to those designed for linear models in terms of convergence rate and approximation accuracy. As a case study, we specialize Graph-Mp to optimize a number of well-known graph scan statistic models for the connected subgraph detection task, and empirical evidence demonstrates that our general algorithm performs superior over state-of-the-art methods that are designed specifically for the task of connected subgraph detection.

Multiple instance learning MIL is a form of weakly supervised learning where training instances are arranged in sets, called bags, and a label is provided for the entire bag. This formulation is gaining interest because it naturally fits various problems and allows to leverage weakly labeled data. Consequently, it has been used in diverse application fields such as computer vision and document classification. However, learning from bags raises important challenges that are unique to MIL. This paper provides a comprehensive survey of the characteristics which define and differentiate the types of MIL problems. Until now, these problem characteristics have not been formally identified and described. As a result, the variations in performance of MIL algorithms from one data set to another are difficult to explain. In this paper, MIL problem characteristics are grouped into four broad categories the composition of the bags, the types of data distribution, the ambiguity of instance labels, and the task to be performed. Methods specialized to address each category are reviewed. Then, the extent to which these characteristics manifest themselves in key MIL application areas are described. Finally, experiments are conducted to compare the performance of  state-of-the-art MIL methods on selected problem characteristics. This paper provides insight on how the problem characteristics affect MIL algorithms, recommendations for future benchmarking and promising avenues for research.

In recent years governments have shown themselves willing to impose blackouts to shut off key communication infrastructure during times of civil strife, and to surveil citizen communications whenever possible. However, it is exactly during such strife that citizens need reliable and anonymous communications the most. In this paper, we present Rangzen, a system for anonymous broadcast messaging during network blackouts. Rangzen is distinctive in both aim and design. Our aim is to provide an anonymous, one-to-many messaging layer that requires only users smartphones and can withstand network-level attacks. Our design is a delay-tolerant mesh network which deprioritizes adversarial messages by means of a social graph while preserving user anonymity. We built a complete implementation that runs on Android smartphones, present benchmarks of its performance and battery usage, and present simulation results suggesting Rangzens efficacy at scale.

There is a trend to acquire high accuracy land-cover maps using multi-source classification methods, most of which are based on data fusion, especially pixel- or feature-level fusions. A probabilistic graphical model PGM approach is proposed in this research for  m resolution land-cover mapping with multi-temporal Landsat and MODerate Resolution Imaging Spectroradiometer MODIS data. Independent classifiers were applied to two single-date Landsat  scenes and the MODIS time-series data, respectively, for probability estimation. A PGM was created for each pixel in Landsat  data. Conditional probability distributions were computed based on data quality and reliability by using information selectively. Using the administrative territory of Beijing City Area- and a coastal region of Shandong province, China Area- as study areas, multiple land-cover maps were generated for comparison. Quantitative results show the effectiveness of the proposed method. Overall accuracies promoted from . maps acquired from single-temporal Landsat images to . output of the PGM for Area-. Improvements can also be seen when using MODIS data and only a single-temporal Landsat image as input overall accuracy . versus . for Area-, and . versus . for Area-. Information from MODIS data did not help much when the PGM was applied to cloud free regions of. One of the advantages of the proposed method is that it can be applied where multi-temporal data cannot be simply stacked as a multi-layered image.

Recently, there has been a considerable attention given to the motion detection problem due to the explosive growth of its application in video analysis and surveillance systems. While the previous approaches can produce good results, accurate detection of motion remains a challenging task due to the difficulties raised by illumination variations, occlusion, camouflage, burst physical motion, dynamic texture and environmental changes such as those on climate changes, sunlight changes during a day, etc. In this paper, we propose a novel per-pixel motion descriptor for both motion detection and dynamic texture segmentation which outperforms the current methods in the literature particularly in severe scenarios. The proposed descriptor is based on two complementary three-dimensional-discrete wavelet transform D-DWT and three-dimensional wavelet leader. In this approach, a feature vector is extracted for each pixel by applying a novel three dimensional wavelet-based motion descriptor. Then, the extracted features are clustered by the well-known k-means algorithm. The experimental results demonstrate the effectiveness of our proposed method compared to the other motion detection approaches from the literature.

In this paper, we present an improved version of recently proposed Quick Hypervolume algorithm for calculating exact hypervolume of the space dominated by a set of d-dimensional points. This value is often used as a quality indicator in multiobjective evolutionary algorithms and the efficiency of calculating this indicator is of crucial importance especially in the case of large set or many dimensional spaces. We use a similar divide and conquer scheme as in the original Quick Hypervolume algorithm, we modify, however, the way the problem is split into smaller sub-problems. Through both theoretical analysis and computational study we show that our approach improves computational complexity of the algorithm and running time of its implementation.

This paper presents an algorithm for the unsupervised learning of latent variable models from unlabeled sets of data. We base our technique on spectral decomposition, providing a technique that proves to be robust both in theory and in practice. We also describe how to use this algorithm to learn the parameters of two well known text mining models single topic model and Latent Dirichlet Allocation, providing in both cases an efficient technique to retrieve the parameters to feed the algorithm. We compare the results of our algorithm with those of existing algorithms on synthetic data, and we provide examples of applications to real world text corpora for both single topic model and LDA, obtaining meaningful results.

Spectral dimensionality reduction algorithms are widely used in numerous domains, including for recognition, segmentation, tracking and visualization. However, despite their popularity, these algorithms suffer from a major limitation known as the repeated Eigen-directions phenomenon. That is, many of the embedding coordinates they produce typically capture the same direction along the data manifold. This leads to redundant and inefficient representations that do not reveal the true intrinsic dimensionality of the data. In this paper, we propose a general method for avoiding redundancy in spectral algorithms. Our approach relies on replacing the orthogonality constraints underlying those methods by unpredictability constraints. Specifically, we require that each embedding coordinate be unpredictable in the statistical sense from all previous ones. We prove that these constraints necessarily prevent redundancy, and provide a simple technique to incorporate them into existing methods. As we illustrate on challenging high-dimensional scenarios, our approach produces significantly more informative and compact representations, which substantially improve visualization and classification tasks.

Background We describe an informatics framework for researchers and clinical investigators to efficiently perform parameter sensitivity analysis and auto-tuning for algorithms that segment and classify image features in a large dataset of high-resolution images. The computational cost of the sensitivity analysis process can be very high, because the process requires processing the input dataset several times to systematically evaluate how output varies when input parameters are varied. Thus, high performance computing techniques are required to quickly execute the sensitivity analysis process.   Results We carried out an empirical evaluation of the proposed method on high performance computing clusters with multi-core CPUs and co-processors GPUs and Intel Xeon Phis. Our results show that  the framework achieves excellent scalability and efficiency on a high performance computing cluster -- execution efficiency remained above  in all experiments  the parameter auto-tuning methods are able to converge by visiting only a small fraction . of the search space with limited impact to the algorithm output . on average.   Conclusions The sensitivity analysis framework provides a range of strategies for the efficient exploration of the parameter space, as well as multiple indexes to evaluate the effect of parameter modification to outputs or even correlation between parameters. Our work demonstrates the feasibility of performing sensitivity analyses, parameter studies, and auto-tuning with large datasets with the use of high-performance systems and techniques. The proposed technologies will enable the quantification of error estimations and output variations in these pipelines, which may be used in application specific ways to assess uncertainty of conclusions extracted from data generated by these image analysis pipelines.

The introduction of graph theory in neuroimaging has pro- vided invaluable tools for the study of brain connectivity. These methods require the definition of a graph, which is typically derived by estimating the effective connectivity between brain regions through the optimization of an ill-posed inverse problem. Considerable efforts have been devoted to the development of methods extracting sparse connectivity graphs. The present paper aims at highlighting the benefits of an alternative ap- proach. We investigate low-rank L regularized matrices recently intro- duced under the denomination of Riccati regularized precision matrices. We demonstrate their benefits for the analysis of cortical thickness map and for the extraction of functional biomarkers from resting state fMRI scans. In addition, we explain how speed and result quality can be further improved with random projections. The promising results obtained using the Human Connectome Project dataset as well as the numerous possi- ble extensions and applications suggest that Riccati precision matrices might usefully complement current sparse approaches.

Consensus formation is investigated for multi-agent systems in which agents beliefs are both vague and uncertain. Vagueness is represented by a third truth state meaning emphborderline. This is combined with a probabilistic model of uncertainty. A belief combination operator is then proposed which exploits borderline truth values to enable agents with conflicting beliefs to reach a compromise. A number of simulation experiments are carried out in which agents apply this operator in pairwise interactions, under the bounded confidence restriction that the two agents beliefs must be sufficiently consistent with each other before agreement can be reached. As well as studying the consensus operator in isolation we also investigate scenarios in which agents are influenced either directly or indirectly by the state of the world. For the former we conduct simulations which combine consensus formation with belief updating based on evidence. For the latter we investigate the effect of assuming that the closer an agents beliefs are to the truth the more visible they are in the consensus building process. In all cases applying the consensus operators results in the population converging to a single shared belief which is both crisp and certain. Furthermore, simulations which combine consensus formation with evidential updating converge faster to a shared opinion which is closer to the actual state of the world than those in which beliefs are only changed as a result of directly receiving new evidence. Finally, if agent interactions are guided by belief quality measured as similarity to the true state of the world, then applying the consensus operator alone results in the population converging to a high quality shared belief.

Stochastic gradient descentSGD and its variants have attracted much attention in machine learning due to their efficiency and effectiveness for optimization. To handle large-scale problems, researchers have recently proposed several lock-free strategy based parallel SGDLF-PSGD methods for multi-core systems. However, existing works have only proved the convergence of these LF-PSGD methods for convex problems. To the best of our knowledge, no work has proved the convergence of the LF-PSGD methods for non-convex problems. In this paper, we provide the theoretical proof about the convergence of two representative LF-PSGD methods, Hogwild! and AsySVRG, for non-convex problems. Empirical results also show that both Hogwild! and AsySVRG are convergent on non-convex problems, which successfully verifies our theoretical results.

Carrier Sense Multiple Access CSMA MAC protocols are known to suffer from the hidden station HS problem. The complete mathematical analysis of CSMA networks with HSs is still an open problem, even for broadcast communication with a simple linear network topology. In this paper we address this challenge by introducing a MAC layer modeling methodology based on time- and space-domain Markov processes. Using this methodology we derive the closed-form solution for the steady-state performance in infinite one-dimensional -D CSMA networks with HSs. The analytical results are validated by simulation and establish that  under the assumption of fixed frame duration, if the conditional channel access probability at each station exceeds a certain threshold, the CSMA system enters the status of synchronized transmissions, where a large number of adjacent stations transmit in overlap and interfere each other resulting in null system goodput.  The maximum system goodput of CSMA broadcast communication increases with increased station density but becomes increasingly sensitive to the conditional channel access probability. In  we validate the analytical results gained in this paper by simulation of a multi-lane highway scenario, and provide quantitative guidance for congestion control algorithms in vehicular networks.

The Decentralized Congestion Control DCC algorithms specified in ETSI ITS standards  address the IEEE .p MAC and provide reliability of periodic broadcast messages at high density of vehicles. However, the deterministic relation between controllable parameters, e.g. transmit power, frame duration, frame transmit rate and channel clear assessment threshold, and the effects of DCC algorithms, e.g. channel busy duration, frame interference-free reception probability and frame channel access delay, is still unknown since a correct mathematical analysis of the hidden station problem in CSMA networks is lacking. In this work, the hidden station problem in a linear IEEE .p broadcast network is analyzed based on analytical results developed in  employing a modified MAC protocol model based on . Simulation results validate the new analytical model for linear IEEE .p networks w.r.t reliability and latency performances of Cooperative Awareness Message broadcast. Evidence is given that the model not only is valid for single-lane highways but also provides good approximate results for multi-lane highway scenarios. Our MAC layer analytical model of IEEE .p broadcast reveals the quantitative relation between DCC parameters and congestion control effects in closed-form solution for linear vehicular networks.

Sparsity-based subspace clustering algorithms have attracted significant attention thanks to their excellent performance in practical applications. A prominent example is the sparse subspace clustering SSC algorithm by Elhamifar and Vidal, which performs spectral clustering based on an adjacency matrix obtained by sparsely representing each data point in terms of all the other data points via the Lasso. When the number of data points is large or the dimension of the ambient space is high, the computational complexity of SSC quickly becomes prohibitive. Dyer et al. observed that SSC-OMP obtained by replacing the Lasso by the greedy orthogonal matching pursuit OMP algorithm results in significantly lower computational complexity, while often yielding comparable performance. The central goal of this paper is an analytical performance characterization of SSC-OMP for noisy data. Moreover, we introduce and analyze the SSC-MP algorithm, which employs matching pursuit MP in lieu of OMP. Both SSC-OMP and SSC-MP are proven to succeed even when the subspaces intersect and when the data points are contaminated by severe noise. The clustering conditions we obtain for SSC-OMP and SSC-MP are similar to those for SSC and for the thresholding-based subspace clustering TSC algorithm due to Heckel and Bolcskei. Analytical results in combination with numerical results indicate that both SSC-OMP and SSC-MP with a data-dependent stopping criterion automatically detect the dimensions of the subspaces underlying the data. Moreover, experiments on synthetic and real data show that SSC-MP compares very favorably to SSC, SSC-OMP, TSC, and the nearest subspace neighbor NSN algorithm, both in terms of clustering performance and running time. In addition, we find that, in contrast to SSC-OMP, the performance of SSC-MP is very robust with respect to the choice of parameters in the stopping criteria.

The explosive wireless data service requirement accompanied with carbon dioxide emission and consumption of traditional energy has put pressure on both industry and academia. Wireless networks powered with the uneven and intermittent generated renewable energy have been widely researched and lead to a new research paradigm called green communication. In this paper, we comprehensively consider the total generated renewable energy, QoS requirement and channel quality, then propose a utility based renewable energy allocation policy. The utility here means the satisfaction degree of users with a certain amount allocated renewable energy. The energy allocation problem is formulated as a constraint optimization problem and a heuristic algorithm with low complexity is derived to solve the raised problem. Numerical results show that the renewable energy allocation policy is applicable for any situation. When the renewable energy is very scarce, only users with good channel quality can achieve allocated energy.

We consider rate-distortion with two decoders, each with distinct side information. This problem is well understood when the side information at the decoders satisfies a certain degradedness condition. We consider cases in which this degradedness condition is violated but the source and the side information consist of jointly Gaussian vectors. We provide a hierarchy of four lower bounds on the optimal rate. These bounds are then used to determine the optimal rate for several classes of instances.

We study discrete logarithms in the setting of group actions. Suppose that G is a group that acts on a set S. When r,s in S, a solution g in G to rg  s can be thought of as a kind of logarithm. In this paper, we study the case where G  Sn, and develop analogs to the Shanks baby-step  giant-step procedure for ordinary discrete logarithms. Specifically, we compute two sets A, B subseteq Sn such that every permutation of Sn can be written as a product ab of elements a in A and b in B. Our deterministic procedure is optimal up to constant factors, in the sense that A and B can be computed in optimal asymptotic complexity, and A and B are a small constant from sqrtn! in size. We also analyze randomized collision algorithms for the same problem.

Consus is a strictly serializable geo-replicated transactional key-value store. The key contribution of Consus is a new commit protocol that reduces the cost of executing a transaction to three wide area message delays in the common case. Augmenting the commit protocol are multiple Paxos implementations optimized for different purposes. Together the different implementations and optimizations comprise a cohesive system that provides low latency, high availability, and strong guarantees. This paper describes the techniques implemented in the open source release of Consus, and lays the groundwork for evaluating Consus once the system implementation is sufficiently robust for a thorough evaluation.

We extend the notion of mathcalA-discriminant, and Kapranovs parametrization of mathcalA-discriminant varieties, to complex exponents. As an application, we focus on the special case where mathcalA is a set of n points in mathbbRn with non-defective Gale dual, g is a real n-variate exponential sum with spectrum mathcalA and sign vector s, and prove the following For fixed A and s, the number of possible isotopy types for the real zero set of g is On. We are unaware of any earlier such upper bound, except for an On bound when all the points of mathcalA lie in mathbbZn.

We consider a rate-distortion problem with side information at multiple decoders. Several upper and lower bounds have been proposed for this general problem or special cases of it. We provide an upper bound for general instances of this problem, which takes the form of a linear program, by utilizing random binning and simultaneous decoding techniques and compare it with the existing bounds. We also provide a lower bound for the general problem, which was inspired by a linear-programming lower bound for index coding, and show that it subsumes most of the lower bounds in literature. Using these upper and lower bounds, we explicitly characterize the rate-distortion function of a problem that can be seen as a Gaussian analogue of the odd-cycle index coding problem.

Two multiplierless pruned -point discrete cosine transform DCT approximation are presented. Both transforms present lower arithmetic complexity than state-of-the-art methods. The performance of such new methods was assessed in the image compression context. A JPEG-like simulation was performed, demonstrating the adequateness and competitiveness of the introduced methods. Digital VLSI implementation in CMOS technology was also considered. Both presented methods were realized in Berkeley Emulation Engine BEE.

The importance of peer influence on consumer actions plays a vital role in marketing efforts. However, peer influence effects are often confounded with latent homophily, which are unobserved commonalities that drive friendship. Understanding causality has become one of the pressing issues of current research. We present an approach to explicitly account for various causal influences. We implement a simulation framework to show the effectiveness of two latent homophily proxies, latent coordinates and community membership, in improving peer influence effect estimates on game downloads in a Japanese social network website. We demonstrate that latent homophily proxies have no significant improvement in peer influence effect bias in the available website data.

Reinforcement learning RL depends critically on the choice of reward functions used to capture the de- sired behavior and constraints of a robot. Usually, these are handcrafted by a expert designer and represent heuristics for relatively simple tasks. Real world applications typically involve more complex tasks with rich temporal and logical structure. In this paper we take advantage of the expressive power of temporal logic TL to specify complex rules the robot should follow, and incorporate domain knowledge into learning. We propose Truncated Linear Temporal Logic TLTL as specifications language, that is arguably well suited for the robotics applications, together with quantitative semantics, i.e., robustness degree. We propose a RL approach to learn tasks expressed as TLTL formulae that uses their associated robustness degree as reward functions, instead of the manually crafted heuristics trying to capture the same specifications. We show in simulated trials that learning is faster and policies obtained using the proposed approach outperform the ones learned using heuristic rewards in terms of the robustness degree, i.e., how well the tasks are satisfied. Furthermore, we demonstrate the proposed RL approach in a toast-placing task learned by a Baxter robot.

Secure spontaneous authentication between devices worn at arbitrary location on the same body is a challenging, yet unsolved problem. We propose BANDANA, the first-ever implicit secure device-to-device authentication scheme for devices worn on the same body. Our approach leverages instantaneous variation in acceleration patterns from gait sequences to extract always-fresh secure secrets. It enables secure spontaneous pairing of devices worn on the same body or interacted with. The method is robust against noise in sensor readings and active attackers. We demonstrate the robustness of BANDANA on two gait datasets and discuss the discriminability of intra- and inter-body cases, robustness to statistical bias, as well as possible attack scenarios.

Ground penetrating radar GPR is one of the most popular and successful sensing modalities that has been investigated for landmine and subsurface threat detection. Many of the detection algorithms applied to this task are supervised and therefore require labeled examples of target and non-target data for training. Training data most often consists of -dimensional images or patches of GPR data, from which features are extracted, and provided to the classifier during training and testing. Identifying desirable training and testing locations to extract patches, which we term keypoints, is well established in the literature. In contrast however, a large variety of strategies have been proposed regarding keypoint utilization e.g., how many of the identified keypoints should be used at targets, or non-target, locations. Given the variety keypoint utilization strategies that are available, it is very unclear i which strategies are best, or ii whether the choice of strategy has a large impact on classifier performance. We address these questions by presenting a taxonomy of existing utilization strategies, and then evaluating their effectiveness on a large dataset using many different classifiers and features. We analyze the results and propose a new strategy, called PatchSelect, which outperforms other strategies across all experiments.

Recently, a novel family of biologically plausible online algorithms for reducing the dimensionality of streaming data has been derived from the similarity matching principle. In these algorithms, the number of output dimensions can be determined adaptively by thresholding the singular values of the input data matrix. However, setting such threshold requires knowing the magnitude of the desired singular values in advance. Here we propose online algorithms where the threshold is self-calibrating based on the singular values computed from the existing observations. To derive these algorithms from the similarity matching cost function we propose novel regularizers. As before, these online algorithms can be implemented by Hebbiananti-Hebbian neural networks in which the learning rule depends on the chosen regularizer. We demonstrate both mathematically and via simulation the effectiveness of these online algorithms in various settings.

Several theories of early sensory processing suggest that it whitens sensory stimuli. Here, we test three key predictions of the whitening theory using recordings from  ganglion cells in salamander retina responding to natural movies. We confirm the previous finding that firing rates of ganglion cells are less correlated compared to natural scenes, although significant correlations remain. We show that while the power spectrum of ganglion cells decays less steeply than that of natural scenes, it is not completely flattened. Finally, we find evidence that only the top principal components of the visual stimulus are transmitted.

Domain-specific languages are becoming increasingly important. Almost every application touches multiple domains. But how to define, use, and combine multiple DSLs within the same application?   The most common approach is to split the project along the domain boundaries into multiple pieces and files. Each file is then compiled separately. Alternatively, multiple languages can be embedded in a flexible host language within the same syntax a new domain semantic is provided. In this paper we follow a less explored route of metamorphic languages. These languages are able to modify their own syntax and semantics on the fly, thus becoming a more flexible host for DSLs.   Our language allows for dynamic creation of grammars and switching languages where needed. We achieve this through a novel concept of Syntax-Directed Execution. A language grammar includes semantic actions that are pieces of functional code executed immediately during parsing. By avoiding additional intermediate representation, connecting actions from different languages and domains is greatly simplified. Still, actions can generate highly specialized code though lambda encapsulation and Dynamic Staging.

We provide a brief technical description of an online platform for disease monitoring, titled as the Flu Detector fludetector.cs.ucl.ac.uk. Flu Detector, in its current version v.., uses either Twitter or Google search data in conjunction with statistical Natural Language Processing models to estimate the rate of influenza-like illness in the population of England. Its back-end is a live service that collects online data, utilises modern technologies for large-scale text processing, and finally applies statistical inference models that are trained offline. The front-end visualises the various disease rate estimates. Notably, the models based on Google data achieve a high level of accuracy with respect to the most recent four flu seasons in England  to . This highlighted Flu Detector as having a great potential of becoming a complementary source to the domestic traditional flu surveillance schemes.

A cost effective approach to remote monitoring of protected areas such as marine reserves and restricted naval waters is to use passive sonar to detect, classify, localize, and track marine vessel activity including small boats and autonomous underwater vehicles. Cepstral analysis of underwater acoustic data enables the time delay between the direct path arrival and the first multipath arrival to be measured, which in turn enables estimation of the instantaneous range of the source a small boat. However, this conventional method is limited to ranges where the Lloyds mirror effect interference pattern formed between the direct and first multipath arrivals is discernible. This paper proposes the use of convolutional neural networks CNNs for the joint detection and ranging of broadband acoustic noise sources such as marine vessels in conjunction with a data augmentation approach for improving network performance in varied signal-to-noise ratio SNR situations. Performance is compared with a conventional passive sonar ranging method for monitoring marine vessel activity using real data from a single hydrophone mounted above the sea floor. It is shown that CNNs operating on cepstrum data are able to detect the presence and estimate the range of transiting vessels at greater distances than the conventional method.

In this paper, we present a novel method of no-reference image quality assessment NR-IQA, which is to predict the perceptual quality score of a given image without using any reference image. The proposed method harnesses three functions i the visual attention mechanism, which affects many aspects of visual perception including image quality assessment, however, is overlooked in the NR-IQA literature. The method assumes that the fixation areas on an image contain key information to the process of IQA. ii the robust averaging strategy, which is a means --- supported by psychology studies --- to integrating multiplestep-wise evidence to make a final perceptual judgment. iii the multi-task learning, which is believed to be an effectual means to shape representation learning and could result in a more generalized model.   To exploit the synergy of the three, we consider the NR-IQA as a dynamic perception process, in which the model samples a sequence of informative areas and aggregates the information to learn a representation for the tasks of jointly predicting the image quality score and the distortion type.   The model learning is implemented by a reinforcement strategy, in which the rewards of both tasks guide the learning of the optimal sampling policy to acquire the task-informative image regions so that the predictions can be made accurately and efficiently in terms of the sampling steps. The reinforcement learning is realized by a deep network with the policy gradient method and trained through back-propagation.   In experiments, the model is tested on the TID dataset and it outperforms several state-of-the-art methods. Furthermore, the model is very efficient in the sense that a small number of fixations are used in NR-IQA.

There are two key issues for the kernel-based regularization method one is how to design a suitable kernel to embed in the kernel the prior knowledge of the LTI system to be identified, and the other one is how to tune the kernel such that the resulting regularized impulse response estimator can achieve a good bias-variance tradeoff. In this paper, we focus on the issue of kernel design. Depending on the type of the prior knowledge, we propose two methods to design kernels one is from a machine learning perspective and the other one is from a system theory perspective. We also provide analysis results for both methods, which not only enhances our understanding for the existing kernels but also directs the design of new kernels.

We discovered novel Anderson localization behaviors of pseudospin systems in a D disordered potential. For a pseudospin- system, due to the absence of backscattering under normal incidence and the presence of a conical band structure, the wave localization behaviors are entirely different from those of normal disordered systems. We show both numerically and analytically that there exists a critical strength of random potential Wc, which is equal to the incident energy E, below which the localization length xi decreases with the random strength W for a fixed incident angle theta. But the localization length drops abruptly to a minimum at WWc and rises immediately afterwards, which has never been observed in ordinary materials. The incidence angle dependence of the localization length has different asymptotic behaviors in two regions of random strength, with xi propto sin-theta when WWc and xi propto sin-theta when WWc. Experimentally, for a given disordered sample with a fixed randomness strength W, the incident wave with incident energy E will experience two different types of localization, depending on whether EW or EW. The existence of a sharp transition at EW is due to the emergence of evanescent waves in the systems when EW. Such localization behavior is unique to pseudospin- systems. For pseudospin- systems, there is a minimum localization length as randomness increases, but the transition from decreasing to increasing localization length at the minimum is smooth rather than abrupt. In both decreasing and increasing regions, the theta -dependence of the localization length has the same asymptotic behavior xi propto sin-theta.

We consider the problem of phase retrieval from corrupted magnitude observations. In particular we show that a fixed x in mathbbRn can be recovered exactly from corrupted magnitude measurements langle ai, x rangle   etai, quad i ,ldots m with high probability for m  On, where ai in mathbbRn are i.i.d standard Gaussian and eta in mathbbRm has fixed sparse support and is otherwise arbitrary, by using a version of the PhaseMax algorithm augmented with slack variables subject to a penalty. This linear programming formulation, which we call RobustPhaseMax, operates in the natural parameter space, and our proofs rely on a direct analysis of the optimality conditions using concentration inequalities.

Positive instance detection, especially for these in positive bags true positive instances, TPIs, plays a key role for multiple instance learning MIL arising from a specific classification problem only provided with bag a set of instances label information. However, most previous MIL methods on this issue ignore the global similarity among positive instances and that negative instances are non-i.i.d., usually resulting in the detection of TPI not precise and sensitive to outliers. To the end, we propose a positive instance detection via graph updating for multiple instance learning, called PIGMIL, to detect TPI accurately. PIGMIL selects instances from working sets WSs of some working bags WBs as positive candidate pool PCP. The global similarity among positive instances and the robust discrimination of instances of PCP from negative instances are measured to construct the consistent similarity and discrimination graph CSDG. As a result, the primary goal i.e. TPI detection is transformed into PCP updating, which is approximated efficiently by updating CSDG with a random walk ranking algorithm and an instance updating strategy. At last bags are transformed into feature representation vector based on the identified TPIs to train a classifier. Extensive experiments demonstrate the high precision of PIGMILs detection of TPIs and its excellent performance compared to classic baseline MIL methods.

This paper introduces a novel neural network model for question answering, the emphentity-based memory network. It enhances neural networks ability of representing and calculating information over a long period by keeping records of entities contained in text. The core component is a memory pool which comprises entities states. These entities states are continuously updated according to the input text. Questions with regard to the input text are used to search the memory pool for related entities and answers are further predicted based on the states of retrieved entities. Compared with previous memory network models, the proposed model is capable of handling fine-grained information and more sophisticated relations based on entities. We formulated several different tasks as question answering problems and tested the proposed model. Experiments reported satisfying results.

Visual attention plays an important role to understand images and demonstrates its effectiveness in generating natural language descriptions of images. On the other hand, recent studies show that language associated with an image can steer visual attention in the scene during our cognitive process. Inspired by this, we introduce a text-guided attention model for image captioning, which learns to drive visual attention using associated captions. For this model, we propose an exemplar-based learning approach that retrieves from training data associated captions with each image, and use them to learn attention on visual features. Our attention model enables to describe a detailed state of scenes by distinguishing small or confusable objects effectively. We validate our model on MS-COCO Captioning benchmark and achieve the state-of-the-art performance in standard metrics.

In this paper, we investigate PN-sequences with ideal autocorrelation property and the consequences of this property on the number of s and -s and run structure of sequences. We begin by discussing and surveying about the length of PNsequences with ideal autocorrelation property. From our discussion and survey we introduce circulant matrix representation of PN-sequence. Through circulant matrix representation we obtain system of non-linear equations that lead to ideal autocorrelation property. Rewriting PN-sequence and its autocorrelation property in , leads to a definition based on Hamming weight and Hamming distance and hence we can easily prove some results on the PN-sequences with ideal autocorrelation property.

Systematic literature studies have received much attention in empirical software engineering in recent years. They have become a powerful tool to collect and structure reported knowledge in a systematic and reproducible way. We distinguish systematic literature reviews to systematically analyze reported evidence in depth, and systematic mapping studies to structure a field of interest in a broader, usually quantified manner. Due to the rapidly increasing body of knowledge in software engineering, researchers who want to capture the published work in a domain often face an extensive amount of publications, which need to be screened, rated for relevance, classified, and eventually analyzed. Although there are several guidelines to conduct literature studies, they do not yet help researchers coping with the specific difficulties encountered in the practical application of these guidelines. In this article, we present an experience-based guideline to aid researchers in designing systematic literature studies with special emphasis on the data collection and selection procedures. Our guideline aims at providing a blueprint for a practical and pragmatic path through the plethora of currently available practices and deliverables capturing the dependencies among the single steps. The guideline emerges from various mapping studies and literature reviews conducted by the authors and provides recommendations for the general study design, data collection, and study selection procedures. Finally, we share our experiences and lessons learned in applying the different practices of the proposed guideline.

Cadieu et al. Cadieu, reported that deep neural networksDNNs could rival the representation of primate inferotemporal cortex for object recognition. Lehky et al. Lehky, provided a statistical analysis on neural responses to object stimuli in primate AIT cortex. They found the intrinsic dimensionality of object representations in AIT cortex is around  Lehky,. Considering the outstanding performance of DNNs in object recognition, it is worthwhile investigating whether the responses of DNN neurons have similar response statistics to those of AIT neurons. Following Lehky et al.s works, we analyze the response statistics to image stimuli and the intrinsic dimensionality of object representations of DNN neurons. Our findings show in terms of kurtosis and Pareto tail index, the response statistics on single-neuron selectivity and population sparseness of DNN neurons are fundamentally different from those of IT neurons except some special cases. By increasing the number of neurons and stimuli, the conclusions could alter substantially. In addition, with the ascendancy of the convolutional layers of DNNs, the single-neuron selectivity and population sparseness of DNN neurons increase, indicating the last convolutional layer is to learn features for object representations, while the following fully-connected layers are to learn categorization features. It is also found that a sufficiently large number of stimuli and neurons are necessary for obtaining a stable dimensionality. To our knowledge, this is the first work to analyze the response statistics of DNN neurons comparing with AIT neurons, and our results provide not only some insights into the discrepancy of DNN neurons with respect to IT neurons in object representation, but also shed some light on possible outcomes of IT neurons when the number of recorded neurons and stimuli is beyond the level in Lehky,,.

Recent research has shown that the performance of search personalization depends on the richness of user profiles which normally represent the users topical interests. In this paper, we propose a new embedding approach to learning user profiles, where users are embedded on a topical interest space. We then directly utilize the user profiles for search personalization. Experiments on query logs from a major commercial web search engine demonstrate that our embedding approach improves the performance of the search engine and also achieves better search performance than other strong baselines.

Ordered polarity alignment of a cell population plays a vital role in biology, such as in hair follicle alignment and asymmetric cell division. Here, we propose a theoretical framework for the understanding of generic dynamical properties of polarity alignment in interacting cellular units, where each cell is described by a reaction-diffusion system and the cells further interact with one another through their proximal surfaces. The system behavior is shown to be strongly dependent on geometric properties such as cell alignment and cell shape. Using a perturbative method under the assumption of weak coupling between cells, we derive a reduced model in which each cell is described by just one variable, the phase. The reduced model resembles an XY model but contains novel terms that possesses geometric information, which enables the understanding of the geometric dependencies as well as the effects of external signal and noise. The model is simple, generic, and analytically and numerically tractable, and is therefore expected to facilitates studies on cellular polarity alignment in various nonequilibrium systems.

In the trace reconstruction problem, an unknown bit string x in ,n is observed through the deletion channel, which deletes each bit of x with some constant probability q, yielding a contracted string widetildex. How many independent copies of widetildex are needed to reconstruct x with high probability? Prior to this work, the best upper bound, due to Holenstein, Mitzenmacher, Panigrahy, and Wieder , was expwidetildeOn. We improve this bound to expOn using statistics of individual bits in the output and show that this bound is sharp in the restricted model where this is the only information used. Our method, that uses elementary complex analysis, can also handle insertions.

An out-branching and an in-branching of a digraph D are called k-distinct if each of them has k arcs absent in the other. Bang-Jensen, Saurabh and Simonsen  proved that the problem of deciding whether a strongly connected digraph D has k-distinct out-branching and in-branching is fixed-parameter tractable FPT when parameterized by k. They asked whether the problem remain FPT when extended to arbitrary digraphs. Bang-Jensen and Yeo  asked whether the same problem is FPT when the out-branching and in-branching have the same root. By linking the two problems with the problem of whether a digraph has an out-branching with at least k leaves a leaf is a vertex of out-degree zero, we first solve the problem of Bang-Jensen and Yeo . We then develop a new digraph decomposition called the rooted cut decomposition and using it we prove that the problem of Bang-Jensen et al.  is FPT for all digraphs. We believe that the emphrooted cut decomposition will be useful for obtaining other results on digraphs.

Graph-based methods pervade the inference toolkits of numerous disciplines including sociology, biology, neuroscience, physics, chemistry, and engineering. A challenging problem encountered in this context pertains to determining the attributes of a set of vertices given those of another subset at possibly different time instants. Leveraging spatiotemporal dynamics can drastically reduce the number of observed vertices, and hence the cost of sampling. Alleviating the limited flexibility of existing approaches, the present paper broadens the existing kernel-based graph function reconstruction framework to accommodate time-evolving functions over possibly time-evolving topologies. This approach inherits the versatility and generality of kernel-based methods, for which no knowledge on distributions or second-order statistics is required. Systematic guidelines are provided to construct two families of space-time kernels with complementary strengths. The first facilitates judicious control of regularization on a space-time frequency plane, whereas the second can afford time-varying topologies. Batch and online estimators are also put forth, and a novel kernel Kalman filter is developed to obtain these estimates at affordable computational cost. Numerical tests with real data sets corroborate the merits of the proposed methods relative to competing alternatives.

One of the first steps to perform most of the software maintenance activities, such as updating features or fixing bugs, is to have a relatively good understanding of the programs source code which is often written by other developers. A code summary is a description about a programs entities e.g., its methods which helps developers have a better comprehension of the code in a shorter period of time. However, generating code summaries can be a challenging task. To mitigate this problem, in this article, we introduce CrowdSummarizer, a code summarization platform that benefits from the concepts of crowdsourcing, gamification, and natural language processing to automatically generate a high level summary for the methods of a Java program. We have implemented CrowdSummarizer as an Eclipse plugin together with a web-based code summarization game that can be played by the crowd. The results of two empirical studies that evaluate the applicability of the approach and the quality of generated summaries indicate that CrowdSummarizer is effective in generating quality results.

In this paper, we address the problem of visual question answering by proposing a novel model, called VIBIKNet. Our model is based on integrating Kernelized Convolutional Neural Networks and Long-Short Term Memory units to generate an answer given a question about an image. We prove that VIBIKNet is an optimal trade-off between accuracy and computational load, in terms of memory and time consumption. We validate our method on the VQA challenge dataset and compare it to the top performing methods in order to illustrate its performance and speed.

In this paper, we develop a binary convolutional encoder-decoder network B-CEDNet for natural scene text processing NSTP. It converts a text image to a class-distinguished salience map that reveals the categorical, spatial and morphological information of characters. The existing solutions are either memory consuming or run-time consuming that cannot be applied to real-time applications on resource-constrained devices such as advanced driver assistance systems. The developed network can process multiple regions containing characters by one-off forward operation, and is trained to have binary weights and binary feature maps, which lead to both remarkable inference run-time speedup and memory usage reduction. By training with over ,  synthesis scene text images size of times, it can achieve  and  pixel-wise accuracy on ICDAR- and ICDAR- datasets. It only consumes . ms inference run-time realized on GPU with a small network size of . MB, which is up to times faster and  smaller than it full-precision version.

We consider several classes of intersection graphs of line segments in the plane and prove new equality and separation results between those classes. In particular, we show that  intersection graphs of grounded segments and intersection graphs of downward rays form the same graph class,  not every intersection graph of rays is an intersection graph of downward rays, and  not every intersection graph of rays is an outer segment graph. The first result answers an open problem posed by Cabello and Jejvcivc. The third result confirms a conjecture by Cabello. We thereby completely elucidate the remaining open questions on the containment relations between these classes of segment graphs. We further characterize the complexity of the recognition problems for the classes of outer segment, grounded segment, and ray intersection graphs. We prove that these recognition problems are complete for the existential theory of the reals. This holds even if a -string realization is given as additional input.

Social graphs, representing online friendships among users, are one of the fundamental types of data for many applications, such as recommendation, virality prediction and marketing in social media. However, this data may be unavailable due to the privacy concerns of users, or kept private by social network operators, which makes such applications difficult. Inferring user interests and discovering user connections through their shared multimedia content has attracted more and more attention in recent years. This paper proposes a Gaussian relational topic model for connection discovery using user shared images in social media. The proposed model not only models user interests as latent variables through their shared images, but also considers the connections between users as a result of their shared images. It explicitly relates user shared images to user connections in a hierarchical, systematic and supervisory way and provides an end-to-end solution for the problem. This paper also derives efficient variational inference and learning algorithms for the posterior of the latent variables and model parameters. It is demonstrated through experiments with over k images from Flickr that the proposed method significantly outperforms the methods in previous works.

The P speller is a well known Brain-Computer Interface paradigm that has been used for over two decades. A new P speller paradigm XP is proposed. It includes several characteristics i the items are not intensified by using rows and columns, ii the order of the visual stimuli is pseudo-random, iii a visual feedback is added on each item to increase the stimulus meaning, which is the main novelty. XP has been tested on ten healthy subjects on copy spelling mode, with only eight sensors. It has been compared with the classical P paradigm CP. With five repetitions, the average recognition rate across subjects is . for XP and . for CP. Single-trial detection is significantly higher with XP by comparing the AUC Area Under Curve of the ROC Receiver Operating Characteristic curve. The mean AUC is . for XP, . for CP. More importantly, XP has also been judged as more convenient and user-friendly than CP, hence being able to allow longer sessions.

Research into cybercrime often points to concentrations of abuse at certain hosting providers. The implication is that these providers are worse in terms of security some are considered bad or even bullet proof. Remarkably little work exists on systematically comparing the security performance of providers. Existing metrics typically count instances of abuse and sometimes normalize these counts by taking into account the advertised address space of the provider. None of these attempts have worked through the serious methodological challenges that plague metric design. In this paper we present a systematic approach for metrics development and identify the main challenges i identification of providers, ii abuse data coverage and quality, iii normalization, iv aggregation and v metric interpretation. We describe a pragmatic approach to deal with these challenges. In the process, we answer an urgent question posed to us by the Dutch police which are the worst providers in our jurisdiction?. Notwithstanding their limitations, there is a clear need for security metrics for hosting providers in the fight against cybercrime.

A comparison of three different experimental datasets leads to the identification of an apparently robust feature of free-recall data a minimum in the rate of contiguous recall near the beginning of the recall process. By simulating verbal retrieval as a homogenous Markov chain with the experimentally observed transition matrix, I show that this behavior cannot be explained in terms of the nonequilibrium initial conditions. I deduce that the process, if markovian, is inhomogenous and I identify a psychological mechanism that would effectively lead to a time-dependent transition matrix. The theory is based on the simultaneous coexistence of competing random walks, all of them homogenous but liable to losing permanently the right to effect retrieval. To test this hypothesis, I construct a many-particle model governed by two free parameters and simulate it with initial conditions taken from the data. Besides reproducing the contiguous-recall curve, the theory leads to a counterintuitive prediction on the behavior of the inter-response intervals as a function of the serial-position lag. Data are found to confirm this prediction. I proceed then to investigate possible consequences of the model, drawing in part on a comparison with classical results from experiments on category recall.

We consider the problem of producing compact architectures for text classification, such that the full model fits in a limited amount of memory. After considering different solutions inspired by the hashing literature, we propose a method built upon product quantization to store word embeddings. While the original technique leads to a loss in accuracy, we adapt this method to circumvent quantization artefacts. Our experiments carried out on several benchmarks show that our approach typically requires two orders of magnitude less memory than fastText while being only slightly inferior with respect to accuracy. As a result, it outperforms the state of the art by a good margin in terms of the compromise between memory usage and accuracy.

We propose an inverse reinforcement learning IRL approach using Deep Q-Networks to extract the rewards in problems with large state spaces. We evaluate the performance of this approach in a simulation-based autonomous driving scenario. Our results resemble the intuitive relation between the reward function and readings of distance sensors mounted at different poses on the car. We also show that, after a few learning rounds, our simulated agent generates collision-free motions and performs human-like lane change behaviour.

We investigate what distinguishes reported dreams from other personal narratives. The continuity hypothesis, stemming from psychological dream analysis work, states that most dreams refer to a persons daily life and personal concerns, similar to other personal narratives such as diary entries. Differences between the two texts may reveal the linguistic markers of dream text, which could be the basis for new dream analysis work and for the automatic detection of dream descriptions. We used three text analytics methods text classification, topic modeling, and text coherence analysis, and applied these methods to a balanced set of texts representing dreams, diary entries, and other personal stories. We observed that dream texts could be distinguished from other personal narratives nearly perfectly, mostly based on the presence of uncertainty markers and descriptions of scenes. Important markers for non-dream narratives are specific time expressions and conversational expressions. Dream texts also exhibit a lower discourse coherence than other personal narratives.

Top-k error is currently a popular performance measure on large scale image classification benchmarks such as ImageNet and Places. Despite its wide acceptance, our understanding of this metric is limited as most of the previous research is focused on its special case, the top- error. In this work, we explore two directions that shed more light on the top-k error. First, we provide an in-depth analysis of established and recently proposed single-label multiclass methods along with a detailed account of efficient optimization algorithms for them. Our results indicate that the softmax loss and the smooth multiclass SVM are surprisingly competitive in top-k error uniformly across all k, which can be explained by our analysis of multiclass top-k calibration. Further improvements for a specific k are possible with a number of proposed top-k loss functions. Second, we use the top-k methods to explore the transition from multiclass to multilabel learning. In particular, we find that it is possible to obtain effective multilabel classifiers on Pascal VOC using a single label per image for training, while the gap between multiclass and multilabel methods on MS COCO is more significant. Finally, our contribution of efficient algorithms for training with the considered top-k and multilabel loss functions is of independent interest.

Quantum key distribution QKD is a quantum-proof key exchange scheme which is fast approaching the communication industry. An essential component in QKD is the information reconciliation step, which is used for correcting the quantum channel noise errors. The recently suggested blind reconciliation technique, based on low-density parity-check LDPC codes, offers remarkable prospectives for efficient information reconciliation without an a priori error rate estimation. In the present work, we suggest an improvement of the blind information reconciliation protocol allowing significant increase the efficiency of the procedure and reducing its interactivity. The proposed technique is based on introducing symmetry in operations of parties, and the consideration of results of unsuccessful belief propagation decodings.

The development of global sensitivity analysis of numerical model outputs has recently raised new issues on -dimensional Poincare inequalities. Typically two kind of sensitivity indices are linked by a Poincare type inequality, which provide upper bounds of the most interpretable index by using the other one, cheaper to compute. This allows performing a low-cost screening of unessential variables. The efficiency of this screening then highly depends on the accuracy of the upper bounds in Poincare inequalities. The novelty in the questions concern the wide range of probability distributions involved, which are often truncated on intervals. After providing an overview of the existing knowledge and techniques, we add some theory about Poincare constants on intervals, with improvements for symmetric intervals. Then we exploit the spectral interpretation for computing exact value of Poincare constants of any admissible distribution on a given interval. We give semi-analytical results for some frequent distributions truncated exponential, triangular, truncated normal, and present a numerical method in the general case. Finally, an application is made to a hydrological problem, showing the benefits of the new results in Poincare inequalities to sensitivity analysis.

In this paper, we introduce a distributed algorithm to compute thve Cech complex. This algorithm is aimed at solving coverage problems in self organized wireless networks. Two applications based on the distributed computation of thve Cech complex are proposed. The first application detects coverage holes while the later one optimizes coverage of wireless networks.

Image segmentation has many applications which range from machine learning to medical diagnosis. In this paper, we propose a framework for the segmentation of images based on super-pixels and algorithms for community identification in graphs. The super-pixel pre-segmentation step reduces the number of nodes in the graph, rendering the method the ability to process large images. Moreover, community detection algorithms provide more accurate segmentation than traditional approaches, such as those based on spectral graph partition. We also compare our method with two algorithms a the graph-based approach by Felzenszwalb and Huttenlocher and b the contour-based method by Arbelaez. Results have shown that our method provides more precise segmentation and is faster than both of them.

Proof of security of cryptographic protocols theoretically establishes the strength of a protocol and the constraints under which it can perform, it does not take into account the overall design of the protocol. In the past model checking has been successfully applied to classical cryptographic protocols to weed out design flaws which would have otherwise gone unnoticed. Quantum cryptographic protocols differ from their classical counterparts, in their ability to detect the presence of an eavesdropper. Although unconditional security has been proven for both BB and B protocols, in this paper we show that identifying an eavesdroppers presence is constrained on the number of qubits exchanged. We first model the protocols in CQP and then explain the mechanism by which we have translated this into a PRISM model. We mainly focus on the protocols ability to detect an active eavesdropper and the extent to which an eavesdropper can retrieve the shared key without being detected by either party. We then conclude by comparing the performance of the protocols.

The standard LSTM, although it succeeds in the modeling long-range dependences, suffers from a highly complex structure that can be simplified through modifications to its gate units. This paper was to perform an empirical comparison between the standard LSTM and three new simplified variants that were obtained by eliminating input signal, bias and hidden unit signal from individual gates, on the tasks of modeling two sequence datasets. The experiments show that the three variants, with reduced parameters, can achieve comparable performance with the standard LSTM. Due attention should be paid to turning the learning rate to achieve high accuracies

Geographic Load Balancing is a strategy for reducing the energy cost of data centers spreading across different terrestrial locations. In this paper, we focus on load balancing among micro-datacenters powered by renewable energy sources. We model via a Markov Chain the problem of scheduling jobs by prioritizing datacenters where renewable energy is currently available. Not finding a convenient closed form solution for the resulting chain, we use mean field techniques to derive an asymptotic approximate model which instead is shown to have an extremely simple and intuitive steady state solution. After proving, using both theoretical and discrete event simulation results, that the system performance converges to the asymptotic model for an increasing number of datacenters, we exploit the simple closed form models solution to investigate relationships and trade-offs among the various system parameters.

Semantic classes can be either things objects with a well-defined shape, e.g. car, person or stuff amorphous background regions, e.g. grass, sky. While lots of classification and detection works focus on thing classes, less attention has been given to stuff classes. Nonetheless, stuff classes are important as they allow to explain important aspects of an image, including  scene type  which thing classes are likely to be present and their location determined through contextual reasoning  physical attributes, material types and geometric properties of the scene. To understand stuff and things in context we annotate , images of the COCO dataset with a broad range of stuff classes, using a specialized stuff annotation protocol allowing us to efficiently label each pixel. On this dataset, we analyze several aspects a the importance of stuff and thing classes in terms of their surface cover and how frequently they are mentioned in image captions b the importance of several visual criteria to discriminate stuff and thing classes c we study the spatial relations between stuff and things, highlighting the rich contextual relations that make our dataset unique. Furthermore, we show experimentally how modern semantic segmentation methods perform on stuff and thing classes and answer the question whether stuff is easier to segment than things. We release our new dataset and the trained models online, hopefully promoting further research on stuff and stuff-thing contextual relations.

For any prime p, lambda-constacyclic codes of length ps over cal RmathbbFpm  umathbbFpm are precisely the ideals of the local ring cal Rlambdafraccal Rxleftlangle xps-lambda rightrangle, where u. In this paper, we first investigate the Hamming distances of cyclic codes of length ps over cal R. The minimum Hamming distances of all cyclic codes of length ps over cal R are determined. Moreover, an isometry between cyclic and alpha-constacyclic codes of length ps over cal R is established, where alpha is a nonzero element of mathbbFpm, which carries over the results regarding cyclic codes corresponding to alpha-constacyclic codes of length ps over cal R.

We present a simple sublinear time algorithm for testing the following geometric property. Let P, ..., Pn be n convex sets in mathbbRd n gg d, such as polytopes, balls, etc. We assume that the complexity of each set depends only on d and not on the number of sets n. We test the property that there exists a common point in all sets, i.e. that their intersection is nonempty. Our goal is to distinguish between the case where the intersection is nonempty, and the case where even after removing many of the sets the intersection is empty. In particular, our algorithm returns PASS if all of the n sets intersect, and returns FAIL with probability at least -epsilon if no point belongs to fracalphad n sets, for any given   alpha, epsilon  .

A graph is well-covered if all its maximal independent sets are of the same cardinality Plummer, . If G is a well-covered graph, has at least two vertices, and G-v is well-covered for every vertex v, then G is a -well-covered graph Staples, . We call G a lambda-quasi-regularizable graph if lambda S  NS for every independent set S of G. The independence polynomial IGx is the generating function of independent sets in a graph G Gutman  Harary, . The Roller-Coaster Conjecture Michael  Travis, , saying that for every permutation sigma of the set alpha,...,alpha there exists a well-covered graph G with independence number alpha such that the coefficients sk of IGx are chosen in accordance with sigma, has been validated in Cutler  Pebody, . In this paper, we show that independence polynomials of lambda-quasi-regularizable graphs are partially unimodal. More precisely, the coefficients of an upper part of IGx are in non-increasing order. Based on this finding, we prove that the domain of the Roller- Coaster Conjecture can be shortened for well-covered graphs and -well-covered graphs.

The paper uses a non-cooperative simultaneous game for coalition structure formation Levando,  to demonstrate some applications of the introduced game a cooperation, a Bayesian game within a coalition with intra-coalition externalities, a stochastic game, where states are coalition structures self-enforcement properties of a non-cooperative equilibrium and a construction of a non-cooperative stability criterion.

Adversaries with physical access to a target platform can perform cold boot or DMA attacks to extract sensitive data from the RAM. In response, several main-memory encryption schemes have been proposed to prevent such attacks. Also hardware vendors have acknowledged the threat and already announced respective hardware extensions. Intels SGX and AMDs SME will provide means to encrypt parts of the RAM to protect security-relevant assets that reside there. Encrypting the RAM will protect the users content against passive eavesdropping. However, the level of protection it provides in scenarios that involve an adversary who is not only able to read from RAM but can also change content in RAM is less clear. Obviously, encryption offers some protection against such an active adversary from the ciphertext the adversary cannot see what value is changed in the plaintext, nor predict the system behaviour based on the changes. But is this enough to prevent an active adversary from performing malicious tasks? This paper addresses the open research question whether encryption alone is a dependable protection mechanism in practice when considering an active adversary. To this end, we first build a software based memory encryption solution on a desktop system which mimics AMDs SME. Subsequently, we demonstrate a proof-of-concept fault attack on this system, by which we are able to extract the private RSA key of a GnuPG user. Our work suggests that transparent memory encryption is not enough to prevent active attacks.

It is starting to become a big trend in the era of social networking that people produce and upload user-generated contents to Internet via wireless networks, bringing a significant burden on wireless uplink networks. In this paper, we contribute to designing and theoretical understanding of wireless cache-enabled upload transmission in a delay-tolerant small cell network to relieve the burden, and then propose the corresponding scheduling policies for the small base station SBS under the infinite and finite cache sizes. Specifically, the cache ability introduced by SBS enables SBS to eliminate the redundancy among the upload contents from users. This strategy not only alleviates the wireless backhual traffic congestion from SBS to a macro base station MBS, but also improves the transmission efficiency of SBS. We then investigate the scheduling schemes of SBS to offload more data traffic under caching size constraint. Moreover, two operational regions for the wireless cache-enabled upload network, namely, the delay-limited region and the cache-limited region, are established to reveal the fundamental tradeoff between the delay tolerance and the cache ability. Finally, numerical results are provided to demonstrate the significant performance gains of the proposed wireless cache-enabled upload network.

A novel approach rooted on the notion of consensus clustering, a strategy developed for community detection in complex networks, is proposed to cope with the heterogeneity that characterizes connectivity matrices in healthy and disease. The method can be summarized as follows i define, for each node, of a distance matrix for the set of subjects ii cluster the distance matrix for each node, iii build the consensus network from the corresponding partitions and iv extract groups of subjects by finding the communities of the consensus network thus obtained. Applications on a toy model and two real data sets, show the effectiveness of the proposed methodology, which represents heterogeneity of a set of subjects in terms of a weighted network, the consensus matrix.

We propose a novel recursive system identification algorithm for linear autoregressive systems with skewed innovations. The algorithm is based on the variational Bayes approximation of the model with a multivariate normal prior for the model coefficients, multivariate skew-normally distributed innovations, and matrix-variate-normal - inverse-Wishart prior for the parameters of the innovation distribution. The proposed algorithm simultaneously estimates the model coefficients as well as the parameters of the innovation distribution, which are both allowed to be slowly time-varying. Through computer simulations, we compare the proposed method with a variational algorithm based on the normally-distributed innovations model, and show that modelling the skewness can provide improvement in identification accuracy.

The collection of narrative spontaneous reports is an irreplaceable source for the prompt detection of suspected adverse drug reactions ADRs qualified domain experts manually revise a huge amount of narrative descriptions and then encode texts according to MedDRA standard terminology. The manual annotation of narrative documents with medical terminology is a subtle and expensive task, since the number of reports is growing up day-by-day. MagiCoder, a Natural Language Processing algorithm, is proposed for the automatic encoding of free-text descriptions into MedDRA terms. MagiCoder procedure is efficient in terms of computational complexity in particular, it is linear in the size of the narrative input and the terminology. We tested it on a large dataset of about  manually revised reports, by performing an automated comparison between human and MagiCoder revisions. For the current base version of MagiCoder, we measured on short descriptions, an average recall of  and an average precision of  on medium-long descriptions up to  characters, an average recall of  and an average precision of . From a practical point of view, MagiCoder reduces the time required for encoding ADR reports. Pharmacologists have simply to review and validate the MagiCoder terms proposed by the application, instead of choosing the right terms among the K low level terms of MedDRA. Such improvement in the efficiency of pharmacologists work has a relevant impact also on the quality of the subsequent data analysis. We developed MagiCoder for the Italian pharmacovigilance language. However, our proposal is based on a general approach, not depending on the considered language nor the term dictionary.

Traditional sentiment analysis often uses sentiment dictionary to extract sentiment information in text and classify documents. However, emerging informal words and phrases in user generated content call for analysis aware to the context. Usually, they have special meanings in a particular context. Because of its great performance in representing inter-word relation, we use sentiment word vectors to identify the special words. Based on the distributed language model wordvec, in this paper we represent a novel method about sentiment representation of word under particular context, to be detailed, to identify the words with abnormal sentiment polarity in long answers. Result shows the improved model shows better performance in representing the words with special meaning, while keep doing well in representing special idiomatic pattern. Finally, we will discuss the meaning of vectors representing in the field of sentiment, which may be different from general object-based conditions.

Neural machine learning methods, such as deep neural networks DNN, have achieved remarkable success in a number of complex data processing tasks. These methods have arguably had their strongest impact on tasks such as image and audio processing - data processing domains in which humans have long held clear advantages over conventional algorithms. In contrast to biological neural systems, which are capable of learning continuously, deep artificial networks have a limited ability for incorporating new information in an already trained network. As a result, methods for continuous learning are potentially highly impactful in enabling the application of deep networks to dynamic data sets. Here, inspired by the process of adult neurogenesis in the hippocampus, we explore the potential for adding new neurons to deep layers of artificial neural networks in order to facilitate their acquisition of novel information while preserving previously trained data representations. Our results on the MNIST handwritten digit dataset and the NIST SD  dataset, which includes lower and upper case letters and digits, demonstrate that neurogenesis is well suited for addressing the stability-plasticity dilemma that has long challenged adaptive machine learning algorithms.

SimTensor is a multi-platform, open-source software for generating artificial tensor data either with CPPARAFAC or Tucker structure for reproducible research on tensor factorization algorithms. SimTensor is a stand-alone application based on MATALB. It provides a wide range of facilities for generating tensor data with various configurations. It comes with a user-friendly graphical user interface, which enables the user to generate tensors with complicated settings in an easy way. It also has this facility to export generated data to universal formats such as CSV and HDF, which can be imported via a wide range of programming languages C, C, Java, R, Fortran, MATLAB, Perl, Python, and many more. The most innovative part of SimTensor is this that can generate temporal tensors with periodic waves, seasonal effects and streaming structure. it can apply constraints such as non-negativity and different kinds of sparsity to the data. SimTensor also provides this facility to simulate different kinds of change-points and inject various types of anomalies. The source code and binary versions of SimTensor is available for download in httpwww.simtensor.org.

CNN-based optical flow estimation has attracted attention recently, mainly due to its impressively high frame rates. These networks perform well on synthetic datasets, but they are still far behind the classical methods in real-world videos. This is because there is no ground truth optical flow for training these networks on real data. In this paper, we boost CNN-based optical flow estimation in real scenes with the help of the freely available self-supervised task of next-frame prediction. To this end, we train the network in a hybrid way, providing it with a mixture of synthetic and real videos. With the help of a sample-variant multi-tasking architecture, the network is trained on different tasks depending on the availability of ground-truth. We also experiment with the prediction of next-flow instead of estimation of the current flow, which is intuitively closer to the task of next-frame prediction and yields favorable results. We demonstrate the improvement in optical flow estimation on the real-world KITTI benchmark. Additionally, we test the optical flow indirectly in an action classification scenario. As a side product of this work, we report significant improvements over state-of-the-art in the task of next-frame prediction.

State-of-the-art computer vision algorithms often achieve efficiency by making discrete choices about which hypotheses to explore next. This allows allocation of computational resources to promising candidates, however, such decisions are non-differentiable. As a result, these algorithms are hard to train in an end-to-end fashion. In this work we propose to learn an efficient algorithm for the task of D object pose estimation. Our system optimizes the parameters of an existing state-of-the art pose estimation system using reinforcement learning, where the pose estimation system now becomes the stochastic policy, parametrized by a CNN. Additionally, we present an efficient training algorithm that dramatically reduces computation time. We show empirically that our learned pose estimation procedure makes better use of limited resources and improves upon the state-of-the-art on a challenging dataset. Our approach enables differentiable end-to-end training of complex algorithmic pipelines and learns to make optimal use of a given computational budget.

This paper presents a new method to learn online policies in continuous state, continuous action, model-free Markov decision processes, with two properties that are crucial for practical applications. First, the policies are implementable with a very low computational cost once the policy is computed, the action corresponding to a given state is obtained in logarithmic time with respect to the number of samples used. Second, our method is versatile it does not rely on any a priori knowledge of the structure of optimal policies. We build upon the Fitted Q-iteration algorithm which represents the Q-value as the average of several regression trees. Our algorithm, the Fitted Policy Forest algorithm FPF, computes a regression forest representing the Q-value and transforms it into a single tree representing the policy, while keeping control on the size of the policy using resampling and leaf merging. We introduce an adaptation of Multi-Resolution Exploration MRE which is particularly suited to FPF. We assess the performance of FPF on three classical benchmarks for reinforcement learning the Inverted Pendulum, the Double Integrator and Car on the Hill and show that FPF equals or outperforms other algorithms, although these algorithms rely on the use of particular representations of the policies, especially chosen in order to fit each of the three problems. Finally, we exhibit that the combination of FPF and MRE allows to find nearly optimal solutions in problems where epsilon-greedy approaches would fail.

This paper proposes a visual-servoing method dedicated to grasping of daily-life objects. In order to obtain an affordable solution, we use a low-accurate robotic arm. Our method corrects errors by using an RGB-D sensor. It is based on SURF invariant features which allows us to perform object recognition at a high frame rate. We define regions of interest based on depth segmentation, and we use them to speed-up the recognition and to improve reliability. The system has been tested on a real-world scenario. In spite of the lack of accuracy of all the components and the uncontrolled environment, it grasps objects successfully on more than  percents of the trials.

One of the main cost factors in software development is the detection and removal of defects. However, the relationships and influencing factors of the costs and revenues of defect-detection techniques are still not well understood. This paper proposes an analytical, stochastic model of the economics of defect detection and removal to improve this understanding. The model is able to incorporate dynamic as well as static techniques in contrast to most other models of that kind. We especially analyse the model with state-ofthe-art sensitivity analysis methods to  identify the most relevant factors for model simplification and  prioritise the factors to guide further research and measurements.

In this letter, we consider the coexistence and spectrum sharing between downlink multi-user multiple-input-multiple-output MU-MIMO communication and a MIMO radar. For a given performance requirement of the downlink communication system, we design the transmit beamforming such that the detection probability of the radar is maximized. While the original optimization problem is non-convex, we exploit the monotonically increasing relationship of the detection probability with the non-centrality parameter of the resulting probability distribution to obtain a convex lower-bound optimization. The proposed beamformer is designed to be robust to imperfect channel state information CSI. Simulation results verify that the proposed approach facilitates the coexistence between radar and communication links, and illustrates a scalable trade-off between the two systems performance.

Several methods exist for a computer to generate music based on data including Markov chains, recurrent neural networks, recombinancy, and grammars. We explore the use of unit selection and concatenation as a means of generating music using a procedure based on ranking, where, we consider a unit to be a variable length number of measures of music. We first examine whether a unit selection method, that is restricted to a finite size unit library, can be sufficient for encompassing a wide spectrum of music. We do this by developing a deep autoencoder that encodes a musical input and reconstructs the input by selecting from the library. We then describe a generative model that combines a deep structured semantic model DSSM with an LSTM to predict the next unit, where units consist of four, two, and one measures of music. We evaluate the generative model using objective metrics including mean rank and accuracy and with a subjective listening test in which expert musicians are asked to complete a forced-choiced ranking task. We compare our model to a note-level generative baseline that consists of a stacked LSTM trained to predict forward by one note.

We present a novel scheme to combine neural machine translation NMT with traditional statistical machine translation SMT. Our approach borrows ideas from linearised lattice minimum Bayes-risk decoding for SMT. The NMT score is combined with the Bayes-risk of the translation according the SMT lattice. This makes our approach much more flexible than n-best list or lattice rescoring as the neural decoder is not restricted to the SMT search space. We show an efficient and simple way to integrate risk estimation into the NMT decoder which is suitable for word-level as well as subword-unit-level NMT. We test our method on English-German and Japanese-English and report significant gains over lattice rescoring on several data sets for both single and ensembled NMT. The MBR decoder produces entirely new hypotheses far beyond simply rescoring the SMT search space or fixing UNKs in the NMT output.

Compressed sensing CS is a sampling paradigm that allows to simultaneously measure and compress signals that are sparse or compressible in some domain. The choice of a sensing matrix that carries out the measurement has a defining impact on the system performance and it is often advocated to draw its elements randomly. It has been noted that in the presence of input signal noise, the application of the sensing matrix causes SNR degradation due to the noise folding effect. In fact, it might also result in the variations of the output SNR in compressive measurements over the support of the input signal, potentially resulting in unexpected non-uniform system performance. In this work, we study the impact of a distribution from which the elements of a sensing matrix are drawn on the spread of the output SNR. We derive analytic expressions for several common types of sensing matrices and show that the SNR spread grows with the decrease of the number of measurements. This makes its negative effect especially pronounced for high compression rates that are often of interest in CS.

Taxi services and product delivery services are instrumental for our modern society. Thanks to the emergence of sharing economy, ride-sharing services such as Uber, Didi, Lyft and Googles Waze Rider are becoming more ubiquitous and grow into an integral part of our everyday lives. However, the efficiency of these services are severely limited by the sub-optimal and imbalanced matching between the supply and demand. We need a generalized framework and corresponding efficient algorithms to address the efficient matching, and hence optimize the performance of these markets. Existing studies for taxi and delivery services are only applicable in scenarios of the one-sided market. In contrast, this work investigates a highly generalized model for the taxi and delivery services in the market economy abbreviated astaxi and delivery market that can be widely used in two-sided markets. Further, we present efficient online and offline algorithms for different applications. We verify our algorithm with theoretical analysis and trace-driven simulations under realistic settings.

Software reliability models are an important tool in quality management and release planning. There is a large number of different models that often exhibit strengths in different areas. This paper proposes a model that is based on a geometric sequence or progression of the failure rates of faults. This property of the failure process was observed in practice at Siemens among others and led to the development of the proposed model. It is described in detail and evaluated using standard criteria. Most importantly, the model performs constantly well over several projects in terms of its predictive validity.

DeepMind Lab is a first-person D game platform designed for research and development of general artificial intelligence and machine learning systems. DeepMind Lab can be used to study how autonomous artificial agents may learn complex tasks in large, partially observed, and visually diverse worlds. DeepMind Lab has a simple and flexible API enabling creative task-designs and novel AI-designs to be explored and quickly iterated upon. It is powered by a fast and widely recognised game engine, and tailored for effective use by the research community.

Humans learn a predictive model of the world and use this model to reason about future events and the consequences of actions. In contrast to most machine predictors, we exhibit an impressive ability to generalize to unseen scenarios and reason intelligently in these settings. One important aspect of this ability is physical intuitionLake et al., . In this work, we explore the potential of unsupervised learning to find features that promote better generalization to settings outside the supervised training distribution. Our task is predicting the stability of towers of square blocks. We demonstrate that an unsupervised model, trained to predict future frames of a video sequence of stable and unstable block configurations, can yield features that support extrapolating stability prediction to blocks configurations outside the training set distribution